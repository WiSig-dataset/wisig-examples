{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import scipy,scipy.spatial\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "from  data_utilities import *\n",
    "# from definitions import *\n",
    "# from run_train_eval_net import run_train_eval_net,run_eval_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 32\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ManyRx'\n",
    "dataset_path='../../orbit_rf_dataset/data/compact_pkl_datasets/'\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path,dataset_name)\n",
    "\n",
    "tx_list = compact_dataset['tx_list']\n",
    "rx_list = compact_dataset['rx_list']\n",
    "\n",
    "equalized = 0\n",
    "\n",
    "capture_date_list = compact_dataset['capture_date_list']\n",
    "capture_date = capture_date_list[0]\n",
    "n_tx = len(tx_list)\n",
    "n_rx = len(rx_list)\n",
    "print(n_tx,n_rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['19-20', '24-13', '19-2', '1-20', '20-20', '20-1', '7-7', '3-19', '23-6', '2-19', '24-5', '14-7', '23-1', '19-1', '8-7', '24-6', '24-16', '1-19', '8-8', '18-19', '13-7', '23-3', '8-14', '23-5', '19-19', '18-2', '7-14', '13-14', '1-1', '23-7', '20-19', '2-1'], ['1-1', '23-1', '24-6', '8-8', '1-19', '23-3', '23-5', '7-14', '19-19', '13-14', '23-6', '7-7', '19-1', '20-1', '20-20', '24-16', '8-14', '19-2', '14-7', '1-20', '13-7', '24-5', '18-2', '2-19', '24-13', '19-20', '3-19', '8-7', '20-19', '2-1', '23-7', '18-19'], ['24-5', '23-7', '18-19', '23-3', '24-6', '8-14', '2-1', '13-7', '19-19', '19-2', '18-2', '1-20', '20-1', '24-16', '3-19', '1-19', '24-13', '23-6', '19-1', '8-7', '20-19', '1-1', '14-7', '20-20', '7-7', '2-19', '23-5', '8-8', '19-20', '13-14', '7-14', '23-1'], ['1-20', '1-19', '20-19', '23-7', '2-1', '20-1', '19-19', '14-7', '23-1', '3-19', '8-8', '7-7', '13-7', '20-20', '24-16', '18-2', '8-7', '23-5', '7-14', '18-19', '24-6', '19-1', '13-14', '2-19', '19-20', '24-5', '23-3', '19-2', '8-14', '23-6', '24-13', '1-1'], ['18-19', '20-1', '13-14', '18-2', '14-7', '20-20', '13-7', '19-20', '2-19', '19-19', '19-1', '1-20', '24-5', '20-19', '8-7', '23-1', '7-7', '8-8', '2-1', '1-19', '3-19', '23-3', '23-6', '23-5', '24-6', '8-14', '24-16', '7-14', '1-1', '19-2', '24-13', '23-7']]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_real = 5\n",
    "rx_list_real = []\n",
    "for i in range(n_real):\n",
    "    np.random.shuffle(rx_list)\n",
    "    rx_list_real.append(np.copy(rx_list).tolist())\n",
    "print(rx_list_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 2)]          0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 256, 2, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 2, 8)         56        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 2, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 2, 16)        784       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 2, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 2, 16)         1552      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 1, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 1, 32)         1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 1, 16)         1552      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 40,102\n",
      "Trainable params: 40,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " def create_net():\n",
    "\n",
    "    inputs = Input(shape=(256,2))\n",
    "    x = Reshape((256,2,1))(inputs)\n",
    "    x = Conv2D(8,(3,2),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,1))(x)\n",
    "    x = Conv2D(16,(3,2),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,1))(x)\n",
    "    x = Conv2D(16,(3,2),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    x = Conv2D(32,(3,1),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,1))(x)\n",
    "    x = Conv2D(16,(3,1),activation='relu',padding = 'same')(x)\n",
    "    #x = resnet(x,64,(3,2),'6')\n",
    "    #x = MaxPool2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "    x = Dense(100, activation='relu', kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "    x = Dense(80, activation='relu',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(n_tx, activation='softmax',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
    "    ops = x\n",
    "\n",
    "    classifier = Model(inputs,ops)\n",
    "    classifier.compile(loss='categorical_crossentropy',metrics=['categorical_accuracy'],optimizer=keras.optimizers.Adam(0.0005))\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "classifier = create_net()\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(classifier):\n",
    "    pred = classifier.predict(sig_dfTest)\n",
    "    acc = np.mean(np.argmax(pred,1)==txidNum_dfTest)\n",
    "\n",
    "    test_indx = ()\n",
    "    for indx in range(len(tx_list)):\n",
    "        cls_indx = np.where(txidNum_dfTest == indx)\n",
    "        test_indx = test_indx + (cls_indx[0][:n_test_samples],)\n",
    "    test_indx = np.concatenate(test_indx) \n",
    "    acc_bal = np.mean(np.argmax(pred[test_indx,:],1)==txidNum_dfTest[test_indx])\n",
    "    return acc,acc_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_rx = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 10, 15, 20, 25]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(range( 0,len(rx_list_real[0])-n_test_rx+1,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cls_weights = np.max(stat,axis=0)/stat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "nrx: 0 - real: 0 \n",
      "Train on 1600 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 2.3097 - categorical_accuracy: 0.1527\n",
      "Epoch 00001: val_loss improved from inf to 2.24668, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 2s 1ms/sample - loss: 2.3051 - categorical_accuracy: 0.1581 - val_loss: 2.2467 - val_categorical_accuracy: 0.3000\n",
      "Epoch 2/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 2.0692 - categorical_accuracy: 0.2827\n",
      "Epoch 00002: val_loss improved from 2.24668 to 1.55767, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 243us/sample - loss: 2.0382 - categorical_accuracy: 0.2881 - val_loss: 1.5577 - val_categorical_accuracy: 0.4900\n",
      "Epoch 3/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 1.5408 - categorical_accuracy: 0.4056\n",
      "Epoch 00003: val_loss improved from 1.55767 to 1.12902, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 233us/sample - loss: 1.5355 - categorical_accuracy: 0.4075 - val_loss: 1.1290 - val_categorical_accuracy: 0.7100\n",
      "Epoch 4/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 1.2432 - categorical_accuracy: 0.5432\n",
      "Epoch 00004: val_loss improved from 1.12902 to 0.89945, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 259us/sample - loss: 1.2041 - categorical_accuracy: 0.5619 - val_loss: 0.8995 - val_categorical_accuracy: 0.7600\n",
      "Epoch 5/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.9672 - categorical_accuracy: 0.6570\n",
      "Epoch 00005: val_loss improved from 0.89945 to 0.77909, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 258us/sample - loss: 0.9712 - categorical_accuracy: 0.6538 - val_loss: 0.7791 - val_categorical_accuracy: 0.7600\n",
      "Epoch 6/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.8221 - categorical_accuracy: 0.7226\n",
      "Epoch 00006: val_loss improved from 0.77909 to 0.61217, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 263us/sample - loss: 0.8176 - categorical_accuracy: 0.7244 - val_loss: 0.6122 - val_categorical_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.6965 - categorical_accuracy: 0.7691\n",
      "Epoch 00007: val_loss improved from 0.61217 to 0.56560, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 255us/sample - loss: 0.6918 - categorical_accuracy: 0.7713 - val_loss: 0.5656 - val_categorical_accuracy: 0.8700\n",
      "Epoch 8/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.6385 - categorical_accuracy: 0.7879\n",
      "Epoch 00008: val_loss improved from 0.56560 to 0.49953, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 250us/sample - loss: 0.6229 - categorical_accuracy: 0.7969 - val_loss: 0.4995 - val_categorical_accuracy: 0.8950\n",
      "Epoch 9/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.5563 - categorical_accuracy: 0.8329\n",
      "Epoch 00009: val_loss improved from 0.49953 to 0.43210, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 230us/sample - loss: 0.5576 - categorical_accuracy: 0.8350 - val_loss: 0.4321 - val_categorical_accuracy: 0.9150\n",
      "Epoch 10/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.4928 - categorical_accuracy: 0.8540\n",
      "Epoch 00010: val_loss improved from 0.43210 to 0.39756, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 264us/sample - loss: 0.4902 - categorical_accuracy: 0.8537 - val_loss: 0.3976 - val_categorical_accuracy: 0.9200\n",
      "Epoch 11/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.8579\n",
      "Epoch 00011: val_loss improved from 0.39756 to 0.35597, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 265us/sample - loss: 0.4956 - categorical_accuracy: 0.8531 - val_loss: 0.3560 - val_categorical_accuracy: 0.9050\n",
      "Epoch 12/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8795\n",
      "Epoch 00012: val_loss improved from 0.35597 to 0.28507, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 260us/sample - loss: 0.4067 - categorical_accuracy: 0.8806 - val_loss: 0.2851 - val_categorical_accuracy: 0.9250\n",
      "Epoch 13/100\n",
      "1376/1600 [========================>.....] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.8743\n",
      "Epoch 00013: val_loss improved from 0.28507 to 0.26568, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 253us/sample - loss: 0.3780 - categorical_accuracy: 0.8806 - val_loss: 0.2657 - val_categorical_accuracy: 0.9400\n",
      "Epoch 14/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.2997 - categorical_accuracy: 0.9155\n",
      "Epoch 00014: val_loss improved from 0.26568 to 0.24560, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 258us/sample - loss: 0.3079 - categorical_accuracy: 0.9156 - val_loss: 0.2456 - val_categorical_accuracy: 0.9550\n",
      "Epoch 15/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.3112 - categorical_accuracy: 0.9208\n",
      "Epoch 00015: val_loss improved from 0.24560 to 0.22281, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 242us/sample - loss: 0.3187 - categorical_accuracy: 0.9212 - val_loss: 0.2228 - val_categorical_accuracy: 0.9450\n",
      "Epoch 16/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.2640 - categorical_accuracy: 0.9353\n",
      "Epoch 00016: val_loss did not improve from 0.22281\n",
      "1600/1600 [==============================] - 0s 222us/sample - loss: 0.2571 - categorical_accuracy: 0.9344 - val_loss: 0.2258 - val_categorical_accuracy: 0.9400\n",
      "Epoch 17/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.2579 - categorical_accuracy: 0.9293\n",
      "Epoch 00017: val_loss did not improve from 0.22281\n",
      "1600/1600 [==============================] - 0s 217us/sample - loss: 0.2617 - categorical_accuracy: 0.9281 - val_loss: 0.3019 - val_categorical_accuracy: 0.9150\n",
      "Epoch 18/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2609 - categorical_accuracy: 0.9343\n",
      "Epoch 00018: val_loss improved from 0.22281 to 0.20319, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 268us/sample - loss: 0.2577 - categorical_accuracy: 0.9356 - val_loss: 0.2032 - val_categorical_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2318 - categorical_accuracy: 0.9452\n",
      "Epoch 00019: val_loss improved from 0.20319 to 0.18421, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 263us/sample - loss: 0.2326 - categorical_accuracy: 0.9450 - val_loss: 0.1842 - val_categorical_accuracy: 0.9550\n",
      "Epoch 20/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2084 - categorical_accuracy: 0.9496\n",
      "Epoch 00020: val_loss improved from 0.18421 to 0.17035, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 259us/sample - loss: 0.2086 - categorical_accuracy: 0.9500 - val_loss: 0.1703 - val_categorical_accuracy: 0.9550\n",
      "Epoch 21/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.2067 - categorical_accuracy: 0.9438\n",
      "Epoch 00021: val_loss did not improve from 0.17035\n",
      "1600/1600 [==============================] - 0s 203us/sample - loss: 0.2148 - categorical_accuracy: 0.9413 - val_loss: 0.1760 - val_categorical_accuracy: 0.9600\n",
      "Epoch 22/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.1936 - categorical_accuracy: 0.9489\n",
      "Epoch 00022: val_loss did not improve from 0.17035\n",
      "1600/1600 [==============================] - 0s 214us/sample - loss: 0.1945 - categorical_accuracy: 0.9494 - val_loss: 0.1896 - val_categorical_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.1738 - categorical_accuracy: 0.9541\n",
      "Epoch 00023: val_loss improved from 0.17035 to 0.16733, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 248us/sample - loss: 0.1731 - categorical_accuracy: 0.9544 - val_loss: 0.1673 - val_categorical_accuracy: 0.9600\n",
      "Epoch 24/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.1737 - categorical_accuracy: 0.9583\n",
      "Epoch 00024: val_loss did not improve from 0.16733\n",
      "1600/1600 [==============================] - 0s 213us/sample - loss: 0.1780 - categorical_accuracy: 0.9581 - val_loss: 0.1788 - val_categorical_accuracy: 0.9600\n",
      "Epoch 25/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.1687 - categorical_accuracy: 0.9557\n",
      "Epoch 00025: val_loss did not improve from 0.16733\n",
      "1600/1600 [==============================] - 0s 231us/sample - loss: 0.1676 - categorical_accuracy: 0.9563 - val_loss: 0.1717 - val_categorical_accuracy: 0.9550\n",
      "Epoch 26/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.1638 - categorical_accuracy: 0.9606\n",
      "Epoch 00026: val_loss did not improve from 0.16733\n",
      "1600/1600 [==============================] - 0s 215us/sample - loss: 0.1596 - categorical_accuracy: 0.9613 - val_loss: 0.1703 - val_categorical_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "1312/1600 [=======================>......] - ETA: 0s - loss: 0.1595 - categorical_accuracy: 0.9604\n",
      "Epoch 00027: val_loss did not improve from 0.16733\n",
      "1600/1600 [==============================] - 0s 225us/sample - loss: 0.1572 - categorical_accuracy: 0.9619 - val_loss: 0.1858 - val_categorical_accuracy: 0.9550\n",
      "Epoch 28/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.1481 - categorical_accuracy: 0.9666\n",
      "Epoch 00028: val_loss did not improve from 0.16733\n",
      "1600/1600 [==============================] - 0s 211us/sample - loss: 0.1501 - categorical_accuracy: 0.9656 - val_loss: 0.1817 - val_categorical_accuracy: 0.9650\n",
      "0.97 0.1456\n",
      "\n",
      "\n",
      "nrx: 5 - real: 0 \n",
      "Train on 9440 samples, validate on 1180 samples\n",
      "Epoch 1/100\n",
      "9248/9440 [============================>.] - ETA: 0s - loss: 2.2118 - categorical_accuracy: 0.1817\n",
      "Epoch 00001: val_loss improved from inf to 1.93085, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 249us/sample - loss: 2.2073 - categorical_accuracy: 0.1839 - val_loss: 1.9308 - val_categorical_accuracy: 0.3356\n",
      "Epoch 2/100\n",
      "9184/9440 [============================>.] - ETA: 0s - loss: 1.7545 - categorical_accuracy: 0.3837\n",
      "Epoch 00002: val_loss improved from 1.93085 to 1.41884, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 216us/sample - loss: 1.7501 - categorical_accuracy: 0.3869 - val_loss: 1.4188 - val_categorical_accuracy: 0.5161\n",
      "Epoch 3/100\n",
      "9088/9440 [===========================>..] - ETA: 0s - loss: 1.4186 - categorical_accuracy: 0.5139\n",
      "Epoch 00003: val_loss improved from 1.41884 to 1.13640, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 204us/sample - loss: 1.4157 - categorical_accuracy: 0.5160 - val_loss: 1.1364 - val_categorical_accuracy: 0.6347\n",
      "Epoch 4/100\n",
      "9312/9440 [============================>.] - ETA: 0s - loss: 1.1520 - categorical_accuracy: 0.6245\n",
      "Epoch 00004: val_loss improved from 1.13640 to 0.96151, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 189us/sample - loss: 1.1520 - categorical_accuracy: 0.6252 - val_loss: 0.9615 - val_categorical_accuracy: 0.6992\n",
      "Epoch 5/100\n",
      "9376/9440 [============================>.] - ETA: 0s - loss: 0.9680 - categorical_accuracy: 0.6958\n",
      "Epoch 00005: val_loss improved from 0.96151 to 0.72094, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 221us/sample - loss: 0.9663 - categorical_accuracy: 0.6963 - val_loss: 0.7209 - val_categorical_accuracy: 0.7822\n",
      "Epoch 6/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.7896 - categorical_accuracy: 0.7578\n",
      "Epoch 00006: val_loss improved from 0.72094 to 0.62304, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 216us/sample - loss: 0.7915 - categorical_accuracy: 0.7568 - val_loss: 0.6230 - val_categorical_accuracy: 0.8220\n",
      "Epoch 7/100\n",
      "9344/9440 [============================>.] - ETA: 0s - loss: 0.7023 - categorical_accuracy: 0.7917\n",
      "Epoch 00007: val_loss improved from 0.62304 to 0.51442, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 221us/sample - loss: 0.7012 - categorical_accuracy: 0.7921 - val_loss: 0.5144 - val_categorical_accuracy: 0.8559\n",
      "Epoch 8/100\n",
      "9216/9440 [============================>.] - ETA: 0s - loss: 0.6189 - categorical_accuracy: 0.8197\n",
      "Epoch 00008: val_loss improved from 0.51442 to 0.45719, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 218us/sample - loss: 0.6148 - categorical_accuracy: 0.8206 - val_loss: 0.4572 - val_categorical_accuracy: 0.8720\n",
      "Epoch 9/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.5608 - categorical_accuracy: 0.8321\n",
      "Epoch 00009: val_loss improved from 0.45719 to 0.39819, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 216us/sample - loss: 0.5610 - categorical_accuracy: 0.8320 - val_loss: 0.3982 - val_categorical_accuracy: 0.8856\n",
      "Epoch 10/100\n",
      "9248/9440 [============================>.] - ETA: 0s - loss: 0.5008 - categorical_accuracy: 0.8536\n",
      "Epoch 00010: val_loss improved from 0.39819 to 0.39046, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 220us/sample - loss: 0.4996 - categorical_accuracy: 0.8541 - val_loss: 0.3905 - val_categorical_accuracy: 0.8873\n",
      "Epoch 11/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.4453 - categorical_accuracy: 0.8683\n",
      "Epoch 00011: val_loss improved from 0.39046 to 0.34938, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 216us/sample - loss: 0.4442 - categorical_accuracy: 0.8686 - val_loss: 0.3494 - val_categorical_accuracy: 0.8941\n",
      "Epoch 12/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.4211 - categorical_accuracy: 0.8745\n",
      "Epoch 00012: val_loss did not improve from 0.34938\n",
      "9440/9440 [==============================] - 2s 216us/sample - loss: 0.4209 - categorical_accuracy: 0.8745 - val_loss: 0.3715 - val_categorical_accuracy: 0.8932\n",
      "Epoch 13/100\n",
      "9312/9440 [============================>.] - ETA: 0s - loss: 0.3943 - categorical_accuracy: 0.8796\n",
      "Epoch 00013: val_loss improved from 0.34938 to 0.34314, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 221us/sample - loss: 0.3941 - categorical_accuracy: 0.8799 - val_loss: 0.3431 - val_categorical_accuracy: 0.8949\n",
      "Epoch 14/100\n",
      "9376/9440 [============================>.] - ETA: 0s - loss: 0.3766 - categorical_accuracy: 0.8858\n",
      "Epoch 00014: val_loss improved from 0.34314 to 0.30567, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 217us/sample - loss: 0.3761 - categorical_accuracy: 0.8860 - val_loss: 0.3057 - val_categorical_accuracy: 0.9085\n",
      "Epoch 15/100\n",
      "9184/9440 [============================>.] - ETA: 0s - loss: 0.3581 - categorical_accuracy: 0.8893\n",
      "Epoch 00015: val_loss did not improve from 0.30567\n",
      "9440/9440 [==============================] - 2s 210us/sample - loss: 0.3574 - categorical_accuracy: 0.8899 - val_loss: 0.3219 - val_categorical_accuracy: 0.9034\n",
      "Epoch 16/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.3410 - categorical_accuracy: 0.8973\n",
      "Epoch 00016: val_loss improved from 0.30567 to 0.30379, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 220us/sample - loss: 0.3405 - categorical_accuracy: 0.8975 - val_loss: 0.3038 - val_categorical_accuracy: 0.9136\n",
      "Epoch 17/100\n",
      "9344/9440 [============================>.] - ETA: 0s - loss: 0.3341 - categorical_accuracy: 0.8948\n",
      "Epoch 00017: val_loss did not improve from 0.30379\n",
      "9440/9440 [==============================] - 2s 212us/sample - loss: 0.3341 - categorical_accuracy: 0.8949 - val_loss: 0.3051 - val_categorical_accuracy: 0.9119\n",
      "Epoch 18/100\n",
      "9280/9440 [============================>.] - ETA: 0s - loss: 0.3155 - categorical_accuracy: 0.9000\n",
      "Epoch 00018: val_loss improved from 0.30379 to 0.29951, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 221us/sample - loss: 0.3155 - categorical_accuracy: 0.8998 - val_loss: 0.2995 - val_categorical_accuracy: 0.9195\n",
      "Epoch 19/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.3109 - categorical_accuracy: 0.9061\n",
      "Epoch 00019: val_loss did not improve from 0.29951\n",
      "9440/9440 [==============================] - 2s 215us/sample - loss: 0.3104 - categorical_accuracy: 0.9064 - val_loss: 0.3097 - val_categorical_accuracy: 0.9153\n",
      "Epoch 20/100\n",
      "9376/9440 [============================>.] - ETA: 0s - loss: 0.3060 - categorical_accuracy: 0.9033\n",
      "Epoch 00020: val_loss did not improve from 0.29951\n",
      "9440/9440 [==============================] - 2s 213us/sample - loss: 0.3057 - categorical_accuracy: 0.9035 - val_loss: 0.3001 - val_categorical_accuracy: 0.9144\n",
      "Epoch 21/100\n",
      "9344/9440 [============================>.] - ETA: 0s - loss: 0.2986 - categorical_accuracy: 0.9066\n",
      "Epoch 00021: val_loss improved from 0.29951 to 0.29572, saving model to t_weights_1\n",
      "9440/9440 [==============================] - 2s 212us/sample - loss: 0.2980 - categorical_accuracy: 0.9070 - val_loss: 0.2957 - val_categorical_accuracy: 0.9178\n",
      "Epoch 22/100\n",
      "9248/9440 [============================>.] - ETA: 0s - loss: 0.2783 - categorical_accuracy: 0.9127\n",
      "Epoch 00022: val_loss did not improve from 0.29572\n",
      "9440/9440 [==============================] - 2s 208us/sample - loss: 0.2768 - categorical_accuracy: 0.9135 - val_loss: 0.3201 - val_categorical_accuracy: 0.9153\n",
      "Epoch 23/100\n",
      "9152/9440 [============================>.] - ETA: 0s - loss: 0.2810 - categorical_accuracy: 0.9135\n",
      "Epoch 00023: val_loss did not improve from 0.29572\n",
      "9440/9440 [==============================] - 2s 209us/sample - loss: 0.2815 - categorical_accuracy: 0.9132 - val_loss: 0.3176 - val_categorical_accuracy: 0.9136\n",
      "Epoch 24/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.2680 - categorical_accuracy: 0.9163\n",
      "Epoch 00024: val_loss did not improve from 0.29572\n",
      "9440/9440 [==============================] - 2s 213us/sample - loss: 0.2683 - categorical_accuracy: 0.9163 - val_loss: 0.2985 - val_categorical_accuracy: 0.9195\n",
      "Epoch 25/100\n",
      "9408/9440 [============================>.] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9118\n",
      "Epoch 00025: val_loss did not improve from 0.29572\n",
      "9440/9440 [==============================] - 2s 219us/sample - loss: 0.2715 - categorical_accuracy: 0.9120 - val_loss: 0.3004 - val_categorical_accuracy: 0.9237\n",
      "Epoch 26/100\n",
      "9312/9440 [============================>.] - ETA: 0s - loss: 0.2640 - categorical_accuracy: 0.9151\n",
      "Epoch 00026: val_loss did not improve from 0.29572\n",
      "9440/9440 [==============================] - 2s 214us/sample - loss: 0.2639 - categorical_accuracy: 0.9150 - val_loss: 0.3056 - val_categorical_accuracy: 0.9144\n",
      "0.9016949 0.2524\n",
      "\n",
      "\n",
      "nrx: 10 - real: 0 \n",
      "Train on 17440 samples, validate on 2180 samples\n",
      "Epoch 1/100\n",
      "17376/17440 [============================>.] - ETA: 0s - loss: 2.0470 - categorical_accuracy: 0.2454\n",
      "Epoch 00001: val_loss improved from inf to 1.60304, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 235us/sample - loss: 2.0462 - categorical_accuracy: 0.2456 - val_loss: 1.6030 - val_categorical_accuracy: 0.4835\n",
      "Epoch 2/100\n",
      "17216/17440 [============================>.] - ETA: 0s - loss: 1.4638 - categorical_accuracy: 0.4936\n",
      "Epoch 00002: val_loss improved from 1.60304 to 1.17026, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 212us/sample - loss: 1.4609 - categorical_accuracy: 0.4945 - val_loss: 1.1703 - val_categorical_accuracy: 0.6450\n",
      "Epoch 3/100\n",
      "17344/17440 [============================>.] - ETA: 0s - loss: 1.1082 - categorical_accuracy: 0.6350\n",
      "Epoch 00003: val_loss improved from 1.17026 to 0.93096, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 213us/sample - loss: 1.1074 - categorical_accuracy: 0.6350 - val_loss: 0.9310 - val_categorical_accuracy: 0.6954\n",
      "Epoch 4/100\n",
      "17344/17440 [============================>.] - ETA: 0s - loss: 0.8654 - categorical_accuracy: 0.7204\n",
      "Epoch 00004: val_loss improved from 0.93096 to 0.67499, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 216us/sample - loss: 0.8653 - categorical_accuracy: 0.7201 - val_loss: 0.6750 - val_categorical_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "17248/17440 [============================>.] - ETA: 0s - loss: 0.6863 - categorical_accuracy: 0.7865\n",
      "Epoch 00005: val_loss improved from 0.67499 to 0.53768, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 215us/sample - loss: 0.6860 - categorical_accuracy: 0.7867 - val_loss: 0.5377 - val_categorical_accuracy: 0.8459\n",
      "Epoch 6/100\n",
      "17408/17440 [============================>.] - ETA: 0s - loss: 0.5585 - categorical_accuracy: 0.8299\n",
      "Epoch 00006: val_loss improved from 0.53768 to 0.45158, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 216us/sample - loss: 0.5583 - categorical_accuracy: 0.8299 - val_loss: 0.4516 - val_categorical_accuracy: 0.8748\n",
      "Epoch 7/100\n",
      "17408/17440 [============================>.] - ETA: 0s - loss: 0.4640 - categorical_accuracy: 0.8615\n",
      "Epoch 00007: val_loss improved from 0.45158 to 0.41432, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 217us/sample - loss: 0.4638 - categorical_accuracy: 0.8615 - val_loss: 0.4143 - val_categorical_accuracy: 0.8780\n",
      "Epoch 8/100\n",
      "17216/17440 [============================>.] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8749\n",
      "Epoch 00008: val_loss improved from 0.41432 to 0.36880, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 217us/sample - loss: 0.4138 - categorical_accuracy: 0.8752 - val_loss: 0.3688 - val_categorical_accuracy: 0.8977\n",
      "Epoch 9/100\n",
      "17184/17440 [============================>.] - ETA: 0s - loss: 0.3760 - categorical_accuracy: 0.8868\n",
      "Epoch 00009: val_loss improved from 0.36880 to 0.36648, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 213us/sample - loss: 0.3748 - categorical_accuracy: 0.8874 - val_loss: 0.3665 - val_categorical_accuracy: 0.8940\n",
      "Epoch 10/100\n",
      "17280/17440 [============================>.] - ETA: 0s - loss: 0.3382 - categorical_accuracy: 0.8981\n",
      "Epoch 00010: val_loss improved from 0.36648 to 0.31477, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 218us/sample - loss: 0.3383 - categorical_accuracy: 0.8981 - val_loss: 0.3148 - val_categorical_accuracy: 0.9128\n",
      "Epoch 11/100\n",
      "17376/17440 [============================>.] - ETA: 0s - loss: 0.3167 - categorical_accuracy: 0.9057\n",
      "Epoch 00011: val_loss improved from 0.31477 to 0.31434, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 216us/sample - loss: 0.3167 - categorical_accuracy: 0.9056 - val_loss: 0.3143 - val_categorical_accuracy: 0.9119\n",
      "Epoch 12/100\n",
      "17408/17440 [============================>.] - ETA: 0s - loss: 0.3006 - categorical_accuracy: 0.9094\n",
      "Epoch 00012: val_loss did not improve from 0.31434\n",
      "17440/17440 [==============================] - 4s 211us/sample - loss: 0.3003 - categorical_accuracy: 0.9095 - val_loss: 0.3320 - val_categorical_accuracy: 0.9087\n",
      "Epoch 13/100\n",
      "17216/17440 [============================>.] - ETA: 0s - loss: 0.2864 - categorical_accuracy: 0.9148\n",
      "Epoch 00013: val_loss did not improve from 0.31434\n",
      "17440/17440 [==============================] - 4s 212us/sample - loss: 0.2860 - categorical_accuracy: 0.9150 - val_loss: 0.3144 - val_categorical_accuracy: 0.9128\n",
      "Epoch 14/100\n",
      "17280/17440 [============================>.] - ETA: 0s - loss: 0.2757 - categorical_accuracy: 0.9166\n",
      "Epoch 00014: val_loss improved from 0.31434 to 0.30387, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 217us/sample - loss: 0.2761 - categorical_accuracy: 0.9164 - val_loss: 0.3039 - val_categorical_accuracy: 0.9156\n",
      "Epoch 15/100\n",
      "17280/17440 [============================>.] - ETA: 0s - loss: 0.2530 - categorical_accuracy: 0.9242\n",
      "Epoch 00015: val_loss improved from 0.30387 to 0.28574, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 217us/sample - loss: 0.2543 - categorical_accuracy: 0.9240 - val_loss: 0.2857 - val_categorical_accuracy: 0.9252\n",
      "Epoch 16/100\n",
      "17248/17440 [============================>.] - ETA: 0s - loss: 0.2473 - categorical_accuracy: 0.9258\n",
      "Epoch 00016: val_loss improved from 0.28574 to 0.28030, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 204us/sample - loss: 0.2473 - categorical_accuracy: 0.9259 - val_loss: 0.2803 - val_categorical_accuracy: 0.9211\n",
      "Epoch 17/100\n",
      "17184/17440 [============================>.] - ETA: 0s - loss: 0.2456 - categorical_accuracy: 0.9257\n",
      "Epoch 00017: val_loss did not improve from 0.28030\n",
      "17440/17440 [==============================] - 4s 203us/sample - loss: 0.2463 - categorical_accuracy: 0.9255 - val_loss: 0.2932 - val_categorical_accuracy: 0.9239\n",
      "Epoch 18/100\n",
      "17120/17440 [============================>.] - ETA: 0s - loss: 0.2303 - categorical_accuracy: 0.9312\n",
      "Epoch 00018: val_loss improved from 0.28030 to 0.27678, saving model to t_weights_1\n",
      "17440/17440 [==============================] - 4s 212us/sample - loss: 0.2292 - categorical_accuracy: 0.9315 - val_loss: 0.2768 - val_categorical_accuracy: 0.9225\n",
      "Epoch 19/100\n",
      "17248/17440 [============================>.] - ETA: 0s - loss: 0.2248 - categorical_accuracy: 0.9324\n",
      "Epoch 00019: val_loss did not improve from 0.27678\n",
      "17440/17440 [==============================] - 4s 212us/sample - loss: 0.2245 - categorical_accuracy: 0.9324 - val_loss: 0.2945 - val_categorical_accuracy: 0.9225\n",
      "Epoch 20/100\n",
      "17376/17440 [============================>.] - ETA: 0s - loss: 0.2258 - categorical_accuracy: 0.9307\n",
      "Epoch 00020: val_loss did not improve from 0.27678\n",
      "17440/17440 [==============================] - 4s 213us/sample - loss: 0.2259 - categorical_accuracy: 0.9306 - val_loss: 0.3141 - val_categorical_accuracy: 0.9183\n",
      "Epoch 21/100\n",
      "17184/17440 [============================>.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9324\n",
      "Epoch 00021: val_loss did not improve from 0.27678\n",
      "17440/17440 [==============================] - 4s 218us/sample - loss: 0.2195 - categorical_accuracy: 0.9322 - val_loss: 0.3126 - val_categorical_accuracy: 0.9183\n",
      "Epoch 22/100\n",
      "17280/17440 [============================>.] - ETA: 0s - loss: 0.2111 - categorical_accuracy: 0.9373\n",
      "Epoch 00022: val_loss did not improve from 0.27678\n",
      "17440/17440 [==============================] - 4s 218us/sample - loss: 0.2110 - categorical_accuracy: 0.9374 - val_loss: 0.3190 - val_categorical_accuracy: 0.9216\n",
      "Epoch 23/100\n",
      "17248/17440 [============================>.] - ETA: 0s - loss: 0.2053 - categorical_accuracy: 0.9373\n",
      "Epoch 00023: val_loss did not improve from 0.27678\n",
      "17440/17440 [==============================] - 4s 217us/sample - loss: 0.2050 - categorical_accuracy: 0.9373 - val_loss: 0.3119 - val_categorical_accuracy: 0.9165\n",
      "0.9229358 0.5632\n",
      "\n",
      "\n",
      "nrx: 15 - real: 0 \n",
      "Train on 25120 samples, validate on 3140 samples\n",
      "Epoch 1/100\n",
      "25056/25120 [============================>.] - ETA: 0s - loss: 1.9654 - categorical_accuracy: 0.2658\n",
      "Epoch 00001: val_loss improved from inf to 1.53422, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 235us/sample - loss: 1.9651 - categorical_accuracy: 0.2660 - val_loss: 1.5342 - val_categorical_accuracy: 0.4580\n",
      "Epoch 2/100\n",
      "24896/25120 [============================>.] - ETA: 0s - loss: 1.4060 - categorical_accuracy: 0.4985\n",
      "Epoch 00002: val_loss improved from 1.53422 to 1.11212, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 218us/sample - loss: 1.4045 - categorical_accuracy: 0.4990 - val_loss: 1.1121 - val_categorical_accuracy: 0.6414\n",
      "Epoch 3/100\n",
      "24992/25120 [============================>.] - ETA: 0s - loss: 1.0871 - categorical_accuracy: 0.6277\n",
      "Epoch 00003: val_loss improved from 1.11212 to 0.90462, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 221us/sample - loss: 1.0867 - categorical_accuracy: 0.6280 - val_loss: 0.9046 - val_categorical_accuracy: 0.7086\n",
      "Epoch 4/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.8980 - categorical_accuracy: 0.7068\n",
      "Epoch 00004: val_loss improved from 0.90462 to 0.70727, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 220us/sample - loss: 0.8971 - categorical_accuracy: 0.7071 - val_loss: 0.7073 - val_categorical_accuracy: 0.7838\n",
      "Epoch 5/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.7561 - categorical_accuracy: 0.7556\n",
      "Epoch 00005: val_loss improved from 0.70727 to 0.64106, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 218us/sample - loss: 0.7558 - categorical_accuracy: 0.7555 - val_loss: 0.6411 - val_categorical_accuracy: 0.8035\n",
      "Epoch 6/100\n",
      "25056/25120 [============================>.] - ETA: 0s - loss: 0.6351 - categorical_accuracy: 0.8003\n",
      "Epoch 00006: val_loss improved from 0.64106 to 0.52605, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 217us/sample - loss: 0.6350 - categorical_accuracy: 0.8003 - val_loss: 0.5261 - val_categorical_accuracy: 0.8414\n",
      "Epoch 7/100\n",
      "24992/25120 [============================>.] - ETA: 0s - loss: 0.5638 - categorical_accuracy: 0.8235\n",
      "Epoch 00007: val_loss improved from 0.52605 to 0.45394, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 219us/sample - loss: 0.5638 - categorical_accuracy: 0.8236 - val_loss: 0.4539 - val_categorical_accuracy: 0.8656\n",
      "Epoch 8/100\n",
      "25088/25120 [============================>.] - ETA: 0s - loss: 0.5049 - categorical_accuracy: 0.8453\n",
      "Epoch 00008: val_loss improved from 0.45394 to 0.42854, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 214us/sample - loss: 0.5047 - categorical_accuracy: 0.8454 - val_loss: 0.4285 - val_categorical_accuracy: 0.8745\n",
      "Epoch 9/100\n",
      "24896/25120 [============================>.] - ETA: 0s - loss: 0.4763 - categorical_accuracy: 0.8542\n",
      "Epoch 00009: val_loss did not improve from 0.42854\n",
      "25120/25120 [==============================] - 5s 218us/sample - loss: 0.4754 - categorical_accuracy: 0.8546 - val_loss: 0.4309 - val_categorical_accuracy: 0.8761\n",
      "Epoch 10/100\n",
      "24800/25120 [============================>.] - ETA: 0s - loss: 0.4333 - categorical_accuracy: 0.8641\n",
      "Epoch 00010: val_loss improved from 0.42854 to 0.38944, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 220us/sample - loss: 0.4343 - categorical_accuracy: 0.8639 - val_loss: 0.3894 - val_categorical_accuracy: 0.8885\n",
      "Epoch 11/100\n",
      "24960/25120 [============================>.] - ETA: 0s - loss: 0.4124 - categorical_accuracy: 0.8718\n",
      "Epoch 00011: val_loss improved from 0.38944 to 0.36150, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 220us/sample - loss: 0.4119 - categorical_accuracy: 0.8719 - val_loss: 0.3615 - val_categorical_accuracy: 0.8965\n",
      "Epoch 12/100\n",
      "24896/25120 [============================>.] - ETA: 0s - loss: 0.3856 - categorical_accuracy: 0.8790\n",
      "Epoch 00012: val_loss improved from 0.36150 to 0.36037, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 220us/sample - loss: 0.3853 - categorical_accuracy: 0.8791 - val_loss: 0.3604 - val_categorical_accuracy: 0.9006\n",
      "Epoch 13/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.3704 - categorical_accuracy: 0.8832\n",
      "Epoch 00013: val_loss improved from 0.36037 to 0.32718, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 219us/sample - loss: 0.3704 - categorical_accuracy: 0.8832 - val_loss: 0.3272 - val_categorical_accuracy: 0.9076\n",
      "Epoch 14/100\n",
      "24864/25120 [============================>.] - ETA: 0s - loss: 0.3547 - categorical_accuracy: 0.8909\n",
      "Epoch 00014: val_loss did not improve from 0.32718\n",
      "25120/25120 [==============================] - 5s 207us/sample - loss: 0.3539 - categorical_accuracy: 0.8911 - val_loss: 0.3352 - val_categorical_accuracy: 0.9073\n",
      "Epoch 15/100\n",
      "24992/25120 [============================>.] - ETA: 0s - loss: 0.3378 - categorical_accuracy: 0.8943\n",
      "Epoch 00015: val_loss improved from 0.32718 to 0.32038, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 214us/sample - loss: 0.3374 - categorical_accuracy: 0.8945 - val_loss: 0.3204 - val_categorical_accuracy: 0.9051\n",
      "Epoch 16/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.3261 - categorical_accuracy: 0.8987\n",
      "Epoch 00016: val_loss did not improve from 0.32038\n",
      "25120/25120 [==============================] - 5s 215us/sample - loss: 0.3262 - categorical_accuracy: 0.8985 - val_loss: 0.3275 - val_categorical_accuracy: 0.9041\n",
      "Epoch 17/100\n",
      "24896/25120 [============================>.] - ETA: 0s - loss: 0.3208 - categorical_accuracy: 0.9005\n",
      "Epoch 00017: val_loss did not improve from 0.32038\n",
      "25120/25120 [==============================] - 5s 217us/sample - loss: 0.3209 - categorical_accuracy: 0.9005 - val_loss: 0.3358 - val_categorical_accuracy: 0.9019\n",
      "Epoch 18/100\n",
      "25056/25120 [============================>.] - ETA: 0s - loss: 0.3117 - categorical_accuracy: 0.9007\n",
      "Epoch 00018: val_loss improved from 0.32038 to 0.30779, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 216us/sample - loss: 0.3117 - categorical_accuracy: 0.9007 - val_loss: 0.3078 - val_categorical_accuracy: 0.9121\n",
      "Epoch 19/100\n",
      "24864/25120 [============================>.] - ETA: 0s - loss: 0.2992 - categorical_accuracy: 0.9062\n",
      "Epoch 00019: val_loss did not improve from 0.30779\n",
      "25120/25120 [==============================] - 5s 209us/sample - loss: 0.3000 - categorical_accuracy: 0.9059 - val_loss: 0.3100 - val_categorical_accuracy: 0.9115\n",
      "Epoch 20/100\n",
      "25056/25120 [============================>.] - ETA: 0s - loss: 0.2929 - categorical_accuracy: 0.9064\n",
      "Epoch 00020: val_loss improved from 0.30779 to 0.29874, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 221us/sample - loss: 0.2926 - categorical_accuracy: 0.9066 - val_loss: 0.2987 - val_categorical_accuracy: 0.9172\n",
      "Epoch 21/100\n",
      "24864/25120 [============================>.] - ETA: 0s - loss: 0.2877 - categorical_accuracy: 0.9082\n",
      "Epoch 00021: val_loss improved from 0.29874 to 0.28977, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 6s 219us/sample - loss: 0.2880 - categorical_accuracy: 0.9081 - val_loss: 0.2898 - val_categorical_accuracy: 0.9159\n",
      "Epoch 22/100\n",
      "24992/25120 [============================>.] - ETA: 0s - loss: 0.2816 - categorical_accuracy: 0.9112\n",
      "Epoch 00022: val_loss improved from 0.28977 to 0.28946, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 218us/sample - loss: 0.2814 - categorical_accuracy: 0.9111 - val_loss: 0.2895 - val_categorical_accuracy: 0.9188\n",
      "Epoch 23/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.2741 - categorical_accuracy: 0.9133\n",
      "Epoch 00023: val_loss did not improve from 0.28946\n",
      "25120/25120 [==============================] - 5s 217us/sample - loss: 0.2739 - categorical_accuracy: 0.9133 - val_loss: 0.2930 - val_categorical_accuracy: 0.9207\n",
      "Epoch 24/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.9150\n",
      "Epoch 00024: val_loss improved from 0.28946 to 0.28777, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 218us/sample - loss: 0.2681 - categorical_accuracy: 0.9146 - val_loss: 0.2878 - val_categorical_accuracy: 0.9255\n",
      "Epoch 25/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9132\n",
      "Epoch 00025: val_loss did not improve from 0.28777\n",
      "25120/25120 [==============================] - 5s 217us/sample - loss: 0.2717 - categorical_accuracy: 0.9131 - val_loss: 0.3064 - val_categorical_accuracy: 0.9210\n",
      "Epoch 26/100\n",
      "24992/25120 [============================>.] - ETA: 0s - loss: 0.2648 - categorical_accuracy: 0.9177\n",
      "Epoch 00026: val_loss did not improve from 0.28777\n",
      "25120/25120 [==============================] - 5s 219us/sample - loss: 0.2642 - categorical_accuracy: 0.9180 - val_loss: 0.2921 - val_categorical_accuracy: 0.9201\n",
      "Epoch 27/100\n",
      "25024/25120 [============================>.] - ETA: 0s - loss: 0.2594 - categorical_accuracy: 0.9194\n",
      "Epoch 00027: val_loss did not improve from 0.28777\n",
      "25120/25120 [==============================] - 5s 216us/sample - loss: 0.2592 - categorical_accuracy: 0.9195 - val_loss: 0.2907 - val_categorical_accuracy: 0.9188\n",
      "Epoch 28/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9220\n",
      "Epoch 00028: val_loss improved from 0.28777 to 0.27580, saving model to t_weights_1\n",
      "25120/25120 [==============================] - 5s 218us/sample - loss: 0.2508 - categorical_accuracy: 0.9220 - val_loss: 0.2758 - val_categorical_accuracy: 0.9248\n",
      "Epoch 29/100\n",
      "24864/25120 [============================>.] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.9208\n",
      "Epoch 00029: val_loss did not improve from 0.27580\n",
      "25120/25120 [==============================] - 5s 216us/sample - loss: 0.2493 - categorical_accuracy: 0.9208 - val_loss: 0.2931 - val_categorical_accuracy: 0.9242\n",
      "Epoch 30/100\n",
      "24896/25120 [============================>.] - ETA: 0s - loss: 0.2487 - categorical_accuracy: 0.9215\n",
      "Epoch 00030: val_loss did not improve from 0.27580\n",
      "25120/25120 [==============================] - 5s 213us/sample - loss: 0.2481 - categorical_accuracy: 0.9218 - val_loss: 0.2849 - val_categorical_accuracy: 0.9258\n",
      "Epoch 31/100\n",
      "25088/25120 [============================>.] - ETA: 0s - loss: 0.2448 - categorical_accuracy: 0.9214\n",
      "Epoch 00031: val_loss did not improve from 0.27580\n",
      "25120/25120 [==============================] - 5s 217us/sample - loss: 0.2449 - categorical_accuracy: 0.9214 - val_loss: 0.3141 - val_categorical_accuracy: 0.9213\n",
      "Epoch 32/100\n",
      "24928/25120 [============================>.] - ETA: 0s - loss: 0.2425 - categorical_accuracy: 0.9215\n",
      "Epoch 00032: val_loss did not improve from 0.27580\n",
      "25120/25120 [==============================] - 5s 209us/sample - loss: 0.2423 - categorical_accuracy: 0.9216 - val_loss: 0.2818 - val_categorical_accuracy: 0.9252\n",
      "Epoch 33/100\n",
      "25056/25120 [============================>.] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9243\n",
      "Epoch 00033: val_loss did not improve from 0.27580\n",
      "25120/25120 [==============================] - 5s 217us/sample - loss: 0.2385 - categorical_accuracy: 0.9244 - val_loss: 0.2921 - val_categorical_accuracy: 0.9248\n",
      "0.92738855 0.5513\n",
      "\n",
      "\n",
      "nrx: 20 - real: 0 \n",
      "Train on 32960 samples, validate on 4120 samples\n",
      "Epoch 1/100\n",
      "32672/32960 [============================>.] - ETA: 0s - loss: 1.9248 - categorical_accuracy: 0.2836\n",
      "Epoch 00001: val_loss improved from inf to 1.50439, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 8s 231us/sample - loss: 1.9210 - categorical_accuracy: 0.2851 - val_loss: 1.5044 - val_categorical_accuracy: 0.4585\n",
      "Epoch 2/100\n",
      "32928/32960 [============================>.] - ETA: 0s - loss: 1.4089 - categorical_accuracy: 0.4967\n",
      "Epoch 00002: val_loss improved from 1.50439 to 1.12468, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 220us/sample - loss: 1.4086 - categorical_accuracy: 0.4968 - val_loss: 1.1247 - val_categorical_accuracy: 0.6175\n",
      "Epoch 3/100\n",
      "32800/32960 [============================>.] - ETA: 0s - loss: 1.1058 - categorical_accuracy: 0.6136\n",
      "Epoch 00003: val_loss improved from 1.12468 to 0.83106, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 218us/sample - loss: 1.1053 - categorical_accuracy: 0.6137 - val_loss: 0.8311 - val_categorical_accuracy: 0.7228\n",
      "Epoch 4/100\n",
      "32864/32960 [============================>.] - ETA: 0s - loss: 0.8706 - categorical_accuracy: 0.7068\n",
      "Epoch 00004: val_loss improved from 0.83106 to 0.64880, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.8705 - categorical_accuracy: 0.7069 - val_loss: 0.6488 - val_categorical_accuracy: 0.7964\n",
      "Epoch 5/100\n",
      "32832/32960 [============================>.] - ETA: 0s - loss: 0.6976 - categorical_accuracy: 0.7765\n",
      "Epoch 00005: val_loss improved from 0.64880 to 0.54576, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 220us/sample - loss: 0.6973 - categorical_accuracy: 0.7765 - val_loss: 0.5458 - val_categorical_accuracy: 0.8318\n",
      "Epoch 6/100\n",
      "32832/32960 [============================>.] - ETA: 0s - loss: 0.5789 - categorical_accuracy: 0.8198\n",
      "Epoch 00006: val_loss improved from 0.54576 to 0.47119, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 214us/sample - loss: 0.5793 - categorical_accuracy: 0.8197 - val_loss: 0.4712 - val_categorical_accuracy: 0.8561\n",
      "Epoch 7/100\n",
      "32768/32960 [============================>.] - ETA: 0s - loss: 0.5066 - categorical_accuracy: 0.8421\n",
      "Epoch 00007: val_loss improved from 0.47119 to 0.40390, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.5065 - categorical_accuracy: 0.8423 - val_loss: 0.4039 - val_categorical_accuracy: 0.8772\n",
      "Epoch 8/100\n",
      "32896/32960 [============================>.] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.8578\n",
      "Epoch 00008: val_loss improved from 0.40390 to 0.36767, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.4555 - categorical_accuracy: 0.8579 - val_loss: 0.3677 - val_categorical_accuracy: 0.8886\n",
      "Epoch 9/100\n",
      "32928/32960 [============================>.] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8720\n",
      "Epoch 00009: val_loss improved from 0.36767 to 0.35261, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 220us/sample - loss: 0.4172 - categorical_accuracy: 0.8720 - val_loss: 0.3526 - val_categorical_accuracy: 0.8939\n",
      "Epoch 10/100\n",
      "32736/32960 [============================>.] - ETA: 0s - loss: 0.3896 - categorical_accuracy: 0.8821\n",
      "Epoch 00010: val_loss did not improve from 0.35261\n",
      "32960/32960 [==============================] - 7s 218us/sample - loss: 0.3892 - categorical_accuracy: 0.8821 - val_loss: 0.3570 - val_categorical_accuracy: 0.8898\n",
      "Epoch 11/100\n",
      "32864/32960 [============================>.] - ETA: 0s - loss: 0.3654 - categorical_accuracy: 0.8881\n",
      "Epoch 00011: val_loss improved from 0.35261 to 0.33090, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 220us/sample - loss: 0.3652 - categorical_accuracy: 0.8882 - val_loss: 0.3309 - val_categorical_accuracy: 0.8988\n",
      "Epoch 12/100\n",
      "32768/32960 [============================>.] - ETA: 0s - loss: 0.3480 - categorical_accuracy: 0.8929\n",
      "Epoch 00012: val_loss improved from 0.33090 to 0.31873, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 220us/sample - loss: 0.3473 - categorical_accuracy: 0.8932 - val_loss: 0.3187 - val_categorical_accuracy: 0.9078\n",
      "Epoch 13/100\n",
      "32896/32960 [============================>.] - ETA: 0s - loss: 0.3321 - categorical_accuracy: 0.8992\n",
      "Epoch 00013: val_loss improved from 0.31873 to 0.30724, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 221us/sample - loss: 0.3325 - categorical_accuracy: 0.8990 - val_loss: 0.3072 - val_categorical_accuracy: 0.9085\n",
      "Epoch 14/100\n",
      "32928/32960 [============================>.] - ETA: 0s - loss: 0.3243 - categorical_accuracy: 0.9005\n",
      "Epoch 00014: val_loss did not improve from 0.30724\n",
      "32960/32960 [==============================] - 7s 213us/sample - loss: 0.3244 - categorical_accuracy: 0.9005 - val_loss: 0.3140 - val_categorical_accuracy: 0.9083\n",
      "Epoch 15/100\n",
      "32896/32960 [============================>.] - ETA: 0s - loss: 0.3119 - categorical_accuracy: 0.9048\n",
      "Epoch 00015: val_loss improved from 0.30724 to 0.30488, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 209us/sample - loss: 0.3119 - categorical_accuracy: 0.9048 - val_loss: 0.3049 - val_categorical_accuracy: 0.9117\n",
      "Epoch 16/100\n",
      "32800/32960 [============================>.] - ETA: 0s - loss: 0.3009 - categorical_accuracy: 0.9088\n",
      "Epoch 00016: val_loss did not improve from 0.30488\n",
      "32960/32960 [==============================] - 7s 217us/sample - loss: 0.3007 - categorical_accuracy: 0.9090 - val_loss: 0.3092 - val_categorical_accuracy: 0.9097\n",
      "Epoch 17/100\n",
      "32896/32960 [============================>.] - ETA: 0s - loss: 0.2939 - categorical_accuracy: 0.9092\n",
      "Epoch 00017: val_loss improved from 0.30488 to 0.29252, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 220us/sample - loss: 0.2937 - categorical_accuracy: 0.9092 - val_loss: 0.2925 - val_categorical_accuracy: 0.9155\n",
      "Epoch 18/100\n",
      "32704/32960 [============================>.] - ETA: 0s - loss: 0.2834 - categorical_accuracy: 0.9130\n",
      "Epoch 00018: val_loss improved from 0.29252 to 0.28837, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 218us/sample - loss: 0.2834 - categorical_accuracy: 0.9131 - val_loss: 0.2884 - val_categorical_accuracy: 0.9150\n",
      "Epoch 19/100\n",
      "32896/32960 [============================>.] - ETA: 0s - loss: 0.2755 - categorical_accuracy: 0.9160\n",
      "Epoch 00019: val_loss did not improve from 0.28837\n",
      "32960/32960 [==============================] - 7s 218us/sample - loss: 0.2755 - categorical_accuracy: 0.9160 - val_loss: 0.3116 - val_categorical_accuracy: 0.9133\n",
      "Epoch 20/100\n",
      "32864/32960 [============================>.] - ETA: 0s - loss: 0.2737 - categorical_accuracy: 0.9166\n",
      "Epoch 00020: val_loss improved from 0.28837 to 0.27985, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.2738 - categorical_accuracy: 0.9166 - val_loss: 0.2799 - val_categorical_accuracy: 0.9197\n",
      "Epoch 21/100\n",
      "32704/32960 [============================>.] - ETA: 0s - loss: 0.2632 - categorical_accuracy: 0.9196\n",
      "Epoch 00021: val_loss did not improve from 0.27985\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.2630 - categorical_accuracy: 0.9196 - val_loss: 0.2976 - val_categorical_accuracy: 0.9170\n",
      "Epoch 22/100\n",
      "32736/32960 [============================>.] - ETA: 0s - loss: 0.2632 - categorical_accuracy: 0.9192\n",
      "Epoch 00022: val_loss improved from 0.27985 to 0.27817, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 217us/sample - loss: 0.2629 - categorical_accuracy: 0.9194 - val_loss: 0.2782 - val_categorical_accuracy: 0.9218\n",
      "Epoch 23/100\n",
      "32832/32960 [============================>.] - ETA: 0s - loss: 0.2567 - categorical_accuracy: 0.9212\n",
      "Epoch 00023: val_loss did not improve from 0.27817\n",
      "32960/32960 [==============================] - 7s 211us/sample - loss: 0.2567 - categorical_accuracy: 0.9212 - val_loss: 0.2832 - val_categorical_accuracy: 0.9233\n",
      "Epoch 24/100\n",
      "32864/32960 [============================>.] - ETA: 0s - loss: 0.2498 - categorical_accuracy: 0.9225\n",
      "Epoch 00024: val_loss improved from 0.27817 to 0.27737, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 221us/sample - loss: 0.2501 - categorical_accuracy: 0.9225 - val_loss: 0.2774 - val_categorical_accuracy: 0.9221\n",
      "Epoch 25/100\n",
      "32832/32960 [============================>.] - ETA: 0s - loss: 0.2496 - categorical_accuracy: 0.9243\n",
      "Epoch 00025: val_loss did not improve from 0.27737\n",
      "32960/32960 [==============================] - 7s 218us/sample - loss: 0.2502 - categorical_accuracy: 0.9240 - val_loss: 0.3102 - val_categorical_accuracy: 0.9235\n",
      "Epoch 26/100\n",
      "32704/32960 [============================>.] - ETA: 0s - loss: 0.2434 - categorical_accuracy: 0.9251\n",
      "Epoch 00026: val_loss did not improve from 0.27737\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.2439 - categorical_accuracy: 0.9249 - val_loss: 0.2985 - val_categorical_accuracy: 0.9211\n",
      "Epoch 27/100\n",
      "32704/32960 [============================>.] - ETA: 0s - loss: 0.2417 - categorical_accuracy: 0.9255\n",
      "Epoch 00027: val_loss improved from 0.27737 to 0.27701, saving model to t_weights_1\n",
      "32960/32960 [==============================] - 7s 217us/sample - loss: 0.2423 - categorical_accuracy: 0.9253 - val_loss: 0.2770 - val_categorical_accuracy: 0.9192\n",
      "Epoch 28/100\n",
      "32768/32960 [============================>.] - ETA: 0s - loss: 0.2380 - categorical_accuracy: 0.9271\n",
      "Epoch 00028: val_loss did not improve from 0.27701\n",
      "32960/32960 [==============================] - 7s 225us/sample - loss: 0.2381 - categorical_accuracy: 0.9270 - val_loss: 0.3211 - val_categorical_accuracy: 0.9194\n",
      "Epoch 29/100\n",
      "32832/32960 [============================>.] - ETA: 0s - loss: 0.2314 - categorical_accuracy: 0.9304\n",
      "Epoch 00029: val_loss did not improve from 0.27701\n",
      "32960/32960 [==============================] - 7s 224us/sample - loss: 0.2317 - categorical_accuracy: 0.9303 - val_loss: 0.3186 - val_categorical_accuracy: 0.9146\n",
      "Epoch 30/100\n",
      "32832/32960 [============================>.] - ETA: 0s - loss: 0.2363 - categorical_accuracy: 0.9290\n",
      "Epoch 00030: val_loss did not improve from 0.27701\n",
      "32960/32960 [==============================] - 7s 226us/sample - loss: 0.2361 - categorical_accuracy: 0.9291 - val_loss: 0.3068 - val_categorical_accuracy: 0.9197\n",
      "Epoch 31/100\n",
      "32864/32960 [============================>.] - ETA: 0s - loss: 0.2260 - categorical_accuracy: 0.9309\n",
      "Epoch 00031: val_loss did not improve from 0.27701\n",
      "32960/32960 [==============================] - 7s 219us/sample - loss: 0.2264 - categorical_accuracy: 0.9306 - val_loss: 0.2797 - val_categorical_accuracy: 0.9245\n",
      "Epoch 32/100\n",
      "32736/32960 [============================>.] - ETA: 0s - loss: 0.2344 - categorical_accuracy: 0.9282\n",
      "Epoch 00032: val_loss did not improve from 0.27701\n",
      "32960/32960 [==============================] - 7s 227us/sample - loss: 0.2342 - categorical_accuracy: 0.9283 - val_loss: 0.2877 - val_categorical_accuracy: 0.9252\n",
      "0.9196602 0.5226\n",
      "\n",
      "\n",
      "nrx: 25 - real: 0 \n",
      "Train on 40296 samples, validate on 5037 samples\n",
      "Epoch 1/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 1.8456 - categorical_accuracy: 0.3224\n",
      "Epoch 00001: val_loss improved from inf to 1.32966, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 234us/sample - loss: 1.8454 - categorical_accuracy: 0.3225 - val_loss: 1.3297 - val_categorical_accuracy: 0.5682\n",
      "Epoch 2/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 1.1606 - categorical_accuracy: 0.6038\n",
      "Epoch 00002: val_loss improved from 1.32966 to 0.82111, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 1.1590 - categorical_accuracy: 0.6046 - val_loss: 0.8211 - val_categorical_accuracy: 0.7213\n",
      "Epoch 3/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.8075 - categorical_accuracy: 0.7393\n",
      "Epoch 00003: val_loss improved from 0.82111 to 0.57870, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 224us/sample - loss: 0.8077 - categorical_accuracy: 0.7392 - val_loss: 0.5787 - val_categorical_accuracy: 0.8241\n",
      "Epoch 4/100\n",
      "40160/40296 [============================>.] - ETA: 0s - loss: 0.6261 - categorical_accuracy: 0.8047\n",
      "Epoch 00004: val_loss improved from 0.57870 to 0.53706, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.6267 - categorical_accuracy: 0.8045 - val_loss: 0.5371 - val_categorical_accuracy: 0.8451\n",
      "Epoch 5/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.5228 - categorical_accuracy: 0.8392\n",
      "Epoch 00005: val_loss improved from 0.53706 to 0.41329, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.5226 - categorical_accuracy: 0.8393 - val_loss: 0.4133 - val_categorical_accuracy: 0.8765\n",
      "Epoch 6/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.8597\n",
      "Epoch 00006: val_loss improved from 0.41329 to 0.37650, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 219us/sample - loss: 0.4634 - categorical_accuracy: 0.8597 - val_loss: 0.3765 - val_categorical_accuracy: 0.8833\n",
      "Epoch 7/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.4145 - categorical_accuracy: 0.8743\n",
      "Epoch 00007: val_loss improved from 0.37650 to 0.37297, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.4143 - categorical_accuracy: 0.8744 - val_loss: 0.3730 - val_categorical_accuracy: 0.8847\n",
      "Epoch 8/100\n",
      "40128/40296 [============================>.] - ETA: 0s - loss: 0.3825 - categorical_accuracy: 0.8846\n",
      "Epoch 00008: val_loss improved from 0.37297 to 0.34311, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.3825 - categorical_accuracy: 0.8845 - val_loss: 0.3431 - val_categorical_accuracy: 0.8978\n",
      "Epoch 9/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.3582 - categorical_accuracy: 0.8902\n",
      "Epoch 00009: val_loss improved from 0.34311 to 0.33477, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.3582 - categorical_accuracy: 0.8902 - val_loss: 0.3348 - val_categorical_accuracy: 0.9005\n",
      "Epoch 10/100\n",
      "40192/40296 [============================>.] - ETA: 0s - loss: 0.3461 - categorical_accuracy: 0.8950\n",
      "Epoch 00010: val_loss did not improve from 0.33477\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.3457 - categorical_accuracy: 0.8951 - val_loss: 0.3356 - val_categorical_accuracy: 0.8991\n",
      "Epoch 11/100\n",
      "40032/40296 [============================>.] - ETA: 0s - loss: 0.3212 - categorical_accuracy: 0.9041\n",
      "Epoch 00011: val_loss improved from 0.33477 to 0.31783, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.3221 - categorical_accuracy: 0.9037 - val_loss: 0.3178 - val_categorical_accuracy: 0.9035\n",
      "Epoch 12/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.3119 - categorical_accuracy: 0.9045\n",
      "Epoch 00012: val_loss improved from 0.31783 to 0.30075, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 224us/sample - loss: 0.3117 - categorical_accuracy: 0.9045 - val_loss: 0.3008 - val_categorical_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "40192/40296 [============================>.] - ETA: 0s - loss: 0.3039 - categorical_accuracy: 0.9076\n",
      "Epoch 00013: val_loss did not improve from 0.30075\n",
      "40296/40296 [==============================] - 9s 213us/sample - loss: 0.3038 - categorical_accuracy: 0.9076 - val_loss: 0.3185 - val_categorical_accuracy: 0.9013\n",
      "Epoch 14/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2984 - categorical_accuracy: 0.9102\n",
      "Epoch 00014: val_loss did not improve from 0.30075\n",
      "40296/40296 [==============================] - 9s 213us/sample - loss: 0.2985 - categorical_accuracy: 0.9102 - val_loss: 0.3289 - val_categorical_accuracy: 0.9061\n",
      "Epoch 15/100\n",
      "40192/40296 [============================>.] - ETA: 0s - loss: 0.2848 - categorical_accuracy: 0.9133\n",
      "Epoch 00015: val_loss improved from 0.30075 to 0.29051, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 218us/sample - loss: 0.2847 - categorical_accuracy: 0.9133 - val_loss: 0.2905 - val_categorical_accuracy: 0.9164\n",
      "Epoch 16/100\n",
      "40160/40296 [============================>.] - ETA: 0s - loss: 0.2768 - categorical_accuracy: 0.9159\n",
      "Epoch 00016: val_loss did not improve from 0.29051\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 0.2769 - categorical_accuracy: 0.9159 - val_loss: 0.3153 - val_categorical_accuracy: 0.9128\n",
      "Epoch 17/100\n",
      "40160/40296 [============================>.] - ETA: 0s - loss: 0.2759 - categorical_accuracy: 0.9181\n",
      "Epoch 00017: val_loss improved from 0.29051 to 0.28985, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.2758 - categorical_accuracy: 0.9182 - val_loss: 0.2899 - val_categorical_accuracy: 0.9168\n",
      "Epoch 18/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.2651 - categorical_accuracy: 0.9198\n",
      "Epoch 00018: val_loss improved from 0.28985 to 0.28908, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 215us/sample - loss: 0.2651 - categorical_accuracy: 0.9198 - val_loss: 0.2891 - val_categorical_accuracy: 0.9200\n",
      "Epoch 19/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 0.2605 - categorical_accuracy: 0.9221\n",
      "Epoch 00019: val_loss did not improve from 0.28908\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.2609 - categorical_accuracy: 0.9220 - val_loss: 0.2919 - val_categorical_accuracy: 0.9164\n",
      "Epoch 20/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 0.2518 - categorical_accuracy: 0.9251\n",
      "Epoch 00020: val_loss did not improve from 0.28908\n",
      "40296/40296 [==============================] - 9s 216us/sample - loss: 0.2518 - categorical_accuracy: 0.9250 - val_loss: 0.2894 - val_categorical_accuracy: 0.9186\n",
      "Epoch 21/100\n",
      "40128/40296 [============================>.] - ETA: 0s - loss: 0.2516 - categorical_accuracy: 0.9244\n",
      "Epoch 00021: val_loss improved from 0.28908 to 0.28384, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 224us/sample - loss: 0.2516 - categorical_accuracy: 0.9245 - val_loss: 0.2838 - val_categorical_accuracy: 0.9190\n",
      "Epoch 22/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2450 - categorical_accuracy: 0.9273\n",
      "Epoch 00022: val_loss improved from 0.28384 to 0.27110, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 224us/sample - loss: 0.2450 - categorical_accuracy: 0.9273 - val_loss: 0.2711 - val_categorical_accuracy: 0.9250\n",
      "Epoch 23/100\n",
      "40192/40296 [============================>.] - ETA: 0s - loss: 0.2394 - categorical_accuracy: 0.9282\n",
      "Epoch 00023: val_loss did not improve from 0.27110\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.2398 - categorical_accuracy: 0.9280 - val_loss: 0.2744 - val_categorical_accuracy: 0.9277\n",
      "Epoch 24/100\n",
      "40160/40296 [============================>.] - ETA: 0s - loss: 0.2383 - categorical_accuracy: 0.9285\n",
      "Epoch 00024: val_loss did not improve from 0.27110\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.2384 - categorical_accuracy: 0.9285 - val_loss: 0.2737 - val_categorical_accuracy: 0.9265\n",
      "Epoch 25/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.2323 - categorical_accuracy: 0.9307\n",
      "Epoch 00025: val_loss did not improve from 0.27110\n",
      "40296/40296 [==============================] - 8s 210us/sample - loss: 0.2323 - categorical_accuracy: 0.9307 - val_loss: 0.2942 - val_categorical_accuracy: 0.9218\n",
      "Epoch 26/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2339 - categorical_accuracy: 0.9298\n",
      "Epoch 00026: val_loss did not improve from 0.27110\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.2338 - categorical_accuracy: 0.9298 - val_loss: 0.2827 - val_categorical_accuracy: 0.9240\n",
      "Epoch 27/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2277 - categorical_accuracy: 0.9325\n",
      "Epoch 00027: val_loss did not improve from 0.27110\n",
      "40296/40296 [==============================] - 9s 216us/sample - loss: 0.2277 - categorical_accuracy: 0.9325 - val_loss: 0.2779 - val_categorical_accuracy: 0.9269\n",
      "0.919595 0.7212\n",
      "\n",
      "\n",
      "nrx: 0 - real: 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cls_weights = np.max(stat,axis=0)/stat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 2.3170 - categorical_accuracy: 0.1420\n",
      "Epoch 00001: val_loss improved from inf to 2.30388, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 1s 475us/sample - loss: 2.3149 - categorical_accuracy: 0.1475 - val_loss: 2.3039 - val_categorical_accuracy: 0.1350\n",
      "Epoch 2/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 2.2251 - categorical_accuracy: 0.2099\n",
      "Epoch 00002: val_loss improved from 2.30388 to 1.95149, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 233us/sample - loss: 2.2116 - categorical_accuracy: 0.2200 - val_loss: 1.9515 - val_categorical_accuracy: 0.4800\n",
      "Epoch 3/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 1.6989 - categorical_accuracy: 0.3699\n",
      "Epoch 00003: val_loss improved from 1.95149 to 1.16405, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 265us/sample - loss: 1.6900 - categorical_accuracy: 0.3750 - val_loss: 1.1641 - val_categorical_accuracy: 0.7550\n",
      "Epoch 4/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 1.1335 - categorical_accuracy: 0.5721\n",
      "Epoch 00004: val_loss improved from 1.16405 to 0.64884, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 274us/sample - loss: 1.1271 - categorical_accuracy: 0.5750 - val_loss: 0.6488 - val_categorical_accuracy: 0.8250\n",
      "Epoch 5/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.8324 - categorical_accuracy: 0.7092\n",
      "Epoch 00005: val_loss improved from 0.64884 to 0.45378, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 276us/sample - loss: 0.8294 - categorical_accuracy: 0.7088 - val_loss: 0.4538 - val_categorical_accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.6309 - categorical_accuracy: 0.7919\n",
      "Epoch 00006: val_loss improved from 0.45378 to 0.29122, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 280us/sample - loss: 0.6214 - categorical_accuracy: 0.7956 - val_loss: 0.2912 - val_categorical_accuracy: 0.9700\n",
      "Epoch 7/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.4260 - categorical_accuracy: 0.8757\n",
      "Epoch 00007: val_loss improved from 0.29122 to 0.20413, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 269us/sample - loss: 0.4228 - categorical_accuracy: 0.8800 - val_loss: 0.2041 - val_categorical_accuracy: 0.9750\n",
      "Epoch 8/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.3410 - categorical_accuracy: 0.8906\n",
      "Epoch 00008: val_loss improved from 0.20413 to 0.15161, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 247us/sample - loss: 0.3382 - categorical_accuracy: 0.8931 - val_loss: 0.1516 - val_categorical_accuracy: 0.9800\n",
      "Epoch 9/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.2707 - categorical_accuracy: 0.9198\n",
      "Epoch 00009: val_loss improved from 0.15161 to 0.11997, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 292us/sample - loss: 0.2667 - categorical_accuracy: 0.9212 - val_loss: 0.1200 - val_categorical_accuracy: 0.9850\n",
      "Epoch 10/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2731 - categorical_accuracy: 0.9247\n",
      "Epoch 00010: val_loss improved from 0.11997 to 0.09097, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 276us/sample - loss: 0.2738 - categorical_accuracy: 0.9250 - val_loss: 0.0910 - val_categorical_accuracy: 0.9900\n",
      "Epoch 11/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2271 - categorical_accuracy: 0.9426\n",
      "Epoch 00011: val_loss improved from 0.09097 to 0.06452, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 278us/sample - loss: 0.2275 - categorical_accuracy: 0.9419 - val_loss: 0.0645 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.1653 - categorical_accuracy: 0.9603\n",
      "Epoch 00012: val_loss did not improve from 0.06452\n",
      "1600/1600 [==============================] - 0s 233us/sample - loss: 0.1631 - categorical_accuracy: 0.9606 - val_loss: 0.0667 - val_categorical_accuracy: 0.9900\n",
      "Epoch 13/100\n",
      "1376/1600 [========================>.....] - ETA: 0s - loss: 0.1434 - categorical_accuracy: 0.9717\n",
      "Epoch 00013: val_loss did not improve from 0.06452\n",
      "1600/1600 [==============================] - 0s 217us/sample - loss: 0.1409 - categorical_accuracy: 0.9712 - val_loss: 0.0708 - val_categorical_accuracy: 0.9900\n",
      "Epoch 14/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.9734\n",
      "Epoch 00014: val_loss improved from 0.06452 to 0.03672, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 236us/sample - loss: 0.1217 - categorical_accuracy: 0.9744 - val_loss: 0.0367 - val_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1312/1600 [=======================>......] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.9848\n",
      "Epoch 00015: val_loss improved from 0.03672 to 0.03259, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 256us/sample - loss: 0.1054 - categorical_accuracy: 0.9837 - val_loss: 0.0326 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.1025 - categorical_accuracy: 0.9747\n",
      "Epoch 00016: val_loss did not improve from 0.03259\n",
      "1600/1600 [==============================] - 0s 222us/sample - loss: 0.1012 - categorical_accuracy: 0.9762 - val_loss: 0.0564 - val_categorical_accuracy: 0.9850\n",
      "Epoch 17/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0740 - categorical_accuracy: 0.9904\n",
      "Epoch 00017: val_loss improved from 0.03259 to 0.02608, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 279us/sample - loss: 0.0872 - categorical_accuracy: 0.9894 - val_loss: 0.0261 - val_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.0958 - categorical_accuracy: 0.9774\n",
      "Epoch 00018: val_loss did not improve from 0.02608\n",
      "1600/1600 [==============================] - 0s 239us/sample - loss: 0.0929 - categorical_accuracy: 0.9787 - val_loss: 0.0440 - val_categorical_accuracy: 0.9950\n",
      "Epoch 19/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0765 - categorical_accuracy: 0.9857\n",
      "Epoch 00019: val_loss improved from 0.02608 to 0.02230, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 243us/sample - loss: 0.0764 - categorical_accuracy: 0.9856 - val_loss: 0.0223 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.0741 - categorical_accuracy: 0.9864\n",
      "Epoch 00020: val_loss did not improve from 0.02230\n",
      "1600/1600 [==============================] - 0s 207us/sample - loss: 0.0764 - categorical_accuracy: 0.9862 - val_loss: 0.0234 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0706 - categorical_accuracy: 0.9917\n",
      "Epoch 00021: val_loss did not improve from 0.02230\n",
      "1600/1600 [==============================] - 0s 234us/sample - loss: 0.0697 - categorical_accuracy: 0.9919 - val_loss: 0.0256 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0684 - categorical_accuracy: 0.9909\n",
      "Epoch 00022: val_loss did not improve from 0.02230\n",
      "1600/1600 [==============================] - 0s 230us/sample - loss: 0.0678 - categorical_accuracy: 0.9906 - val_loss: 0.0242 - val_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.0654 - categorical_accuracy: 0.9879\n",
      "Epoch 00023: val_loss did not improve from 0.02230\n",
      "1600/1600 [==============================] - 0s 216us/sample - loss: 0.0652 - categorical_accuracy: 0.9881 - val_loss: 0.0270 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.0593 - categorical_accuracy: 0.9840\n",
      "Epoch 00024: val_loss did not improve from 0.02230\n",
      "1600/1600 [==============================] - 0s 207us/sample - loss: 0.0703 - categorical_accuracy: 0.9825 - val_loss: 0.0548 - val_categorical_accuracy: 0.9900\n",
      "1.0 0.0907\n",
      "\n",
      "\n",
      "nrx: 5 - real: 1 \n",
      "Train on 9120 samples, validate on 1140 samples\n",
      "Epoch 1/100\n",
      "9024/9120 [============================>.] - ETA: 0s - loss: 2.2354 - categorical_accuracy: 0.1662\n",
      "Epoch 00001: val_loss improved from inf to 2.03938, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 270us/sample - loss: 2.2352 - categorical_accuracy: 0.1668 - val_loss: 2.0394 - val_categorical_accuracy: 0.2851\n",
      "Epoch 2/100\n",
      "8832/9120 [============================>.] - ETA: 0s - loss: 1.7760 - categorical_accuracy: 0.3788\n",
      "Epoch 00002: val_loss improved from 2.03938 to 1.43602, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 229us/sample - loss: 1.7668 - categorical_accuracy: 0.3828 - val_loss: 1.4360 - val_categorical_accuracy: 0.4816\n",
      "Epoch 3/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 1.3444 - categorical_accuracy: 0.5261\n",
      "Epoch 00003: val_loss improved from 1.43602 to 1.09441, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 235us/sample - loss: 1.3430 - categorical_accuracy: 0.5264 - val_loss: 1.0944 - val_categorical_accuracy: 0.6175\n",
      "Epoch 4/100\n",
      "9024/9120 [============================>.] - ETA: 0s - loss: 1.0565 - categorical_accuracy: 0.6308\n",
      "Epoch 00004: val_loss improved from 1.09441 to 0.80266, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 231us/sample - loss: 1.0550 - categorical_accuracy: 0.6310 - val_loss: 0.8027 - val_categorical_accuracy: 0.7439\n",
      "Epoch 5/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.8556 - categorical_accuracy: 0.7016\n",
      "Epoch 00005: val_loss improved from 0.80266 to 0.69553, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 226us/sample - loss: 0.8544 - categorical_accuracy: 0.7020 - val_loss: 0.6955 - val_categorical_accuracy: 0.7825\n",
      "Epoch 6/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.7340 - categorical_accuracy: 0.7487\n",
      "Epoch 00006: val_loss improved from 0.69553 to 0.59708, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.7329 - categorical_accuracy: 0.7490 - val_loss: 0.5971 - val_categorical_accuracy: 0.8281\n",
      "Epoch 7/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.6096 - categorical_accuracy: 0.8001\n",
      "Epoch 00007: val_loss improved from 0.59708 to 0.49501, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 231us/sample - loss: 0.6076 - categorical_accuracy: 0.8002 - val_loss: 0.4950 - val_categorical_accuracy: 0.8482\n",
      "Epoch 8/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.5227 - categorical_accuracy: 0.8305\n",
      "Epoch 00008: val_loss improved from 0.49501 to 0.43543, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.5253 - categorical_accuracy: 0.8296 - val_loss: 0.4354 - val_categorical_accuracy: 0.8728\n",
      "Epoch 9/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 0.4611 - categorical_accuracy: 0.8525\n",
      "Epoch 00009: val_loss improved from 0.43543 to 0.37745, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 233us/sample - loss: 0.4610 - categorical_accuracy: 0.8522 - val_loss: 0.3775 - val_categorical_accuracy: 0.8991\n",
      "Epoch 10/100\n",
      "8928/9120 [============================>.] - ETA: 0s - loss: 0.3997 - categorical_accuracy: 0.8763\n",
      "Epoch 00010: val_loss improved from 0.37745 to 0.33000, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 231us/sample - loss: 0.3999 - categorical_accuracy: 0.8768 - val_loss: 0.3300 - val_categorical_accuracy: 0.9026\n",
      "Epoch 11/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.3623 - categorical_accuracy: 0.8925\n",
      "Epoch 00011: val_loss improved from 0.33000 to 0.30934, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 235us/sample - loss: 0.3604 - categorical_accuracy: 0.8936 - val_loss: 0.3093 - val_categorical_accuracy: 0.9228\n",
      "Epoch 12/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.3125 - categorical_accuracy: 0.9135\n",
      "Epoch 00012: val_loss improved from 0.30934 to 0.30074, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 228us/sample - loss: 0.3136 - categorical_accuracy: 0.9135 - val_loss: 0.3007 - val_categorical_accuracy: 0.9307\n",
      "Epoch 13/100\n",
      "8864/9120 [============================>.] - ETA: 0s - loss: 0.2855 - categorical_accuracy: 0.9181\n",
      "Epoch 00013: val_loss improved from 0.30074 to 0.25647, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.2848 - categorical_accuracy: 0.9181 - val_loss: 0.2565 - val_categorical_accuracy: 0.9272\n",
      "Epoch 14/100\n",
      "9024/9120 [============================>.] - ETA: 0s - loss: 0.2700 - categorical_accuracy: 0.9252\n",
      "Epoch 00014: val_loss did not improve from 0.25647\n",
      "9120/9120 [==============================] - 2s 219us/sample - loss: 0.2693 - categorical_accuracy: 0.9254 - val_loss: 0.2624 - val_categorical_accuracy: 0.9368\n",
      "Epoch 15/100\n",
      "9024/9120 [============================>.] - ETA: 0s - loss: 0.2517 - categorical_accuracy: 0.9292\n",
      "Epoch 00015: val_loss improved from 0.25647 to 0.21707, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.2506 - categorical_accuracy: 0.9295 - val_loss: 0.2171 - val_categorical_accuracy: 0.9482\n",
      "Epoch 16/100\n",
      "8864/9120 [============================>.] - ETA: 0s - loss: 0.2276 - categorical_accuracy: 0.9411\n",
      "Epoch 00016: val_loss improved from 0.21707 to 0.20900, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 231us/sample - loss: 0.2263 - categorical_accuracy: 0.9410 - val_loss: 0.2090 - val_categorical_accuracy: 0.9509\n",
      "Epoch 17/100\n",
      "9088/9120 [============================>.] - ETA: 0s - loss: 0.2129 - categorical_accuracy: 0.9444\n",
      "Epoch 00017: val_loss did not improve from 0.20900\n",
      "9120/9120 [==============================] - 2s 228us/sample - loss: 0.2131 - categorical_accuracy: 0.9443 - val_loss: 0.2266 - val_categorical_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.2085 - categorical_accuracy: 0.9453\n",
      "Epoch 00018: val_loss did not improve from 0.20900\n",
      "9120/9120 [==============================] - 2s 225us/sample - loss: 0.2080 - categorical_accuracy: 0.9452 - val_loss: 0.2282 - val_categorical_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.1899 - categorical_accuracy: 0.9522\n",
      "Epoch 00019: val_loss did not improve from 0.20900\n",
      "9120/9120 [==============================] - 2s 201us/sample - loss: 0.1899 - categorical_accuracy: 0.9526 - val_loss: 0.2106 - val_categorical_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "8928/9120 [============================>.] - ETA: 0s - loss: 0.1855 - categorical_accuracy: 0.9522\n",
      "Epoch 00020: val_loss improved from 0.20900 to 0.20351, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.1849 - categorical_accuracy: 0.9529 - val_loss: 0.2035 - val_categorical_accuracy: 0.9553\n",
      "Epoch 21/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.1569 - categorical_accuracy: 0.9609\n",
      "Epoch 00021: val_loss did not improve from 0.20351\n",
      "9120/9120 [==============================] - 2s 222us/sample - loss: 0.1562 - categorical_accuracy: 0.9613 - val_loss: 0.2153 - val_categorical_accuracy: 0.9535\n",
      "Epoch 22/100\n",
      "9088/9120 [============================>.] - ETA: 0s - loss: 0.1437 - categorical_accuracy: 0.9651\n",
      "Epoch 00022: val_loss did not improve from 0.20351\n",
      "9120/9120 [==============================] - 2s 224us/sample - loss: 0.1440 - categorical_accuracy: 0.9651 - val_loss: 0.2069 - val_categorical_accuracy: 0.9596\n",
      "Epoch 23/100\n",
      "8768/9120 [===========================>..] - ETA: 0s - loss: 0.1442 - categorical_accuracy: 0.9665\n",
      "Epoch 00023: val_loss improved from 0.20351 to 0.19252, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 216us/sample - loss: 0.1456 - categorical_accuracy: 0.9667 - val_loss: 0.1925 - val_categorical_accuracy: 0.9623\n",
      "Epoch 24/100\n",
      "8864/9120 [============================>.] - ETA: 0s - loss: 0.1463 - categorical_accuracy: 0.9638\n",
      "Epoch 00024: val_loss did not improve from 0.19252\n",
      "9120/9120 [==============================] - 2s 196us/sample - loss: 0.1458 - categorical_accuracy: 0.9640 - val_loss: 0.3020 - val_categorical_accuracy: 0.9184\n",
      "Epoch 25/100\n",
      "8928/9120 [============================>.] - ETA: 0s - loss: 0.1546 - categorical_accuracy: 0.9643\n",
      "Epoch 00025: val_loss did not improve from 0.19252\n",
      "9120/9120 [==============================] - 2s 221us/sample - loss: 0.1545 - categorical_accuracy: 0.9643 - val_loss: 0.2043 - val_categorical_accuracy: 0.9632\n",
      "Epoch 26/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.1285 - categorical_accuracy: 0.9682\n",
      "Epoch 00026: val_loss did not improve from 0.19252\n",
      "9120/9120 [==============================] - 2s 223us/sample - loss: 0.1293 - categorical_accuracy: 0.9681 - val_loss: 0.2168 - val_categorical_accuracy: 0.9544\n",
      "Epoch 27/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.1345 - categorical_accuracy: 0.9661\n",
      "Epoch 00027: val_loss improved from 0.19252 to 0.18550, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 227us/sample - loss: 0.1352 - categorical_accuracy: 0.9657 - val_loss: 0.1855 - val_categorical_accuracy: 0.9649\n",
      "Epoch 28/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.1308 - categorical_accuracy: 0.9695\n",
      "Epoch 00028: val_loss did not improve from 0.18550\n",
      "9120/9120 [==============================] - 2s 222us/sample - loss: 0.1308 - categorical_accuracy: 0.9695 - val_loss: 0.2150 - val_categorical_accuracy: 0.9640\n",
      "Epoch 29/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.9722\n",
      "Epoch 00029: val_loss did not improve from 0.18550\n",
      "9120/9120 [==============================] - 2s 229us/sample - loss: 0.1165 - categorical_accuracy: 0.9721 - val_loss: 0.1890 - val_categorical_accuracy: 0.9667\n",
      "Epoch 30/100\n",
      "8864/9120 [============================>.] - ETA: 0s - loss: 0.1153 - categorical_accuracy: 0.9728\n",
      "Epoch 00030: val_loss did not improve from 0.18550\n",
      "9120/9120 [==============================] - 2s 223us/sample - loss: 0.1146 - categorical_accuracy: 0.9730 - val_loss: 0.1918 - val_categorical_accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "8992/9120 [============================>.] - ETA: 0s - loss: 0.1044 - categorical_accuracy: 0.9785\n",
      "Epoch 00031: val_loss did not improve from 0.18550\n",
      "9120/9120 [==============================] - 2s 221us/sample - loss: 0.1054 - categorical_accuracy: 0.9783 - val_loss: 0.2253 - val_categorical_accuracy: 0.9596\n",
      "Epoch 32/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 0.1215 - categorical_accuracy: 0.9695\n",
      "Epoch 00032: val_loss did not improve from 0.18550\n",
      "9120/9120 [==============================] - 2s 220us/sample - loss: 0.1215 - categorical_accuracy: 0.9694 - val_loss: 0.1907 - val_categorical_accuracy: 0.9632\n",
      "0.97192985 0.2325\n",
      "\n",
      "\n",
      "nrx: 10 - real: 1 \n",
      "Train on 16640 samples, validate on 2080 samples\n",
      "Epoch 1/100\n",
      "16512/16640 [============================>.] - ETA: 0s - loss: 2.0228 - categorical_accuracy: 0.2610\n",
      "Epoch 00001: val_loss improved from inf to 1.56836, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 254us/sample - loss: 2.0197 - categorical_accuracy: 0.2620 - val_loss: 1.5684 - val_categorical_accuracy: 0.4428\n",
      "Epoch 2/100\n",
      "16576/16640 [============================>.] - ETA: 0s - loss: 1.5042 - categorical_accuracy: 0.4597\n",
      "Epoch 00002: val_loss improved from 1.56836 to 1.23147, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 224us/sample - loss: 1.5042 - categorical_accuracy: 0.4598 - val_loss: 1.2315 - val_categorical_accuracy: 0.5904\n",
      "Epoch 3/100\n",
      "16384/16640 [============================>.] - ETA: 0s - loss: 1.2430 - categorical_accuracy: 0.5601\n",
      "Epoch 00003: val_loss improved from 1.23147 to 0.97370, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 227us/sample - loss: 1.2410 - categorical_accuracy: 0.5611 - val_loss: 0.9737 - val_categorical_accuracy: 0.6942\n",
      "Epoch 4/100\n",
      "16416/16640 [============================>.] - ETA: 0s - loss: 1.0138 - categorical_accuracy: 0.6527\n",
      "Epoch 00004: val_loss improved from 0.97370 to 0.76890, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 222us/sample - loss: 1.0132 - categorical_accuracy: 0.6534 - val_loss: 0.7689 - val_categorical_accuracy: 0.7716\n",
      "Epoch 5/100\n",
      "16512/16640 [============================>.] - ETA: 0s - loss: 0.8136 - categorical_accuracy: 0.7298\n",
      "Epoch 00005: val_loss improved from 0.76890 to 0.60450, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 226us/sample - loss: 0.8140 - categorical_accuracy: 0.7294 - val_loss: 0.6045 - val_categorical_accuracy: 0.8250\n",
      "Epoch 6/100\n",
      "16480/16640 [============================>.] - ETA: 0s - loss: 0.6683 - categorical_accuracy: 0.7840\n",
      "Epoch 00006: val_loss improved from 0.60450 to 0.50101, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 224us/sample - loss: 0.6686 - categorical_accuracy: 0.7840 - val_loss: 0.5010 - val_categorical_accuracy: 0.8649\n",
      "Epoch 7/100\n",
      "16544/16640 [============================>.] - ETA: 0s - loss: 0.5583 - categorical_accuracy: 0.8226\n",
      "Epoch 00007: val_loss improved from 0.50101 to 0.40495, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 226us/sample - loss: 0.5578 - categorical_accuracy: 0.8227 - val_loss: 0.4049 - val_categorical_accuracy: 0.8923\n",
      "Epoch 8/100\n",
      "16416/16640 [============================>.] - ETA: 0s - loss: 0.4809 - categorical_accuracy: 0.8483\n",
      "Epoch 00008: val_loss improved from 0.40495 to 0.36743, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 229us/sample - loss: 0.4797 - categorical_accuracy: 0.8487 - val_loss: 0.3674 - val_categorical_accuracy: 0.9067\n",
      "Epoch 9/100\n",
      "16576/16640 [============================>.] - ETA: 0s - loss: 0.4162 - categorical_accuracy: 0.8736\n",
      "Epoch 00009: val_loss improved from 0.36743 to 0.31708, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 215us/sample - loss: 0.4162 - categorical_accuracy: 0.8735 - val_loss: 0.3171 - val_categorical_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "16512/16640 [============================>.] - ETA: 0s - loss: 0.3727 - categorical_accuracy: 0.8900\n",
      "Epoch 00010: val_loss improved from 0.31708 to 0.30454, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 230us/sample - loss: 0.3720 - categorical_accuracy: 0.8903 - val_loss: 0.3045 - val_categorical_accuracy: 0.9149\n",
      "Epoch 11/100\n",
      "16384/16640 [============================>.] - ETA: 0s - loss: 0.3410 - categorical_accuracy: 0.8994\n",
      "Epoch 00011: val_loss improved from 0.30454 to 0.29501, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 226us/sample - loss: 0.3404 - categorical_accuracy: 0.8995 - val_loss: 0.2950 - val_categorical_accuracy: 0.9269\n",
      "Epoch 12/100\n",
      "16608/16640 [============================>.] - ETA: 0s - loss: 0.3102 - categorical_accuracy: 0.9112\n",
      "Epoch 00012: val_loss improved from 0.29501 to 0.26980, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 230us/sample - loss: 0.3105 - categorical_accuracy: 0.9111 - val_loss: 0.2698 - val_categorical_accuracy: 0.9303\n",
      "Epoch 13/100\n",
      "16416/16640 [============================>.] - ETA: 0s - loss: 0.2803 - categorical_accuracy: 0.9199\n",
      "Epoch 00013: val_loss improved from 0.26980 to 0.25555, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 225us/sample - loss: 0.2799 - categorical_accuracy: 0.9199 - val_loss: 0.2555 - val_categorical_accuracy: 0.9293\n",
      "Epoch 14/100\n",
      "16512/16640 [============================>.] - ETA: 0s - loss: 0.2604 - categorical_accuracy: 0.9258\n",
      "Epoch 00014: val_loss improved from 0.25555 to 0.24554, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 228us/sample - loss: 0.2601 - categorical_accuracy: 0.9260 - val_loss: 0.2455 - val_categorical_accuracy: 0.9413\n",
      "Epoch 15/100\n",
      "16576/16640 [============================>.] - ETA: 0s - loss: 0.2394 - categorical_accuracy: 0.9311\n",
      "Epoch 00015: val_loss improved from 0.24554 to 0.24169, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 223us/sample - loss: 0.2397 - categorical_accuracy: 0.9310 - val_loss: 0.2417 - val_categorical_accuracy: 0.9399\n",
      "Epoch 16/100\n",
      "16576/16640 [============================>.] - ETA: 0s - loss: 0.2354 - categorical_accuracy: 0.9333\n",
      "Epoch 00016: val_loss improved from 0.24169 to 0.24092, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 231us/sample - loss: 0.2357 - categorical_accuracy: 0.9332 - val_loss: 0.2409 - val_categorical_accuracy: 0.9399\n",
      "Epoch 17/100\n",
      "16512/16640 [============================>.] - ETA: 0s - loss: 0.2233 - categorical_accuracy: 0.9360\n",
      "Epoch 00017: val_loss improved from 0.24092 to 0.22868, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 224us/sample - loss: 0.2238 - categorical_accuracy: 0.9359 - val_loss: 0.2287 - val_categorical_accuracy: 0.9413\n",
      "Epoch 18/100\n",
      "16608/16640 [============================>.] - ETA: 0s - loss: 0.2099 - categorical_accuracy: 0.9441\n",
      "Epoch 00018: val_loss did not improve from 0.22868\n",
      "16640/16640 [==============================] - 4s 223us/sample - loss: 0.2101 - categorical_accuracy: 0.9440 - val_loss: 0.2645 - val_categorical_accuracy: 0.9380\n",
      "Epoch 19/100\n",
      "16608/16640 [============================>.] - ETA: 0s - loss: 0.2115 - categorical_accuracy: 0.9424\n",
      "Epoch 00019: val_loss improved from 0.22868 to 0.21392, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 228us/sample - loss: 0.2116 - categorical_accuracy: 0.9422 - val_loss: 0.2139 - val_categorical_accuracy: 0.9481\n",
      "Epoch 20/100\n",
      "16544/16640 [============================>.] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.9497\n",
      "Epoch 00020: val_loss did not improve from 0.21392\n",
      "16640/16640 [==============================] - 4s 222us/sample - loss: 0.1875 - categorical_accuracy: 0.9498 - val_loss: 0.2147 - val_categorical_accuracy: 0.9524\n",
      "Epoch 21/100\n",
      "16512/16640 [============================>.] - ETA: 0s - loss: 0.1805 - categorical_accuracy: 0.9511\n",
      "Epoch 00021: val_loss did not improve from 0.21392\n",
      "16640/16640 [==============================] - 4s 222us/sample - loss: 0.1809 - categorical_accuracy: 0.9510 - val_loss: 0.2275 - val_categorical_accuracy: 0.9471\n",
      "Epoch 22/100\n",
      "16384/16640 [============================>.] - ETA: 0s - loss: 0.1830 - categorical_accuracy: 0.9495\n",
      "Epoch 00022: val_loss improved from 0.21392 to 0.19947, saving model to t_weights_1\n",
      "16640/16640 [==============================] - 4s 226us/sample - loss: 0.1840 - categorical_accuracy: 0.9489 - val_loss: 0.1995 - val_categorical_accuracy: 0.9553\n",
      "Epoch 23/100\n",
      "16544/16640 [============================>.] - ETA: 0s - loss: 0.1622 - categorical_accuracy: 0.9561\n",
      "Epoch 00023: val_loss did not improve from 0.19947\n",
      "16640/16640 [==============================] - 4s 225us/sample - loss: 0.1621 - categorical_accuracy: 0.9561 - val_loss: 0.2379 - val_categorical_accuracy: 0.9490\n",
      "Epoch 24/100\n",
      "16544/16640 [============================>.] - ETA: 0s - loss: 0.1681 - categorical_accuracy: 0.9539\n",
      "Epoch 00024: val_loss did not improve from 0.19947\n",
      "16640/16640 [==============================] - 4s 219us/sample - loss: 0.1680 - categorical_accuracy: 0.9540 - val_loss: 0.2083 - val_categorical_accuracy: 0.9543\n",
      "Epoch 25/100\n",
      "16480/16640 [============================>.] - ETA: 0s - loss: 0.1561 - categorical_accuracy: 0.9604\n",
      "Epoch 00025: val_loss did not improve from 0.19947\n",
      "16640/16640 [==============================] - 4s 215us/sample - loss: 0.1569 - categorical_accuracy: 0.9603 - val_loss: 0.2235 - val_categorical_accuracy: 0.9577\n",
      "Epoch 26/100\n",
      "16608/16640 [============================>.] - ETA: 0s - loss: 0.1544 - categorical_accuracy: 0.9601\n",
      "Epoch 00026: val_loss did not improve from 0.19947\n",
      "16640/16640 [==============================] - 4s 221us/sample - loss: 0.1544 - categorical_accuracy: 0.9601 - val_loss: 0.2124 - val_categorical_accuracy: 0.9510\n",
      "Epoch 27/100\n",
      "16416/16640 [============================>.] - ETA: 0s - loss: 0.1470 - categorical_accuracy: 0.9640\n",
      "Epoch 00027: val_loss did not improve from 0.19947\n",
      "16640/16640 [==============================] - 4s 226us/sample - loss: 0.1475 - categorical_accuracy: 0.9640 - val_loss: 0.2142 - val_categorical_accuracy: 0.9534\n",
      "0.9485577 0.4219\n",
      "\n",
      "\n",
      "nrx: 15 - real: 1 \n",
      "Train on 24640 samples, validate on 3080 samples\n",
      "Epoch 1/100\n",
      "24480/24640 [============================>.] - ETA: 0s - loss: 1.9360 - categorical_accuracy: 0.2796\n",
      "Epoch 00001: val_loss improved from inf to 1.48871, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 241us/sample - loss: 1.9336 - categorical_accuracy: 0.2808 - val_loss: 1.4887 - val_categorical_accuracy: 0.4903\n",
      "Epoch 2/100\n",
      "24448/24640 [============================>.] - ETA: 0s - loss: 1.4078 - categorical_accuracy: 0.5000\n",
      "Epoch 00002: val_loss improved from 1.48871 to 1.23220, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 222us/sample - loss: 1.4065 - categorical_accuracy: 0.5006 - val_loss: 1.2322 - val_categorical_accuracy: 0.5744\n",
      "Epoch 3/100\n",
      "24544/24640 [============================>.] - ETA: 0s - loss: 1.1260 - categorical_accuracy: 0.6125\n",
      "Epoch 00003: val_loss improved from 1.23220 to 0.96280, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 221us/sample - loss: 1.1250 - categorical_accuracy: 0.6128 - val_loss: 0.9628 - val_categorical_accuracy: 0.6711\n",
      "Epoch 4/100\n",
      "24512/24640 [============================>.] - ETA: 0s - loss: 0.9268 - categorical_accuracy: 0.6883\n",
      "Epoch 00004: val_loss improved from 0.96280 to 0.84551, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 224us/sample - loss: 0.9269 - categorical_accuracy: 0.6881 - val_loss: 0.8455 - val_categorical_accuracy: 0.7247\n",
      "Epoch 5/100\n",
      "24576/24640 [============================>.] - ETA: 0s - loss: 0.7651 - categorical_accuracy: 0.7480\n",
      "Epoch 00005: val_loss improved from 0.84551 to 0.62620, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 207us/sample - loss: 0.7652 - categorical_accuracy: 0.7481 - val_loss: 0.6262 - val_categorical_accuracy: 0.8110\n",
      "Epoch 6/100\n",
      "24480/24640 [============================>.] - ETA: 0s - loss: 0.6445 - categorical_accuracy: 0.7916\n",
      "Epoch 00006: val_loss improved from 0.62620 to 0.52632, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 225us/sample - loss: 0.6442 - categorical_accuracy: 0.7917 - val_loss: 0.5263 - val_categorical_accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "24384/24640 [============================>.] - ETA: 0s - loss: 0.5445 - categorical_accuracy: 0.8270\n",
      "Epoch 00007: val_loss improved from 0.52632 to 0.46284, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 223us/sample - loss: 0.5442 - categorical_accuracy: 0.8272 - val_loss: 0.4628 - val_categorical_accuracy: 0.8714\n",
      "Epoch 8/100\n",
      "24608/24640 [============================>.] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.8530\n",
      "Epoch 00008: val_loss improved from 0.46284 to 0.36699, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 223us/sample - loss: 0.4705 - categorical_accuracy: 0.8530 - val_loss: 0.3670 - val_categorical_accuracy: 0.9026\n",
      "Epoch 9/100\n",
      "24608/24640 [============================>.] - ETA: 0s - loss: 0.4106 - categorical_accuracy: 0.8744\n",
      "Epoch 00009: val_loss improved from 0.36699 to 0.34976, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 224us/sample - loss: 0.4104 - categorical_accuracy: 0.8745 - val_loss: 0.3498 - val_categorical_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "24608/24640 [============================>.] - ETA: 0s - loss: 0.3660 - categorical_accuracy: 0.8895\n",
      "Epoch 00010: val_loss improved from 0.34976 to 0.31270, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 217us/sample - loss: 0.3658 - categorical_accuracy: 0.8896 - val_loss: 0.3127 - val_categorical_accuracy: 0.9224\n",
      "Epoch 11/100\n",
      "24512/24640 [============================>.] - ETA: 0s - loss: 0.3260 - categorical_accuracy: 0.9049\n",
      "Epoch 00011: val_loss improved from 0.31270 to 0.30729, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 223us/sample - loss: 0.3265 - categorical_accuracy: 0.9047 - val_loss: 0.3073 - val_categorical_accuracy: 0.9185\n",
      "Epoch 12/100\n",
      "24384/24640 [============================>.] - ETA: 0s - loss: 0.3065 - categorical_accuracy: 0.9126\n",
      "Epoch 00012: val_loss did not improve from 0.30729\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.3064 - categorical_accuracy: 0.9125 - val_loss: 0.3095 - val_categorical_accuracy: 0.9179\n",
      "Epoch 13/100\n",
      "24480/24640 [============================>.] - ETA: 0s - loss: 0.2799 - categorical_accuracy: 0.9190\n",
      "Epoch 00013: val_loss improved from 0.30729 to 0.28011, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 224us/sample - loss: 0.2793 - categorical_accuracy: 0.9192 - val_loss: 0.2801 - val_categorical_accuracy: 0.9266\n",
      "Epoch 14/100\n",
      "24608/24640 [============================>.] - ETA: 0s - loss: 0.2695 - categorical_accuracy: 0.9216\n",
      "Epoch 00014: val_loss improved from 0.28011 to 0.25157, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 222us/sample - loss: 0.2696 - categorical_accuracy: 0.9216 - val_loss: 0.2516 - val_categorical_accuracy: 0.9380\n",
      "Epoch 15/100\n",
      "24576/24640 [============================>.] - ETA: 0s - loss: 0.2505 - categorical_accuracy: 0.9281\n",
      "Epoch 00015: val_loss improved from 0.25157 to 0.23096, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 224us/sample - loss: 0.2503 - categorical_accuracy: 0.9281 - val_loss: 0.2310 - val_categorical_accuracy: 0.9422\n",
      "Epoch 16/100\n",
      "24512/24640 [============================>.] - ETA: 0s - loss: 0.2419 - categorical_accuracy: 0.9324\n",
      "Epoch 00016: val_loss did not improve from 0.23096\n",
      "24640/24640 [==============================] - 5s 218us/sample - loss: 0.2416 - categorical_accuracy: 0.9325 - val_loss: 0.2530 - val_categorical_accuracy: 0.9396\n",
      "Epoch 17/100\n",
      "24512/24640 [============================>.] - ETA: 0s - loss: 0.2274 - categorical_accuracy: 0.9369\n",
      "Epoch 00017: val_loss did not improve from 0.23096\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.2273 - categorical_accuracy: 0.9369 - val_loss: 0.2403 - val_categorical_accuracy: 0.9380\n",
      "Epoch 18/100\n",
      "24448/24640 [============================>.] - ETA: 0s - loss: 0.2205 - categorical_accuracy: 0.9398\n",
      "Epoch 00018: val_loss improved from 0.23096 to 0.22694, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 6s 226us/sample - loss: 0.2203 - categorical_accuracy: 0.9399 - val_loss: 0.2269 - val_categorical_accuracy: 0.9471\n",
      "Epoch 19/100\n",
      "24448/24640 [============================>.] - ETA: 0s - loss: 0.2115 - categorical_accuracy: 0.9405\n",
      "Epoch 00019: val_loss did not improve from 0.22694\n",
      "24640/24640 [==============================] - 5s 223us/sample - loss: 0.2111 - categorical_accuracy: 0.9406 - val_loss: 0.2322 - val_categorical_accuracy: 0.9461\n",
      "Epoch 20/100\n",
      "24512/24640 [============================>.] - ETA: 0s - loss: 0.2049 - categorical_accuracy: 0.9441\n",
      "Epoch 00020: val_loss improved from 0.22694 to 0.22656, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 222us/sample - loss: 0.2049 - categorical_accuracy: 0.9442 - val_loss: 0.2266 - val_categorical_accuracy: 0.9497\n",
      "Epoch 21/100\n",
      "24576/24640 [============================>.] - ETA: 0s - loss: 0.1932 - categorical_accuracy: 0.9473\n",
      "Epoch 00021: val_loss did not improve from 0.22656\n",
      "24640/24640 [==============================] - 5s 211us/sample - loss: 0.1931 - categorical_accuracy: 0.9474 - val_loss: 0.2445 - val_categorical_accuracy: 0.9464\n",
      "Epoch 22/100\n",
      "24448/24640 [============================>.] - ETA: 0s - loss: 0.1885 - categorical_accuracy: 0.9499\n",
      "Epoch 00022: val_loss did not improve from 0.22656\n",
      "24640/24640 [==============================] - 5s 222us/sample - loss: 0.1884 - categorical_accuracy: 0.9500 - val_loss: 0.2334 - val_categorical_accuracy: 0.9487\n",
      "Epoch 23/100\n",
      "24384/24640 [============================>.] - ETA: 0s - loss: 0.1845 - categorical_accuracy: 0.9494\n",
      "Epoch 00023: val_loss did not improve from 0.22656\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.1845 - categorical_accuracy: 0.9494 - val_loss: 0.2580 - val_categorical_accuracy: 0.9435\n",
      "Epoch 24/100\n",
      "24384/24640 [============================>.] - ETA: 0s - loss: 0.1799 - categorical_accuracy: 0.9533\n",
      "Epoch 00024: val_loss did not improve from 0.22656\n",
      "24640/24640 [==============================] - 5s 223us/sample - loss: 0.1802 - categorical_accuracy: 0.9531 - val_loss: 0.2279 - val_categorical_accuracy: 0.9555\n",
      "Epoch 25/100\n",
      "24384/24640 [============================>.] - ETA: 0s - loss: 0.1681 - categorical_accuracy: 0.9554\n",
      "Epoch 00025: val_loss improved from 0.22656 to 0.21956, saving model to t_weights_1\n",
      "24640/24640 [==============================] - 5s 223us/sample - loss: 0.1682 - categorical_accuracy: 0.9553 - val_loss: 0.2196 - val_categorical_accuracy: 0.9536\n",
      "Epoch 26/100\n",
      "24576/24640 [============================>.] - ETA: 0s - loss: 0.1666 - categorical_accuracy: 0.9565\n",
      "Epoch 00026: val_loss did not improve from 0.21956\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.1664 - categorical_accuracy: 0.9566 - val_loss: 0.2355 - val_categorical_accuracy: 0.9539\n",
      "Epoch 27/100\n",
      "24512/24640 [============================>.] - ETA: 0s - loss: 0.1721 - categorical_accuracy: 0.9550\n",
      "Epoch 00027: val_loss did not improve from 0.21956\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.1721 - categorical_accuracy: 0.9550 - val_loss: 0.2455 - val_categorical_accuracy: 0.9474\n",
      "Epoch 28/100\n",
      "24448/24640 [============================>.] - ETA: 0s - loss: 0.1604 - categorical_accuracy: 0.9579\n",
      "Epoch 00028: val_loss did not improve from 0.21956\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.1612 - categorical_accuracy: 0.9578 - val_loss: 0.2510 - val_categorical_accuracy: 0.9442\n",
      "Epoch 29/100\n",
      "24544/24640 [============================>.] - ETA: 0s - loss: 0.1612 - categorical_accuracy: 0.9584\n",
      "Epoch 00029: val_loss did not improve from 0.21956\n",
      "24640/24640 [==============================] - 5s 198us/sample - loss: 0.1615 - categorical_accuracy: 0.9582 - val_loss: 0.2950 - val_categorical_accuracy: 0.9269\n",
      "Epoch 30/100\n",
      "24352/24640 [============================>.] - ETA: 0s - loss: 0.1576 - categorical_accuracy: 0.9595\n",
      "Epoch 00030: val_loss did not improve from 0.21956\n",
      "24640/24640 [==============================] - 5s 220us/sample - loss: 0.1580 - categorical_accuracy: 0.9596 - val_loss: 0.2308 - val_categorical_accuracy: 0.9545\n",
      "0.95681816 0.438\n",
      "\n",
      "\n",
      "nrx: 20 - real: 1 \n",
      "Train on 32160 samples, validate on 4020 samples\n",
      "Epoch 1/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 1.8825 - categorical_accuracy: 0.3120\n",
      "Epoch 00001: val_loss improved from inf to 1.43005, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 229us/sample - loss: 1.8801 - categorical_accuracy: 0.3130 - val_loss: 1.4300 - val_categorical_accuracy: 0.5488\n",
      "Epoch 2/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 1.2745 - categorical_accuracy: 0.5638\n",
      "Epoch 00002: val_loss improved from 1.43005 to 1.00437, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 1.2736 - categorical_accuracy: 0.5641 - val_loss: 1.0044 - val_categorical_accuracy: 0.6786\n",
      "Epoch 3/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 0.9080 - categorical_accuracy: 0.6982\n",
      "Epoch 00003: val_loss improved from 1.00437 to 0.70506, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 224us/sample - loss: 0.9073 - categorical_accuracy: 0.6985 - val_loss: 0.7051 - val_categorical_accuracy: 0.7796\n",
      "Epoch 4/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 0.7152 - categorical_accuracy: 0.7698\n",
      "Epoch 00004: val_loss improved from 0.70506 to 0.55430, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 224us/sample - loss: 0.7149 - categorical_accuracy: 0.7698 - val_loss: 0.5543 - val_categorical_accuracy: 0.8328\n",
      "Epoch 5/100\n",
      "31936/32160 [============================>.] - ETA: 0s - loss: 0.6008 - categorical_accuracy: 0.8093\n",
      "Epoch 00005: val_loss improved from 0.55430 to 0.49188, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 0.6002 - categorical_accuracy: 0.8096 - val_loss: 0.4919 - val_categorical_accuracy: 0.8522\n",
      "Epoch 6/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 0.5192 - categorical_accuracy: 0.8384\n",
      "Epoch 00006: val_loss improved from 0.49188 to 0.40583, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 0.5190 - categorical_accuracy: 0.8385 - val_loss: 0.4058 - val_categorical_accuracy: 0.8828\n",
      "Epoch 7/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.8573\n",
      "Epoch 00007: val_loss improved from 0.40583 to 0.38632, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 223us/sample - loss: 0.4620 - categorical_accuracy: 0.8574 - val_loss: 0.3863 - val_categorical_accuracy: 0.8843\n",
      "Epoch 8/100\n",
      "32032/32160 [============================>.] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8685\n",
      "Epoch 00008: val_loss improved from 0.38632 to 0.37031, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 224us/sample - loss: 0.4234 - categorical_accuracy: 0.8686 - val_loss: 0.3703 - val_categorical_accuracy: 0.8925\n",
      "Epoch 9/100\n",
      "31936/32160 [============================>.] - ETA: 0s - loss: 0.3909 - categorical_accuracy: 0.8809\n",
      "Epoch 00009: val_loss improved from 0.37031 to 0.34399, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 223us/sample - loss: 0.3918 - categorical_accuracy: 0.8808 - val_loss: 0.3440 - val_categorical_accuracy: 0.8990\n",
      "Epoch 10/100\n",
      "32096/32160 [============================>.] - ETA: 0s - loss: 0.3643 - categorical_accuracy: 0.8894\n",
      "Epoch 00010: val_loss improved from 0.34399 to 0.31660, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 216us/sample - loss: 0.3641 - categorical_accuracy: 0.8894 - val_loss: 0.3166 - val_categorical_accuracy: 0.9085\n",
      "Epoch 11/100\n",
      "32032/32160 [============================>.] - ETA: 0s - loss: 0.3454 - categorical_accuracy: 0.8949\n",
      "Epoch 00011: val_loss improved from 0.31660 to 0.31235, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 0.3451 - categorical_accuracy: 0.8950 - val_loss: 0.3124 - val_categorical_accuracy: 0.9080\n",
      "Epoch 12/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.3253 - categorical_accuracy: 0.9024\n",
      "Epoch 00012: val_loss improved from 0.31235 to 0.29046, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 226us/sample - loss: 0.3251 - categorical_accuracy: 0.9024 - val_loss: 0.2905 - val_categorical_accuracy: 0.9144\n",
      "Epoch 13/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 0.3143 - categorical_accuracy: 0.9040\n",
      "Epoch 00013: val_loss did not improve from 0.29046\n",
      "32160/32160 [==============================] - 7s 222us/sample - loss: 0.3145 - categorical_accuracy: 0.9040 - val_loss: 0.2918 - val_categorical_accuracy: 0.9142\n",
      "Epoch 14/100\n",
      "31936/32160 [============================>.] - ETA: 0s - loss: 0.3061 - categorical_accuracy: 0.9085\n",
      "Epoch 00014: val_loss improved from 0.29046 to 0.28722, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 0.3062 - categorical_accuracy: 0.9085 - val_loss: 0.2872 - val_categorical_accuracy: 0.9174\n",
      "Epoch 15/100\n",
      "32096/32160 [============================>.] - ETA: 0s - loss: 0.2891 - categorical_accuracy: 0.9144\n",
      "Epoch 00015: val_loss improved from 0.28722 to 0.28285, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 224us/sample - loss: 0.2889 - categorical_accuracy: 0.9144 - val_loss: 0.2828 - val_categorical_accuracy: 0.9204\n",
      "Epoch 16/100\n",
      "32128/32160 [============================>.] - ETA: 0s - loss: 0.2782 - categorical_accuracy: 0.9157\n",
      "Epoch 00016: val_loss did not improve from 0.28285\n",
      "32160/32160 [==============================] - 7s 222us/sample - loss: 0.2785 - categorical_accuracy: 0.9156 - val_loss: 0.2878 - val_categorical_accuracy: 0.9197\n",
      "Epoch 17/100\n",
      "32128/32160 [============================>.] - ETA: 0s - loss: 0.2676 - categorical_accuracy: 0.9198\n",
      "Epoch 00017: val_loss improved from 0.28285 to 0.27429, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 0.2676 - categorical_accuracy: 0.9197 - val_loss: 0.2743 - val_categorical_accuracy: 0.9214\n",
      "Epoch 18/100\n",
      "32064/32160 [============================>.] - ETA: 0s - loss: 0.2628 - categorical_accuracy: 0.9208\n",
      "Epoch 00018: val_loss did not improve from 0.27429\n",
      "32160/32160 [==============================] - 7s 219us/sample - loss: 0.2629 - categorical_accuracy: 0.9207 - val_loss: 0.2861 - val_categorical_accuracy: 0.9179\n",
      "Epoch 19/100\n",
      "31904/32160 [============================>.] - ETA: 0s - loss: 0.2541 - categorical_accuracy: 0.9245\n",
      "Epoch 00019: val_loss improved from 0.27429 to 0.26849, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 226us/sample - loss: 0.2541 - categorical_accuracy: 0.9245 - val_loss: 0.2685 - val_categorical_accuracy: 0.9254\n",
      "Epoch 20/100\n",
      "31936/32160 [============================>.] - ETA: 0s - loss: 0.2460 - categorical_accuracy: 0.9271\n",
      "Epoch 00020: val_loss did not improve from 0.26849\n",
      "32160/32160 [==============================] - 7s 223us/sample - loss: 0.2457 - categorical_accuracy: 0.9272 - val_loss: 0.2872 - val_categorical_accuracy: 0.9152\n",
      "Epoch 21/100\n",
      "31904/32160 [============================>.] - ETA: 0s - loss: 0.2423 - categorical_accuracy: 0.9271\n",
      "Epoch 00021: val_loss did not improve from 0.26849\n",
      "32160/32160 [==============================] - 7s 224us/sample - loss: 0.2425 - categorical_accuracy: 0.9271 - val_loss: 0.3013 - val_categorical_accuracy: 0.9194\n",
      "Epoch 22/100\n",
      "31904/32160 [============================>.] - ETA: 0s - loss: 0.2375 - categorical_accuracy: 0.9293\n",
      "Epoch 00022: val_loss improved from 0.26849 to 0.24987, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 225us/sample - loss: 0.2374 - categorical_accuracy: 0.9294 - val_loss: 0.2499 - val_categorical_accuracy: 0.9311\n",
      "Epoch 23/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 0.2305 - categorical_accuracy: 0.9324\n",
      "Epoch 00023: val_loss did not improve from 0.24987\n",
      "32160/32160 [==============================] - 7s 207us/sample - loss: 0.2307 - categorical_accuracy: 0.9324 - val_loss: 0.2737 - val_categorical_accuracy: 0.9254\n",
      "Epoch 24/100\n",
      "32128/32160 [============================>.] - ETA: 0s - loss: 0.2264 - categorical_accuracy: 0.9329\n",
      "Epoch 00024: val_loss improved from 0.24987 to 0.24955, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 223us/sample - loss: 0.2264 - categorical_accuracy: 0.9329 - val_loss: 0.2496 - val_categorical_accuracy: 0.9306\n",
      "Epoch 25/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.2202 - categorical_accuracy: 0.9356\n",
      "Epoch 00025: val_loss did not improve from 0.24955\n",
      "32160/32160 [==============================] - 7s 209us/sample - loss: 0.2202 - categorical_accuracy: 0.9355 - val_loss: 0.2606 - val_categorical_accuracy: 0.9318\n",
      "Epoch 26/100\n",
      "32064/32160 [============================>.] - ETA: 0s - loss: 0.2154 - categorical_accuracy: 0.9379\n",
      "Epoch 00026: val_loss did not improve from 0.24955\n",
      "32160/32160 [==============================] - 7s 223us/sample - loss: 0.2151 - categorical_accuracy: 0.9380 - val_loss: 0.3041 - val_categorical_accuracy: 0.9256\n",
      "Epoch 27/100\n",
      "31904/32160 [============================>.] - ETA: 0s - loss: 0.2189 - categorical_accuracy: 0.9362\n",
      "Epoch 00027: val_loss improved from 0.24955 to 0.24161, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 219us/sample - loss: 0.2187 - categorical_accuracy: 0.9361 - val_loss: 0.2416 - val_categorical_accuracy: 0.9358\n",
      "Epoch 28/100\n",
      "31904/32160 [============================>.] - ETA: 0s - loss: 0.2082 - categorical_accuracy: 0.9390\n",
      "Epoch 00028: val_loss improved from 0.24161 to 0.24103, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 224us/sample - loss: 0.2079 - categorical_accuracy: 0.9392 - val_loss: 0.2410 - val_categorical_accuracy: 0.9361\n",
      "Epoch 29/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.2105 - categorical_accuracy: 0.9379\n",
      "Epoch 00029: val_loss did not improve from 0.24103\n",
      "32160/32160 [==============================] - 7s 223us/sample - loss: 0.2100 - categorical_accuracy: 0.9380 - val_loss: 0.2416 - val_categorical_accuracy: 0.9353\n",
      "Epoch 30/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9418\n",
      "Epoch 00030: val_loss improved from 0.24103 to 0.24008, saving model to t_weights_1\n",
      "32160/32160 [==============================] - 7s 226us/sample - loss: 0.2003 - categorical_accuracy: 0.9418 - val_loss: 0.2401 - val_categorical_accuracy: 0.9363\n",
      "Epoch 31/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9422\n",
      "Epoch 00031: val_loss did not improve from 0.24008\n",
      "32160/32160 [==============================] - 7s 222us/sample - loss: 0.1997 - categorical_accuracy: 0.9423 - val_loss: 0.2768 - val_categorical_accuracy: 0.9299\n",
      "Epoch 32/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.1973 - categorical_accuracy: 0.9428\n",
      "Epoch 00032: val_loss did not improve from 0.24008\n",
      "32160/32160 [==============================] - 7s 208us/sample - loss: 0.1971 - categorical_accuracy: 0.9428 - val_loss: 0.2537 - val_categorical_accuracy: 0.9358\n",
      "Epoch 33/100\n",
      "31968/32160 [============================>.] - ETA: 0s - loss: 0.1943 - categorical_accuracy: 0.9449\n",
      "Epoch 00033: val_loss did not improve from 0.24008\n",
      "32160/32160 [==============================] - 7s 220us/sample - loss: 0.1943 - categorical_accuracy: 0.9449 - val_loss: 0.2433 - val_categorical_accuracy: 0.9371\n",
      "Epoch 34/100\n",
      "32128/32160 [============================>.] - ETA: 0s - loss: 0.1951 - categorical_accuracy: 0.9435\n",
      "Epoch 00034: val_loss did not improve from 0.24008\n",
      "32160/32160 [==============================] - 7s 222us/sample - loss: 0.1950 - categorical_accuracy: 0.9435 - val_loss: 0.2548 - val_categorical_accuracy: 0.9358\n",
      "Epoch 35/100\n",
      "32000/32160 [============================>.] - ETA: 0s - loss: 0.1864 - categorical_accuracy: 0.9470\n",
      "Epoch 00035: val_loss did not improve from 0.24008\n",
      "32160/32160 [==============================] - 7s 216us/sample - loss: 0.1862 - categorical_accuracy: 0.9470 - val_loss: 0.2497 - val_categorical_accuracy: 0.9371\n",
      "0.93955225 0.6864\n",
      "\n",
      "\n",
      "nrx: 25 - real: 1 \n",
      "Train on 40136 samples, validate on 5017 samples\n",
      "Epoch 1/100\n",
      "39968/40136 [============================>.] - ETA: 0s - loss: 1.8736 - categorical_accuracy: 0.3041\n",
      "Epoch 00001: val_loss improved from inf to 1.40427, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 233us/sample - loss: 1.8719 - categorical_accuracy: 0.3048 - val_loss: 1.4043 - val_categorical_accuracy: 0.5087\n",
      "Epoch 2/100\n",
      "40096/40136 [============================>.] - ETA: 0s - loss: 1.2305 - categorical_accuracy: 0.5682\n",
      "Epoch 00002: val_loss improved from 1.40427 to 0.92322, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 225us/sample - loss: 1.2305 - categorical_accuracy: 0.5683 - val_loss: 0.9232 - val_categorical_accuracy: 0.7060\n",
      "Epoch 3/100\n",
      "39936/40136 [============================>.] - ETA: 0s - loss: 0.9024 - categorical_accuracy: 0.6974\n",
      "Epoch 00003: val_loss improved from 0.92322 to 0.64303, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.9019 - categorical_accuracy: 0.6977 - val_loss: 0.6430 - val_categorical_accuracy: 0.7909\n",
      "Epoch 4/100\n",
      "40096/40136 [============================>.] - ETA: 0s - loss: 0.6901 - categorical_accuracy: 0.7757\n",
      "Epoch 00004: val_loss improved from 0.64303 to 0.53702, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 226us/sample - loss: 0.6900 - categorical_accuracy: 0.7757 - val_loss: 0.5370 - val_categorical_accuracy: 0.8318\n",
      "Epoch 5/100\n",
      "39968/40136 [============================>.] - ETA: 0s - loss: 0.5657 - categorical_accuracy: 0.8198\n",
      "Epoch 00005: val_loss improved from 0.53702 to 0.46121, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.5654 - categorical_accuracy: 0.8199 - val_loss: 0.4612 - val_categorical_accuracy: 0.8603\n",
      "Epoch 6/100\n",
      "39904/40136 [============================>.] - ETA: 0s - loss: 0.4883 - categorical_accuracy: 0.8453\n",
      "Epoch 00006: val_loss improved from 0.46121 to 0.41967, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 225us/sample - loss: 0.4880 - categorical_accuracy: 0.8453 - val_loss: 0.4197 - val_categorical_accuracy: 0.8722\n",
      "Epoch 7/100\n",
      "39904/40136 [============================>.] - ETA: 0s - loss: 0.4373 - categorical_accuracy: 0.8636\n",
      "Epoch 00007: val_loss improved from 0.41967 to 0.37152, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 221us/sample - loss: 0.4377 - categorical_accuracy: 0.8635 - val_loss: 0.3715 - val_categorical_accuracy: 0.8848\n",
      "Epoch 8/100\n",
      "40032/40136 [============================>.] - ETA: 0s - loss: 0.4028 - categorical_accuracy: 0.8756\n",
      "Epoch 00008: val_loss improved from 0.37152 to 0.37106, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 225us/sample - loss: 0.4029 - categorical_accuracy: 0.8756 - val_loss: 0.3711 - val_categorical_accuracy: 0.8872\n",
      "Epoch 9/100\n",
      "40000/40136 [============================>.] - ETA: 0s - loss: 0.3679 - categorical_accuracy: 0.8856\n",
      "Epoch 00009: val_loss improved from 0.37106 to 0.36390, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 216us/sample - loss: 0.3678 - categorical_accuracy: 0.8856 - val_loss: 0.3639 - val_categorical_accuracy: 0.8910\n",
      "Epoch 10/100\n",
      "39936/40136 [============================>.] - ETA: 0s - loss: 0.3543 - categorical_accuracy: 0.8905\n",
      "Epoch 00010: val_loss improved from 0.36390 to 0.33547, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.3542 - categorical_accuracy: 0.8906 - val_loss: 0.3355 - val_categorical_accuracy: 0.8993\n",
      "Epoch 11/100\n",
      "40064/40136 [============================>.] - ETA: 0s - loss: 0.3371 - categorical_accuracy: 0.8961\n",
      "Epoch 00011: val_loss improved from 0.33547 to 0.31425, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.3370 - categorical_accuracy: 0.8960 - val_loss: 0.3142 - val_categorical_accuracy: 0.9039\n",
      "Epoch 12/100\n",
      "40032/40136 [============================>.] - ETA: 0s - loss: 0.3217 - categorical_accuracy: 0.9001\n",
      "Epoch 00012: val_loss improved from 0.31425 to 0.31253, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 226us/sample - loss: 0.3221 - categorical_accuracy: 0.9000 - val_loss: 0.3125 - val_categorical_accuracy: 0.9057\n",
      "Epoch 13/100\n",
      "39904/40136 [============================>.] - ETA: 0s - loss: 0.3114 - categorical_accuracy: 0.9029\n",
      "Epoch 00013: val_loss improved from 0.31253 to 0.29376, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 226us/sample - loss: 0.3117 - categorical_accuracy: 0.9029 - val_loss: 0.2938 - val_categorical_accuracy: 0.9115\n",
      "Epoch 14/100\n",
      "40032/40136 [============================>.] - ETA: 0s - loss: 0.3028 - categorical_accuracy: 0.9075\n",
      "Epoch 00014: val_loss improved from 0.29376 to 0.29292, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 220us/sample - loss: 0.3025 - categorical_accuracy: 0.9077 - val_loss: 0.2929 - val_categorical_accuracy: 0.9123\n",
      "Epoch 15/100\n",
      "39968/40136 [============================>.] - ETA: 0s - loss: 0.2916 - categorical_accuracy: 0.9112\n",
      "Epoch 00015: val_loss did not improve from 0.29292\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.2916 - categorical_accuracy: 0.9112 - val_loss: 0.3032 - val_categorical_accuracy: 0.9139\n",
      "Epoch 16/100\n",
      "40096/40136 [============================>.] - ETA: 0s - loss: 0.2814 - categorical_accuracy: 0.9143\n",
      "Epoch 00016: val_loss did not improve from 0.29292\n",
      "40136/40136 [==============================] - 9s 225us/sample - loss: 0.2816 - categorical_accuracy: 0.9143 - val_loss: 0.3025 - val_categorical_accuracy: 0.9143\n",
      "Epoch 17/100\n",
      "40032/40136 [============================>.] - ETA: 0s - loss: 0.2808 - categorical_accuracy: 0.9146\n",
      "Epoch 00017: val_loss improved from 0.29292 to 0.28302, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 225us/sample - loss: 0.2806 - categorical_accuracy: 0.9146 - val_loss: 0.2830 - val_categorical_accuracy: 0.9163\n",
      "Epoch 18/100\n",
      "40096/40136 [============================>.] - ETA: 0s - loss: 0.2754 - categorical_accuracy: 0.9164\n",
      "Epoch 00018: val_loss improved from 0.28302 to 0.27371, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.2755 - categorical_accuracy: 0.9163 - val_loss: 0.2737 - val_categorical_accuracy: 0.9179\n",
      "Epoch 19/100\n",
      "40128/40136 [============================>.] - ETA: 0s - loss: 0.2620 - categorical_accuracy: 0.9202\n",
      "Epoch 00019: val_loss improved from 0.27371 to 0.27258, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 227us/sample - loss: 0.2620 - categorical_accuracy: 0.9201 - val_loss: 0.2726 - val_categorical_accuracy: 0.9173\n",
      "Epoch 20/100\n",
      "40128/40136 [============================>.] - ETA: 0s - loss: 0.2600 - categorical_accuracy: 0.9206\n",
      "Epoch 00020: val_loss did not improve from 0.27258\n",
      "40136/40136 [==============================] - 9s 217us/sample - loss: 0.2599 - categorical_accuracy: 0.9206 - val_loss: 0.2753 - val_categorical_accuracy: 0.9209\n",
      "Epoch 21/100\n",
      "40000/40136 [============================>.] - ETA: 0s - loss: 0.2539 - categorical_accuracy: 0.9228\n",
      "Epoch 00021: val_loss did not improve from 0.27258\n",
      "40136/40136 [==============================] - 9s 223us/sample - loss: 0.2538 - categorical_accuracy: 0.9229 - val_loss: 0.2932 - val_categorical_accuracy: 0.9203\n",
      "Epoch 22/100\n",
      "39936/40136 [============================>.] - ETA: 0s - loss: 0.2497 - categorical_accuracy: 0.9232\n",
      "Epoch 00022: val_loss did not improve from 0.27258\n",
      "40136/40136 [==============================] - 9s 224us/sample - loss: 0.2497 - categorical_accuracy: 0.9232 - val_loss: 0.2818 - val_categorical_accuracy: 0.9201\n",
      "Epoch 23/100\n",
      "40128/40136 [============================>.] - ETA: 0s - loss: 0.2409 - categorical_accuracy: 0.9269\n",
      "Epoch 00023: val_loss improved from 0.27258 to 0.26309, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 226us/sample - loss: 0.2409 - categorical_accuracy: 0.9268 - val_loss: 0.2631 - val_categorical_accuracy: 0.9251\n",
      "Epoch 24/100\n",
      "40000/40136 [============================>.] - ETA: 0s - loss: 0.2404 - categorical_accuracy: 0.9281\n",
      "Epoch 00024: val_loss improved from 0.26309 to 0.25901, saving model to t_weights_1\n",
      "40136/40136 [==============================] - 9s 226us/sample - loss: 0.2403 - categorical_accuracy: 0.9281 - val_loss: 0.2590 - val_categorical_accuracy: 0.9284\n",
      "Epoch 25/100\n",
      "40096/40136 [============================>.] - ETA: 0s - loss: 0.2423 - categorical_accuracy: 0.9259\n",
      "Epoch 00025: val_loss did not improve from 0.25901\n",
      "40136/40136 [==============================] - 8s 211us/sample - loss: 0.2424 - categorical_accuracy: 0.9259 - val_loss: 0.2648 - val_categorical_accuracy: 0.9274\n",
      "Epoch 26/100\n",
      "39968/40136 [============================>.] - ETA: 0s - loss: 0.2312 - categorical_accuracy: 0.9303\n",
      "Epoch 00026: val_loss did not improve from 0.25901\n",
      "40136/40136 [==============================] - 9s 220us/sample - loss: 0.2316 - categorical_accuracy: 0.9301 - val_loss: 0.2665 - val_categorical_accuracy: 0.9257\n",
      "Epoch 27/100\n",
      "40096/40136 [============================>.] - ETA: 0s - loss: 0.2328 - categorical_accuracy: 0.9294\n",
      "Epoch 00027: val_loss did not improve from 0.25901\n",
      "40136/40136 [==============================] - 9s 220us/sample - loss: 0.2327 - categorical_accuracy: 0.9295 - val_loss: 0.2645 - val_categorical_accuracy: 0.9272\n",
      "Epoch 28/100\n",
      "39936/40136 [============================>.] - ETA: 0s - loss: 0.2294 - categorical_accuracy: 0.9306\n",
      "Epoch 00028: val_loss did not improve from 0.25901\n",
      "40136/40136 [==============================] - 9s 222us/sample - loss: 0.2294 - categorical_accuracy: 0.9306 - val_loss: 0.2774 - val_categorical_accuracy: 0.9257\n",
      "Epoch 29/100\n",
      "39936/40136 [============================>.] - ETA: 0s - loss: 0.2276 - categorical_accuracy: 0.9315\n",
      "Epoch 00029: val_loss did not improve from 0.25901\n",
      "40136/40136 [==============================] - 9s 223us/sample - loss: 0.2276 - categorical_accuracy: 0.9314 - val_loss: 0.2663 - val_categorical_accuracy: 0.9253\n",
      "0.9280447 0.7775\n",
      "\n",
      "\n",
      "nrx: 0 - real: 2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cls_weights = np.max(stat,axis=0)/stat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 2.3168 - categorical_accuracy: 0.1370\n",
      "Epoch 00001: val_loss improved from inf to 2.29227, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 1s 459us/sample - loss: 2.3160 - categorical_accuracy: 0.1388 - val_loss: 2.2923 - val_categorical_accuracy: 0.2350\n",
      "Epoch 2/100\n",
      "1376/1600 [========================>.....] - ETA: 0s - loss: 2.2217 - categorical_accuracy: 0.2456\n",
      "Epoch 00002: val_loss improved from 2.29227 to 1.94983, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 268us/sample - loss: 2.2008 - categorical_accuracy: 0.2519 - val_loss: 1.9498 - val_categorical_accuracy: 0.4050\n",
      "Epoch 3/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 1.6952 - categorical_accuracy: 0.3939\n",
      "Epoch 00003: val_loss improved from 1.94983 to 1.15491, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 282us/sample - loss: 1.6801 - categorical_accuracy: 0.4006 - val_loss: 1.1549 - val_categorical_accuracy: 0.7850\n",
      "Epoch 4/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 1.1784 - categorical_accuracy: 0.5818\n",
      "Epoch 00004: val_loss improved from 1.15491 to 0.72999, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 280us/sample - loss: 1.1693 - categorical_accuracy: 0.5863 - val_loss: 0.7300 - val_categorical_accuracy: 0.9100\n",
      "Epoch 5/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.7879 - categorical_accuracy: 0.7423\n",
      "Epoch 00005: val_loss improved from 0.72999 to 0.35894, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 281us/sample - loss: 0.7844 - categorical_accuracy: 0.7419 - val_loss: 0.3589 - val_categorical_accuracy: 0.9650\n",
      "Epoch 6/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.5740 - categorical_accuracy: 0.8139\n",
      "Epoch 00006: val_loss improved from 0.35894 to 0.25572, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 242us/sample - loss: 0.5661 - categorical_accuracy: 0.8200 - val_loss: 0.2557 - val_categorical_accuracy: 0.9700\n",
      "Epoch 7/100\n",
      "1376/1600 [========================>.....] - ETA: 0s - loss: 0.4110 - categorical_accuracy: 0.8765\n",
      "Epoch 00007: val_loss improved from 0.25572 to 0.15284, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 252us/sample - loss: 0.4016 - categorical_accuracy: 0.8806 - val_loss: 0.1528 - val_categorical_accuracy: 0.9850\n",
      "Epoch 8/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.3576 - categorical_accuracy: 0.8899\n",
      "Epoch 00008: val_loss improved from 0.15284 to 0.12894, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 269us/sample - loss: 0.3485 - categorical_accuracy: 0.8925 - val_loss: 0.1289 - val_categorical_accuracy: 0.9900\n",
      "Epoch 9/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2966 - categorical_accuracy: 0.9088\n",
      "Epoch 00009: val_loss improved from 0.12894 to 0.09103, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 278us/sample - loss: 0.2965 - categorical_accuracy: 0.9094 - val_loss: 0.0910 - val_categorical_accuracy: 0.9950\n",
      "Epoch 10/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9206\n",
      "Epoch 00010: val_loss improved from 0.09103 to 0.07102, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 273us/sample - loss: 0.2510 - categorical_accuracy: 0.9206 - val_loss: 0.0710 - val_categorical_accuracy: 0.9950\n",
      "Epoch 11/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.1892 - categorical_accuracy: 0.9471\n",
      "Epoch 00011: val_loss improved from 0.07102 to 0.05258, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 271us/sample - loss: 0.1886 - categorical_accuracy: 0.9475 - val_loss: 0.0526 - val_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.1773 - categorical_accuracy: 0.9524\n",
      "Epoch 00012: val_loss did not improve from 0.05258\n",
      "1600/1600 [==============================] - 0s 203us/sample - loss: 0.1751 - categorical_accuracy: 0.9531 - val_loss: 0.0544 - val_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.1866 - categorical_accuracy: 0.9452\n",
      "Epoch 00013: val_loss did not improve from 0.05258\n",
      "1600/1600 [==============================] - 0s 229us/sample - loss: 0.1846 - categorical_accuracy: 0.9463 - val_loss: 0.0716 - val_categorical_accuracy: 0.9900\n",
      "Epoch 14/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.1470 - categorical_accuracy: 0.9643\n",
      "Epoch 00014: val_loss improved from 0.05258 to 0.03903, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 272us/sample - loss: 0.1466 - categorical_accuracy: 0.9644 - val_loss: 0.0390 - val_categorical_accuracy: 0.9950\n",
      "Epoch 15/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.9772\n",
      "Epoch 00015: val_loss improved from 0.03903 to 0.03348, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 282us/sample - loss: 0.1137 - categorical_accuracy: 0.9769 - val_loss: 0.0335 - val_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.1078 - categorical_accuracy: 0.9741\n",
      "Epoch 00016: val_loss did not improve from 0.03348\n",
      "1600/1600 [==============================] - 0s 237us/sample - loss: 0.1105 - categorical_accuracy: 0.9731 - val_loss: 0.0380 - val_categorical_accuracy: 0.9950\n",
      "Epoch 17/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0933 - categorical_accuracy: 0.9811\n",
      "Epoch 00017: val_loss improved from 0.03348 to 0.03150, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 263us/sample - loss: 0.0928 - categorical_accuracy: 0.9812 - val_loss: 0.0315 - val_categorical_accuracy: 0.9950\n",
      "Epoch 18/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.0944 - categorical_accuracy: 0.9787\n",
      "Epoch 00018: val_loss improved from 0.03150 to 0.03136, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 227us/sample - loss: 0.0940 - categorical_accuracy: 0.9787 - val_loss: 0.0314 - val_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9820\n",
      "Epoch 00019: val_loss did not improve from 0.03136\n",
      "1600/1600 [==============================] - 0s 230us/sample - loss: 0.0831 - categorical_accuracy: 0.9819 - val_loss: 0.0340 - val_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9777\n",
      "Epoch 00020: val_loss improved from 0.03136 to 0.02585, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 262us/sample - loss: 0.0903 - categorical_accuracy: 0.9781 - val_loss: 0.0259 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0670 - categorical_accuracy: 0.9857\n",
      "Epoch 00021: val_loss did not improve from 0.02585\n",
      "1600/1600 [==============================] - 0s 235us/sample - loss: 0.0673 - categorical_accuracy: 0.9856 - val_loss: 0.0298 - val_categorical_accuracy: 0.9950\n",
      "Epoch 22/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.0910 - categorical_accuracy: 0.9771\n",
      "Epoch 00022: val_loss improved from 0.02585 to 0.02572, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 282us/sample - loss: 0.0903 - categorical_accuracy: 0.9769 - val_loss: 0.0257 - val_categorical_accuracy: 0.9950\n",
      "Epoch 23/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0701 - categorical_accuracy: 0.9857\n",
      "Epoch 00023: val_loss did not improve from 0.02572\n",
      "1600/1600 [==============================] - 0s 235us/sample - loss: 0.0710 - categorical_accuracy: 0.9856 - val_loss: 0.0275 - val_categorical_accuracy: 0.9950\n",
      "Epoch 24/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.0774 - categorical_accuracy: 0.9840\n",
      "Epoch 00024: val_loss did not improve from 0.02572\n",
      "1600/1600 [==============================] - 0s 206us/sample - loss: 0.0768 - categorical_accuracy: 0.9844 - val_loss: 0.0279 - val_categorical_accuracy: 0.9950\n",
      "Epoch 25/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.0566 - categorical_accuracy: 0.9901\n",
      "Epoch 00025: val_loss improved from 0.02572 to 0.02417, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 247us/sample - loss: 0.0545 - categorical_accuracy: 0.9906 - val_loss: 0.0242 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.0539 - categorical_accuracy: 0.9914\n",
      "Epoch 00026: val_loss did not improve from 0.02417\n",
      "1600/1600 [==============================] - 0s 242us/sample - loss: 0.0545 - categorical_accuracy: 0.9906 - val_loss: 0.0245 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0566 - categorical_accuracy: 0.9911\n",
      "Epoch 00027: val_loss improved from 0.02417 to 0.02116, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 289us/sample - loss: 0.0563 - categorical_accuracy: 0.9912 - val_loss: 0.0212 - val_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0472 - categorical_accuracy: 0.9922\n",
      "Epoch 00028: val_loss did not improve from 0.02116\n",
      "1600/1600 [==============================] - 0s 238us/sample - loss: 0.0464 - categorical_accuracy: 0.9925 - val_loss: 0.0212 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0513 - categorical_accuracy: 0.9898\n",
      "Epoch 00029: val_loss improved from 0.02116 to 0.01997, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 280us/sample - loss: 0.0506 - categorical_accuracy: 0.9900 - val_loss: 0.0200 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.0713 - categorical_accuracy: 0.9830\n",
      "Epoch 00030: val_loss did not improve from 0.01997\n",
      "1600/1600 [==============================] - 0s 208us/sample - loss: 0.0697 - categorical_accuracy: 0.9837 - val_loss: 0.0243 - val_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.0446 - categorical_accuracy: 0.9937\n",
      "Epoch 00031: val_loss did not improve from 0.01997\n",
      "1600/1600 [==============================] - 0s 207us/sample - loss: 0.0443 - categorical_accuracy: 0.9931 - val_loss: 0.0226 - val_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0412 - categorical_accuracy: 0.9941\n",
      "Epoch 00032: val_loss did not improve from 0.01997\n",
      "1600/1600 [==============================] - 0s 237us/sample - loss: 0.0409 - categorical_accuracy: 0.9944 - val_loss: 0.0203 - val_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.0625 - categorical_accuracy: 0.9830\n",
      "Epoch 00033: val_loss did not improve from 0.01997\n",
      "1600/1600 [==============================] - 0s 238us/sample - loss: 0.0675 - categorical_accuracy: 0.9825 - val_loss: 0.0248 - val_categorical_accuracy: 0.9950\n",
      "Epoch 34/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0476 - categorical_accuracy: 0.9928\n",
      "Epoch 00034: val_loss did not improve from 0.01997\n",
      "1600/1600 [==============================] - 0s 237us/sample - loss: 0.0476 - categorical_accuracy: 0.9925 - val_loss: 0.0204 - val_categorical_accuracy: 1.0000\n",
      "1.0 0.15244897959183673\n",
      "\n",
      "\n",
      "nrx: 5 - real: 2 \n",
      "Train on 9120 samples, validate on 1140 samples\n",
      "Epoch 1/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 2.1926 - categorical_accuracy: 0.1875\n",
      "Epoch 00001: val_loss improved from inf to 1.74718, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 269us/sample - loss: 2.1842 - categorical_accuracy: 0.1906 - val_loss: 1.7472 - val_categorical_accuracy: 0.3623\n",
      "Epoch 2/100\n",
      "8928/9120 [============================>.] - ETA: 0s - loss: 1.6073 - categorical_accuracy: 0.4024\n",
      "Epoch 00002: val_loss improved from 1.74718 to 1.38935, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 228us/sample - loss: 1.6032 - categorical_accuracy: 0.4039 - val_loss: 1.3893 - val_categorical_accuracy: 0.5149\n",
      "Epoch 3/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 1.3385 - categorical_accuracy: 0.4952\n",
      "Epoch 00003: val_loss improved from 1.38935 to 1.17319, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 235us/sample - loss: 1.3360 - categorical_accuracy: 0.4959 - val_loss: 1.1732 - val_categorical_accuracy: 0.5921\n",
      "Epoch 4/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 1.0925 - categorical_accuracy: 0.6064\n",
      "Epoch 00004: val_loss improved from 1.17319 to 0.96719, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 233us/sample - loss: 1.0923 - categorical_accuracy: 0.6062 - val_loss: 0.9672 - val_categorical_accuracy: 0.6798\n",
      "Epoch 5/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.8972 - categorical_accuracy: 0.6915\n",
      "Epoch 00005: val_loss improved from 0.96719 to 0.79064, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.8968 - categorical_accuracy: 0.6908 - val_loss: 0.7906 - val_categorical_accuracy: 0.7623\n",
      "Epoch 6/100\n",
      "8928/9120 [============================>.] - ETA: 0s - loss: 0.7570 - categorical_accuracy: 0.7485\n",
      "Epoch 00006: val_loss improved from 0.79064 to 0.61153, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 229us/sample - loss: 0.7534 - categorical_accuracy: 0.7492 - val_loss: 0.6115 - val_categorical_accuracy: 0.8158\n",
      "Epoch 7/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.6151 - categorical_accuracy: 0.8010\n",
      "Epoch 00007: val_loss improved from 0.61153 to 0.51135, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 230us/sample - loss: 0.6140 - categorical_accuracy: 0.8016 - val_loss: 0.5113 - val_categorical_accuracy: 0.8474\n",
      "Epoch 8/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.5109 - categorical_accuracy: 0.8409\n",
      "Epoch 00008: val_loss improved from 0.51135 to 0.47562, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 228us/sample - loss: 0.5087 - categorical_accuracy: 0.8417 - val_loss: 0.4756 - val_categorical_accuracy: 0.8605\n",
      "Epoch 9/100\n",
      "9088/9120 [============================>.] - ETA: 0s - loss: 0.4299 - categorical_accuracy: 0.8741\n",
      "Epoch 00009: val_loss improved from 0.47562 to 0.34058, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 229us/sample - loss: 0.4292 - categorical_accuracy: 0.8742 - val_loss: 0.3406 - val_categorical_accuracy: 0.9246\n",
      "Epoch 10/100\n",
      "8928/9120 [============================>.] - ETA: 0s - loss: 0.3556 - categorical_accuracy: 0.8982\n",
      "Epoch 00010: val_loss improved from 0.34058 to 0.29269, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 232us/sample - loss: 0.3548 - categorical_accuracy: 0.8986 - val_loss: 0.2927 - val_categorical_accuracy: 0.9421\n",
      "Epoch 11/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.3046 - categorical_accuracy: 0.9183\n",
      "Epoch 00011: val_loss did not improve from 0.29269\n",
      "9120/9120 [==============================] - 2s 203us/sample - loss: 0.3063 - categorical_accuracy: 0.9184 - val_loss: 0.2951 - val_categorical_accuracy: 0.9404\n",
      "Epoch 12/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.2807 - categorical_accuracy: 0.9258\n",
      "Epoch 00012: val_loss improved from 0.29269 to 0.23212, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 231us/sample - loss: 0.2805 - categorical_accuracy: 0.9255 - val_loss: 0.2321 - val_categorical_accuracy: 0.9579\n",
      "Epoch 13/100\n",
      "8864/9120 [============================>.] - ETA: 0s - loss: 0.2388 - categorical_accuracy: 0.9393\n",
      "Epoch 00013: val_loss did not improve from 0.23212\n",
      "9120/9120 [==============================] - 2s 223us/sample - loss: 0.2389 - categorical_accuracy: 0.9394 - val_loss: 0.2794 - val_categorical_accuracy: 0.9430\n",
      "Epoch 14/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 0.2198 - categorical_accuracy: 0.9407\n",
      "Epoch 00014: val_loss improved from 0.23212 to 0.22895, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 233us/sample - loss: 0.2203 - categorical_accuracy: 0.9405 - val_loss: 0.2289 - val_categorical_accuracy: 0.9579\n",
      "Epoch 15/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.2106 - categorical_accuracy: 0.9455\n",
      "Epoch 00015: val_loss improved from 0.22895 to 0.21399, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 229us/sample - loss: 0.2097 - categorical_accuracy: 0.9458 - val_loss: 0.2140 - val_categorical_accuracy: 0.9640\n",
      "Epoch 16/100\n",
      "8864/9120 [============================>.] - ETA: 0s - loss: 0.1877 - categorical_accuracy: 0.9528\n",
      "Epoch 00016: val_loss did not improve from 0.21399\n",
      "9120/9120 [==============================] - 2s 225us/sample - loss: 0.1864 - categorical_accuracy: 0.9532 - val_loss: 0.2329 - val_categorical_accuracy: 0.9570\n",
      "Epoch 17/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.1879 - categorical_accuracy: 0.9505\n",
      "Epoch 00017: val_loss improved from 0.21399 to 0.21381, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 232us/sample - loss: 0.1866 - categorical_accuracy: 0.9510 - val_loss: 0.2138 - val_categorical_accuracy: 0.9632\n",
      "Epoch 18/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 0.1621 - categorical_accuracy: 0.9602\n",
      "Epoch 00018: val_loss improved from 0.21381 to 0.20151, saving model to t_weights_1\n",
      "9120/9120 [==============================] - 2s 229us/sample - loss: 0.1623 - categorical_accuracy: 0.9601 - val_loss: 0.2015 - val_categorical_accuracy: 0.9623\n",
      "Epoch 19/100\n",
      "9088/9120 [============================>.] - ETA: 0s - loss: 0.1617 - categorical_accuracy: 0.9594\n",
      "Epoch 00019: val_loss did not improve from 0.20151\n",
      "9120/9120 [==============================] - 2s 222us/sample - loss: 0.1617 - categorical_accuracy: 0.9594 - val_loss: 0.2070 - val_categorical_accuracy: 0.9596\n",
      "Epoch 20/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.1528 - categorical_accuracy: 0.9608\n",
      "Epoch 00020: val_loss did not improve from 0.20151\n",
      "9120/9120 [==============================] - 2s 223us/sample - loss: 0.1512 - categorical_accuracy: 0.9615 - val_loss: 0.2436 - val_categorical_accuracy: 0.9535\n",
      "Epoch 21/100\n",
      "8896/9120 [============================>.] - ETA: 0s - loss: 0.1529 - categorical_accuracy: 0.9607\n",
      "Epoch 00021: val_loss did not improve from 0.20151\n",
      "9120/9120 [==============================] - 2s 222us/sample - loss: 0.1510 - categorical_accuracy: 0.9613 - val_loss: 0.2126 - val_categorical_accuracy: 0.9640\n",
      "Epoch 22/100\n",
      "8960/9120 [============================>.] - ETA: 0s - loss: 0.1452 - categorical_accuracy: 0.9618\n",
      "Epoch 00022: val_loss did not improve from 0.20151\n",
      "9120/9120 [==============================] - 2s 225us/sample - loss: 0.1454 - categorical_accuracy: 0.9618 - val_loss: 0.2102 - val_categorical_accuracy: 0.9649\n",
      "Epoch 23/100\n",
      "9056/9120 [============================>.] - ETA: 0s - loss: 0.1304 - categorical_accuracy: 0.9688\n",
      "Epoch 00023: val_loss did not improve from 0.20151\n",
      "9120/9120 [==============================] - 2s 228us/sample - loss: 0.1310 - categorical_accuracy: 0.9685 - val_loss: 0.2045 - val_categorical_accuracy: 0.9684\n",
      "0.9649123 0.15346938775510205\n",
      "\n",
      "\n",
      "nrx: 10 - real: 2 \n",
      "Train on 16936 samples, validate on 2117 samples\n",
      "Epoch 1/100\n",
      "16832/16936 [============================>.] - ETA: 0s - loss: 2.0387 - categorical_accuracy: 0.2444\n",
      "Epoch 00001: val_loss improved from inf to 1.65547, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 246us/sample - loss: 2.0366 - categorical_accuracy: 0.2452 - val_loss: 1.6555 - val_categorical_accuracy: 0.3807\n",
      "Epoch 2/100\n",
      "16864/16936 [============================>.] - ETA: 0s - loss: 1.5445 - categorical_accuracy: 0.4485\n",
      "Epoch 00002: val_loss improved from 1.65547 to 1.28727, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 228us/sample - loss: 1.5431 - categorical_accuracy: 0.4489 - val_loss: 1.2873 - val_categorical_accuracy: 0.5569\n",
      "Epoch 3/100\n",
      "16864/16936 [============================>.] - ETA: 0s - loss: 1.2493 - categorical_accuracy: 0.5660\n",
      "Epoch 00003: val_loss improved from 1.28727 to 1.01569, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 224us/sample - loss: 1.2493 - categorical_accuracy: 0.5658 - val_loss: 1.0157 - val_categorical_accuracy: 0.6920\n",
      "Epoch 4/100\n",
      "16896/16936 [============================>.] - ETA: 0s - loss: 1.0174 - categorical_accuracy: 0.6603\n",
      "Epoch 00004: val_loss improved from 1.01569 to 0.83002, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 224us/sample - loss: 1.0170 - categorical_accuracy: 0.6605 - val_loss: 0.8300 - val_categorical_accuracy: 0.7364\n",
      "Epoch 5/100\n",
      "16864/16936 [============================>.] - ETA: 0s - loss: 0.8557 - categorical_accuracy: 0.7196\n",
      "Epoch 00005: val_loss improved from 0.83002 to 0.67915, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 222us/sample - loss: 0.8551 - categorical_accuracy: 0.7199 - val_loss: 0.6791 - val_categorical_accuracy: 0.7931\n",
      "Epoch 6/100\n",
      "16704/16936 [============================>.] - ETA: 0s - loss: 0.7164 - categorical_accuracy: 0.7721\n",
      "Epoch 00006: val_loss improved from 0.67915 to 0.54060, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 224us/sample - loss: 0.7155 - categorical_accuracy: 0.7723 - val_loss: 0.5406 - val_categorical_accuracy: 0.8389\n",
      "Epoch 7/100\n",
      "16896/16936 [============================>.] - ETA: 0s - loss: 0.6202 - categorical_accuracy: 0.8060\n",
      "Epoch 00007: val_loss improved from 0.54060 to 0.51822, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 224us/sample - loss: 0.6201 - categorical_accuracy: 0.8060 - val_loss: 0.5182 - val_categorical_accuracy: 0.8441\n",
      "Epoch 8/100\n",
      "16928/16936 [============================>.] - ETA: 0s - loss: 0.5551 - categorical_accuracy: 0.8272\n",
      "Epoch 00008: val_loss improved from 0.51822 to 0.44179, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 222us/sample - loss: 0.5550 - categorical_accuracy: 0.8272 - val_loss: 0.4418 - val_categorical_accuracy: 0.8772\n",
      "Epoch 9/100\n",
      "16704/16936 [============================>.] - ETA: 0s - loss: 0.4935 - categorical_accuracy: 0.8510\n",
      "Epoch 00009: val_loss improved from 0.44179 to 0.40986, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 216us/sample - loss: 0.4946 - categorical_accuracy: 0.8507 - val_loss: 0.4099 - val_categorical_accuracy: 0.8781\n",
      "Epoch 10/100\n",
      "16832/16936 [============================>.] - ETA: 0s - loss: 0.4603 - categorical_accuracy: 0.8587\n",
      "Epoch 00010: val_loss improved from 0.40986 to 0.39022, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 222us/sample - loss: 0.4601 - categorical_accuracy: 0.8589 - val_loss: 0.3902 - val_categorical_accuracy: 0.8914\n",
      "Epoch 11/100\n",
      "16832/16936 [============================>.] - ETA: 0s - loss: 0.4305 - categorical_accuracy: 0.8650\n",
      "Epoch 00011: val_loss improved from 0.39022 to 0.36477, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 235us/sample - loss: 0.4300 - categorical_accuracy: 0.8652 - val_loss: 0.3648 - val_categorical_accuracy: 0.8980\n",
      "Epoch 12/100\n",
      "16736/16936 [============================>.] - ETA: 0s - loss: 0.3986 - categorical_accuracy: 0.8752\n",
      "Epoch 00012: val_loss improved from 0.36477 to 0.34482, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 220us/sample - loss: 0.3991 - categorical_accuracy: 0.8756 - val_loss: 0.3448 - val_categorical_accuracy: 0.9017\n",
      "Epoch 13/100\n",
      "16800/16936 [============================>.] - ETA: 0s - loss: 0.3822 - categorical_accuracy: 0.8821\n",
      "Epoch 00013: val_loss improved from 0.34482 to 0.32106, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 229us/sample - loss: 0.3825 - categorical_accuracy: 0.8821 - val_loss: 0.3211 - val_categorical_accuracy: 0.9145\n",
      "Epoch 14/100\n",
      "16768/16936 [============================>.] - ETA: 0s - loss: 0.3550 - categorical_accuracy: 0.8918\n",
      "Epoch 00014: val_loss did not improve from 0.32106\n",
      "16936/16936 [==============================] - 4s 220us/sample - loss: 0.3559 - categorical_accuracy: 0.8917 - val_loss: 0.3663 - val_categorical_accuracy: 0.8961\n",
      "Epoch 15/100\n",
      "16896/16936 [============================>.] - ETA: 0s - loss: 0.3525 - categorical_accuracy: 0.8913\n",
      "Epoch 00015: val_loss did not improve from 0.32106\n",
      "16936/16936 [==============================] - 4s 225us/sample - loss: 0.3520 - categorical_accuracy: 0.8914 - val_loss: 0.3217 - val_categorical_accuracy: 0.9093\n",
      "Epoch 16/100\n",
      "16704/16936 [============================>.] - ETA: 0s - loss: 0.3320 - categorical_accuracy: 0.8996\n",
      "Epoch 00016: val_loss improved from 0.32106 to 0.30780, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 226us/sample - loss: 0.3310 - categorical_accuracy: 0.9000 - val_loss: 0.3078 - val_categorical_accuracy: 0.9192\n",
      "Epoch 17/100\n",
      "16736/16936 [============================>.] - ETA: 0s - loss: 0.3192 - categorical_accuracy: 0.9021\n",
      "Epoch 00017: val_loss improved from 0.30780 to 0.29384, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 224us/sample - loss: 0.3193 - categorical_accuracy: 0.9019 - val_loss: 0.2938 - val_categorical_accuracy: 0.9225\n",
      "Epoch 18/100\n",
      "16864/16936 [============================>.] - ETA: 0s - loss: 0.3116 - categorical_accuracy: 0.9060\n",
      "Epoch 00018: val_loss improved from 0.29384 to 0.28100, saving model to t_weights_1\n",
      "16936/16936 [==============================] - 4s 227us/sample - loss: 0.3116 - categorical_accuracy: 0.9059 - val_loss: 0.2810 - val_categorical_accuracy: 0.9249\n",
      "Epoch 19/100\n",
      "16672/16936 [============================>.] - ETA: 0s - loss: 0.3097 - categorical_accuracy: 0.9051\n",
      "Epoch 00019: val_loss did not improve from 0.28100\n",
      "16936/16936 [==============================] - 4s 221us/sample - loss: 0.3092 - categorical_accuracy: 0.9053 - val_loss: 0.2899 - val_categorical_accuracy: 0.9244\n",
      "Epoch 20/100\n",
      "16800/16936 [============================>.] - ETA: 0s - loss: 0.2961 - categorical_accuracy: 0.9080\n",
      "Epoch 00020: val_loss did not improve from 0.28100\n",
      "16936/16936 [==============================] - 4s 225us/sample - loss: 0.2958 - categorical_accuracy: 0.9082 - val_loss: 0.2921 - val_categorical_accuracy: 0.9258\n",
      "Epoch 21/100\n",
      "16768/16936 [============================>.] - ETA: 0s - loss: 0.2874 - categorical_accuracy: 0.9109\n",
      "Epoch 00021: val_loss did not improve from 0.28100\n",
      "16936/16936 [==============================] - 4s 219us/sample - loss: 0.2877 - categorical_accuracy: 0.9106 - val_loss: 0.3074 - val_categorical_accuracy: 0.9225\n",
      "Epoch 22/100\n",
      "16896/16936 [============================>.] - ETA: 0s - loss: 0.2820 - categorical_accuracy: 0.9126\n",
      "Epoch 00022: val_loss did not improve from 0.28100\n",
      "16936/16936 [==============================] - 4s 223us/sample - loss: 0.2820 - categorical_accuracy: 0.9126 - val_loss: 0.3074 - val_categorical_accuracy: 0.9211\n",
      "Epoch 23/100\n",
      "16768/16936 [============================>.] - ETA: 0s - loss: 0.2801 - categorical_accuracy: 0.9141\n",
      "Epoch 00023: val_loss did not improve from 0.28100\n",
      "16936/16936 [==============================] - 4s 218us/sample - loss: 0.2802 - categorical_accuracy: 0.9141 - val_loss: 0.2971 - val_categorical_accuracy: 0.9254\n",
      "0.9055267 0.3662244897959184\n",
      "\n",
      "\n",
      "nrx: 15 - real: 2 \n",
      "Train on 24616 samples, validate on 3077 samples\n",
      "Epoch 1/100\n",
      "24416/24616 [============================>.] - ETA: 0s - loss: 1.9664 - categorical_accuracy: 0.2796\n",
      "Epoch 00001: val_loss improved from inf to 1.64921, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 232us/sample - loss: 1.9648 - categorical_accuracy: 0.2802 - val_loss: 1.6492 - val_categorical_accuracy: 0.4235\n",
      "Epoch 2/100\n",
      "24416/24616 [============================>.] - ETA: 0s - loss: 1.5350 - categorical_accuracy: 0.4574\n",
      "Epoch 00002: val_loss improved from 1.64921 to 1.34670, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 226us/sample - loss: 1.5329 - categorical_accuracy: 0.4581 - val_loss: 1.3467 - val_categorical_accuracy: 0.5479\n",
      "Epoch 3/100\n",
      "24384/24616 [============================>.] - ETA: 0s - loss: 1.2864 - categorical_accuracy: 0.5573\n",
      "Epoch 00003: val_loss improved from 1.34670 to 1.09746, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 225us/sample - loss: 1.2853 - categorical_accuracy: 0.5576 - val_loss: 1.0975 - val_categorical_accuracy: 0.6263\n",
      "Epoch 4/100\n",
      "24480/24616 [============================>.] - ETA: 0s - loss: 1.0689 - categorical_accuracy: 0.6459\n",
      "Epoch 00004: val_loss improved from 1.09746 to 0.88401, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 5s 222us/sample - loss: 1.0686 - categorical_accuracy: 0.6458 - val_loss: 0.8840 - val_categorical_accuracy: 0.7124\n",
      "Epoch 5/100\n",
      "24512/24616 [============================>.] - ETA: 0s - loss: 0.8938 - categorical_accuracy: 0.7102\n",
      "Epoch 00005: val_loss improved from 0.88401 to 0.69004, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 225us/sample - loss: 0.8939 - categorical_accuracy: 0.7101 - val_loss: 0.6900 - val_categorical_accuracy: 0.7940\n",
      "Epoch 6/100\n",
      "24512/24616 [============================>.] - ETA: 0s - loss: 0.7242 - categorical_accuracy: 0.7733\n",
      "Epoch 00006: val_loss improved from 0.69004 to 0.53711, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 228us/sample - loss: 0.7249 - categorical_accuracy: 0.7730 - val_loss: 0.5371 - val_categorical_accuracy: 0.8450\n",
      "Epoch 7/100\n",
      "24576/24616 [============================>.] - ETA: 0s - loss: 0.6096 - categorical_accuracy: 0.8110\n",
      "Epoch 00007: val_loss improved from 0.53711 to 0.45920, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 225us/sample - loss: 0.6094 - categorical_accuracy: 0.8111 - val_loss: 0.4592 - val_categorical_accuracy: 0.8736\n",
      "Epoch 8/100\n",
      "24576/24616 [============================>.] - ETA: 0s - loss: 0.5334 - categorical_accuracy: 0.8379\n",
      "Epoch 00008: val_loss improved from 0.45920 to 0.40766, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 5s 223us/sample - loss: 0.5333 - categorical_accuracy: 0.8380 - val_loss: 0.4077 - val_categorical_accuracy: 0.8801\n",
      "Epoch 9/100\n",
      "24576/24616 [============================>.] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.8566\n",
      "Epoch 00009: val_loss improved from 0.40766 to 0.39680, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 225us/sample - loss: 0.4788 - categorical_accuracy: 0.8567 - val_loss: 0.3968 - val_categorical_accuracy: 0.8882\n",
      "Epoch 10/100\n",
      "24608/24616 [============================>.] - ETA: 0s - loss: 0.4344 - categorical_accuracy: 0.8700\n",
      "Epoch 00010: val_loss improved from 0.39680 to 0.35699, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 5s 214us/sample - loss: 0.4343 - categorical_accuracy: 0.8701 - val_loss: 0.3570 - val_categorical_accuracy: 0.9064\n",
      "Epoch 11/100\n",
      "24544/24616 [============================>.] - ETA: 0s - loss: 0.3985 - categorical_accuracy: 0.8794\n",
      "Epoch 00011: val_loss improved from 0.35699 to 0.33658, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.3983 - categorical_accuracy: 0.8795 - val_loss: 0.3366 - val_categorical_accuracy: 0.9032\n",
      "Epoch 12/100\n",
      "24576/24616 [============================>.] - ETA: 0s - loss: 0.3807 - categorical_accuracy: 0.8872\n",
      "Epoch 00012: val_loss improved from 0.33658 to 0.30912, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 5s 216us/sample - loss: 0.3803 - categorical_accuracy: 0.8874 - val_loss: 0.3091 - val_categorical_accuracy: 0.9155\n",
      "Epoch 13/100\n",
      "24480/24616 [============================>.] - ETA: 0s - loss: 0.3490 - categorical_accuracy: 0.8981\n",
      "Epoch 00013: val_loss improved from 0.30912 to 0.30344, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 5s 223us/sample - loss: 0.3496 - categorical_accuracy: 0.8982 - val_loss: 0.3034 - val_categorical_accuracy: 0.9149\n",
      "Epoch 14/100\n",
      "24480/24616 [============================>.] - ETA: 0s - loss: 0.3384 - categorical_accuracy: 0.8998\n",
      "Epoch 00014: val_loss did not improve from 0.30344\n",
      "24616/24616 [==============================] - 5s 223us/sample - loss: 0.3387 - categorical_accuracy: 0.8997 - val_loss: 0.3170 - val_categorical_accuracy: 0.9123\n",
      "Epoch 15/100\n",
      "24480/24616 [============================>.] - ETA: 0s - loss: 0.3183 - categorical_accuracy: 0.9053\n",
      "Epoch 00015: val_loss improved from 0.30344 to 0.29468, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 226us/sample - loss: 0.3181 - categorical_accuracy: 0.9053 - val_loss: 0.2947 - val_categorical_accuracy: 0.9197\n",
      "Epoch 16/100\n",
      "24608/24616 [============================>.] - ETA: 0s - loss: 0.3054 - categorical_accuracy: 0.9097\n",
      "Epoch 00016: val_loss did not improve from 0.29468\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.3055 - categorical_accuracy: 0.9097 - val_loss: 0.3160 - val_categorical_accuracy: 0.9204\n",
      "Epoch 17/100\n",
      "24608/24616 [============================>.] - ETA: 0s - loss: 0.2907 - categorical_accuracy: 0.9159\n",
      "Epoch 00017: val_loss improved from 0.29468 to 0.29284, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.2906 - categorical_accuracy: 0.9159 - val_loss: 0.2928 - val_categorical_accuracy: 0.9210\n",
      "Epoch 18/100\n",
      "24608/24616 [============================>.] - ETA: 0s - loss: 0.2904 - categorical_accuracy: 0.9143\n",
      "Epoch 00018: val_loss improved from 0.29284 to 0.27044, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 227us/sample - loss: 0.2903 - categorical_accuracy: 0.9143 - val_loss: 0.2704 - val_categorical_accuracy: 0.9292\n",
      "Epoch 19/100\n",
      "24512/24616 [============================>.] - ETA: 0s - loss: 0.2738 - categorical_accuracy: 0.9198\n",
      "Epoch 00019: val_loss did not improve from 0.27044\n",
      "24616/24616 [==============================] - 6s 225us/sample - loss: 0.2736 - categorical_accuracy: 0.9198 - val_loss: 0.2798 - val_categorical_accuracy: 0.9305\n",
      "Epoch 20/100\n",
      "24512/24616 [============================>.] - ETA: 0s - loss: 0.2751 - categorical_accuracy: 0.9200\n",
      "Epoch 00020: val_loss did not improve from 0.27044\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.2755 - categorical_accuracy: 0.9198 - val_loss: 0.2883 - val_categorical_accuracy: 0.9246\n",
      "Epoch 21/100\n",
      "24480/24616 [============================>.] - ETA: 0s - loss: 0.2597 - categorical_accuracy: 0.9239\n",
      "Epoch 00021: val_loss did not improve from 0.27044\n",
      "24616/24616 [==============================] - 5s 222us/sample - loss: 0.2596 - categorical_accuracy: 0.9241 - val_loss: 0.2790 - val_categorical_accuracy: 0.9321\n",
      "Epoch 22/100\n",
      "24448/24616 [============================>.] - ETA: 0s - loss: 0.2531 - categorical_accuracy: 0.9252\n",
      "Epoch 00022: val_loss did not improve from 0.27044\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.2531 - categorical_accuracy: 0.9252 - val_loss: 0.2706 - val_categorical_accuracy: 0.9259\n",
      "Epoch 23/100\n",
      "24352/24616 [============================>.] - ETA: 0s - loss: 0.2583 - categorical_accuracy: 0.9249\n",
      "Epoch 00023: val_loss improved from 0.27044 to 0.26934, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 5s 216us/sample - loss: 0.2586 - categorical_accuracy: 0.9250 - val_loss: 0.2693 - val_categorical_accuracy: 0.9366\n",
      "Epoch 24/100\n",
      "24544/24616 [============================>.] - ETA: 0s - loss: 0.2413 - categorical_accuracy: 0.9309\n",
      "Epoch 00024: val_loss improved from 0.26934 to 0.24972, saving model to t_weights_1\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.2412 - categorical_accuracy: 0.9309 - val_loss: 0.2497 - val_categorical_accuracy: 0.9386\n",
      "Epoch 25/100\n",
      "24416/24616 [============================>.] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9327\n",
      "Epoch 00025: val_loss did not improve from 0.24972\n",
      "24616/24616 [==============================] - 5s 221us/sample - loss: 0.2382 - categorical_accuracy: 0.9328 - val_loss: 0.2519 - val_categorical_accuracy: 0.9376\n",
      "Epoch 26/100\n",
      "24544/24616 [============================>.] - ETA: 0s - loss: 0.2331 - categorical_accuracy: 0.9340\n",
      "Epoch 00026: val_loss did not improve from 0.24972\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.2335 - categorical_accuracy: 0.9338 - val_loss: 0.2674 - val_categorical_accuracy: 0.9350\n",
      "Epoch 27/100\n",
      "24576/24616 [============================>.] - ETA: 0s - loss: 0.2301 - categorical_accuracy: 0.9336\n",
      "Epoch 00027: val_loss did not improve from 0.24972\n",
      "24616/24616 [==============================] - 6s 224us/sample - loss: 0.2304 - categorical_accuracy: 0.9335 - val_loss: 0.2620 - val_categorical_accuracy: 0.9363\n",
      "Epoch 28/100\n",
      "24512/24616 [============================>.] - ETA: 0s - loss: 0.2215 - categorical_accuracy: 0.9377\n",
      "Epoch 00028: val_loss did not improve from 0.24972\n",
      "24616/24616 [==============================] - 6s 225us/sample - loss: 0.2218 - categorical_accuracy: 0.9377 - val_loss: 0.2683 - val_categorical_accuracy: 0.9383\n",
      "Epoch 29/100\n",
      "24448/24616 [============================>.] - ETA: 0s - loss: 0.2253 - categorical_accuracy: 0.9358\n",
      "Epoch 00029: val_loss did not improve from 0.24972\n",
      "24616/24616 [==============================] - 5s 222us/sample - loss: 0.2252 - categorical_accuracy: 0.9358 - val_loss: 0.2641 - val_categorical_accuracy: 0.9399\n",
      "0.9359766 0.42989795918367346\n",
      "\n",
      "\n",
      "nrx: 20 - real: 2 \n",
      "Train on 32616 samples, validate on 4077 samples\n",
      "Epoch 1/100\n",
      "32544/32616 [============================>.] - ETA: 0s - loss: 1.9103 - categorical_accuracy: 0.2847\n",
      "Epoch 00001: val_loss improved from inf to 1.49684, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 8s 236us/sample - loss: 1.9096 - categorical_accuracy: 0.2848 - val_loss: 1.4968 - val_categorical_accuracy: 0.4589\n",
      "Epoch 2/100\n",
      "32608/32616 [============================>.] - ETA: 0s - loss: 1.4134 - categorical_accuracy: 0.4901\n",
      "Epoch 00002: val_loss improved from 1.49684 to 1.15168, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 1.4134 - categorical_accuracy: 0.4900 - val_loss: 1.1517 - val_categorical_accuracy: 0.5833\n",
      "Epoch 3/100\n",
      "32416/32616 [============================>.] - ETA: 0s - loss: 1.1442 - categorical_accuracy: 0.5976\n",
      "Epoch 00003: val_loss improved from 1.15168 to 0.90726, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 1.1432 - categorical_accuracy: 0.5979 - val_loss: 0.9073 - val_categorical_accuracy: 0.6883\n",
      "Epoch 4/100\n",
      "32384/32616 [============================>.] - ETA: 0s - loss: 0.9437 - categorical_accuracy: 0.6793\n",
      "Epoch 00004: val_loss improved from 0.90726 to 0.77130, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 219us/sample - loss: 0.9430 - categorical_accuracy: 0.6795 - val_loss: 0.7713 - val_categorical_accuracy: 0.7501\n",
      "Epoch 5/100\n",
      "32480/32616 [============================>.] - ETA: 0s - loss: 0.7893 - categorical_accuracy: 0.7376\n",
      "Epoch 00005: val_loss improved from 0.77130 to 0.62619, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 0.7892 - categorical_accuracy: 0.7376 - val_loss: 0.6262 - val_categorical_accuracy: 0.8133\n",
      "Epoch 6/100\n",
      "32384/32616 [============================>.] - ETA: 0s - loss: 0.6736 - categorical_accuracy: 0.7789\n",
      "Epoch 00006: val_loss improved from 0.62619 to 0.53084, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 0.6735 - categorical_accuracy: 0.7788 - val_loss: 0.5308 - val_categorical_accuracy: 0.8278\n",
      "Epoch 7/100\n",
      "32384/32616 [============================>.] - ETA: 0s - loss: 0.5970 - categorical_accuracy: 0.8056\n",
      "Epoch 00007: val_loss improved from 0.53084 to 0.44835, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 0.5964 - categorical_accuracy: 0.8056 - val_loss: 0.4483 - val_categorical_accuracy: 0.8624\n",
      "Epoch 8/100\n",
      "32416/32616 [============================>.] - ETA: 0s - loss: 0.5334 - categorical_accuracy: 0.8288\n",
      "Epoch 00008: val_loss improved from 0.44835 to 0.40615, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 225us/sample - loss: 0.5329 - categorical_accuracy: 0.8289 - val_loss: 0.4061 - val_categorical_accuracy: 0.8791\n",
      "Epoch 9/100\n",
      "32576/32616 [============================>.] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.8430\n",
      "Epoch 00009: val_loss improved from 0.40615 to 0.37962, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 0.4846 - categorical_accuracy: 0.8431 - val_loss: 0.3796 - val_categorical_accuracy: 0.8894\n",
      "Epoch 10/100\n",
      "32608/32616 [============================>.] - ETA: 0s - loss: 0.4496 - categorical_accuracy: 0.8576\n",
      "Epoch 00010: val_loss improved from 0.37962 to 0.36083, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 227us/sample - loss: 0.4499 - categorical_accuracy: 0.8575 - val_loss: 0.3608 - val_categorical_accuracy: 0.8943\n",
      "Epoch 11/100\n",
      "32352/32616 [============================>.] - ETA: 0s - loss: 0.4160 - categorical_accuracy: 0.8697\n",
      "Epoch 00011: val_loss improved from 0.36083 to 0.35356, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 0.4167 - categorical_accuracy: 0.8695 - val_loss: 0.3536 - val_categorical_accuracy: 0.8953\n",
      "Epoch 12/100\n",
      "32288/32616 [============================>.] - ETA: 0s - loss: 0.3961 - categorical_accuracy: 0.8785\n",
      "Epoch 00012: val_loss improved from 0.35356 to 0.32613, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 211us/sample - loss: 0.3954 - categorical_accuracy: 0.8786 - val_loss: 0.3261 - val_categorical_accuracy: 0.9058\n",
      "Epoch 13/100\n",
      "32608/32616 [============================>.] - ETA: 0s - loss: 0.3711 - categorical_accuracy: 0.8850\n",
      "Epoch 00013: val_loss improved from 0.32613 to 0.30643, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 222us/sample - loss: 0.3710 - categorical_accuracy: 0.8851 - val_loss: 0.3064 - val_categorical_accuracy: 0.9129\n",
      "Epoch 14/100\n",
      "32384/32616 [============================>.] - ETA: 0s - loss: 0.3566 - categorical_accuracy: 0.8895\n",
      "Epoch 00014: val_loss improved from 0.30643 to 0.30520, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 207us/sample - loss: 0.3566 - categorical_accuracy: 0.8895 - val_loss: 0.3052 - val_categorical_accuracy: 0.9164\n",
      "Epoch 15/100\n",
      "32544/32616 [============================>.] - ETA: 0s - loss: 0.3439 - categorical_accuracy: 0.8947\n",
      "Epoch 00015: val_loss improved from 0.30520 to 0.29303, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 222us/sample - loss: 0.3436 - categorical_accuracy: 0.8948 - val_loss: 0.2930 - val_categorical_accuracy: 0.9203\n",
      "Epoch 16/100\n",
      "32512/32616 [============================>.] - ETA: 0s - loss: 0.3271 - categorical_accuracy: 0.9007\n",
      "Epoch 00016: val_loss did not improve from 0.29303\n",
      "32616/32616 [==============================] - 7s 221us/sample - loss: 0.3271 - categorical_accuracy: 0.9007 - val_loss: 0.2932 - val_categorical_accuracy: 0.9171\n",
      "Epoch 17/100\n",
      "32384/32616 [============================>.] - ETA: 0s - loss: 0.3158 - categorical_accuracy: 0.9026\n",
      "Epoch 00017: val_loss did not improve from 0.29303\n",
      "32616/32616 [==============================] - 7s 225us/sample - loss: 0.3156 - categorical_accuracy: 0.9027 - val_loss: 0.2991 - val_categorical_accuracy: 0.9183\n",
      "Epoch 18/100\n",
      "32416/32616 [============================>.] - ETA: 0s - loss: 0.3103 - categorical_accuracy: 0.9055\n",
      "Epoch 00018: val_loss improved from 0.29303 to 0.27739, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 226us/sample - loss: 0.3104 - categorical_accuracy: 0.9055 - val_loss: 0.2774 - val_categorical_accuracy: 0.9237\n",
      "Epoch 19/100\n",
      "32384/32616 [============================>.] - ETA: 0s - loss: 0.3017 - categorical_accuracy: 0.9085\n",
      "Epoch 00019: val_loss did not improve from 0.27739\n",
      "32616/32616 [==============================] - 7s 224us/sample - loss: 0.3019 - categorical_accuracy: 0.9084 - val_loss: 0.2996 - val_categorical_accuracy: 0.9127\n",
      "Epoch 20/100\n",
      "32544/32616 [============================>.] - ETA: 0s - loss: 0.2927 - categorical_accuracy: 0.9107\n",
      "Epoch 00020: val_loss improved from 0.27739 to 0.27315, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 225us/sample - loss: 0.2926 - categorical_accuracy: 0.9107 - val_loss: 0.2731 - val_categorical_accuracy: 0.9218\n",
      "Epoch 21/100\n",
      "32512/32616 [============================>.] - ETA: 0s - loss: 0.2825 - categorical_accuracy: 0.9121\n",
      "Epoch 00021: val_loss improved from 0.27315 to 0.26742, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 218us/sample - loss: 0.2825 - categorical_accuracy: 0.9122 - val_loss: 0.2674 - val_categorical_accuracy: 0.9269\n",
      "Epoch 22/100\n",
      "32416/32616 [============================>.] - ETA: 0s - loss: 0.2779 - categorical_accuracy: 0.9141\n",
      "Epoch 00022: val_loss did not improve from 0.26742\n",
      "32616/32616 [==============================] - 7s 214us/sample - loss: 0.2780 - categorical_accuracy: 0.9141 - val_loss: 0.2698 - val_categorical_accuracy: 0.9254\n",
      "Epoch 23/100\n",
      "32544/32616 [============================>.] - ETA: 0s - loss: 0.2780 - categorical_accuracy: 0.9153\n",
      "Epoch 00023: val_loss improved from 0.26742 to 0.25852, saving model to t_weights_1\n",
      "32616/32616 [==============================] - 7s 225us/sample - loss: 0.2784 - categorical_accuracy: 0.9152 - val_loss: 0.2585 - val_categorical_accuracy: 0.9269\n",
      "Epoch 24/100\n",
      "32416/32616 [============================>.] - ETA: 0s - loss: 0.2693 - categorical_accuracy: 0.9188\n",
      "Epoch 00024: val_loss did not improve from 0.25852\n",
      "32616/32616 [==============================] - 7s 224us/sample - loss: 0.2702 - categorical_accuracy: 0.9185 - val_loss: 0.2740 - val_categorical_accuracy: 0.9203\n",
      "Epoch 25/100\n",
      "32576/32616 [============================>.] - ETA: 0s - loss: 0.2666 - categorical_accuracy: 0.9189\n",
      "Epoch 00025: val_loss did not improve from 0.25852\n",
      "32616/32616 [==============================] - 7s 224us/sample - loss: 0.2668 - categorical_accuracy: 0.9188 - val_loss: 0.2658 - val_categorical_accuracy: 0.9269\n",
      "Epoch 26/100\n",
      "32480/32616 [============================>.] - ETA: 0s - loss: 0.2620 - categorical_accuracy: 0.9197\n",
      "Epoch 00026: val_loss did not improve from 0.25852\n",
      "32616/32616 [==============================] - 7s 225us/sample - loss: 0.2618 - categorical_accuracy: 0.9199 - val_loss: 0.2604 - val_categorical_accuracy: 0.9276\n",
      "Epoch 27/100\n",
      "32576/32616 [============================>.] - ETA: 0s - loss: 0.2575 - categorical_accuracy: 0.9230\n",
      "Epoch 00027: val_loss did not improve from 0.25852\n",
      "32616/32616 [==============================] - 7s 225us/sample - loss: 0.2576 - categorical_accuracy: 0.9230 - val_loss: 0.2601 - val_categorical_accuracy: 0.9299\n",
      "Epoch 28/100\n",
      "32576/32616 [============================>.] - ETA: 0s - loss: 0.2589 - categorical_accuracy: 0.9221\n",
      "Epoch 00028: val_loss did not improve from 0.25852\n",
      "32616/32616 [==============================] - 7s 224us/sample - loss: 0.2589 - categorical_accuracy: 0.9222 - val_loss: 0.2748 - val_categorical_accuracy: 0.9235\n",
      "0.922492 0.4023469387755102\n",
      "\n",
      "\n",
      "nrx: 25 - real: 2 \n",
      "Train on 40456 samples, validate on 5057 samples\n",
      "Epoch 1/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 1.8840 - categorical_accuracy: 0.2932\n",
      "Epoch 00001: val_loss improved from inf to 1.42099, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 229us/sample - loss: 1.8821 - categorical_accuracy: 0.2940 - val_loss: 1.4210 - val_categorical_accuracy: 0.5217\n",
      "Epoch 2/100\n",
      "40320/40456 [============================>.] - ETA: 0s - loss: 1.1970 - categorical_accuracy: 0.5889\n",
      "Epoch 00002: val_loss improved from 1.42099 to 0.85154, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 1.1964 - categorical_accuracy: 0.5894 - val_loss: 0.8515 - val_categorical_accuracy: 0.7218\n",
      "Epoch 3/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.7995 - categorical_accuracy: 0.7391\n",
      "Epoch 00003: val_loss improved from 0.85154 to 0.60479, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.7990 - categorical_accuracy: 0.7393 - val_loss: 0.6048 - val_categorical_accuracy: 0.7993\n",
      "Epoch 4/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.6235 - categorical_accuracy: 0.8013\n",
      "Epoch 00004: val_loss improved from 0.60479 to 0.50706, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 213us/sample - loss: 0.6229 - categorical_accuracy: 0.8015 - val_loss: 0.5071 - val_categorical_accuracy: 0.8365\n",
      "Epoch 5/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.5221 - categorical_accuracy: 0.8394\n",
      "Epoch 00005: val_loss improved from 0.50706 to 0.41371, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.5221 - categorical_accuracy: 0.8395 - val_loss: 0.4137 - val_categorical_accuracy: 0.8709\n",
      "Epoch 6/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.4635 - categorical_accuracy: 0.8579\n",
      "Epoch 00006: val_loss did not improve from 0.41371\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.4633 - categorical_accuracy: 0.8579 - val_loss: 0.4227 - val_categorical_accuracy: 0.8730\n",
      "Epoch 7/100\n",
      "40192/40456 [============================>.] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8735\n",
      "Epoch 00007: val_loss improved from 0.41371 to 0.40033, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 218us/sample - loss: 0.4175 - categorical_accuracy: 0.8735 - val_loss: 0.4003 - val_categorical_accuracy: 0.8770\n",
      "Epoch 8/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.3877 - categorical_accuracy: 0.8818\n",
      "Epoch 00008: val_loss improved from 0.40033 to 0.34476, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.3875 - categorical_accuracy: 0.8818 - val_loss: 0.3448 - val_categorical_accuracy: 0.8942\n",
      "Epoch 9/100\n",
      "40320/40456 [============================>.] - ETA: 0s - loss: 0.3622 - categorical_accuracy: 0.8912\n",
      "Epoch 00009: val_loss improved from 0.34476 to 0.32741, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.3618 - categorical_accuracy: 0.8914 - val_loss: 0.3274 - val_categorical_accuracy: 0.9025\n",
      "Epoch 10/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.3382 - categorical_accuracy: 0.8978\n",
      "Epoch 00010: val_loss did not improve from 0.32741\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.3384 - categorical_accuracy: 0.8978 - val_loss: 0.3351 - val_categorical_accuracy: 0.9007\n",
      "Epoch 11/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.3233 - categorical_accuracy: 0.9030\n",
      "Epoch 00011: val_loss did not improve from 0.32741\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.3232 - categorical_accuracy: 0.9030 - val_loss: 0.3573 - val_categorical_accuracy: 0.8910\n",
      "Epoch 12/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.9064\n",
      "Epoch 00012: val_loss improved from 0.32741 to 0.30603, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.3134 - categorical_accuracy: 0.9064 - val_loss: 0.3060 - val_categorical_accuracy: 0.9082\n",
      "Epoch 13/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.3008 - categorical_accuracy: 0.9106\n",
      "Epoch 00013: val_loss did not improve from 0.30603\n",
      "40456/40456 [==============================] - 9s 221us/sample - loss: 0.3003 - categorical_accuracy: 0.9109 - val_loss: 0.3070 - val_categorical_accuracy: 0.9118\n",
      "Epoch 14/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.2935 - categorical_accuracy: 0.9124\n",
      "Epoch 00014: val_loss improved from 0.30603 to 0.29265, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 218us/sample - loss: 0.2935 - categorical_accuracy: 0.9124 - val_loss: 0.2927 - val_categorical_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "40224/40456 [============================>.] - ETA: 0s - loss: 0.2870 - categorical_accuracy: 0.9139\n",
      "Epoch 00015: val_loss did not improve from 0.29265\n",
      "40456/40456 [==============================] - 8s 208us/sample - loss: 0.2865 - categorical_accuracy: 0.9140 - val_loss: 0.2952 - val_categorical_accuracy: 0.9140\n",
      "Epoch 16/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.2762 - categorical_accuracy: 0.9185\n",
      "Epoch 00016: val_loss improved from 0.29265 to 0.29258, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 225us/sample - loss: 0.2764 - categorical_accuracy: 0.9184 - val_loss: 0.2926 - val_categorical_accuracy: 0.9185\n",
      "Epoch 17/100\n",
      "40224/40456 [============================>.] - ETA: 0s - loss: 0.2721 - categorical_accuracy: 0.9193\n",
      "Epoch 00017: val_loss did not improve from 0.29258\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2721 - categorical_accuracy: 0.9193 - val_loss: 0.3219 - val_categorical_accuracy: 0.9080\n",
      "Epoch 18/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.2602 - categorical_accuracy: 0.9233\n",
      "Epoch 00018: val_loss did not improve from 0.29258\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2601 - categorical_accuracy: 0.9233 - val_loss: 0.2927 - val_categorical_accuracy: 0.9219\n",
      "Epoch 19/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.2558 - categorical_accuracy: 0.9243\n",
      "Epoch 00019: val_loss improved from 0.29258 to 0.28990, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 225us/sample - loss: 0.2562 - categorical_accuracy: 0.9242 - val_loss: 0.2899 - val_categorical_accuracy: 0.9215\n",
      "Epoch 20/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.2531 - categorical_accuracy: 0.9246\n",
      "Epoch 00020: val_loss improved from 0.28990 to 0.28906, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 226us/sample - loss: 0.2530 - categorical_accuracy: 0.9246 - val_loss: 0.2891 - val_categorical_accuracy: 0.9243\n",
      "Epoch 21/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.2513 - categorical_accuracy: 0.9255\n",
      "Epoch 00021: val_loss improved from 0.28906 to 0.27337, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 220us/sample - loss: 0.2515 - categorical_accuracy: 0.9254 - val_loss: 0.2734 - val_categorical_accuracy: 0.9254\n",
      "Epoch 22/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.2429 - categorical_accuracy: 0.9276\n",
      "Epoch 00022: val_loss improved from 0.27337 to 0.26675, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 226us/sample - loss: 0.2429 - categorical_accuracy: 0.9276 - val_loss: 0.2667 - val_categorical_accuracy: 0.9300\n",
      "Epoch 23/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.2391 - categorical_accuracy: 0.9298\n",
      "Epoch 00023: val_loss did not improve from 0.26675\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2389 - categorical_accuracy: 0.9299 - val_loss: 0.2859 - val_categorical_accuracy: 0.9221\n",
      "Epoch 24/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.2327 - categorical_accuracy: 0.9308\n",
      "Epoch 00024: val_loss did not improve from 0.26675\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.2327 - categorical_accuracy: 0.9307 - val_loss: 0.2820 - val_categorical_accuracy: 0.9290\n",
      "Epoch 25/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.2361 - categorical_accuracy: 0.9297\n",
      "Epoch 00025: val_loss did not improve from 0.26675\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.2361 - categorical_accuracy: 0.9297 - val_loss: 0.2805 - val_categorical_accuracy: 0.9288\n",
      "Epoch 26/100\n",
      "40320/40456 [============================>.] - ETA: 0s - loss: 0.2265 - categorical_accuracy: 0.9328\n",
      "Epoch 00026: val_loss improved from 0.26675 to 0.25896, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 228us/sample - loss: 0.2264 - categorical_accuracy: 0.9328 - val_loss: 0.2590 - val_categorical_accuracy: 0.9302\n",
      "Epoch 27/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.2248 - categorical_accuracy: 0.9342\n",
      "Epoch 00027: val_loss did not improve from 0.25896\n",
      "40456/40456 [==============================] - 9s 226us/sample - loss: 0.2250 - categorical_accuracy: 0.9341 - val_loss: 0.2709 - val_categorical_accuracy: 0.9298\n",
      "Epoch 28/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9359\n",
      "Epoch 00028: val_loss did not improve from 0.25896\n",
      "40456/40456 [==============================] - 9s 217us/sample - loss: 0.2198 - categorical_accuracy: 0.9358 - val_loss: 0.2789 - val_categorical_accuracy: 0.9278\n",
      "Epoch 29/100\n",
      "40224/40456 [============================>.] - ETA: 0s - loss: 0.2181 - categorical_accuracy: 0.9365\n",
      "Epoch 00029: val_loss did not improve from 0.25896\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2180 - categorical_accuracy: 0.9365 - val_loss: 0.2795 - val_categorical_accuracy: 0.9322\n",
      "Epoch 30/100\n",
      "40320/40456 [============================>.] - ETA: 0s - loss: 0.2145 - categorical_accuracy: 0.9378\n",
      "Epoch 00030: val_loss did not improve from 0.25896\n",
      "40456/40456 [==============================] - 9s 225us/sample - loss: 0.2151 - categorical_accuracy: 0.9376 - val_loss: 0.3232 - val_categorical_accuracy: 0.9195\n",
      "Epoch 31/100\n",
      "40192/40456 [============================>.] - ETA: 0s - loss: 0.2121 - categorical_accuracy: 0.9371\n",
      "Epoch 00031: val_loss did not improve from 0.25896\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2120 - categorical_accuracy: 0.9371 - val_loss: 0.2660 - val_categorical_accuracy: 0.9324\n",
      "0.9305913 0.8426530612244898\n",
      "\n",
      "\n",
      "nrx: 0 - real: 3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cls_weights = np.max(stat,axis=0)/stat\n",
      "/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  cls_weights = np.max(stat,axis=0)/stat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 180 samples\n",
      "Epoch 1/100\n",
      "1376/1440 [===========================>..] - ETA: 0s - loss: 2.2814 - categorical_accuracy: 0.1315\n",
      "Epoch 00001: val_loss improved from inf to 2.21202, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 1s 530us/sample - loss: 2.2773 - categorical_accuracy: 0.1340 - val_loss: 2.2120 - val_categorical_accuracy: 0.1556\n",
      "Epoch 2/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 2.1784 - categorical_accuracy: 0.2058\n",
      "Epoch 00002: val_loss improved from 2.21202 to 2.02653, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 272us/sample - loss: 2.1676 - categorical_accuracy: 0.2132 - val_loss: 2.0265 - val_categorical_accuracy: 0.3167\n",
      "Epoch 3/100\n",
      "1280/1440 [=========================>....] - ETA: 0s - loss: 1.8525 - categorical_accuracy: 0.3703\n",
      "Epoch 00003: val_loss improved from 2.02653 to 1.43206, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 1.8178 - categorical_accuracy: 0.3799 - val_loss: 1.4321 - val_categorical_accuracy: 0.5611\n",
      "Epoch 4/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 1.4336 - categorical_accuracy: 0.4726\n",
      "Epoch 00004: val_loss improved from 1.43206 to 1.19024, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 268us/sample - loss: 1.4168 - categorical_accuracy: 0.4792 - val_loss: 1.1902 - val_categorical_accuracy: 0.5722\n",
      "Epoch 5/100\n",
      "1152/1440 [=======================>......] - ETA: 0s - loss: 1.1355 - categorical_accuracy: 0.5990\n",
      "Epoch 00005: val_loss improved from 1.19024 to 0.88315, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 1.1342 - categorical_accuracy: 0.5993 - val_loss: 0.8832 - val_categorical_accuracy: 0.6778\n",
      "Epoch 6/100\n",
      "1248/1440 [=========================>....] - ETA: 0s - loss: 0.9651 - categorical_accuracy: 0.6466\n",
      "Epoch 00006: val_loss improved from 0.88315 to 0.66060, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 289us/sample - loss: 0.9438 - categorical_accuracy: 0.6611 - val_loss: 0.6606 - val_categorical_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "1280/1440 [=========================>....] - ETA: 0s - loss: 0.7977 - categorical_accuracy: 0.7344\n",
      "Epoch 00007: val_loss improved from 0.66060 to 0.57379, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 272us/sample - loss: 0.8075 - categorical_accuracy: 0.7271 - val_loss: 0.5738 - val_categorical_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "1248/1440 [=========================>....] - ETA: 0s - loss: 0.6599 - categorical_accuracy: 0.7893\n",
      "Epoch 00008: val_loss improved from 0.57379 to 0.45219, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 0.6600 - categorical_accuracy: 0.7903 - val_loss: 0.4522 - val_categorical_accuracy: 0.8722\n",
      "Epoch 9/100\n",
      "1280/1440 [=========================>....] - ETA: 0s - loss: 0.5638 - categorical_accuracy: 0.8203\n",
      "Epoch 00009: val_loss improved from 0.45219 to 0.39130, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 284us/sample - loss: 0.5775 - categorical_accuracy: 0.8208 - val_loss: 0.3913 - val_categorical_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "1280/1440 [=========================>....] - ETA: 0s - loss: 0.4862 - categorical_accuracy: 0.8594\n",
      "Epoch 00010: val_loss improved from 0.39130 to 0.30888, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 0.4999 - categorical_accuracy: 0.8528 - val_loss: 0.3089 - val_categorical_accuracy: 0.9222\n",
      "Epoch 11/100\n",
      "1376/1440 [===========================>..] - ETA: 0s - loss: 0.4368 - categorical_accuracy: 0.8823\n",
      "Epoch 00011: val_loss improved from 0.30888 to 0.25814, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.4338 - categorical_accuracy: 0.8826 - val_loss: 0.2581 - val_categorical_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.3483 - categorical_accuracy: 0.9062\n",
      "Epoch 00012: val_loss improved from 0.25814 to 0.21527, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.3570 - categorical_accuracy: 0.9076 - val_loss: 0.2153 - val_categorical_accuracy: 0.9333\n",
      "Epoch 13/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.3280 - categorical_accuracy: 0.9162\n",
      "Epoch 00013: val_loss improved from 0.21527 to 0.20883, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.3318 - categorical_accuracy: 0.9174 - val_loss: 0.2088 - val_categorical_accuracy: 0.9333\n",
      "Epoch 14/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.2979 - categorical_accuracy: 0.9245\n",
      "Epoch 00014: val_loss improved from 0.20883 to 0.16075, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 265us/sample - loss: 0.2907 - categorical_accuracy: 0.9271 - val_loss: 0.1608 - val_categorical_accuracy: 0.9667\n",
      "Epoch 15/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.2846 - categorical_accuracy: 0.9375\n",
      "Epoch 00015: val_loss did not improve from 0.16075\n",
      "1440/1440 [==============================] - 0s 230us/sample - loss: 0.2898 - categorical_accuracy: 0.9361 - val_loss: 0.1816 - val_categorical_accuracy: 0.9556\n",
      "Epoch 16/100\n",
      "1280/1440 [=========================>....] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.9523\n",
      "Epoch 00016: val_loss improved from 0.16075 to 0.13191, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 281us/sample - loss: 0.2185 - categorical_accuracy: 0.9549 - val_loss: 0.1319 - val_categorical_accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.2392 - categorical_accuracy: 0.9482\n",
      "Epoch 00017: val_loss did not improve from 0.13191\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.2423 - categorical_accuracy: 0.9451 - val_loss: 0.2810 - val_categorical_accuracy: 0.9111\n",
      "Epoch 18/100\n",
      "1184/1440 [=======================>......] - ETA: 0s - loss: 0.2321 - categorical_accuracy: 0.9459\n",
      "Epoch 00018: val_loss improved from 0.13191 to 0.11978, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.2260 - categorical_accuracy: 0.9472 - val_loss: 0.1198 - val_categorical_accuracy: 0.9667\n",
      "Epoch 19/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.1671 - categorical_accuracy: 0.9672\n",
      "Epoch 00019: val_loss improved from 0.11978 to 0.10406, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1755 - categorical_accuracy: 0.9667 - val_loss: 0.1041 - val_categorical_accuracy: 0.9833\n",
      "Epoch 20/100\n",
      "1344/1440 [===========================>..] - ETA: 0s - loss: 0.1889 - categorical_accuracy: 0.9598\n",
      "Epoch 00020: val_loss did not improve from 0.10406\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1843 - categorical_accuracy: 0.9604 - val_loss: 0.1171 - val_categorical_accuracy: 0.9556\n",
      "Epoch 21/100\n",
      "1248/1440 [=========================>....] - ETA: 0s - loss: 0.1629 - categorical_accuracy: 0.9663\n",
      "Epoch 00021: val_loss did not improve from 0.10406\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1688 - categorical_accuracy: 0.9653 - val_loss: 0.1304 - val_categorical_accuracy: 0.9667\n",
      "Epoch 22/100\n",
      "1216/1440 [========================>.....] - ETA: 0s - loss: 0.1632 - categorical_accuracy: 0.9581\n",
      "Epoch 00022: val_loss improved from 0.10406 to 0.07210, saving model to t_weights_1\n",
      "1440/1440 [==============================] - 0s 288us/sample - loss: 0.1543 - categorical_accuracy: 0.9625 - val_loss: 0.0721 - val_categorical_accuracy: 0.9889\n",
      "Epoch 23/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.1298 - categorical_accuracy: 0.9771\n",
      "Epoch 00023: val_loss did not improve from 0.07210\n",
      "1440/1440 [==============================] - 0s 234us/sample - loss: 0.1344 - categorical_accuracy: 0.9729 - val_loss: 0.0885 - val_categorical_accuracy: 0.9889\n",
      "Epoch 24/100\n",
      "1376/1440 [===========================>..] - ETA: 0s - loss: 0.1532 - categorical_accuracy: 0.9608\n",
      "Epoch 00024: val_loss did not improve from 0.07210\n",
      "1440/1440 [==============================] - 0s 211us/sample - loss: 0.1501 - categorical_accuracy: 0.9625 - val_loss: 0.0765 - val_categorical_accuracy: 0.9833\n",
      "Epoch 25/100\n",
      "1408/1440 [============================>.] - ETA: 0s - loss: 0.1116 - categorical_accuracy: 0.9766\n",
      "Epoch 00025: val_loss did not improve from 0.07210\n",
      "1440/1440 [==============================] - 0s 209us/sample - loss: 0.1102 - categorical_accuracy: 0.9771 - val_loss: 0.0887 - val_categorical_accuracy: 0.9778\n",
      "Epoch 26/100\n",
      "1312/1440 [==========================>...] - ETA: 0s - loss: 0.1265 - categorical_accuracy: 0.9703\n",
      "Epoch 00026: val_loss did not improve from 0.07210\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1307 - categorical_accuracy: 0.9688 - val_loss: 0.0940 - val_categorical_accuracy: 0.9722\n",
      "Epoch 27/100\n",
      "1216/1440 [========================>.....] - ETA: 0s - loss: 0.1386 - categorical_accuracy: 0.9712\n",
      "Epoch 00027: val_loss did not improve from 0.07210\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1304 - categorical_accuracy: 0.9736 - val_loss: 0.1278 - val_categorical_accuracy: 0.9611\n",
      "0.9722222 0.15448979591836734\n",
      "\n",
      "\n",
      "nrx: 5 - real: 3 \n",
      "Train on 9280 samples, validate on 1160 samples\n",
      "Epoch 1/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 2.1897 - categorical_accuracy: 0.1902\n",
      "Epoch 00001: val_loss improved from inf to 1.80300, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 3s 271us/sample - loss: 2.1864 - categorical_accuracy: 0.1908 - val_loss: 1.8030 - val_categorical_accuracy: 0.4069\n",
      "Epoch 2/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 1.6717 - categorical_accuracy: 0.3943\n",
      "Epoch 00002: val_loss improved from 1.80300 to 1.38264, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 194us/sample - loss: 1.6692 - categorical_accuracy: 0.3955 - val_loss: 1.3826 - val_categorical_accuracy: 0.5612\n",
      "Epoch 3/100\n",
      "9088/9280 [============================>.] - ETA: 0s - loss: 1.4102 - categorical_accuracy: 0.4992\n",
      "Epoch 00003: val_loss improved from 1.38264 to 1.16308, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 228us/sample - loss: 1.4073 - categorical_accuracy: 0.5004 - val_loss: 1.1631 - val_categorical_accuracy: 0.6293\n",
      "Epoch 4/100\n",
      "9152/9280 [============================>.] - ETA: 0s - loss: 1.1997 - categorical_accuracy: 0.5915\n",
      "Epoch 00004: val_loss improved from 1.16308 to 1.01036, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 232us/sample - loss: 1.1984 - categorical_accuracy: 0.5923 - val_loss: 1.0104 - val_categorical_accuracy: 0.7026\n",
      "Epoch 5/100\n",
      "9152/9280 [============================>.] - ETA: 0s - loss: 1.0265 - categorical_accuracy: 0.6641\n",
      "Epoch 00005: val_loss improved from 1.01036 to 0.85044, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 232us/sample - loss: 1.0242 - categorical_accuracy: 0.6652 - val_loss: 0.8504 - val_categorical_accuracy: 0.7353\n",
      "Epoch 6/100\n",
      "9120/9280 [============================>.] - ETA: 0s - loss: 0.8620 - categorical_accuracy: 0.7262\n",
      "Epoch 00006: val_loss improved from 0.85044 to 0.68262, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 209us/sample - loss: 0.8627 - categorical_accuracy: 0.7260 - val_loss: 0.6826 - val_categorical_accuracy: 0.8138\n",
      "Epoch 7/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 0.7322 - categorical_accuracy: 0.7732\n",
      "Epoch 00007: val_loss improved from 0.68262 to 0.56773, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 224us/sample - loss: 0.7309 - categorical_accuracy: 0.7740 - val_loss: 0.5677 - val_categorical_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "9248/9280 [============================>.] - ETA: 0s - loss: 0.6383 - categorical_accuracy: 0.8075\n",
      "Epoch 00008: val_loss improved from 0.56773 to 0.49563, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 235us/sample - loss: 0.6381 - categorical_accuracy: 0.8073 - val_loss: 0.4956 - val_categorical_accuracy: 0.8629\n",
      "Epoch 9/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 0.5391 - categorical_accuracy: 0.8411\n",
      "Epoch 00009: val_loss improved from 0.49563 to 0.41389, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 234us/sample - loss: 0.5390 - categorical_accuracy: 0.8411 - val_loss: 0.4139 - val_categorical_accuracy: 0.8784\n",
      "Epoch 10/100\n",
      "9088/9280 [============================>.] - ETA: 0s - loss: 0.4614 - categorical_accuracy: 0.8695\n",
      "Epoch 00010: val_loss improved from 0.41389 to 0.36091, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 237us/sample - loss: 0.4624 - categorical_accuracy: 0.8687 - val_loss: 0.3609 - val_categorical_accuracy: 0.8897\n",
      "Epoch 11/100\n",
      "9088/9280 [============================>.] - ETA: 0s - loss: 0.4187 - categorical_accuracy: 0.8833\n",
      "Epoch 00011: val_loss improved from 0.36091 to 0.32554, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 229us/sample - loss: 0.4186 - categorical_accuracy: 0.8841 - val_loss: 0.3255 - val_categorical_accuracy: 0.9147\n",
      "Epoch 12/100\n",
      "9120/9280 [============================>.] - ETA: 0s - loss: 0.3721 - categorical_accuracy: 0.9008\n",
      "Epoch 00012: val_loss improved from 0.32554 to 0.30844, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 230us/sample - loss: 0.3726 - categorical_accuracy: 0.9004 - val_loss: 0.3084 - val_categorical_accuracy: 0.9181\n",
      "Epoch 13/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 0.3381 - categorical_accuracy: 0.9098\n",
      "Epoch 00013: val_loss improved from 0.30844 to 0.28645, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 230us/sample - loss: 0.3370 - categorical_accuracy: 0.9102 - val_loss: 0.2864 - val_categorical_accuracy: 0.9328\n",
      "Epoch 14/100\n",
      "9152/9280 [============================>.] - ETA: 0s - loss: 0.3045 - categorical_accuracy: 0.9170\n",
      "Epoch 00014: val_loss improved from 0.28645 to 0.25693, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 232us/sample - loss: 0.3046 - categorical_accuracy: 0.9169 - val_loss: 0.2569 - val_categorical_accuracy: 0.9328\n",
      "Epoch 15/100\n",
      "9216/9280 [============================>.] - ETA: 0s - loss: 0.2830 - categorical_accuracy: 0.9235\n",
      "Epoch 00015: val_loss improved from 0.25693 to 0.23234, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 223us/sample - loss: 0.2823 - categorical_accuracy: 0.9238 - val_loss: 0.2323 - val_categorical_accuracy: 0.9448\n",
      "Epoch 16/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 0.2539 - categorical_accuracy: 0.9334\n",
      "Epoch 00016: val_loss improved from 0.23234 to 0.20684, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 235us/sample - loss: 0.2529 - categorical_accuracy: 0.9335 - val_loss: 0.2068 - val_categorical_accuracy: 0.9509\n",
      "Epoch 17/100\n",
      "9152/9280 [============================>.] - ETA: 0s - loss: 0.2371 - categorical_accuracy: 0.9399\n",
      "Epoch 00017: val_loss did not improve from 0.20684\n",
      "9280/9280 [==============================] - 2s 231us/sample - loss: 0.2370 - categorical_accuracy: 0.9399 - val_loss: 0.2199 - val_categorical_accuracy: 0.9397\n",
      "Epoch 18/100\n",
      "9248/9280 [============================>.] - ETA: 0s - loss: 0.2137 - categorical_accuracy: 0.9466\n",
      "Epoch 00018: val_loss did not improve from 0.20684\n",
      "9280/9280 [==============================] - 2s 225us/sample - loss: 0.2135 - categorical_accuracy: 0.9467 - val_loss: 0.2168 - val_categorical_accuracy: 0.9491\n",
      "Epoch 19/100\n",
      "9216/9280 [============================>.] - ETA: 0s - loss: 0.2052 - categorical_accuracy: 0.9475\n",
      "Epoch 00019: val_loss improved from 0.20684 to 0.18271, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 234us/sample - loss: 0.2049 - categorical_accuracy: 0.9475 - val_loss: 0.1827 - val_categorical_accuracy: 0.9612\n",
      "Epoch 20/100\n",
      "9216/9280 [============================>.] - ETA: 0s - loss: 0.2004 - categorical_accuracy: 0.9475\n",
      "Epoch 00020: val_loss improved from 0.18271 to 0.17969, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 236us/sample - loss: 0.2005 - categorical_accuracy: 0.9473 - val_loss: 0.1797 - val_categorical_accuracy: 0.9578\n",
      "Epoch 21/100\n",
      "9120/9280 [============================>.] - ETA: 0s - loss: 0.1810 - categorical_accuracy: 0.9549\n",
      "Epoch 00021: val_loss improved from 0.17969 to 0.17193, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 230us/sample - loss: 0.1808 - categorical_accuracy: 0.9547 - val_loss: 0.1719 - val_categorical_accuracy: 0.9621\n",
      "Epoch 22/100\n",
      "9024/9280 [============================>.] - ETA: 0s - loss: 0.1856 - categorical_accuracy: 0.9548\n",
      "Epoch 00022: val_loss did not improve from 0.17193\n",
      "9280/9280 [==============================] - 2s 225us/sample - loss: 0.1856 - categorical_accuracy: 0.9548 - val_loss: 0.1877 - val_categorical_accuracy: 0.9569\n",
      "Epoch 23/100\n",
      "9024/9280 [============================>.] - ETA: 0s - loss: 0.1683 - categorical_accuracy: 0.9590\n",
      "Epoch 00023: val_loss did not improve from 0.17193\n",
      "9280/9280 [==============================] - 2s 223us/sample - loss: 0.1693 - categorical_accuracy: 0.9587 - val_loss: 0.1764 - val_categorical_accuracy: 0.9586\n",
      "Epoch 24/100\n",
      "9120/9280 [============================>.] - ETA: 0s - loss: 0.1658 - categorical_accuracy: 0.9607\n",
      "Epoch 00024: val_loss did not improve from 0.17193\n",
      "9280/9280 [==============================] - 2s 231us/sample - loss: 0.1670 - categorical_accuracy: 0.9603 - val_loss: 0.1731 - val_categorical_accuracy: 0.9595\n",
      "Epoch 25/100\n",
      "9216/9280 [============================>.] - ETA: 0s - loss: 0.1430 - categorical_accuracy: 0.9665\n",
      "Epoch 00025: val_loss did not improve from 0.17193\n",
      "9280/9280 [==============================] - 2s 225us/sample - loss: 0.1434 - categorical_accuracy: 0.9665 - val_loss: 0.1804 - val_categorical_accuracy: 0.9569\n",
      "Epoch 26/100\n",
      "9088/9280 [============================>.] - ETA: 0s - loss: 0.1411 - categorical_accuracy: 0.9669\n",
      "Epoch 00026: val_loss improved from 0.17193 to 0.15879, saving model to t_weights_1\n",
      "9280/9280 [==============================] - 2s 234us/sample - loss: 0.1408 - categorical_accuracy: 0.9668 - val_loss: 0.1588 - val_categorical_accuracy: 0.9681\n",
      "Epoch 27/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 0.1359 - categorical_accuracy: 0.9688\n",
      "Epoch 00027: val_loss did not improve from 0.15879\n",
      "9280/9280 [==============================] - 2s 227us/sample - loss: 0.1357 - categorical_accuracy: 0.9688 - val_loss: 0.1744 - val_categorical_accuracy: 0.9569\n",
      "Epoch 28/100\n",
      "9184/9280 [============================>.] - ETA: 0s - loss: 0.1350 - categorical_accuracy: 0.9682\n",
      "Epoch 00028: val_loss did not improve from 0.15879\n",
      "9280/9280 [==============================] - 2s 226us/sample - loss: 0.1346 - categorical_accuracy: 0.9683 - val_loss: 0.1711 - val_categorical_accuracy: 0.9629\n",
      "Epoch 29/100\n",
      "9216/9280 [============================>.] - ETA: 0s - loss: 0.1193 - categorical_accuracy: 0.9721\n",
      "Epoch 00029: val_loss did not improve from 0.15879\n",
      "9280/9280 [==============================] - 2s 230us/sample - loss: 0.1194 - categorical_accuracy: 0.9721 - val_loss: 0.1800 - val_categorical_accuracy: 0.9612\n",
      "Epoch 30/100\n",
      "9056/9280 [============================>.] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.9725\n",
      "Epoch 00030: val_loss did not improve from 0.15879\n",
      "9280/9280 [==============================] - 2s 223us/sample - loss: 0.1193 - categorical_accuracy: 0.9724 - val_loss: 0.2047 - val_categorical_accuracy: 0.9534\n",
      "Epoch 31/100\n",
      "9216/9280 [============================>.] - ETA: 0s - loss: 0.1160 - categorical_accuracy: 0.9723\n",
      "Epoch 00031: val_loss did not improve from 0.15879\n",
      "9280/9280 [==============================] - 2s 228us/sample - loss: 0.1163 - categorical_accuracy: 0.9722 - val_loss: 0.1609 - val_categorical_accuracy: 0.9672\n",
      "0.9534483 0.3006122448979592\n",
      "\n",
      "\n",
      "nrx: 10 - real: 3 \n",
      "Train on 16960 samples, validate on 2120 samples\n",
      "Epoch 1/100\n",
      "16928/16960 [============================>.] - ETA: 0s - loss: 2.0163 - categorical_accuracy: 0.2450\n",
      "Epoch 00001: val_loss improved from inf to 1.58465, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 245us/sample - loss: 2.0155 - categorical_accuracy: 0.2453 - val_loss: 1.5847 - val_categorical_accuracy: 0.4467\n",
      "Epoch 2/100\n",
      "16928/16960 [============================>.] - ETA: 0s - loss: 1.4785 - categorical_accuracy: 0.4696\n",
      "Epoch 00002: val_loss improved from 1.58465 to 1.16686, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 219us/sample - loss: 1.4781 - categorical_accuracy: 0.4698 - val_loss: 1.1669 - val_categorical_accuracy: 0.6274\n",
      "Epoch 3/100\n",
      "16896/16960 [============================>.] - ETA: 0s - loss: 1.1544 - categorical_accuracy: 0.6050\n",
      "Epoch 00003: val_loss improved from 1.16686 to 0.89769, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 228us/sample - loss: 1.1530 - categorical_accuracy: 0.6059 - val_loss: 0.8977 - val_categorical_accuracy: 0.7274\n",
      "Epoch 4/100\n",
      "16800/16960 [============================>.] - ETA: 0s - loss: 0.9273 - categorical_accuracy: 0.6907\n",
      "Epoch 00004: val_loss improved from 0.89769 to 0.73264, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 224us/sample - loss: 0.9261 - categorical_accuracy: 0.6909 - val_loss: 0.7326 - val_categorical_accuracy: 0.7637\n",
      "Epoch 5/100\n",
      "16800/16960 [============================>.] - ETA: 0s - loss: 0.7605 - categorical_accuracy: 0.7527\n",
      "Epoch 00005: val_loss improved from 0.73264 to 0.57448, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 234us/sample - loss: 0.7602 - categorical_accuracy: 0.7532 - val_loss: 0.5745 - val_categorical_accuracy: 0.8406\n",
      "Epoch 6/100\n",
      "16832/16960 [============================>.] - ETA: 0s - loss: 0.6275 - categorical_accuracy: 0.8021\n",
      "Epoch 00006: val_loss improved from 0.57448 to 0.46145, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 226us/sample - loss: 0.6264 - categorical_accuracy: 0.8025 - val_loss: 0.4615 - val_categorical_accuracy: 0.8755\n",
      "Epoch 7/100\n",
      "16896/16960 [============================>.] - ETA: 0s - loss: 0.5327 - categorical_accuracy: 0.8384\n",
      "Epoch 00007: val_loss improved from 0.46145 to 0.40072, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 232us/sample - loss: 0.5325 - categorical_accuracy: 0.8385 - val_loss: 0.4007 - val_categorical_accuracy: 0.8925\n",
      "Epoch 8/100\n",
      "16736/16960 [============================>.] - ETA: 0s - loss: 0.4666 - categorical_accuracy: 0.8620\n",
      "Epoch 00008: val_loss improved from 0.40072 to 0.34044, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 230us/sample - loss: 0.4671 - categorical_accuracy: 0.8617 - val_loss: 0.3404 - val_categorical_accuracy: 0.9085\n",
      "Epoch 9/100\n",
      "16864/16960 [============================>.] - ETA: 0s - loss: 0.4018 - categorical_accuracy: 0.8827\n",
      "Epoch 00009: val_loss improved from 0.34044 to 0.31927, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 227us/sample - loss: 0.4028 - categorical_accuracy: 0.8821 - val_loss: 0.3193 - val_categorical_accuracy: 0.9151\n",
      "Epoch 10/100\n",
      "16736/16960 [============================>.] - ETA: 0s - loss: 0.3650 - categorical_accuracy: 0.8923\n",
      "Epoch 00010: val_loss did not improve from 0.31927\n",
      "16960/16960 [==============================] - 4s 227us/sample - loss: 0.3652 - categorical_accuracy: 0.8921 - val_loss: 0.3405 - val_categorical_accuracy: 0.9123\n",
      "Epoch 11/100\n",
      "16928/16960 [============================>.] - ETA: 0s - loss: 0.3290 - categorical_accuracy: 0.9064\n",
      "Epoch 00011: val_loss improved from 0.31927 to 0.28265, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 230us/sample - loss: 0.3291 - categorical_accuracy: 0.9064 - val_loss: 0.2826 - val_categorical_accuracy: 0.9241\n",
      "Epoch 12/100\n",
      "16896/16960 [============================>.] - ETA: 0s - loss: 0.3053 - categorical_accuracy: 0.9131\n",
      "Epoch 00012: val_loss improved from 0.28265 to 0.26251, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 233us/sample - loss: 0.3054 - categorical_accuracy: 0.9132 - val_loss: 0.2625 - val_categorical_accuracy: 0.9325\n",
      "Epoch 13/100\n",
      "16736/16960 [============================>.] - ETA: 0s - loss: 0.2812 - categorical_accuracy: 0.9207\n",
      "Epoch 00013: val_loss improved from 0.26251 to 0.25115, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 226us/sample - loss: 0.2810 - categorical_accuracy: 0.9208 - val_loss: 0.2512 - val_categorical_accuracy: 0.9344\n",
      "Epoch 14/100\n",
      "16768/16960 [============================>.] - ETA: 0s - loss: 0.2651 - categorical_accuracy: 0.9266\n",
      "Epoch 00014: val_loss did not improve from 0.25115\n",
      "16960/16960 [==============================] - 4s 226us/sample - loss: 0.2641 - categorical_accuracy: 0.9266 - val_loss: 0.2636 - val_categorical_accuracy: 0.9330\n",
      "Epoch 15/100\n",
      "16704/16960 [============================>.] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9288\n",
      "Epoch 00015: val_loss improved from 0.25115 to 0.23540, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 232us/sample - loss: 0.2507 - categorical_accuracy: 0.9287 - val_loss: 0.2354 - val_categorical_accuracy: 0.9401\n",
      "Epoch 16/100\n",
      "16896/16960 [============================>.] - ETA: 0s - loss: 0.2374 - categorical_accuracy: 0.9319\n",
      "Epoch 00016: val_loss did not improve from 0.23540\n",
      "16960/16960 [==============================] - 4s 225us/sample - loss: 0.2375 - categorical_accuracy: 0.9318 - val_loss: 0.2360 - val_categorical_accuracy: 0.9368\n",
      "Epoch 17/100\n",
      "16928/16960 [============================>.] - ETA: 0s - loss: 0.2305 - categorical_accuracy: 0.9353\n",
      "Epoch 00017: val_loss did not improve from 0.23540\n",
      "16960/16960 [==============================] - 4s 215us/sample - loss: 0.2305 - categorical_accuracy: 0.9353 - val_loss: 0.2403 - val_categorical_accuracy: 0.9425\n",
      "Epoch 18/100\n",
      "16800/16960 [============================>.] - ETA: 0s - loss: 0.2152 - categorical_accuracy: 0.9393\n",
      "Epoch 00018: val_loss improved from 0.23540 to 0.23489, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 223us/sample - loss: 0.2154 - categorical_accuracy: 0.9390 - val_loss: 0.2349 - val_categorical_accuracy: 0.9415\n",
      "Epoch 19/100\n",
      "16928/16960 [============================>.] - ETA: 0s - loss: 0.2161 - categorical_accuracy: 0.9381\n",
      "Epoch 00019: val_loss improved from 0.23489 to 0.22990, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 232us/sample - loss: 0.2160 - categorical_accuracy: 0.9381 - val_loss: 0.2299 - val_categorical_accuracy: 0.9377\n",
      "Epoch 20/100\n",
      "16896/16960 [============================>.] - ETA: 0s - loss: 0.1958 - categorical_accuracy: 0.9449\n",
      "Epoch 00020: val_loss improved from 0.22990 to 0.21135, saving model to t_weights_1\n",
      "16960/16960 [==============================] - 4s 228us/sample - loss: 0.1957 - categorical_accuracy: 0.9449 - val_loss: 0.2114 - val_categorical_accuracy: 0.9486\n",
      "Epoch 21/100\n",
      "16672/16960 [============================>.] - ETA: 0s - loss: 0.1941 - categorical_accuracy: 0.9444\n",
      "Epoch 00021: val_loss did not improve from 0.21135\n",
      "16960/16960 [==============================] - 4s 227us/sample - loss: 0.1939 - categorical_accuracy: 0.9445 - val_loss: 0.2129 - val_categorical_accuracy: 0.9519\n",
      "Epoch 22/100\n",
      "16800/16960 [============================>.] - ETA: 0s - loss: 0.1859 - categorical_accuracy: 0.9472\n",
      "Epoch 00022: val_loss did not improve from 0.21135\n",
      "16960/16960 [==============================] - 4s 227us/sample - loss: 0.1855 - categorical_accuracy: 0.9473 - val_loss: 0.2199 - val_categorical_accuracy: 0.9509\n",
      "Epoch 23/100\n",
      "16672/16960 [============================>.] - ETA: 0s - loss: 0.1819 - categorical_accuracy: 0.9486\n",
      "Epoch 00023: val_loss did not improve from 0.21135\n",
      "16960/16960 [==============================] - 4s 226us/sample - loss: 0.1815 - categorical_accuracy: 0.9488 - val_loss: 0.2198 - val_categorical_accuracy: 0.9528\n",
      "Epoch 24/100\n",
      "16768/16960 [============================>.] - ETA: 0s - loss: 0.1733 - categorical_accuracy: 0.9507\n",
      "Epoch 00024: val_loss did not improve from 0.21135\n",
      "16960/16960 [==============================] - 4s 231us/sample - loss: 0.1727 - categorical_accuracy: 0.9509 - val_loss: 0.2233 - val_categorical_accuracy: 0.9505\n",
      "Epoch 25/100\n",
      "16736/16960 [============================>.] - ETA: 0s - loss: 0.1730 - categorical_accuracy: 0.9512\n",
      "Epoch 00025: val_loss did not improve from 0.21135\n",
      "16960/16960 [==============================] - 4s 223us/sample - loss: 0.1728 - categorical_accuracy: 0.9515 - val_loss: 0.2229 - val_categorical_accuracy: 0.9509\n",
      "0.9466981 0.2642857142857143\n",
      "\n",
      "\n",
      "nrx: 15 - real: 3 \n",
      "Train on 24936 samples, validate on 3117 samples\n",
      "Epoch 1/100\n",
      "24832/24936 [============================>.] - ETA: 0s - loss: 1.9065 - categorical_accuracy: 0.2985\n",
      "Epoch 00001: val_loss improved from inf to 1.39857, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 223us/sample - loss: 1.9045 - categorical_accuracy: 0.2992 - val_loss: 1.3986 - val_categorical_accuracy: 0.5287\n",
      "Epoch 2/100\n",
      "24928/24936 [============================>.] - ETA: 0s - loss: 1.3064 - categorical_accuracy: 0.5462\n",
      "Epoch 00002: val_loss improved from 1.39857 to 0.96388, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 227us/sample - loss: 1.3065 - categorical_accuracy: 0.5462 - val_loss: 0.9639 - val_categorical_accuracy: 0.6907\n",
      "Epoch 3/100\n",
      "24832/24936 [============================>.] - ETA: 0s - loss: 0.9527 - categorical_accuracy: 0.6811\n",
      "Epoch 00003: val_loss improved from 0.96388 to 0.67365, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 5s 212us/sample - loss: 0.9520 - categorical_accuracy: 0.6814 - val_loss: 0.6736 - val_categorical_accuracy: 0.7902\n",
      "Epoch 4/100\n",
      "24736/24936 [============================>.] - ETA: 0s - loss: 0.7126 - categorical_accuracy: 0.7711\n",
      "Epoch 00004: val_loss improved from 0.67365 to 0.50996, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 228us/sample - loss: 0.7118 - categorical_accuracy: 0.7713 - val_loss: 0.5100 - val_categorical_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "24864/24936 [============================>.] - ETA: 0s - loss: 0.5712 - categorical_accuracy: 0.8204\n",
      "Epoch 00005: val_loss improved from 0.50996 to 0.42823, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 221us/sample - loss: 0.5711 - categorical_accuracy: 0.8204 - val_loss: 0.4282 - val_categorical_accuracy: 0.8726\n",
      "Epoch 6/100\n",
      "24768/24936 [============================>.] - ETA: 0s - loss: 0.4765 - categorical_accuracy: 0.8571\n",
      "Epoch 00006: val_loss improved from 0.42823 to 0.36588, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 228us/sample - loss: 0.4760 - categorical_accuracy: 0.8571 - val_loss: 0.3659 - val_categorical_accuracy: 0.8877\n",
      "Epoch 7/100\n",
      "24832/24936 [============================>.] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.8746\n",
      "Epoch 00007: val_loss improved from 0.36588 to 0.30419, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 229us/sample - loss: 0.4094 - categorical_accuracy: 0.8747 - val_loss: 0.3042 - val_categorical_accuracy: 0.9115\n",
      "Epoch 8/100\n",
      "24736/24936 [============================>.] - ETA: 0s - loss: 0.3691 - categorical_accuracy: 0.8925\n",
      "Epoch 00008: val_loss did not improve from 0.30419\n",
      "24936/24936 [==============================] - 6s 229us/sample - loss: 0.3689 - categorical_accuracy: 0.8925 - val_loss: 0.3042 - val_categorical_accuracy: 0.9102\n",
      "Epoch 9/100\n",
      "24928/24936 [============================>.] - ETA: 0s - loss: 0.3365 - categorical_accuracy: 0.9004\n",
      "Epoch 00009: val_loss improved from 0.30419 to 0.28161, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 231us/sample - loss: 0.3365 - categorical_accuracy: 0.9005 - val_loss: 0.2816 - val_categorical_accuracy: 0.9147\n",
      "Epoch 10/100\n",
      "24704/24936 [============================>.] - ETA: 0s - loss: 0.3013 - categorical_accuracy: 0.9128\n",
      "Epoch 00010: val_loss improved from 0.28161 to 0.26097, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 228us/sample - loss: 0.3016 - categorical_accuracy: 0.9127 - val_loss: 0.2610 - val_categorical_accuracy: 0.9224\n",
      "Epoch 11/100\n",
      "24704/24936 [============================>.] - ETA: 0s - loss: 0.2878 - categorical_accuracy: 0.9160\n",
      "Epoch 00011: val_loss improved from 0.26097 to 0.25319, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 230us/sample - loss: 0.2876 - categorical_accuracy: 0.9163 - val_loss: 0.2532 - val_categorical_accuracy: 0.9265\n",
      "Epoch 12/100\n",
      "24928/24936 [============================>.] - ETA: 0s - loss: 0.2669 - categorical_accuracy: 0.9244\n",
      "Epoch 00012: val_loss improved from 0.25319 to 0.21573, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 5s 209us/sample - loss: 0.2668 - categorical_accuracy: 0.9244 - val_loss: 0.2157 - val_categorical_accuracy: 0.9397\n",
      "Epoch 13/100\n",
      "24928/24936 [============================>.] - ETA: 0s - loss: 0.2598 - categorical_accuracy: 0.9252\n",
      "Epoch 00013: val_loss did not improve from 0.21573\n",
      "24936/24936 [==============================] - 6s 227us/sample - loss: 0.2597 - categorical_accuracy: 0.9252 - val_loss: 0.2158 - val_categorical_accuracy: 0.9429\n",
      "Epoch 14/100\n",
      "24704/24936 [============================>.] - ETA: 0s - loss: 0.2390 - categorical_accuracy: 0.9303\n",
      "Epoch 00014: val_loss improved from 0.21573 to 0.21046, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 229us/sample - loss: 0.2386 - categorical_accuracy: 0.9305 - val_loss: 0.2105 - val_categorical_accuracy: 0.9432\n",
      "Epoch 15/100\n",
      "24832/24936 [============================>.] - ETA: 0s - loss: 0.2309 - categorical_accuracy: 0.9325\n",
      "Epoch 00015: val_loss did not improve from 0.21046\n",
      "24936/24936 [==============================] - 6s 228us/sample - loss: 0.2306 - categorical_accuracy: 0.9326 - val_loss: 0.2183 - val_categorical_accuracy: 0.9461\n",
      "Epoch 16/100\n",
      "24864/24936 [============================>.] - ETA: 0s - loss: 0.2251 - categorical_accuracy: 0.9356\n",
      "Epoch 00016: val_loss did not improve from 0.21046\n",
      "24936/24936 [==============================] - 5s 220us/sample - loss: 0.2251 - categorical_accuracy: 0.9356 - val_loss: 0.2223 - val_categorical_accuracy: 0.9435\n",
      "Epoch 17/100\n",
      "24864/24936 [============================>.] - ETA: 0s - loss: 0.2155 - categorical_accuracy: 0.9389\n",
      "Epoch 00017: val_loss did not improve from 0.21046\n",
      "24936/24936 [==============================] - 6s 225us/sample - loss: 0.2158 - categorical_accuracy: 0.9389 - val_loss: 0.2132 - val_categorical_accuracy: 0.9461\n",
      "Epoch 18/100\n",
      "24864/24936 [============================>.] - ETA: 0s - loss: 0.2023 - categorical_accuracy: 0.9428\n",
      "Epoch 00018: val_loss improved from 0.21046 to 0.20583, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 232us/sample - loss: 0.2021 - categorical_accuracy: 0.9428 - val_loss: 0.2058 - val_categorical_accuracy: 0.9474\n",
      "Epoch 19/100\n",
      "24928/24936 [============================>.] - ETA: 0s - loss: 0.2039 - categorical_accuracy: 0.9419\n",
      "Epoch 00019: val_loss did not improve from 0.20583\n",
      "24936/24936 [==============================] - 6s 227us/sample - loss: 0.2039 - categorical_accuracy: 0.9419 - val_loss: 0.2145 - val_categorical_accuracy: 0.9467\n",
      "Epoch 20/100\n",
      "24704/24936 [============================>.] - ETA: 0s - loss: 0.1940 - categorical_accuracy: 0.9446\n",
      "Epoch 00020: val_loss did not improve from 0.20583\n",
      "24936/24936 [==============================] - 6s 225us/sample - loss: 0.1944 - categorical_accuracy: 0.9445 - val_loss: 0.2089 - val_categorical_accuracy: 0.9477\n",
      "Epoch 21/100\n",
      "24736/24936 [============================>.] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9489\n",
      "Epoch 00021: val_loss improved from 0.20583 to 0.20564, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 230us/sample - loss: 0.1883 - categorical_accuracy: 0.9489 - val_loss: 0.2056 - val_categorical_accuracy: 0.9471\n",
      "Epoch 22/100\n",
      "24736/24936 [============================>.] - ETA: 0s - loss: 0.1864 - categorical_accuracy: 0.9473\n",
      "Epoch 00022: val_loss did not improve from 0.20564\n",
      "24936/24936 [==============================] - 6s 228us/sample - loss: 0.1865 - categorical_accuracy: 0.9471 - val_loss: 0.2076 - val_categorical_accuracy: 0.9512\n",
      "Epoch 23/100\n",
      "24928/24936 [============================>.] - ETA: 0s - loss: 0.1809 - categorical_accuracy: 0.9498\n",
      "Epoch 00023: val_loss improved from 0.20564 to 0.19599, saving model to t_weights_1\n",
      "24936/24936 [==============================] - 6s 227us/sample - loss: 0.1809 - categorical_accuracy: 0.9498 - val_loss: 0.1960 - val_categorical_accuracy: 0.9532\n",
      "Epoch 24/100\n",
      "24896/24936 [============================>.] - ETA: 0s - loss: 0.1785 - categorical_accuracy: 0.9510\n",
      "Epoch 00024: val_loss did not improve from 0.19599\n",
      "24936/24936 [==============================] - 6s 228us/sample - loss: 0.1785 - categorical_accuracy: 0.9510 - val_loss: 0.2163 - val_categorical_accuracy: 0.9461\n",
      "Epoch 25/100\n",
      "24832/24936 [============================>.] - ETA: 0s - loss: 0.1779 - categorical_accuracy: 0.9508\n",
      "Epoch 00025: val_loss did not improve from 0.19599\n",
      "24936/24936 [==============================] - 6s 229us/sample - loss: 0.1777 - categorical_accuracy: 0.9509 - val_loss: 0.2006 - val_categorical_accuracy: 0.9512\n",
      "Epoch 26/100\n",
      "24736/24936 [============================>.] - ETA: 0s - loss: 0.1660 - categorical_accuracy: 0.9535\n",
      "Epoch 00026: val_loss did not improve from 0.19599\n",
      "24936/24936 [==============================] - 6s 222us/sample - loss: 0.1660 - categorical_accuracy: 0.9534 - val_loss: 0.2259 - val_categorical_accuracy: 0.9423\n",
      "Epoch 27/100\n",
      "24864/24936 [============================>.] - ETA: 0s - loss: 0.1658 - categorical_accuracy: 0.9532\n",
      "Epoch 00027: val_loss did not improve from 0.19599\n",
      "24936/24936 [==============================] - 5s 219us/sample - loss: 0.1661 - categorical_accuracy: 0.9531 - val_loss: 0.2122 - val_categorical_accuracy: 0.9506\n",
      "Epoch 28/100\n",
      "24800/24936 [============================>.] - ETA: 0s - loss: 0.1618 - categorical_accuracy: 0.9550\n",
      "Epoch 00028: val_loss did not improve from 0.19599\n",
      "24936/24936 [==============================] - 6s 230us/sample - loss: 0.1618 - categorical_accuracy: 0.9550 - val_loss: 0.2080 - val_categorical_accuracy: 0.9538\n",
      "0.946102 0.4014285714285714\n",
      "\n",
      "\n",
      "nrx: 20 - real: 3 \n",
      "Train on 32456 samples, validate on 4057 samples\n",
      "Epoch 1/100\n",
      "32448/32456 [============================>.] - ETA: 0s - loss: 1.9271 - categorical_accuracy: 0.2766\n",
      "Epoch 00001: val_loss improved from inf to 1.59246, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 225us/sample - loss: 1.9269 - categorical_accuracy: 0.2767 - val_loss: 1.5925 - val_categorical_accuracy: 0.4420\n",
      "Epoch 2/100\n",
      "32352/32456 [============================>.] - ETA: 0s - loss: 1.4787 - categorical_accuracy: 0.4672\n",
      "Epoch 00002: val_loss improved from 1.59246 to 1.22679, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 224us/sample - loss: 1.4783 - categorical_accuracy: 0.4676 - val_loss: 1.2268 - val_categorical_accuracy: 0.5864\n",
      "Epoch 3/100\n",
      "32256/32456 [============================>.] - ETA: 0s - loss: 1.1522 - categorical_accuracy: 0.6033\n",
      "Epoch 00003: val_loss improved from 1.22679 to 0.94027, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 226us/sample - loss: 1.1515 - categorical_accuracy: 0.6033 - val_loss: 0.9403 - val_categorical_accuracy: 0.7064\n",
      "Epoch 4/100\n",
      "32320/32456 [============================>.] - ETA: 0s - loss: 0.8970 - categorical_accuracy: 0.7000\n",
      "Epoch 00004: val_loss improved from 0.94027 to 0.68235, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 227us/sample - loss: 0.8963 - categorical_accuracy: 0.7003 - val_loss: 0.6823 - val_categorical_accuracy: 0.7747\n",
      "Epoch 5/100\n",
      "32352/32456 [============================>.] - ETA: 0s - loss: 0.7141 - categorical_accuracy: 0.7677\n",
      "Epoch 00005: val_loss improved from 0.68235 to 0.55277, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 227us/sample - loss: 0.7145 - categorical_accuracy: 0.7675 - val_loss: 0.5528 - val_categorical_accuracy: 0.8329\n",
      "Epoch 6/100\n",
      "32352/32456 [============================>.] - ETA: 0s - loss: 0.5883 - categorical_accuracy: 0.8148\n",
      "Epoch 00006: val_loss improved from 0.55277 to 0.45512, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 227us/sample - loss: 0.5884 - categorical_accuracy: 0.8148 - val_loss: 0.4551 - val_categorical_accuracy: 0.8642\n",
      "Epoch 7/100\n",
      "32384/32456 [============================>.] - ETA: 0s - loss: 0.5075 - categorical_accuracy: 0.8424\n",
      "Epoch 00007: val_loss improved from 0.45512 to 0.37219, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 219us/sample - loss: 0.5076 - categorical_accuracy: 0.8425 - val_loss: 0.3722 - val_categorical_accuracy: 0.8913\n",
      "Epoch 8/100\n",
      "32416/32456 [============================>.] - ETA: 0s - loss: 0.4479 - categorical_accuracy: 0.8639\n",
      "Epoch 00008: val_loss improved from 0.37219 to 0.34992, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 227us/sample - loss: 0.4478 - categorical_accuracy: 0.8640 - val_loss: 0.3499 - val_categorical_accuracy: 0.8980\n",
      "Epoch 9/100\n",
      "32288/32456 [============================>.] - ETA: 0s - loss: 0.4015 - categorical_accuracy: 0.8789\n",
      "Epoch 00009: val_loss improved from 0.34992 to 0.33690, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 225us/sample - loss: 0.4013 - categorical_accuracy: 0.8791 - val_loss: 0.3369 - val_categorical_accuracy: 0.9051\n",
      "Epoch 10/100\n",
      "32448/32456 [============================>.] - ETA: 0s - loss: 0.3648 - categorical_accuracy: 0.8893\n",
      "Epoch 00010: val_loss improved from 0.33690 to 0.29426, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 226us/sample - loss: 0.3648 - categorical_accuracy: 0.8893 - val_loss: 0.2943 - val_categorical_accuracy: 0.9187\n",
      "Epoch 11/100\n",
      "32384/32456 [============================>.] - ETA: 0s - loss: 0.3405 - categorical_accuracy: 0.8974\n",
      "Epoch 00011: val_loss improved from 0.29426 to 0.29015, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 226us/sample - loss: 0.3404 - categorical_accuracy: 0.8974 - val_loss: 0.2901 - val_categorical_accuracy: 0.9196\n",
      "Epoch 12/100\n",
      "32352/32456 [============================>.] - ETA: 0s - loss: 0.3193 - categorical_accuracy: 0.9071\n",
      "Epoch 00012: val_loss improved from 0.29015 to 0.27607, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 226us/sample - loss: 0.3195 - categorical_accuracy: 0.9070 - val_loss: 0.2761 - val_categorical_accuracy: 0.9243\n",
      "Epoch 13/100\n",
      "32384/32456 [============================>.] - ETA: 0s - loss: 0.2989 - categorical_accuracy: 0.9130\n",
      "Epoch 00013: val_loss improved from 0.27607 to 0.27166, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 225us/sample - loss: 0.2992 - categorical_accuracy: 0.9130 - val_loss: 0.2717 - val_categorical_accuracy: 0.9288\n",
      "Epoch 14/100\n",
      "32352/32456 [============================>.] - ETA: 0s - loss: 0.2850 - categorical_accuracy: 0.9170\n",
      "Epoch 00014: val_loss improved from 0.27166 to 0.24868, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 226us/sample - loss: 0.2856 - categorical_accuracy: 0.9168 - val_loss: 0.2487 - val_categorical_accuracy: 0.9349\n",
      "Epoch 15/100\n",
      "32224/32456 [============================>.] - ETA: 0s - loss: 0.2704 - categorical_accuracy: 0.9227\n",
      "Epoch 00015: val_loss did not improve from 0.24868\n",
      "32456/32456 [==============================] - 7s 226us/sample - loss: 0.2702 - categorical_accuracy: 0.9226 - val_loss: 0.2556 - val_categorical_accuracy: 0.9352\n",
      "Epoch 16/100\n",
      "32384/32456 [============================>.] - ETA: 0s - loss: 0.2569 - categorical_accuracy: 0.9260\n",
      "Epoch 00016: val_loss did not improve from 0.24868\n",
      "32456/32456 [==============================] - 7s 220us/sample - loss: 0.2569 - categorical_accuracy: 0.9260 - val_loss: 0.2535 - val_categorical_accuracy: 0.9384\n",
      "Epoch 17/100\n",
      "32288/32456 [============================>.] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.9282\n",
      "Epoch 00017: val_loss did not improve from 0.24868\n",
      "32456/32456 [==============================] - 7s 222us/sample - loss: 0.2492 - categorical_accuracy: 0.9283 - val_loss: 0.2854 - val_categorical_accuracy: 0.9201\n",
      "Epoch 18/100\n",
      "32288/32456 [============================>.] - ETA: 0s - loss: 0.2447 - categorical_accuracy: 0.9292\n",
      "Epoch 00018: val_loss improved from 0.24868 to 0.23941, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 207us/sample - loss: 0.2448 - categorical_accuracy: 0.9292 - val_loss: 0.2394 - val_categorical_accuracy: 0.9408\n",
      "Epoch 19/100\n",
      "32416/32456 [============================>.] - ETA: 0s - loss: 0.2364 - categorical_accuracy: 0.9311\n",
      "Epoch 00019: val_loss improved from 0.23941 to 0.23281, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 222us/sample - loss: 0.2365 - categorical_accuracy: 0.9310 - val_loss: 0.2328 - val_categorical_accuracy: 0.9431\n",
      "Epoch 20/100\n",
      "32256/32456 [============================>.] - ETA: 0s - loss: 0.2293 - categorical_accuracy: 0.9356\n",
      "Epoch 00020: val_loss improved from 0.23281 to 0.22642, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 224us/sample - loss: 0.2293 - categorical_accuracy: 0.9356 - val_loss: 0.2264 - val_categorical_accuracy: 0.9440\n",
      "Epoch 21/100\n",
      "32320/32456 [============================>.] - ETA: 0s - loss: 0.2243 - categorical_accuracy: 0.9358\n",
      "Epoch 00021: val_loss did not improve from 0.22642\n",
      "32456/32456 [==============================] - 7s 220us/sample - loss: 0.2244 - categorical_accuracy: 0.9358 - val_loss: 0.2291 - val_categorical_accuracy: 0.9438\n",
      "Epoch 22/100\n",
      "32288/32456 [============================>.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9371\n",
      "Epoch 00022: val_loss did not improve from 0.22642\n",
      "32456/32456 [==============================] - 7s 223us/sample - loss: 0.2194 - categorical_accuracy: 0.9371 - val_loss: 0.2297 - val_categorical_accuracy: 0.9436\n",
      "Epoch 23/100\n",
      "32352/32456 [============================>.] - ETA: 0s - loss: 0.2147 - categorical_accuracy: 0.9395\n",
      "Epoch 00023: val_loss did not improve from 0.22642\n",
      "32456/32456 [==============================] - 7s 221us/sample - loss: 0.2145 - categorical_accuracy: 0.9395 - val_loss: 0.2428 - val_categorical_accuracy: 0.9440\n",
      "Epoch 24/100\n",
      "32448/32456 [============================>.] - ETA: 0s - loss: 0.2102 - categorical_accuracy: 0.9418\n",
      "Epoch 00024: val_loss improved from 0.22642 to 0.22489, saving model to t_weights_1\n",
      "32456/32456 [==============================] - 7s 219us/sample - loss: 0.2103 - categorical_accuracy: 0.9418 - val_loss: 0.2249 - val_categorical_accuracy: 0.9458\n",
      "Epoch 25/100\n",
      "32288/32456 [============================>.] - ETA: 0s - loss: 0.2026 - categorical_accuracy: 0.9421\n",
      "Epoch 00025: val_loss did not improve from 0.22489\n",
      "32456/32456 [==============================] - 7s 222us/sample - loss: 0.2032 - categorical_accuracy: 0.9419 - val_loss: 0.2786 - val_categorical_accuracy: 0.9416\n",
      "Epoch 26/100\n",
      "32384/32456 [============================>.] - ETA: 0s - loss: 0.2017 - categorical_accuracy: 0.9433\n",
      "Epoch 00026: val_loss did not improve from 0.22489\n",
      "32456/32456 [==============================] - 7s 223us/sample - loss: 0.2019 - categorical_accuracy: 0.9432 - val_loss: 0.2543 - val_categorical_accuracy: 0.9416\n",
      "Epoch 27/100\n",
      "32320/32456 [============================>.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9437\n",
      "Epoch 00027: val_loss did not improve from 0.22489\n",
      "32456/32456 [==============================] - 7s 223us/sample - loss: 0.1997 - categorical_accuracy: 0.9439 - val_loss: 0.2265 - val_categorical_accuracy: 0.9482\n",
      "Epoch 28/100\n",
      "32288/32456 [============================>.] - ETA: 0s - loss: 0.1891 - categorical_accuracy: 0.9473\n",
      "Epoch 00028: val_loss did not improve from 0.22489\n",
      "32456/32456 [==============================] - 7s 223us/sample - loss: 0.1890 - categorical_accuracy: 0.9473 - val_loss: 0.2610 - val_categorical_accuracy: 0.9438\n",
      "Epoch 29/100\n",
      "32256/32456 [============================>.] - ETA: 0s - loss: 0.1906 - categorical_accuracy: 0.9472\n",
      "Epoch 00029: val_loss did not improve from 0.22489\n",
      "32456/32456 [==============================] - 7s 221us/sample - loss: 0.1911 - categorical_accuracy: 0.9472 - val_loss: 0.2539 - val_categorical_accuracy: 0.9475\n",
      "0.9327089 0.5624489795918367\n",
      "\n",
      "\n",
      "nrx: 25 - real: 3 \n",
      "Train on 40456 samples, validate on 5057 samples\n",
      "Epoch 1/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 1.8552 - categorical_accuracy: 0.3132\n",
      "Epoch 00001: val_loss improved from inf to 1.43255, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 234us/sample - loss: 1.8534 - categorical_accuracy: 0.3139 - val_loss: 1.4325 - val_categorical_accuracy: 0.4940\n",
      "Epoch 2/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 1.3059 - categorical_accuracy: 0.5346\n",
      "Epoch 00002: val_loss improved from 1.43255 to 1.07776, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 1.3059 - categorical_accuracy: 0.5346 - val_loss: 1.0778 - val_categorical_accuracy: 0.6488\n",
      "Epoch 3/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.9957 - categorical_accuracy: 0.6618\n",
      "Epoch 00003: val_loss improved from 1.07776 to 0.78111, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 220us/sample - loss: 0.9947 - categorical_accuracy: 0.6623 - val_loss: 0.7811 - val_categorical_accuracy: 0.7558\n",
      "Epoch 4/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.7824 - categorical_accuracy: 0.7466\n",
      "Epoch 00004: val_loss improved from 0.78111 to 0.59556, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 225us/sample - loss: 0.7824 - categorical_accuracy: 0.7466 - val_loss: 0.5956 - val_categorical_accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.6230 - categorical_accuracy: 0.8011\n",
      "Epoch 00005: val_loss improved from 0.59556 to 0.49403, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 225us/sample - loss: 0.6230 - categorical_accuracy: 0.8010 - val_loss: 0.4940 - val_categorical_accuracy: 0.8462\n",
      "Epoch 6/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.5151 - categorical_accuracy: 0.8407\n",
      "Epoch 00006: val_loss improved from 0.49403 to 0.44229, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 226us/sample - loss: 0.5151 - categorical_accuracy: 0.8407 - val_loss: 0.4423 - val_categorical_accuracy: 0.8582\n",
      "Epoch 7/100\n",
      "40320/40456 [============================>.] - ETA: 0s - loss: 0.4541 - categorical_accuracy: 0.8608\n",
      "Epoch 00007: val_loss improved from 0.44229 to 0.36561, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.4540 - categorical_accuracy: 0.8609 - val_loss: 0.3656 - val_categorical_accuracy: 0.8904\n",
      "Epoch 8/100\n",
      "40192/40456 [============================>.] - ETA: 0s - loss: 0.4045 - categorical_accuracy: 0.8747\n",
      "Epoch 00008: val_loss improved from 0.36561 to 0.33431, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.4042 - categorical_accuracy: 0.8749 - val_loss: 0.3343 - val_categorical_accuracy: 0.9003\n",
      "Epoch 9/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.3682 - categorical_accuracy: 0.8901\n",
      "Epoch 00009: val_loss did not improve from 0.33431\n",
      "40456/40456 [==============================] - 9s 217us/sample - loss: 0.3682 - categorical_accuracy: 0.8901 - val_loss: 0.3362 - val_categorical_accuracy: 0.8980\n",
      "Epoch 10/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.3478 - categorical_accuracy: 0.8955\n",
      "Epoch 00010: val_loss improved from 0.33431 to 0.30834, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.3478 - categorical_accuracy: 0.8955 - val_loss: 0.3083 - val_categorical_accuracy: 0.9073\n",
      "Epoch 11/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.3235 - categorical_accuracy: 0.9031\n",
      "Epoch 00011: val_loss improved from 0.30834 to 0.29105, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 211us/sample - loss: 0.3236 - categorical_accuracy: 0.9030 - val_loss: 0.2911 - val_categorical_accuracy: 0.9175\n",
      "Epoch 12/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.3108 - categorical_accuracy: 0.9074\n",
      "Epoch 00012: val_loss improved from 0.29105 to 0.28258, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.3111 - categorical_accuracy: 0.9074 - val_loss: 0.2826 - val_categorical_accuracy: 0.9183\n",
      "Epoch 13/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.2994 - categorical_accuracy: 0.9128\n",
      "Epoch 00013: val_loss did not improve from 0.28258\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.2991 - categorical_accuracy: 0.9129 - val_loss: 0.3139 - val_categorical_accuracy: 0.9106\n",
      "Epoch 14/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.2817 - categorical_accuracy: 0.9180\n",
      "Epoch 00014: val_loss improved from 0.28258 to 0.27895, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.2820 - categorical_accuracy: 0.9179 - val_loss: 0.2790 - val_categorical_accuracy: 0.9221\n",
      "Epoch 15/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9204\n",
      "Epoch 00015: val_loss improved from 0.27895 to 0.27257, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2719 - categorical_accuracy: 0.9203 - val_loss: 0.2726 - val_categorical_accuracy: 0.9258\n",
      "Epoch 16/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.2652 - categorical_accuracy: 0.9229\n",
      "Epoch 00016: val_loss improved from 0.27257 to 0.27195, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 218us/sample - loss: 0.2650 - categorical_accuracy: 0.9230 - val_loss: 0.2719 - val_categorical_accuracy: 0.9217\n",
      "Epoch 17/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.2552 - categorical_accuracy: 0.9264\n",
      "Epoch 00017: val_loss improved from 0.27195 to 0.25643, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2553 - categorical_accuracy: 0.9263 - val_loss: 0.2564 - val_categorical_accuracy: 0.9316\n",
      "Epoch 18/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.2463 - categorical_accuracy: 0.9295\n",
      "Epoch 00018: val_loss did not improve from 0.25643\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2463 - categorical_accuracy: 0.9295 - val_loss: 0.2769 - val_categorical_accuracy: 0.9270\n",
      "Epoch 19/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.2398 - categorical_accuracy: 0.9315\n",
      "Epoch 00019: val_loss did not improve from 0.25643\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.2399 - categorical_accuracy: 0.9315 - val_loss: 0.2616 - val_categorical_accuracy: 0.9347\n",
      "Epoch 20/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.2297 - categorical_accuracy: 0.9335\n",
      "Epoch 00020: val_loss did not improve from 0.25643\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.2295 - categorical_accuracy: 0.9336 - val_loss: 0.2785 - val_categorical_accuracy: 0.9266\n",
      "Epoch 21/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.2321 - categorical_accuracy: 0.9340\n",
      "Epoch 00021: val_loss did not improve from 0.25643\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.2325 - categorical_accuracy: 0.9340 - val_loss: 0.2756 - val_categorical_accuracy: 0.9278\n",
      "Epoch 22/100\n",
      "40224/40456 [============================>.] - ETA: 0s - loss: 0.2201 - categorical_accuracy: 0.9370\n",
      "Epoch 00022: val_loss improved from 0.25643 to 0.24427, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2206 - categorical_accuracy: 0.9369 - val_loss: 0.2443 - val_categorical_accuracy: 0.9379\n",
      "Epoch 23/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.2180 - categorical_accuracy: 0.9384\n",
      "Epoch 00023: val_loss did not improve from 0.24427\n",
      "40456/40456 [==============================] - 9s 217us/sample - loss: 0.2181 - categorical_accuracy: 0.9384 - val_loss: 0.2631 - val_categorical_accuracy: 0.9349\n",
      "Epoch 24/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.2134 - categorical_accuracy: 0.9395\n",
      "Epoch 00024: val_loss did not improve from 0.24427\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.2135 - categorical_accuracy: 0.9395 - val_loss: 0.2545 - val_categorical_accuracy: 0.9361\n",
      "Epoch 25/100\n",
      "40288/40456 [============================>.] - ETA: 0s - loss: 0.2118 - categorical_accuracy: 0.9418\n",
      "Epoch 00025: val_loss improved from 0.24427 to 0.24344, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.2117 - categorical_accuracy: 0.9419 - val_loss: 0.2434 - val_categorical_accuracy: 0.9387\n",
      "Epoch 26/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.2027 - categorical_accuracy: 0.9428\n",
      "Epoch 00026: val_loss did not improve from 0.24344\n",
      "40456/40456 [==============================] - 9s 221us/sample - loss: 0.2030 - categorical_accuracy: 0.9428 - val_loss: 0.2683 - val_categorical_accuracy: 0.9343\n",
      "Epoch 27/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9446\n",
      "Epoch 00027: val_loss improved from 0.24344 to 0.24229, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.1999 - categorical_accuracy: 0.9446 - val_loss: 0.2423 - val_categorical_accuracy: 0.9425\n",
      "Epoch 28/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.1951 - categorical_accuracy: 0.9448\n",
      "Epoch 00028: val_loss did not improve from 0.24229\n",
      "40456/40456 [==============================] - 9s 221us/sample - loss: 0.1950 - categorical_accuracy: 0.9448 - val_loss: 0.2649 - val_categorical_accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "40448/40456 [============================>.] - ETA: 0s - loss: 0.1916 - categorical_accuracy: 0.9466\n",
      "Epoch 00029: val_loss did not improve from 0.24229\n",
      "40456/40456 [==============================] - 9s 221us/sample - loss: 0.1916 - categorical_accuracy: 0.9466 - val_loss: 0.2555 - val_categorical_accuracy: 0.9403\n",
      "Epoch 30/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.1912 - categorical_accuracy: 0.9473\n",
      "Epoch 00030: val_loss improved from 0.24229 to 0.23799, saving model to t_weights_1\n",
      "40456/40456 [==============================] - 9s 220us/sample - loss: 0.1911 - categorical_accuracy: 0.9472 - val_loss: 0.2380 - val_categorical_accuracy: 0.9405\n",
      "Epoch 31/100\n",
      "40416/40456 [============================>.] - ETA: 0s - loss: 0.1869 - categorical_accuracy: 0.9488\n",
      "Epoch 00031: val_loss did not improve from 0.23799\n",
      "40456/40456 [==============================] - 9s 222us/sample - loss: 0.1869 - categorical_accuracy: 0.9487 - val_loss: 0.2611 - val_categorical_accuracy: 0.9397\n",
      "Epoch 32/100\n",
      "40352/40456 [============================>.] - ETA: 0s - loss: 0.1853 - categorical_accuracy: 0.9493\n",
      "Epoch 00032: val_loss did not improve from 0.23799\n",
      "40456/40456 [==============================] - 9s 221us/sample - loss: 0.1854 - categorical_accuracy: 0.9493 - val_loss: 0.2577 - val_categorical_accuracy: 0.9371\n",
      "Epoch 33/100\n",
      "40384/40456 [============================>.] - ETA: 0s - loss: 0.1818 - categorical_accuracy: 0.9492\n",
      "Epoch 00033: val_loss did not improve from 0.23799\n",
      "40456/40456 [==============================] - 9s 224us/sample - loss: 0.1821 - categorical_accuracy: 0.9491 - val_loss: 0.2487 - val_categorical_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "40320/40456 [============================>.] - ETA: 0s - loss: 0.1788 - categorical_accuracy: 0.9517\n",
      "Epoch 00034: val_loss did not improve from 0.23799\n",
      "40456/40456 [==============================] - 9s 223us/sample - loss: 0.1787 - categorical_accuracy: 0.9518 - val_loss: 0.2386 - val_categorical_accuracy: 0.9432\n",
      "Epoch 35/100\n",
      "40256/40456 [============================>.] - ETA: 0s - loss: 0.1727 - categorical_accuracy: 0.9530\n",
      "Epoch 00035: val_loss did not improve from 0.23799\n",
      "40456/40456 [==============================] - 9s 220us/sample - loss: 0.1733 - categorical_accuracy: 0.9528 - val_loss: 0.2471 - val_categorical_accuracy: 0.9438\n",
      "0.94680643 0.6004081632653061\n",
      "\n",
      "\n",
      "nrx: 0 - real: 4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cls_weights = np.max(stat,axis=0)/stat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 2.3116 - categorical_accuracy: 0.1556\n",
      "Epoch 00001: val_loss improved from inf to 2.28646, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 1s 479us/sample - loss: 2.3097 - categorical_accuracy: 0.1600 - val_loss: 2.2865 - val_categorical_accuracy: 0.1500\n",
      "Epoch 2/100\n",
      "1376/1600 [========================>.....] - ETA: 0s - loss: 2.1333 - categorical_accuracy: 0.2362\n",
      "Epoch 00002: val_loss improved from 2.28646 to 1.71905, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 262us/sample - loss: 2.0916 - categorical_accuracy: 0.2425 - val_loss: 1.7190 - val_categorical_accuracy: 0.3800\n",
      "Epoch 3/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 1.5043 - categorical_accuracy: 0.4260\n",
      "Epoch 00003: val_loss improved from 1.71905 to 1.13674, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 276us/sample - loss: 1.4982 - categorical_accuracy: 0.4263 - val_loss: 1.1367 - val_categorical_accuracy: 0.7250\n",
      "Epoch 4/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 1.0578 - categorical_accuracy: 0.6122\n",
      "Epoch 00004: val_loss improved from 1.13674 to 0.72906, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 273us/sample - loss: 1.0512 - categorical_accuracy: 0.6156 - val_loss: 0.7291 - val_categorical_accuracy: 0.8350\n",
      "Epoch 5/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.7767 - categorical_accuracy: 0.7245\n",
      "Epoch 00005: val_loss improved from 0.72906 to 0.59130, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 260us/sample - loss: 0.7741 - categorical_accuracy: 0.7256 - val_loss: 0.5913 - val_categorical_accuracy: 0.8700\n",
      "Epoch 6/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.5532 - categorical_accuracy: 0.8125\n",
      "Epoch 00006: val_loss improved from 0.59130 to 0.35973, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 223us/sample - loss: 0.5495 - categorical_accuracy: 0.8131 - val_loss: 0.3597 - val_categorical_accuracy: 0.9400\n",
      "Epoch 7/100\n",
      "1376/1600 [========================>.....] - ETA: 0s - loss: 0.4048 - categorical_accuracy: 0.8641\n",
      "Epoch 00007: val_loss improved from 0.35973 to 0.29009, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 260us/sample - loss: 0.4065 - categorical_accuracy: 0.8675 - val_loss: 0.2901 - val_categorical_accuracy: 0.9550\n",
      "Epoch 8/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.3188 - categorical_accuracy: 0.8992\n",
      "Epoch 00008: val_loss improved from 0.29009 to 0.21346, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 271us/sample - loss: 0.3156 - categorical_accuracy: 0.9006 - val_loss: 0.2135 - val_categorical_accuracy: 0.9300\n",
      "Epoch 9/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2701 - categorical_accuracy: 0.9114\n",
      "Epoch 00009: val_loss improved from 0.21346 to 0.18155, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 280us/sample - loss: 0.2713 - categorical_accuracy: 0.9112 - val_loss: 0.1815 - val_categorical_accuracy: 0.9700\n",
      "Epoch 10/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.2169 - categorical_accuracy: 0.9445\n",
      "Epoch 00010: val_loss improved from 0.18155 to 0.14211, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 280us/sample - loss: 0.2169 - categorical_accuracy: 0.9425 - val_loss: 0.1421 - val_categorical_accuracy: 0.9750\n",
      "Epoch 11/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.1710 - categorical_accuracy: 0.9570\n",
      "Epoch 00011: val_loss improved from 0.14211 to 0.14080, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 270us/sample - loss: 0.1784 - categorical_accuracy: 0.9550 - val_loss: 0.1408 - val_categorical_accuracy: 0.9600\n",
      "Epoch 12/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.1587 - categorical_accuracy: 0.9555\n",
      "Epoch 00012: val_loss improved from 0.14080 to 0.10955, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 240us/sample - loss: 0.1575 - categorical_accuracy: 0.9563 - val_loss: 0.1095 - val_categorical_accuracy: 0.9850\n",
      "Epoch 13/100\n",
      "1344/1600 [========================>.....] - ETA: 0s - loss: 0.1358 - categorical_accuracy: 0.9725\n",
      "Epoch 00013: val_loss did not improve from 0.10955\n",
      "1600/1600 [==============================] - 0s 221us/sample - loss: 0.1350 - categorical_accuracy: 0.9719 - val_loss: 0.1437 - val_categorical_accuracy: 0.9800\n",
      "Epoch 14/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.1165 - categorical_accuracy: 0.9715\n",
      "Epoch 00014: val_loss improved from 0.10955 to 0.09884, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 244us/sample - loss: 0.1169 - categorical_accuracy: 0.9712 - val_loss: 0.0988 - val_categorical_accuracy: 0.9800\n",
      "Epoch 15/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.1261 - categorical_accuracy: 0.9647\n",
      "Epoch 00015: val_loss did not improve from 0.09884\n",
      "1600/1600 [==============================] - 0s 199us/sample - loss: 0.1265 - categorical_accuracy: 0.9656 - val_loss: 0.1019 - val_categorical_accuracy: 0.9900\n",
      "Epoch 16/100\n",
      "1472/1600 [==========================>...] - ETA: 0s - loss: 0.0835 - categorical_accuracy: 0.9851\n",
      "Epoch 00016: val_loss improved from 0.09884 to 0.08600, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 221us/sample - loss: 0.0821 - categorical_accuracy: 0.9850 - val_loss: 0.0860 - val_categorical_accuracy: 0.9900\n",
      "Epoch 17/100\n",
      "1504/1600 [===========================>..] - ETA: 0s - loss: 0.0742 - categorical_accuracy: 0.9854\n",
      "Epoch 00017: val_loss improved from 0.08600 to 0.07595, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 237us/sample - loss: 0.0776 - categorical_accuracy: 0.9850 - val_loss: 0.0759 - val_categorical_accuracy: 0.9900\n",
      "Epoch 18/100\n",
      "1408/1600 [=========================>....] - ETA: 0s - loss: 0.0764 - categorical_accuracy: 0.9830\n",
      "Epoch 00018: val_loss improved from 0.07595 to 0.05960, saving model to t_weights_1\n",
      "1600/1600 [==============================] - 0s 242us/sample - loss: 0.0801 - categorical_accuracy: 0.9806 - val_loss: 0.0596 - val_categorical_accuracy: 0.9900\n",
      "Epoch 19/100\n",
      "1440/1600 [==========================>...] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9757\n",
      "Epoch 00019: val_loss did not improve from 0.05960\n",
      "1600/1600 [==============================] - 0s 214us/sample - loss: 0.0932 - categorical_accuracy: 0.9750 - val_loss: 0.0829 - val_categorical_accuracy: 0.9900\n",
      "Epoch 20/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0685 - categorical_accuracy: 0.9834\n",
      "Epoch 00020: val_loss did not improve from 0.05960\n",
      "1600/1600 [==============================] - 0s 234us/sample - loss: 0.0677 - categorical_accuracy: 0.9837 - val_loss: 0.0639 - val_categorical_accuracy: 0.9900\n",
      "Epoch 21/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0667 - categorical_accuracy: 0.9866\n",
      "Epoch 00021: val_loss did not improve from 0.05960\n",
      "1600/1600 [==============================] - 0s 238us/sample - loss: 0.0659 - categorical_accuracy: 0.9869 - val_loss: 0.0787 - val_categorical_accuracy: 0.9900\n",
      "Epoch 22/100\n",
      "1536/1600 [===========================>..] - ETA: 0s - loss: 0.0597 - categorical_accuracy: 0.9915\n",
      "Epoch 00022: val_loss did not improve from 0.05960\n",
      "1600/1600 [==============================] - 0s 234us/sample - loss: 0.0589 - categorical_accuracy: 0.9919 - val_loss: 0.0744 - val_categorical_accuracy: 0.9900\n",
      "Epoch 23/100\n",
      "1568/1600 [============================>.] - ETA: 0s - loss: 0.0466 - categorical_accuracy: 0.9943\n",
      "Epoch 00023: val_loss did not improve from 0.05960\n",
      "1600/1600 [==============================] - 0s 232us/sample - loss: 0.0462 - categorical_accuracy: 0.9944 - val_loss: 0.0819 - val_categorical_accuracy: 0.9900\n",
      "0.995 0.18948979591836734\n",
      "\n",
      "\n",
      "nrx: 5 - real: 4 \n",
      "Train on 9416 samples, validate on 1177 samples\n",
      "Epoch 1/100\n",
      "9280/9416 [============================>.] - ETA: 0s - loss: 2.1694 - categorical_accuracy: 0.2004\n",
      "Epoch 00001: val_loss improved from inf to 1.78121, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 3s 267us/sample - loss: 2.1653 - categorical_accuracy: 0.2025 - val_loss: 1.7812 - val_categorical_accuracy: 0.3815\n",
      "Epoch 2/100\n",
      "9344/9416 [============================>.] - ETA: 0s - loss: 1.6214 - categorical_accuracy: 0.4270\n",
      "Epoch 00002: val_loss improved from 1.78121 to 1.36346, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 226us/sample - loss: 1.6198 - categorical_accuracy: 0.4277 - val_loss: 1.3635 - val_categorical_accuracy: 0.5752\n",
      "Epoch 3/100\n",
      "9152/9416 [============================>.] - ETA: 0s - loss: 1.3030 - categorical_accuracy: 0.5561\n",
      "Epoch 00003: val_loss improved from 1.36346 to 1.06205, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 229us/sample - loss: 1.3029 - categorical_accuracy: 0.5560 - val_loss: 1.0621 - val_categorical_accuracy: 0.7043\n",
      "Epoch 4/100\n",
      "9248/9416 [============================>.] - ETA: 0s - loss: 1.0420 - categorical_accuracy: 0.6480\n",
      "Epoch 00004: val_loss improved from 1.06205 to 0.89397, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 232us/sample - loss: 1.0401 - categorical_accuracy: 0.6488 - val_loss: 0.8940 - val_categorical_accuracy: 0.7341\n",
      "Epoch 5/100\n",
      "9216/9416 [============================>.] - ETA: 0s - loss: 0.8366 - categorical_accuracy: 0.7246\n",
      "Epoch 00005: val_loss improved from 0.89397 to 0.67078, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 235us/sample - loss: 0.8347 - categorical_accuracy: 0.7254 - val_loss: 0.6708 - val_categorical_accuracy: 0.8233\n",
      "Epoch 6/100\n",
      "9376/9416 [============================>.] - ETA: 0s - loss: 0.6940 - categorical_accuracy: 0.7771\n",
      "Epoch 00006: val_loss improved from 0.67078 to 0.51202, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 233us/sample - loss: 0.6940 - categorical_accuracy: 0.7771 - val_loss: 0.5120 - val_categorical_accuracy: 0.8811\n",
      "Epoch 7/100\n",
      "9216/9416 [============================>.] - ETA: 0s - loss: 0.5634 - categorical_accuracy: 0.8197\n",
      "Epoch 00007: val_loss improved from 0.51202 to 0.43157, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 228us/sample - loss: 0.5629 - categorical_accuracy: 0.8200 - val_loss: 0.4316 - val_categorical_accuracy: 0.9099\n",
      "Epoch 8/100\n",
      "9248/9416 [============================>.] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.8540\n",
      "Epoch 00008: val_loss improved from 0.43157 to 0.39175, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 229us/sample - loss: 0.4826 - categorical_accuracy: 0.8541 - val_loss: 0.3918 - val_categorical_accuracy: 0.9057\n",
      "Epoch 9/100\n",
      "9408/9416 [============================>.] - ETA: 0s - loss: 0.4259 - categorical_accuracy: 0.8700\n",
      "Epoch 00009: val_loss improved from 0.39175 to 0.32164, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 232us/sample - loss: 0.4256 - categorical_accuracy: 0.8701 - val_loss: 0.3216 - val_categorical_accuracy: 0.9252\n",
      "Epoch 10/100\n",
      "9184/9416 [============================>.] - ETA: 0s - loss: 0.3781 - categorical_accuracy: 0.8898\n",
      "Epoch 00010: val_loss improved from 0.32164 to 0.29934, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 231us/sample - loss: 0.3780 - categorical_accuracy: 0.8898 - val_loss: 0.2993 - val_categorical_accuracy: 0.9329\n",
      "Epoch 11/100\n",
      "9216/9416 [============================>.] - ETA: 0s - loss: 0.3527 - categorical_accuracy: 0.8923\n",
      "Epoch 00011: val_loss did not improve from 0.29934\n",
      "9416/9416 [==============================] - 2s 221us/sample - loss: 0.3509 - categorical_accuracy: 0.8933 - val_loss: 0.3280 - val_categorical_accuracy: 0.9227\n",
      "Epoch 12/100\n",
      "9312/9416 [============================>.] - ETA: 0s - loss: 0.3102 - categorical_accuracy: 0.9098\n",
      "Epoch 00012: val_loss improved from 0.29934 to 0.27079, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 231us/sample - loss: 0.3115 - categorical_accuracy: 0.9094 - val_loss: 0.2708 - val_categorical_accuracy: 0.9388\n",
      "Epoch 13/100\n",
      "9280/9416 [============================>.] - ETA: 0s - loss: 0.2859 - categorical_accuracy: 0.9154\n",
      "Epoch 00013: val_loss did not improve from 0.27079\n",
      "9416/9416 [==============================] - 2s 226us/sample - loss: 0.2874 - categorical_accuracy: 0.9148 - val_loss: 0.2778 - val_categorical_accuracy: 0.9320\n",
      "Epoch 14/100\n",
      "9312/9416 [============================>.] - ETA: 0s - loss: 0.2867 - categorical_accuracy: 0.9149\n",
      "Epoch 00014: val_loss improved from 0.27079 to 0.25703, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 236us/sample - loss: 0.2865 - categorical_accuracy: 0.9149 - val_loss: 0.2570 - val_categorical_accuracy: 0.9465\n",
      "Epoch 15/100\n",
      "9216/9416 [============================>.] - ETA: 0s - loss: 0.2440 - categorical_accuracy: 0.9284\n",
      "Epoch 00015: val_loss improved from 0.25703 to 0.25381, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 229us/sample - loss: 0.2429 - categorical_accuracy: 0.9287 - val_loss: 0.2538 - val_categorical_accuracy: 0.9414\n",
      "Epoch 16/100\n",
      "9216/9416 [============================>.] - ETA: 0s - loss: 0.2358 - categorical_accuracy: 0.9281\n",
      "Epoch 00016: val_loss improved from 0.25381 to 0.23319, saving model to t_weights_1\n",
      "9416/9416 [==============================] - 2s 230us/sample - loss: 0.2347 - categorical_accuracy: 0.9286 - val_loss: 0.2332 - val_categorical_accuracy: 0.9482\n",
      "Epoch 17/100\n",
      "9184/9416 [============================>.] - ETA: 0s - loss: 0.2322 - categorical_accuracy: 0.9299\n",
      "Epoch 00017: val_loss did not improve from 0.23319\n",
      "9416/9416 [==============================] - 2s 223us/sample - loss: 0.2322 - categorical_accuracy: 0.9299 - val_loss: 0.2381 - val_categorical_accuracy: 0.9431\n",
      "Epoch 18/100\n",
      "9248/9416 [============================>.] - ETA: 0s - loss: 0.2207 - categorical_accuracy: 0.9339\n",
      "Epoch 00018: val_loss did not improve from 0.23319\n",
      "9416/9416 [==============================] - 2s 223us/sample - loss: 0.2215 - categorical_accuracy: 0.9340 - val_loss: 0.2851 - val_categorical_accuracy: 0.9320\n",
      "Epoch 19/100\n",
      "9248/9416 [============================>.] - ETA: 0s - loss: 0.2133 - categorical_accuracy: 0.9378\n",
      "Epoch 00019: val_loss did not improve from 0.23319\n",
      "9416/9416 [==============================] - 2s 221us/sample - loss: 0.2142 - categorical_accuracy: 0.9371 - val_loss: 0.2422 - val_categorical_accuracy: 0.9465\n",
      "Epoch 20/100\n",
      "9152/9416 [============================>.] - ETA: 0s - loss: 0.2108 - categorical_accuracy: 0.9356\n",
      "Epoch 00020: val_loss did not improve from 0.23319\n",
      "9416/9416 [==============================] - 2s 223us/sample - loss: 0.2119 - categorical_accuracy: 0.9350 - val_loss: 0.2404 - val_categorical_accuracy: 0.9456\n",
      "Epoch 21/100\n",
      "9312/9416 [============================>.] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9398\n",
      "Epoch 00021: val_loss did not improve from 0.23319\n",
      "9416/9416 [==============================] - 2s 225us/sample - loss: 0.2003 - categorical_accuracy: 0.9395 - val_loss: 0.2527 - val_categorical_accuracy: 0.9516\n",
      "0.9379779 0.25112244897959185\n",
      "\n",
      "\n",
      "nrx: 10 - real: 4 \n",
      "Train on 17256 samples, validate on 2157 samples\n",
      "Epoch 1/100\n",
      "17216/17256 [============================>.] - ETA: 0s - loss: 2.0457 - categorical_accuracy: 0.2370\n",
      "Epoch 00001: val_loss improved from inf to 1.56823, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 243us/sample - loss: 2.0448 - categorical_accuracy: 0.2373 - val_loss: 1.5682 - val_categorical_accuracy: 0.4775\n",
      "Epoch 2/100\n",
      "17024/17256 [============================>.] - ETA: 0s - loss: 1.5310 - categorical_accuracy: 0.4564\n",
      "Epoch 00002: val_loss improved from 1.56823 to 1.19382, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 225us/sample - loss: 1.5289 - categorical_accuracy: 0.4569 - val_loss: 1.1938 - val_categorical_accuracy: 0.6208\n",
      "Epoch 3/100\n",
      "17152/17256 [============================>.] - ETA: 0s - loss: 1.2092 - categorical_accuracy: 0.5805\n",
      "Epoch 00003: val_loss improved from 1.19382 to 0.97840, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 209us/sample - loss: 1.2097 - categorical_accuracy: 0.5803 - val_loss: 0.9784 - val_categorical_accuracy: 0.6764\n",
      "Epoch 4/100\n",
      "17248/17256 [============================>.] - ETA: 0s - loss: 1.0021 - categorical_accuracy: 0.6623\n",
      "Epoch 00004: val_loss improved from 0.97840 to 0.83837, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 224us/sample - loss: 1.0021 - categorical_accuracy: 0.6623 - val_loss: 0.8384 - val_categorical_accuracy: 0.7399\n",
      "Epoch 5/100\n",
      "17216/17256 [============================>.] - ETA: 0s - loss: 0.8323 - categorical_accuracy: 0.7293\n",
      "Epoch 00005: val_loss improved from 0.83837 to 0.66200, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 223us/sample - loss: 0.8321 - categorical_accuracy: 0.7294 - val_loss: 0.6620 - val_categorical_accuracy: 0.7974\n",
      "Epoch 6/100\n",
      "17216/17256 [============================>.] - ETA: 0s - loss: 0.7063 - categorical_accuracy: 0.7781\n",
      "Epoch 00006: val_loss improved from 0.66200 to 0.54009, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 220us/sample - loss: 0.7066 - categorical_accuracy: 0.7781 - val_loss: 0.5401 - val_categorical_accuracy: 0.8340\n",
      "Epoch 7/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.5993 - categorical_accuracy: 0.8097\n",
      "Epoch 00007: val_loss improved from 0.54009 to 0.46327, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 228us/sample - loss: 0.5989 - categorical_accuracy: 0.8099 - val_loss: 0.4633 - val_categorical_accuracy: 0.8605\n",
      "Epoch 8/100\n",
      "17248/17256 [============================>.] - ETA: 0s - loss: 0.5255 - categorical_accuracy: 0.8354\n",
      "Epoch 00008: val_loss improved from 0.46327 to 0.43107, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 223us/sample - loss: 0.5254 - categorical_accuracy: 0.8354 - val_loss: 0.4311 - val_categorical_accuracy: 0.8725\n",
      "Epoch 9/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.8581\n",
      "Epoch 00009: val_loss improved from 0.43107 to 0.37756, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 227us/sample - loss: 0.4674 - categorical_accuracy: 0.8581 - val_loss: 0.3776 - val_categorical_accuracy: 0.8920\n",
      "Epoch 10/100\n",
      "17152/17256 [============================>.] - ETA: 0s - loss: 0.4239 - categorical_accuracy: 0.8729\n",
      "Epoch 00010: val_loss did not improve from 0.37756\n",
      "17256/17256 [==============================] - 4s 220us/sample - loss: 0.4243 - categorical_accuracy: 0.8728 - val_loss: 0.3863 - val_categorical_accuracy: 0.8924\n",
      "Epoch 11/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.3964 - categorical_accuracy: 0.8804\n",
      "Epoch 00011: val_loss improved from 0.37756 to 0.32143, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 222us/sample - loss: 0.3960 - categorical_accuracy: 0.8805 - val_loss: 0.3214 - val_categorical_accuracy: 0.9128\n",
      "Epoch 12/100\n",
      "17056/17256 [============================>.] - ETA: 0s - loss: 0.3620 - categorical_accuracy: 0.8909\n",
      "Epoch 00012: val_loss improved from 0.32143 to 0.30770, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 226us/sample - loss: 0.3613 - categorical_accuracy: 0.8914 - val_loss: 0.3077 - val_categorical_accuracy: 0.9133\n",
      "Epoch 13/100\n",
      "17088/17256 [============================>.] - ETA: 0s - loss: 0.3497 - categorical_accuracy: 0.8923\n",
      "Epoch 00013: val_loss improved from 0.30770 to 0.30638, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 224us/sample - loss: 0.3495 - categorical_accuracy: 0.8923 - val_loss: 0.3064 - val_categorical_accuracy: 0.9152\n",
      "Epoch 14/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.3260 - categorical_accuracy: 0.9026\n",
      "Epoch 00014: val_loss improved from 0.30638 to 0.30323, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 228us/sample - loss: 0.3270 - categorical_accuracy: 0.9024 - val_loss: 0.3032 - val_categorical_accuracy: 0.9207\n",
      "Epoch 15/100\n",
      "17088/17256 [============================>.] - ETA: 0s - loss: 0.3089 - categorical_accuracy: 0.9073\n",
      "Epoch 00015: val_loss improved from 0.30323 to 0.29880, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 220us/sample - loss: 0.3099 - categorical_accuracy: 0.9069 - val_loss: 0.2988 - val_categorical_accuracy: 0.9179\n",
      "Epoch 16/100\n",
      "17152/17256 [============================>.] - ETA: 0s - loss: 0.2964 - categorical_accuracy: 0.9121\n",
      "Epoch 00016: val_loss improved from 0.29880 to 0.28412, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 227us/sample - loss: 0.2962 - categorical_accuracy: 0.9123 - val_loss: 0.2841 - val_categorical_accuracy: 0.9179\n",
      "Epoch 17/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.2914 - categorical_accuracy: 0.9132\n",
      "Epoch 00017: val_loss improved from 0.28412 to 0.27426, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 224us/sample - loss: 0.2912 - categorical_accuracy: 0.9131 - val_loss: 0.2743 - val_categorical_accuracy: 0.9240\n",
      "Epoch 18/100\n",
      "17024/17256 [============================>.] - ETA: 0s - loss: 0.2766 - categorical_accuracy: 0.9171\n",
      "Epoch 00018: val_loss did not improve from 0.27426\n",
      "17256/17256 [==============================] - 4s 218us/sample - loss: 0.2766 - categorical_accuracy: 0.9168 - val_loss: 0.2996 - val_categorical_accuracy: 0.9175\n",
      "Epoch 19/100\n",
      "17056/17256 [============================>.] - ETA: 0s - loss: 0.2803 - categorical_accuracy: 0.9164\n",
      "Epoch 00019: val_loss improved from 0.27426 to 0.27030, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 219us/sample - loss: 0.2802 - categorical_accuracy: 0.9163 - val_loss: 0.2703 - val_categorical_accuracy: 0.9263\n",
      "Epoch 20/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.2592 - categorical_accuracy: 0.9221\n",
      "Epoch 00020: val_loss did not improve from 0.27030\n",
      "17256/17256 [==============================] - 4s 221us/sample - loss: 0.2594 - categorical_accuracy: 0.9219 - val_loss: 0.2842 - val_categorical_accuracy: 0.9286\n",
      "Epoch 21/100\n",
      "17216/17256 [============================>.] - ETA: 0s - loss: 0.2502 - categorical_accuracy: 0.9250\n",
      "Epoch 00021: val_loss did not improve from 0.27030\n",
      "17256/17256 [==============================] - 4s 223us/sample - loss: 0.2501 - categorical_accuracy: 0.9250 - val_loss: 0.2715 - val_categorical_accuracy: 0.9268\n",
      "Epoch 22/100\n",
      "17056/17256 [============================>.] - ETA: 0s - loss: 0.2552 - categorical_accuracy: 0.9233\n",
      "Epoch 00022: val_loss improved from 0.27030 to 0.26295, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 222us/sample - loss: 0.2553 - categorical_accuracy: 0.9234 - val_loss: 0.2629 - val_categorical_accuracy: 0.9309\n",
      "Epoch 23/100\n",
      "17216/17256 [============================>.] - ETA: 0s - loss: 0.2438 - categorical_accuracy: 0.9261\n",
      "Epoch 00023: val_loss did not improve from 0.26295\n",
      "17256/17256 [==============================] - 4s 223us/sample - loss: 0.2440 - categorical_accuracy: 0.9260 - val_loss: 0.2741 - val_categorical_accuracy: 0.9277\n",
      "Epoch 24/100\n",
      "17248/17256 [============================>.] - ETA: 0s - loss: 0.2380 - categorical_accuracy: 0.9293\n",
      "Epoch 00024: val_loss improved from 0.26295 to 0.24627, saving model to t_weights_1\n",
      "17256/17256 [==============================] - 4s 224us/sample - loss: 0.2380 - categorical_accuracy: 0.9294 - val_loss: 0.2463 - val_categorical_accuracy: 0.9314\n",
      "Epoch 25/100\n",
      "17184/17256 [============================>.] - ETA: 0s - loss: 0.2290 - categorical_accuracy: 0.9320\n",
      "Epoch 00025: val_loss did not improve from 0.24627\n",
      "17256/17256 [==============================] - 4s 218us/sample - loss: 0.2291 - categorical_accuracy: 0.9320 - val_loss: 0.2971 - val_categorical_accuracy: 0.9277\n",
      "Epoch 26/100\n",
      "17056/17256 [============================>.] - ETA: 0s - loss: 0.2337 - categorical_accuracy: 0.9297\n",
      "Epoch 00026: val_loss did not improve from 0.24627\n",
      "17256/17256 [==============================] - 4s 222us/sample - loss: 0.2335 - categorical_accuracy: 0.9298 - val_loss: 0.2647 - val_categorical_accuracy: 0.9332\n",
      "Epoch 27/100\n",
      "17056/17256 [============================>.] - ETA: 0s - loss: 0.2259 - categorical_accuracy: 0.9309\n",
      "Epoch 00027: val_loss did not improve from 0.24627\n",
      "17256/17256 [==============================] - 4s 221us/sample - loss: 0.2253 - categorical_accuracy: 0.9312 - val_loss: 0.2558 - val_categorical_accuracy: 0.9360\n",
      "Epoch 28/100\n",
      "17216/17256 [============================>.] - ETA: 0s - loss: 0.2285 - categorical_accuracy: 0.9330\n",
      "Epoch 00028: val_loss did not improve from 0.24627\n",
      "17256/17256 [==============================] - 4s 223us/sample - loss: 0.2288 - categorical_accuracy: 0.9328 - val_loss: 0.2702 - val_categorical_accuracy: 0.9309\n",
      "Epoch 29/100\n",
      "17120/17256 [============================>.] - ETA: 0s - loss: 0.2170 - categorical_accuracy: 0.9335\n",
      "Epoch 00029: val_loss did not improve from 0.24627\n",
      "17256/17256 [==============================] - 4s 220us/sample - loss: 0.2166 - categorical_accuracy: 0.9336 - val_loss: 0.2831 - val_categorical_accuracy: 0.9268\n",
      "0.94112194 0.2436734693877551\n",
      "\n",
      "\n",
      "nrx: 15 - real: 4 \n",
      "Train on 25096 samples, validate on 3137 samples\n",
      "Epoch 1/100\n",
      "24896/25096 [============================>.] - ETA: 0s - loss: 1.9143 - categorical_accuracy: 0.2809\n",
      "Epoch 00001: val_loss improved from inf to 1.52526, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 239us/sample - loss: 1.9117 - categorical_accuracy: 0.2819 - val_loss: 1.5253 - val_categorical_accuracy: 0.4523\n",
      "Epoch 2/100\n",
      "24928/25096 [============================>.] - ETA: 0s - loss: 1.4716 - categorical_accuracy: 0.4579\n",
      "Epoch 00002: val_loss improved from 1.52526 to 1.25462, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 225us/sample - loss: 1.4706 - categorical_accuracy: 0.4582 - val_loss: 1.2546 - val_categorical_accuracy: 0.5958\n",
      "Epoch 3/100\n",
      "24960/25096 [============================>.] - ETA: 0s - loss: 1.2360 - categorical_accuracy: 0.5681\n",
      "Epoch 00003: val_loss improved from 1.25462 to 1.01848, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 220us/sample - loss: 1.2356 - categorical_accuracy: 0.5685 - val_loss: 1.0185 - val_categorical_accuracy: 0.6662\n",
      "Epoch 4/100\n",
      "24864/25096 [============================>.] - ETA: 0s - loss: 1.0479 - categorical_accuracy: 0.6422\n",
      "Epoch 00004: val_loss improved from 1.01848 to 0.88149, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 224us/sample - loss: 1.0481 - categorical_accuracy: 0.6420 - val_loss: 0.8815 - val_categorical_accuracy: 0.7233\n",
      "Epoch 5/100\n",
      "24896/25096 [============================>.] - ETA: 0s - loss: 0.9009 - categorical_accuracy: 0.6986\n",
      "Epoch 00005: val_loss improved from 0.88149 to 0.78427, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 223us/sample - loss: 0.9011 - categorical_accuracy: 0.6987 - val_loss: 0.7843 - val_categorical_accuracy: 0.7427\n",
      "Epoch 6/100\n",
      "24928/25096 [============================>.] - ETA: 0s - loss: 0.7703 - categorical_accuracy: 0.7455\n",
      "Epoch 00006: val_loss improved from 0.78427 to 0.60372, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 222us/sample - loss: 0.7691 - categorical_accuracy: 0.7459 - val_loss: 0.6037 - val_categorical_accuracy: 0.8215\n",
      "Epoch 7/100\n",
      "25024/25096 [============================>.] - ETA: 0s - loss: 0.6675 - categorical_accuracy: 0.7883\n",
      "Epoch 00007: val_loss improved from 0.60372 to 0.52421, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 223us/sample - loss: 0.6671 - categorical_accuracy: 0.7886 - val_loss: 0.5242 - val_categorical_accuracy: 0.8441\n",
      "Epoch 8/100\n",
      "24992/25096 [============================>.] - ETA: 0s - loss: 0.5771 - categorical_accuracy: 0.8207\n",
      "Epoch 00008: val_loss improved from 0.52421 to 0.44581, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 225us/sample - loss: 0.5770 - categorical_accuracy: 0.8207 - val_loss: 0.4458 - val_categorical_accuracy: 0.8757\n",
      "Epoch 9/100\n",
      "24992/25096 [============================>.] - ETA: 0s - loss: 0.5060 - categorical_accuracy: 0.8460\n",
      "Epoch 00009: val_loss improved from 0.44581 to 0.39695, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 223us/sample - loss: 0.5057 - categorical_accuracy: 0.8460 - val_loss: 0.3970 - val_categorical_accuracy: 0.8932\n",
      "Epoch 10/100\n",
      "25024/25096 [============================>.] - ETA: 0s - loss: 0.4461 - categorical_accuracy: 0.8680\n",
      "Epoch 00010: val_loss improved from 0.39695 to 0.36648, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 219us/sample - loss: 0.4460 - categorical_accuracy: 0.8680 - val_loss: 0.3665 - val_categorical_accuracy: 0.8996\n",
      "Epoch 11/100\n",
      "24864/25096 [============================>.] - ETA: 0s - loss: 0.4050 - categorical_accuracy: 0.8771\n",
      "Epoch 00011: val_loss improved from 0.36648 to 0.34515, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 221us/sample - loss: 0.4056 - categorical_accuracy: 0.8770 - val_loss: 0.3451 - val_categorical_accuracy: 0.8980\n",
      "Epoch 12/100\n",
      "25024/25096 [============================>.] - ETA: 0s - loss: 0.3768 - categorical_accuracy: 0.8869\n",
      "Epoch 00012: val_loss improved from 0.34515 to 0.33826, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 225us/sample - loss: 0.3765 - categorical_accuracy: 0.8872 - val_loss: 0.3383 - val_categorical_accuracy: 0.9079\n",
      "Epoch 13/100\n",
      "24864/25096 [============================>.] - ETA: 0s - loss: 0.3418 - categorical_accuracy: 0.8987\n",
      "Epoch 00013: val_loss improved from 0.33826 to 0.30443, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 224us/sample - loss: 0.3416 - categorical_accuracy: 0.8987 - val_loss: 0.3044 - val_categorical_accuracy: 0.9142\n",
      "Epoch 14/100\n",
      "24960/25096 [============================>.] - ETA: 0s - loss: 0.3280 - categorical_accuracy: 0.9039\n",
      "Epoch 00014: val_loss improved from 0.30443 to 0.27987, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 5s 212us/sample - loss: 0.3278 - categorical_accuracy: 0.9039 - val_loss: 0.2799 - val_categorical_accuracy: 0.9238\n",
      "Epoch 15/100\n",
      "24896/25096 [============================>.] - ETA: 0s - loss: 0.2992 - categorical_accuracy: 0.9129\n",
      "Epoch 00015: val_loss improved from 0.27987 to 0.27564, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 223us/sample - loss: 0.2991 - categorical_accuracy: 0.9129 - val_loss: 0.2756 - val_categorical_accuracy: 0.9248\n",
      "Epoch 16/100\n",
      "24864/25096 [============================>.] - ETA: 0s - loss: 0.2947 - categorical_accuracy: 0.9140\n",
      "Epoch 00016: val_loss did not improve from 0.27564\n",
      "25096/25096 [==============================] - 6s 222us/sample - loss: 0.2952 - categorical_accuracy: 0.9140 - val_loss: 0.3074 - val_categorical_accuracy: 0.9216\n",
      "Epoch 17/100\n",
      "24864/25096 [============================>.] - ETA: 0s - loss: 0.2769 - categorical_accuracy: 0.9189\n",
      "Epoch 00017: val_loss improved from 0.27564 to 0.26656, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 225us/sample - loss: 0.2764 - categorical_accuracy: 0.9192 - val_loss: 0.2666 - val_categorical_accuracy: 0.9289\n",
      "Epoch 18/100\n",
      "25024/25096 [============================>.] - ETA: 0s - loss: 0.2645 - categorical_accuracy: 0.9232\n",
      "Epoch 00018: val_loss improved from 0.26656 to 0.26076, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 220us/sample - loss: 0.2644 - categorical_accuracy: 0.9233 - val_loss: 0.2608 - val_categorical_accuracy: 0.9343\n",
      "Epoch 19/100\n",
      "24960/25096 [============================>.] - ETA: 0s - loss: 0.2533 - categorical_accuracy: 0.9253\n",
      "Epoch 00019: val_loss improved from 0.26076 to 0.26009, saving model to t_weights_1\n",
      "25096/25096 [==============================] - 6s 224us/sample - loss: 0.2529 - categorical_accuracy: 0.9254 - val_loss: 0.2601 - val_categorical_accuracy: 0.9318\n",
      "Epoch 20/100\n",
      "25056/25096 [============================>.] - ETA: 0s - loss: 0.2412 - categorical_accuracy: 0.9300\n",
      "Epoch 00020: val_loss did not improve from 0.26009\n",
      "25096/25096 [==============================] - 6s 221us/sample - loss: 0.2412 - categorical_accuracy: 0.9300 - val_loss: 0.2682 - val_categorical_accuracy: 0.9264\n",
      "Epoch 21/100\n",
      "25024/25096 [============================>.] - ETA: 0s - loss: 0.2350 - categorical_accuracy: 0.9315\n",
      "Epoch 00021: val_loss did not improve from 0.26009\n",
      "25096/25096 [==============================] - 6s 221us/sample - loss: 0.2347 - categorical_accuracy: 0.9315 - val_loss: 0.2752 - val_categorical_accuracy: 0.9327\n",
      "Epoch 22/100\n",
      "24960/25096 [============================>.] - ETA: 0s - loss: 0.2304 - categorical_accuracy: 0.9331\n",
      "Epoch 00022: val_loss did not improve from 0.26009\n",
      "25096/25096 [==============================] - 6s 220us/sample - loss: 0.2308 - categorical_accuracy: 0.9330 - val_loss: 0.2640 - val_categorical_accuracy: 0.9331\n",
      "Epoch 23/100\n",
      "24928/25096 [============================>.] - ETA: 0s - loss: 0.2229 - categorical_accuracy: 0.9368\n",
      "Epoch 00023: val_loss did not improve from 0.26009\n",
      "25096/25096 [==============================] - 6s 221us/sample - loss: 0.2229 - categorical_accuracy: 0.9367 - val_loss: 0.2641 - val_categorical_accuracy: 0.9347\n",
      "Epoch 24/100\n",
      "24928/25096 [============================>.] - ETA: 0s - loss: 0.2214 - categorical_accuracy: 0.9358\n",
      "Epoch 00024: val_loss did not improve from 0.26009\n",
      "25096/25096 [==============================] - 6s 221us/sample - loss: 0.2214 - categorical_accuracy: 0.9358 - val_loss: 0.2736 - val_categorical_accuracy: 0.9369\n",
      "0.93465096 0.3486734693877551\n",
      "\n",
      "\n",
      "nrx: 20 - real: 4 \n",
      "Train on 32936 samples, validate on 4117 samples\n",
      "Epoch 1/100\n",
      "32896/32936 [============================>.] - ETA: 0s - loss: 1.8792 - categorical_accuracy: 0.2937\n",
      "Epoch 00001: val_loss improved from inf to 1.48137, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 8s 237us/sample - loss: 1.8788 - categorical_accuracy: 0.2938 - val_loss: 1.4814 - val_categorical_accuracy: 0.4889\n",
      "Epoch 2/100\n",
      "32864/32936 [============================>.] - ETA: 0s - loss: 1.3711 - categorical_accuracy: 0.5041\n",
      "Epoch 00002: val_loss improved from 1.48137 to 1.17268, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 225us/sample - loss: 1.3712 - categorical_accuracy: 0.5040 - val_loss: 1.1727 - val_categorical_accuracy: 0.6094\n",
      "Epoch 3/100\n",
      "32896/32936 [============================>.] - ETA: 0s - loss: 1.0822 - categorical_accuracy: 0.6217\n",
      "Epoch 00003: val_loss improved from 1.17268 to 0.87536, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 225us/sample - loss: 1.0824 - categorical_accuracy: 0.6217 - val_loss: 0.8754 - val_categorical_accuracy: 0.7148\n",
      "Epoch 4/100\n",
      "32896/32936 [============================>.] - ETA: 0s - loss: 0.8784 - categorical_accuracy: 0.7060\n",
      "Epoch 00004: val_loss improved from 0.87536 to 0.68312, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.8783 - categorical_accuracy: 0.7059 - val_loss: 0.6831 - val_categorical_accuracy: 0.7819\n",
      "Epoch 5/100\n",
      "32768/32936 [============================>.] - ETA: 0s - loss: 0.7435 - categorical_accuracy: 0.7537\n",
      "Epoch 00005: val_loss improved from 0.68312 to 0.58328, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.7430 - categorical_accuracy: 0.7540 - val_loss: 0.5833 - val_categorical_accuracy: 0.8237\n",
      "Epoch 6/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.6368 - categorical_accuracy: 0.7925\n",
      "Epoch 00006: val_loss improved from 0.58328 to 0.49972, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.6358 - categorical_accuracy: 0.7930 - val_loss: 0.4997 - val_categorical_accuracy: 0.8494\n",
      "Epoch 7/100\n",
      "32800/32936 [============================>.] - ETA: 0s - loss: 0.5634 - categorical_accuracy: 0.8210\n",
      "Epoch 00007: val_loss improved from 0.49972 to 0.48817, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 225us/sample - loss: 0.5636 - categorical_accuracy: 0.8210 - val_loss: 0.4882 - val_categorical_accuracy: 0.8487\n",
      "Epoch 8/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.5030 - categorical_accuracy: 0.8436\n",
      "Epoch 00008: val_loss improved from 0.48817 to 0.41715, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.5024 - categorical_accuracy: 0.8437 - val_loss: 0.4171 - val_categorical_accuracy: 0.8817\n",
      "Epoch 9/100\n",
      "32704/32936 [============================>.] - ETA: 0s - loss: 0.4482 - categorical_accuracy: 0.8614\n",
      "Epoch 00009: val_loss improved from 0.41715 to 0.36531, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 219us/sample - loss: 0.4484 - categorical_accuracy: 0.8612 - val_loss: 0.3653 - val_categorical_accuracy: 0.8934\n",
      "Epoch 10/100\n",
      "32864/32936 [============================>.] - ETA: 0s - loss: 0.4165 - categorical_accuracy: 0.8735\n",
      "Epoch 00010: val_loss improved from 0.36531 to 0.33477, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.4162 - categorical_accuracy: 0.8736 - val_loss: 0.3348 - val_categorical_accuracy: 0.9055\n",
      "Epoch 11/100\n",
      "32768/32936 [============================>.] - ETA: 0s - loss: 0.3815 - categorical_accuracy: 0.8839\n",
      "Epoch 00011: val_loss improved from 0.33477 to 0.32398, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 225us/sample - loss: 0.3816 - categorical_accuracy: 0.8838 - val_loss: 0.3240 - val_categorical_accuracy: 0.9121\n",
      "Epoch 12/100\n",
      "32704/32936 [============================>.] - ETA: 0s - loss: 0.3544 - categorical_accuracy: 0.8934\n",
      "Epoch 00012: val_loss improved from 0.32398 to 0.31982, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 224us/sample - loss: 0.3548 - categorical_accuracy: 0.8932 - val_loss: 0.3198 - val_categorical_accuracy: 0.9104\n",
      "Epoch 13/100\n",
      "32832/32936 [============================>.] - ETA: 0s - loss: 0.3396 - categorical_accuracy: 0.8974\n",
      "Epoch 00013: val_loss improved from 0.31982 to 0.29967, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 224us/sample - loss: 0.3393 - categorical_accuracy: 0.8975 - val_loss: 0.2997 - val_categorical_accuracy: 0.9196\n",
      "Epoch 14/100\n",
      "32864/32936 [============================>.] - ETA: 0s - loss: 0.3152 - categorical_accuracy: 0.9044\n",
      "Epoch 00014: val_loss did not improve from 0.29967\n",
      "32936/32936 [==============================] - 7s 223us/sample - loss: 0.3154 - categorical_accuracy: 0.9044 - val_loss: 0.3257 - val_categorical_accuracy: 0.9116\n",
      "Epoch 15/100\n",
      "32768/32936 [============================>.] - ETA: 0s - loss: 0.3072 - categorical_accuracy: 0.9083\n",
      "Epoch 00015: val_loss improved from 0.29967 to 0.27474, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 224us/sample - loss: 0.3075 - categorical_accuracy: 0.9082 - val_loss: 0.2747 - val_categorical_accuracy: 0.9281\n",
      "Epoch 16/100\n",
      "32768/32936 [============================>.] - ETA: 0s - loss: 0.2919 - categorical_accuracy: 0.9117\n",
      "Epoch 00016: val_loss did not improve from 0.27474\n",
      "32936/32936 [==============================] - 7s 223us/sample - loss: 0.2922 - categorical_accuracy: 0.9117 - val_loss: 0.2800 - val_categorical_accuracy: 0.9247\n",
      "Epoch 17/100\n",
      "32928/32936 [============================>.] - ETA: 0s - loss: 0.2820 - categorical_accuracy: 0.9144\n",
      "Epoch 00017: val_loss improved from 0.27474 to 0.27109, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.2822 - categorical_accuracy: 0.9144 - val_loss: 0.2711 - val_categorical_accuracy: 0.9266\n",
      "Epoch 18/100\n",
      "32864/32936 [============================>.] - ETA: 0s - loss: 0.2752 - categorical_accuracy: 0.9160\n",
      "Epoch 00018: val_loss did not improve from 0.27109\n",
      "32936/32936 [==============================] - 7s 224us/sample - loss: 0.2754 - categorical_accuracy: 0.9159 - val_loss: 0.2818 - val_categorical_accuracy: 0.9264\n",
      "Epoch 19/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.2670 - categorical_accuracy: 0.9204\n",
      "Epoch 00019: val_loss improved from 0.27109 to 0.26303, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 226us/sample - loss: 0.2669 - categorical_accuracy: 0.9204 - val_loss: 0.2630 - val_categorical_accuracy: 0.9334\n",
      "Epoch 20/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.2581 - categorical_accuracy: 0.9212\n",
      "Epoch 00020: val_loss did not improve from 0.26303\n",
      "32936/32936 [==============================] - 7s 223us/sample - loss: 0.2581 - categorical_accuracy: 0.9212 - val_loss: 0.2877 - val_categorical_accuracy: 0.9211\n",
      "Epoch 21/100\n",
      "32896/32936 [============================>.] - ETA: 0s - loss: 0.2519 - categorical_accuracy: 0.9259\n",
      "Epoch 00021: val_loss did not improve from 0.26303\n",
      "32936/32936 [==============================] - 7s 222us/sample - loss: 0.2518 - categorical_accuracy: 0.9259 - val_loss: 0.2634 - val_categorical_accuracy: 0.9344\n",
      "Epoch 22/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.2426 - categorical_accuracy: 0.9274\n",
      "Epoch 00022: val_loss improved from 0.26303 to 0.25468, saving model to t_weights_1\n",
      "32936/32936 [==============================] - 7s 225us/sample - loss: 0.2422 - categorical_accuracy: 0.9276 - val_loss: 0.2547 - val_categorical_accuracy: 0.9371\n",
      "Epoch 23/100\n",
      "32800/32936 [============================>.] - ETA: 0s - loss: 0.2378 - categorical_accuracy: 0.9299\n",
      "Epoch 00023: val_loss did not improve from 0.25468\n",
      "32936/32936 [==============================] - 7s 223us/sample - loss: 0.2386 - categorical_accuracy: 0.9298 - val_loss: 0.2663 - val_categorical_accuracy: 0.9359\n",
      "Epoch 24/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.2368 - categorical_accuracy: 0.9304\n",
      "Epoch 00024: val_loss did not improve from 0.25468\n",
      "32936/32936 [==============================] - 7s 223us/sample - loss: 0.2368 - categorical_accuracy: 0.9304 - val_loss: 0.2722 - val_categorical_accuracy: 0.9334\n",
      "Epoch 25/100\n",
      "32736/32936 [============================>.] - ETA: 0s - loss: 0.2257 - categorical_accuracy: 0.9326\n",
      "Epoch 00025: val_loss did not improve from 0.25468\n",
      "32936/32936 [==============================] - 7s 219us/sample - loss: 0.2260 - categorical_accuracy: 0.9326 - val_loss: 0.2884 - val_categorical_accuracy: 0.9334\n",
      "Epoch 26/100\n",
      "32704/32936 [============================>.] - ETA: 0s - loss: 0.2255 - categorical_accuracy: 0.9333\n",
      "Epoch 00026: val_loss did not improve from 0.25468\n",
      "32936/32936 [==============================] - 7s 224us/sample - loss: 0.2255 - categorical_accuracy: 0.9332 - val_loss: 0.2825 - val_categorical_accuracy: 0.9361\n",
      "Epoch 27/100\n",
      "32864/32936 [============================>.] - ETA: 0s - loss: 0.2229 - categorical_accuracy: 0.9349\n",
      "Epoch 00027: val_loss did not improve from 0.25468\n",
      "32936/32936 [==============================] - 7s 224us/sample - loss: 0.2230 - categorical_accuracy: 0.9348 - val_loss: 0.2593 - val_categorical_accuracy: 0.9376\n",
      "0.94219095 0.45418367346938776\n",
      "\n",
      "\n",
      "nrx: 25 - real: 4 \n",
      "Train on 40296 samples, validate on 5037 samples\n",
      "Epoch 1/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 1.8182 - categorical_accuracy: 0.3347\n",
      "Epoch 00001: val_loss improved from inf to 1.41952, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 231us/sample - loss: 1.8165 - categorical_accuracy: 0.3353 - val_loss: 1.4195 - val_categorical_accuracy: 0.4793\n",
      "Epoch 2/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 1.2572 - categorical_accuracy: 0.5615\n",
      "Epoch 00002: val_loss improved from 1.41952 to 0.95304, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 1.2575 - categorical_accuracy: 0.5616 - val_loss: 0.9530 - val_categorical_accuracy: 0.6871\n",
      "Epoch 3/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.9129 - categorical_accuracy: 0.6972\n",
      "Epoch 00003: val_loss improved from 0.95304 to 0.67986, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.9128 - categorical_accuracy: 0.6973 - val_loss: 0.6799 - val_categorical_accuracy: 0.7951\n",
      "Epoch 4/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.7115 - categorical_accuracy: 0.7694\n",
      "Epoch 00004: val_loss improved from 0.67986 to 0.54568, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.7115 - categorical_accuracy: 0.7694 - val_loss: 0.5457 - val_categorical_accuracy: 0.8318\n",
      "Epoch 5/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.5931 - categorical_accuracy: 0.8078\n",
      "Epoch 00005: val_loss improved from 0.54568 to 0.44708, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.5934 - categorical_accuracy: 0.8077 - val_loss: 0.4471 - val_categorical_accuracy: 0.8628\n",
      "Epoch 6/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.5164 - categorical_accuracy: 0.8366\n",
      "Epoch 00006: val_loss improved from 0.44708 to 0.39130, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.5163 - categorical_accuracy: 0.8367 - val_loss: 0.3913 - val_categorical_accuracy: 0.8829\n",
      "Epoch 7/100\n",
      "40192/40296 [============================>.] - ETA: 0s - loss: 0.4495 - categorical_accuracy: 0.8595\n",
      "Epoch 00007: val_loss improved from 0.39130 to 0.37494, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.4497 - categorical_accuracy: 0.8594 - val_loss: 0.3749 - val_categorical_accuracy: 0.8884\n",
      "Epoch 8/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.4062 - categorical_accuracy: 0.8733\n",
      "Epoch 00008: val_loss improved from 0.37494 to 0.33561, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.4061 - categorical_accuracy: 0.8733 - val_loss: 0.3356 - val_categorical_accuracy: 0.8980\n",
      "Epoch 9/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.3758 - categorical_accuracy: 0.8844\n",
      "Epoch 00009: val_loss improved from 0.33561 to 0.31646, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.3758 - categorical_accuracy: 0.8844 - val_loss: 0.3165 - val_categorical_accuracy: 0.9063\n",
      "Epoch 10/100\n",
      "40128/40296 [============================>.] - ETA: 0s - loss: 0.3499 - categorical_accuracy: 0.8910\n",
      "Epoch 00010: val_loss improved from 0.31646 to 0.30736, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.3498 - categorical_accuracy: 0.8912 - val_loss: 0.3074 - val_categorical_accuracy: 0.9073\n",
      "Epoch 11/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.3362 - categorical_accuracy: 0.8973\n",
      "Epoch 00011: val_loss improved from 0.30736 to 0.29442, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 222us/sample - loss: 0.3361 - categorical_accuracy: 0.8973 - val_loss: 0.2944 - val_categorical_accuracy: 0.9154\n",
      "Epoch 12/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 0.3137 - categorical_accuracy: 0.9030\n",
      "Epoch 00012: val_loss improved from 0.29442 to 0.27830, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 218us/sample - loss: 0.3136 - categorical_accuracy: 0.9031 - val_loss: 0.2783 - val_categorical_accuracy: 0.9190\n",
      "Epoch 13/100\n",
      "40128/40296 [============================>.] - ETA: 0s - loss: 0.3032 - categorical_accuracy: 0.9069\n",
      "Epoch 00013: val_loss improved from 0.27830 to 0.27696, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.3037 - categorical_accuracy: 0.9068 - val_loss: 0.2770 - val_categorical_accuracy: 0.9180\n",
      "Epoch 14/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2863 - categorical_accuracy: 0.9126\n",
      "Epoch 00014: val_loss improved from 0.27696 to 0.26966, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.2863 - categorical_accuracy: 0.9126 - val_loss: 0.2697 - val_categorical_accuracy: 0.9218\n",
      "Epoch 15/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.2822 - categorical_accuracy: 0.9141\n",
      "Epoch 00015: val_loss improved from 0.26966 to 0.26706, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.2822 - categorical_accuracy: 0.9141 - val_loss: 0.2671 - val_categorical_accuracy: 0.9236\n",
      "Epoch 16/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2756 - categorical_accuracy: 0.9163\n",
      "Epoch 00016: val_loss did not improve from 0.26706\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 0.2756 - categorical_accuracy: 0.9163 - val_loss: 0.2678 - val_categorical_accuracy: 0.9206\n",
      "Epoch 17/100\n",
      "40160/40296 [============================>.] - ETA: 0s - loss: 0.2665 - categorical_accuracy: 0.9193\n",
      "Epoch 00017: val_loss did not improve from 0.26706\n",
      "40296/40296 [==============================] - 9s 219us/sample - loss: 0.2666 - categorical_accuracy: 0.9193 - val_loss: 0.2974 - val_categorical_accuracy: 0.9166\n",
      "Epoch 18/100\n",
      "40064/40296 [============================>.] - ETA: 0s - loss: 0.2552 - categorical_accuracy: 0.9222\n",
      "Epoch 00018: val_loss improved from 0.26706 to 0.24701, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.2553 - categorical_accuracy: 0.9223 - val_loss: 0.2470 - val_categorical_accuracy: 0.9297\n",
      "Epoch 19/100\n",
      "40160/40296 [============================>.] - ETA: 0s - loss: 0.2541 - categorical_accuracy: 0.9243\n",
      "Epoch 00019: val_loss did not improve from 0.24701\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 0.2541 - categorical_accuracy: 0.9243 - val_loss: 0.2727 - val_categorical_accuracy: 0.9277\n",
      "Epoch 20/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.2408 - categorical_accuracy: 0.9269\n",
      "Epoch 00020: val_loss improved from 0.24701 to 0.24434, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 223us/sample - loss: 0.2410 - categorical_accuracy: 0.9269 - val_loss: 0.2443 - val_categorical_accuracy: 0.9297\n",
      "Epoch 21/100\n",
      "40288/40296 [============================>.] - ETA: 0s - loss: 0.2414 - categorical_accuracy: 0.9266\n",
      "Epoch 00021: val_loss did not improve from 0.24434\n",
      "40296/40296 [==============================] - 9s 219us/sample - loss: 0.2414 - categorical_accuracy: 0.9266 - val_loss: 0.2472 - val_categorical_accuracy: 0.9339\n",
      "Epoch 22/100\n",
      "40256/40296 [============================>.] - ETA: 0s - loss: 0.2343 - categorical_accuracy: 0.9305\n",
      "Epoch 00022: val_loss improved from 0.24434 to 0.24009, saving model to t_weights_1\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.2343 - categorical_accuracy: 0.9305 - val_loss: 0.2401 - val_categorical_accuracy: 0.9327\n",
      "Epoch 23/100\n",
      "40096/40296 [============================>.] - ETA: 0s - loss: 0.2315 - categorical_accuracy: 0.9318\n",
      "Epoch 00023: val_loss did not improve from 0.24009\n",
      "40296/40296 [==============================] - 9s 221us/sample - loss: 0.2313 - categorical_accuracy: 0.9318 - val_loss: 0.2522 - val_categorical_accuracy: 0.9329\n",
      "Epoch 24/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.2242 - categorical_accuracy: 0.9336\n",
      "Epoch 00024: val_loss did not improve from 0.24009\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 0.2248 - categorical_accuracy: 0.9335 - val_loss: 0.2436 - val_categorical_accuracy: 0.9359\n",
      "Epoch 25/100\n",
      "40128/40296 [============================>.] - ETA: 0s - loss: 0.2201 - categorical_accuracy: 0.9342\n",
      "Epoch 00025: val_loss did not improve from 0.24009\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 0.2201 - categorical_accuracy: 0.9341 - val_loss: 0.2748 - val_categorical_accuracy: 0.9261\n",
      "Epoch 26/100\n",
      "40224/40296 [============================>.] - ETA: 0s - loss: 0.2227 - categorical_accuracy: 0.9331\n",
      "Epoch 00026: val_loss did not improve from 0.24009\n",
      "40296/40296 [==============================] - 9s 217us/sample - loss: 0.2227 - categorical_accuracy: 0.9331 - val_loss: 0.2509 - val_categorical_accuracy: 0.9327\n",
      "Epoch 27/100\n",
      "40032/40296 [============================>.] - ETA: 0s - loss: 0.2150 - categorical_accuracy: 0.9365\n",
      "Epoch 00027: val_loss did not improve from 0.24009\n",
      "40296/40296 [==============================] - 9s 220us/sample - loss: 0.2143 - categorical_accuracy: 0.9368 - val_loss: 0.2601 - val_categorical_accuracy: 0.9349\n",
      "0.9388525 0.633061224489796\n"
     ]
    }
   ],
   "source": [
    "TRAIN = True\n",
    "continue_training = True\n",
    "nreal = 5\n",
    "\n",
    "real_list = list(range(nreal))\n",
    "nrx_list =  list(range( 0,len(rx_list_real[0])-n_test_rx+1,5))  # [0,len(rx_list_real[0])-1] #\n",
    "\n",
    "patience = 5\n",
    "n_epochs = 100\n",
    "\n",
    "smTest_results = []\n",
    "dfTest_results = []\n",
    "dfTestBal_results = []\n",
    "\n",
    "for real in real_list:\n",
    "    rx_list = rx_list_real[real]\n",
    "    rx_test_list = rx_list[-n_test_rx:]\n",
    "    test_dataset = merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_test_list)\n",
    "    test_augset_dfRx,_,_ = prepare_dataset(test_dataset,tx_list,val_frac=0.0, test_frac=0.0)\n",
    "\n",
    "    [sig_dfTest,txidNum_dfTest,txid_dfTest,cls_weights] = test_augset_dfRx\n",
    "\n",
    "    cnt=np.histogram(txidNum_dfTest,bins=np.arange(len(tx_list)+1)-0.5)\n",
    "    n_test_samples = int(np.min(cnt[0]))\n",
    "\n",
    "    smTest_results_real = []\n",
    "    dfTest_results_real = []\n",
    "    dfTestBal_results_real = []\n",
    "    for nrx in nrx_list:\n",
    "        print(\"\");print(\"\")\n",
    "        print(\"nrx: {} - real: {} \".format(nrx,real))\n",
    "        fname_w = 'weights/d003_{:02d}_{:02d}.hd5'.format(nrx,real)\n",
    "        rx_train_list= rx_list[:nrx+1]\n",
    "\n",
    "        dataset = merge_compact_dataset(compact_dataset,capture_date,tx_list,rx_train_list)\n",
    "\n",
    "        train_augset,val_augset,test_augset_smRx =  prepare_dataset(dataset,tx_list,\n",
    "                                                            val_frac=0.1, test_frac=0.1)\n",
    "        [sig_train,txidNum_train,txid_train,cls_weights] = train_augset\n",
    "        [sig_valid,txidNum_valid,txid_valid,_] = val_augset\n",
    "        [sig_smTest,txidNum_smTest,txid_smTest,cls_weights] = test_augset_smRx\n",
    "        \n",
    "        if continue_training:\n",
    "            skip = os.path.isfile(fname_w)\n",
    "        else:\n",
    "            skip = False\n",
    "        classifier = create_net()\n",
    "        if TRAIN and not skip:\n",
    "            filepath = 't_weights_'+GPU\n",
    "            c=[ keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "              keras.callbacks.EarlyStopping(monitor='val_loss',  patience=patience)]\n",
    "            history = classifier.fit(sig_train,txid_train,class_weight=cls_weights,\n",
    "                                     validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs)\n",
    "            classifier.load_weights(filepath)\n",
    "            classifier.save_weights(fname_w,save_format=\"h5\")\n",
    "        else:\n",
    "            classifier.load_weights(fname_w)\n",
    "\n",
    "        smTest_r = classifier.evaluate(sig_smTest,txid_smTest,verbose=0)[1]\n",
    "    #     dfTest_r = classifier.evaluate(sig_dfTest,txid_dfTest)[1]\n",
    "        dfTest_r,dfTestBal_r = evaluate_test(classifier)\n",
    "\n",
    "        print(smTest_r,dfTest_r)\n",
    "        smTest_results_real.append(smTest_r)\n",
    "        dfTest_results_real.append(dfTest_r)\n",
    "        dfTestBal_results_real.append(dfTestBal_r)\n",
    "        K.clear_session()\n",
    "    smTest_results.append(smTest_results_real)\n",
    "    dfTest_results.append(dfTest_results_real)\n",
    "    dfTestBal_results.append(dfTestBal_results_real)    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 10, 15, 20, 25]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14654571428571428, 0.23802081632653058, 0.3718567346938776, 0.43385999999999997, 0.525595918367347, 0.7149644897959183]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "plt.errorbar(np.array(nrx_list)+1,np.mean(smTest_results,0),np.std(smTest_results,0),capsize=4)\n",
    "plt.errorbar(np.array(nrx_list)+1,np.mean(dfTest_results,0),np.std(dfTest_results,0),capsize=4)\n",
    "plt.legend(['Same Rx(s)','Diff. Rx'])\n",
    "plt.xlabel('N Train Rx')\n",
    "plt.ylabel('Class. Accuracy')\n",
    "#plt.xticks(range(0,len(nrx_list),2))\n",
    "plt.grid()\n",
    "print(np.mean(dfTest_results,0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-10', '11-1', '14-10', '14-7', '17-11', '20-15', '20-19', '7-11', '7-14', '8-20']\n",
      "[0, 5, 10, 15, 20, 25]\n",
      "[0, 1, 2, 3, 4]\n",
      "[[0.97, 0.9016949, 0.9229358, 0.92738855, 0.9196602, 0.919595], [1.0, 0.97192985, 0.9485577, 0.95681816, 0.93955225, 0.9280447], [1.0, 0.9649123, 0.9055267, 0.9359766, 0.922492, 0.9305913], [0.9722222, 0.9534483, 0.9466981, 0.946102, 0.9327089, 0.94680643], [0.995, 0.9379779, 0.94112194, 0.93465096, 0.94219095, 0.9388525]]\n",
      "[[0.1456, 0.2524, 0.5632, 0.5513, 0.5226, 0.7212], [0.0907, 0.2325, 0.4219, 0.438, 0.6864, 0.7775], [0.15244897959183673, 0.15346938775510205, 0.3662244897959184, 0.42989795918367346, 0.4023469387755102, 0.8426530612244898], [0.15448979591836734, 0.3006122448979592, 0.2642857142857143, 0.4014285714285714, 0.5624489795918367, 0.6004081632653061], [0.18948979591836734, 0.25112244897959185, 0.2436734693877551, 0.3486734693877551, 0.45418367346938776, 0.633061224489796]]\n",
      "[[0.1456, 0.2524, 0.5632, 0.5513, 0.5226, 0.7212], [0.0907, 0.2325, 0.4219, 0.438, 0.6864, 0.7775], [0.14975, 0.15175, 0.353375, 0.420875, 0.396125, 0.845625], [0.155375, 0.29675, 0.260625, 0.403, 0.565125, 0.596625], [0.190875, 0.247875, 0.245125, 0.349375, 0.457, 0.641125]]\n"
     ]
    }
   ],
   "source": [
    "print(tx_list)\n",
    "print(nrx_list)\n",
    "print(real_list)\n",
    "print(smTest_results)\n",
    "print(dfTest_results)\n",
    "print(dfTestBal_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['19-20', '24-13', '19-2', '1-20', '20-20', '20-1', '7-7', '3-19', '23-6', '2-19', '24-5', '14-7', '23-1', '19-1', '8-7', '24-6', '24-16', '1-19', '8-8', '18-19', '13-7', '23-3', '8-14', '23-5', '19-19', '18-2', '7-14', '13-14', '1-1', '23-7', '20-19', '2-1'], ['1-1', '23-1', '24-6', '8-8', '1-19', '23-3', '23-5', '7-14', '19-19', '13-14', '23-6', '7-7', '19-1', '20-1', '20-20', '24-16', '8-14', '19-2', '14-7', '1-20', '13-7', '24-5', '18-2', '2-19', '24-13', '19-20', '3-19', '8-7', '20-19', '2-1', '23-7', '18-19'], ['24-5', '23-7', '18-19', '23-3', '24-6', '8-14', '2-1', '13-7', '19-19', '19-2', '18-2', '1-20', '20-1', '24-16', '3-19', '1-19', '24-13', '23-6', '19-1', '8-7', '20-19', '1-1', '14-7', '20-20', '7-7', '2-19', '23-5', '8-8', '19-20', '13-14', '7-14', '23-1'], ['1-20', '1-19', '20-19', '23-7', '2-1', '20-1', '19-19', '14-7', '23-1', '3-19', '8-8', '7-7', '13-7', '20-20', '24-16', '18-2', '8-7', '23-5', '7-14', '18-19', '24-6', '19-1', '13-14', '2-19', '19-20', '24-5', '23-3', '19-2', '8-14', '23-6', '24-13', '1-1'], ['18-19', '20-1', '13-14', '18-2', '14-7', '20-20', '13-7', '19-20', '2-19', '19-19', '19-1', '1-20', '24-5', '20-19', '8-7', '23-1', '7-7', '8-8', '2-1', '1-19', '3-19', '23-3', '23-6', '23-5', '24-6', '8-14', '24-16', '7-14', '1-1', '19-2', '24-13', '23-7']]\n"
     ]
    }
   ],
   "source": [
    "print(rx_list_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
