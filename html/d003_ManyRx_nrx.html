<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>d003_ManyRx_nrx</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload

<span class="o">%</span><span class="k">autoreload</span> 2
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">os.path</span>

<span class="kn">import</span> <span class="nn">scipy</span><span class="o">,</span><span class="nn">scipy.spatial</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>

<span class="kn">from</span>  <span class="nn">data_utilities</span> <span class="k">import</span> <span class="o">*</span>
<span class="c1"># from definitions import *</span>
<span class="c1"># from run_train_eval_net import run_train_eval_net,run_eval_net</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">GPU</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_DEVICE_ORDER&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;PCI_BUS_ID&quot;</span>   
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">GPU</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">&#39;ManyRx&#39;</span>
<span class="n">dataset_path</span><span class="o">=</span><span class="s1">&#39;../../orbit_rf_dataset/data/compact_pkl_datasets/&#39;</span>

<span class="n">compact_dataset</span> <span class="o">=</span> <span class="n">load_compact_pkl_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span><span class="n">dataset_name</span><span class="p">)</span>

<span class="n">tx_list</span> <span class="o">=</span> <span class="n">compact_dataset</span><span class="p">[</span><span class="s1">&#39;tx_list&#39;</span><span class="p">]</span>
<span class="n">rx_list</span> <span class="o">=</span> <span class="n">compact_dataset</span><span class="p">[</span><span class="s1">&#39;rx_list&#39;</span><span class="p">]</span>

<span class="n">equalized</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">capture_date_list</span> <span class="o">=</span> <span class="n">compact_dataset</span><span class="p">[</span><span class="s1">&#39;capture_date_list&#39;</span><span class="p">]</span>
<span class="n">capture_date</span> <span class="o">=</span> <span class="n">capture_date_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">n_tx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)</span>
<span class="n">n_rx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">rx_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n_tx</span><span class="p">,</span><span class="n">n_rx</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>10 32
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_real</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">rx_list_real</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_real</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">rx_list</span><span class="p">)</span>
    <span class="n">rx_list_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">rx_list</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[&#39;19-20&#39;, &#39;24-13&#39;, &#39;19-2&#39;, &#39;1-20&#39;, &#39;20-20&#39;, &#39;20-1&#39;, &#39;7-7&#39;, &#39;3-19&#39;, &#39;23-6&#39;, &#39;2-19&#39;, &#39;24-5&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;24-6&#39;, &#39;24-16&#39;, &#39;1-19&#39;, &#39;8-8&#39;, &#39;18-19&#39;, &#39;13-7&#39;, &#39;23-3&#39;, &#39;8-14&#39;, &#39;23-5&#39;, &#39;19-19&#39;, &#39;18-2&#39;, &#39;7-14&#39;, &#39;13-14&#39;, &#39;1-1&#39;, &#39;23-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;], [&#39;1-1&#39;, &#39;23-1&#39;, &#39;24-6&#39;, &#39;8-8&#39;, &#39;1-19&#39;, &#39;23-3&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;19-19&#39;, &#39;13-14&#39;, &#39;23-6&#39;, &#39;7-7&#39;, &#39;19-1&#39;, &#39;20-1&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;8-14&#39;, &#39;19-2&#39;, &#39;14-7&#39;, &#39;1-20&#39;, &#39;13-7&#39;, &#39;24-5&#39;, &#39;18-2&#39;, &#39;2-19&#39;, &#39;24-13&#39;, &#39;19-20&#39;, &#39;3-19&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;, &#39;23-7&#39;, &#39;18-19&#39;], [&#39;24-5&#39;, &#39;23-7&#39;, &#39;18-19&#39;, &#39;23-3&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;2-1&#39;, &#39;13-7&#39;, &#39;19-19&#39;, &#39;19-2&#39;, &#39;18-2&#39;, &#39;1-20&#39;, &#39;20-1&#39;, &#39;24-16&#39;, &#39;3-19&#39;, &#39;1-19&#39;, &#39;24-13&#39;, &#39;23-6&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;1-1&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;7-7&#39;, &#39;2-19&#39;, &#39;23-5&#39;, &#39;8-8&#39;, &#39;19-20&#39;, &#39;13-14&#39;, &#39;7-14&#39;, &#39;23-1&#39;], [&#39;1-20&#39;, &#39;1-19&#39;, &#39;20-19&#39;, &#39;23-7&#39;, &#39;2-1&#39;, &#39;20-1&#39;, &#39;19-19&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;3-19&#39;, &#39;8-8&#39;, &#39;7-7&#39;, &#39;13-7&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;18-2&#39;, &#39;8-7&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;18-19&#39;, &#39;24-6&#39;, &#39;19-1&#39;, &#39;13-14&#39;, &#39;2-19&#39;, &#39;19-20&#39;, &#39;24-5&#39;, &#39;23-3&#39;, &#39;19-2&#39;, &#39;8-14&#39;, &#39;23-6&#39;, &#39;24-13&#39;, &#39;1-1&#39;], [&#39;18-19&#39;, &#39;20-1&#39;, &#39;13-14&#39;, &#39;18-2&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;13-7&#39;, &#39;19-20&#39;, &#39;2-19&#39;, &#39;19-19&#39;, &#39;19-1&#39;, &#39;1-20&#39;, &#39;24-5&#39;, &#39;20-19&#39;, &#39;8-7&#39;, &#39;23-1&#39;, &#39;7-7&#39;, &#39;8-8&#39;, &#39;2-1&#39;, &#39;1-19&#39;, &#39;3-19&#39;, &#39;23-3&#39;, &#39;23-6&#39;, &#39;23-5&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;24-16&#39;, &#39;7-14&#39;, &#39;1-1&#39;, &#39;19-2&#39;, &#39;24-13&#39;, &#39;23-7&#39;]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="k">import</span> <span class="n">regularizers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> <span class="k">def</span> <span class="nf">create_net</span><span class="p">():</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1">#x = resnet(x,64,(3,2),&#39;6&#39;)</span>
    <span class="c1">#x = MaxPool2D((2,2))(x)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>



    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># x = Dropout(0.3)(x)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n_tx</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ops</span> <span class="o">=</span> <span class="n">x</span>

    <span class="n">classifier</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">ops</span><span class="p">)</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;categorical_accuracy&#39;</span><span class="p">],</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0005</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">classifier</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">create_net</span><span class="p">()</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: &#34;model&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 2)]          0         
_________________________________________________________________
reshape (Reshape)            (None, 256, 2, 1)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 256, 2, 8)         56        
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 128, 2, 8)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 128, 2, 16)        784       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 64, 2, 16)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 64, 2, 16)         1552      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 1, 16)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 1, 32)         1568      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 16, 1, 32)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 1, 16)         1552      
_________________________________________________________________
flatten (Flatten)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 100)               25700     
_________________________________________________________________
dense_1 (Dense)              (None, 80)                8080      
_________________________________________________________________
dropout (Dropout)            (None, 80)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                810       
=================================================================
Total params: 40,102
Trainable params: 40,102
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_test</span><span class="p">(</span><span class="n">classifier</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sig_dfTest</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="n">txidNum_dfTest</span><span class="p">)</span>

    <span class="n">test_indx</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">indx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)):</span>
        <span class="n">cls_indx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">txidNum_dfTest</span> <span class="o">==</span> <span class="n">indx</span><span class="p">)</span>
        <span class="n">test_indx</span> <span class="o">=</span> <span class="n">test_indx</span> <span class="o">+</span> <span class="p">(</span><span class="n">cls_indx</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">n_test_samples</span><span class="p">],)</span>
    <span class="n">test_indx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_indx</span><span class="p">)</span> 
    <span class="n">acc_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">test_indx</span><span class="p">,:],</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="n">txidNum_dfTest</span><span class="p">[</span><span class="n">test_indx</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">acc</span><span class="p">,</span><span class="n">acc_bal</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_test_rx</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">n_test_rx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[9]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[0, 5, 10, 15, 20, 25]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">TRAIN</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">continue_training</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">nreal</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">real_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nreal</span><span class="p">))</span>
<span class="n">nrx_list</span> <span class="o">=</span>  <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">n_test_rx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>  <span class="c1"># [0,len(rx_list_real[0])-1] #</span>

<span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">smTest_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dfTest_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dfTestBal_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">real</span> <span class="ow">in</span> <span class="n">real_list</span><span class="p">:</span>
    <span class="n">rx_list</span> <span class="o">=</span> <span class="n">rx_list_real</span><span class="p">[</span><span class="n">real</span><span class="p">]</span>
    <span class="n">rx_test_list</span> <span class="o">=</span> <span class="n">rx_list</span><span class="p">[</span><span class="o">-</span><span class="n">n_test_rx</span><span class="p">:]</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">merge_compact_dataset</span><span class="p">(</span><span class="n">compact_dataset</span><span class="p">,</span><span class="n">capture_date</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span><span class="n">rx_test_list</span><span class="p">)</span>
    <span class="n">test_augset_dfRx</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">prepare_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span><span class="n">val_frac</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">test_frac</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="p">[</span><span class="n">sig_dfTest</span><span class="p">,</span><span class="n">txidNum_dfTest</span><span class="p">,</span><span class="n">txid_dfTest</span><span class="p">,</span><span class="n">cls_weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_augset_dfRx</span>

    <span class="n">cnt</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">txidNum_dfTest</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">n_test_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="n">smTest_results_real</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dfTest_results_real</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dfTestBal_results_real</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">nrx</span> <span class="ow">in</span> <span class="n">nrx_list</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">);</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;nrx: </span><span class="si">{}</span><span class="s2"> - real: </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nrx</span><span class="p">,</span><span class="n">real</span><span class="p">))</span>
        <span class="n">fname_w</span> <span class="o">=</span> <span class="s1">&#39;weights/d003_</span><span class="si">{:02d}</span><span class="s1">_</span><span class="si">{:02d}</span><span class="s1">.hd5&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nrx</span><span class="p">,</span><span class="n">real</span><span class="p">)</span>
        <span class="n">rx_train_list</span><span class="o">=</span> <span class="n">rx_list</span><span class="p">[:</span><span class="n">nrx</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">merge_compact_dataset</span><span class="p">(</span><span class="n">compact_dataset</span><span class="p">,</span><span class="n">capture_date</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span><span class="n">rx_train_list</span><span class="p">)</span>

        <span class="n">train_augset</span><span class="p">,</span><span class="n">val_augset</span><span class="p">,</span><span class="n">test_augset_smRx</span> <span class="o">=</span>  <span class="n">prepare_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span>
                                                            <span class="n">val_frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">test_frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="p">[</span><span class="n">sig_train</span><span class="p">,</span><span class="n">txidNum_train</span><span class="p">,</span><span class="n">txid_train</span><span class="p">,</span><span class="n">cls_weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_augset</span>
        <span class="p">[</span><span class="n">sig_valid</span><span class="p">,</span><span class="n">txidNum_valid</span><span class="p">,</span><span class="n">txid_valid</span><span class="p">,</span><span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_augset</span>
        <span class="p">[</span><span class="n">sig_smTest</span><span class="p">,</span><span class="n">txidNum_smTest</span><span class="p">,</span><span class="n">txid_smTest</span><span class="p">,</span><span class="n">cls_weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_augset_smRx</span>
        
        <span class="k">if</span> <span class="n">continue_training</span><span class="p">:</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname_w</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">classifier</span> <span class="o">=</span> <span class="n">create_net</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">TRAIN</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">skip</span><span class="p">:</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="s1">&#39;t_weights_&#39;</span><span class="o">+</span><span class="n">GPU</span>
            <span class="n">c</span><span class="o">=</span><span class="p">[</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
              <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>  <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">)]</span>
            <span class="n">history</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sig_train</span><span class="p">,</span><span class="n">txid_train</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="n">cls_weights</span><span class="p">,</span>
                                     <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">sig_valid</span> <span class="p">,</span> <span class="n">txid_valid</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">)</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">fname_w</span><span class="p">,</span><span class="n">save_format</span><span class="o">=</span><span class="s2">&quot;h5&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">fname_w</span><span class="p">)</span>

        <span class="n">smTest_r</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">sig_smTest</span><span class="p">,</span><span class="n">txid_smTest</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1">#     dfTest_r = classifier.evaluate(sig_dfTest,txid_dfTest)[1]</span>
        <span class="n">dfTest_r</span><span class="p">,</span><span class="n">dfTestBal_r</span> <span class="o">=</span> <span class="n">evaluate_test</span><span class="p">(</span><span class="n">classifier</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">smTest_r</span><span class="p">,</span><span class="n">dfTest_r</span><span class="p">)</span>
        <span class="n">smTest_results_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smTest_r</span><span class="p">)</span>
        <span class="n">dfTest_results_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTest_r</span><span class="p">)</span>
        <span class="n">dfTestBal_results_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTestBal_r</span><span class="p">)</span>
        <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
    <span class="n">smTest_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smTest_results_real</span><span class="p">)</span>
    <span class="n">dfTest_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTest_results_real</span><span class="p">)</span>
    <span class="n">dfTestBal_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTestBal_results_real</span><span class="p">)</span>    
    
    
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>

nrx: 0 - real: 0 
Train on 1600 samples, validate on 200 samples
Epoch 1/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 2.3097 - categorical_accuracy: 0.1527
Epoch 00001: val_loss improved from inf to 2.24668, saving model to t_weights_1
1600/1600 [==============================] - 2s 1ms/sample - loss: 2.3051 - categorical_accuracy: 0.1581 - val_loss: 2.2467 - val_categorical_accuracy: 0.3000
Epoch 2/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 2.0692 - categorical_accuracy: 0.2827
Epoch 00002: val_loss improved from 2.24668 to 1.55767, saving model to t_weights_1
1600/1600 [==============================] - 0s 243us/sample - loss: 2.0382 - categorical_accuracy: 0.2881 - val_loss: 1.5577 - val_categorical_accuracy: 0.4900
Epoch 3/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 1.5408 - categorical_accuracy: 0.4056
Epoch 00003: val_loss improved from 1.55767 to 1.12902, saving model to t_weights_1
1600/1600 [==============================] - 0s 233us/sample - loss: 1.5355 - categorical_accuracy: 0.4075 - val_loss: 1.1290 - val_categorical_accuracy: 0.7100
Epoch 4/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 1.2432 - categorical_accuracy: 0.5432
Epoch 00004: val_loss improved from 1.12902 to 0.89945, saving model to t_weights_1
1600/1600 [==============================] - 0s 259us/sample - loss: 1.2041 - categorical_accuracy: 0.5619 - val_loss: 0.8995 - val_categorical_accuracy: 0.7600
Epoch 5/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.9672 - categorical_accuracy: 0.6570
Epoch 00005: val_loss improved from 0.89945 to 0.77909, saving model to t_weights_1
1600/1600 [==============================] - 0s 258us/sample - loss: 0.9712 - categorical_accuracy: 0.6538 - val_loss: 0.7791 - val_categorical_accuracy: 0.7600
Epoch 6/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.8221 - categorical_accuracy: 0.7226
Epoch 00006: val_loss improved from 0.77909 to 0.61217, saving model to t_weights_1
1600/1600 [==============================] - 0s 263us/sample - loss: 0.8176 - categorical_accuracy: 0.7244 - val_loss: 0.6122 - val_categorical_accuracy: 0.8500
Epoch 7/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.6965 - categorical_accuracy: 0.7691
Epoch 00007: val_loss improved from 0.61217 to 0.56560, saving model to t_weights_1
1600/1600 [==============================] - 0s 255us/sample - loss: 0.6918 - categorical_accuracy: 0.7713 - val_loss: 0.5656 - val_categorical_accuracy: 0.8700
Epoch 8/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.6385 - categorical_accuracy: 0.7879
Epoch 00008: val_loss improved from 0.56560 to 0.49953, saving model to t_weights_1
1600/1600 [==============================] - 0s 250us/sample - loss: 0.6229 - categorical_accuracy: 0.7969 - val_loss: 0.4995 - val_categorical_accuracy: 0.8950
Epoch 9/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.5563 - categorical_accuracy: 0.8329
Epoch 00009: val_loss improved from 0.49953 to 0.43210, saving model to t_weights_1
1600/1600 [==============================] - 0s 230us/sample - loss: 0.5576 - categorical_accuracy: 0.8350 - val_loss: 0.4321 - val_categorical_accuracy: 0.9150
Epoch 10/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.4928 - categorical_accuracy: 0.8540
Epoch 00010: val_loss improved from 0.43210 to 0.39756, saving model to t_weights_1
1600/1600 [==============================] - 0s 264us/sample - loss: 0.4902 - categorical_accuracy: 0.8537 - val_loss: 0.3976 - val_categorical_accuracy: 0.9200
Epoch 11/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.4812 - categorical_accuracy: 0.8579
Epoch 00011: val_loss improved from 0.39756 to 0.35597, saving model to t_weights_1
1600/1600 [==============================] - 0s 265us/sample - loss: 0.4956 - categorical_accuracy: 0.8531 - val_loss: 0.3560 - val_categorical_accuracy: 0.9050
Epoch 12/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.4100 - categorical_accuracy: 0.8795
Epoch 00012: val_loss improved from 0.35597 to 0.28507, saving model to t_weights_1
1600/1600 [==============================] - 0s 260us/sample - loss: 0.4067 - categorical_accuracy: 0.8806 - val_loss: 0.2851 - val_categorical_accuracy: 0.9250
Epoch 13/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.8743
Epoch 00013: val_loss improved from 0.28507 to 0.26568, saving model to t_weights_1
1600/1600 [==============================] - 0s 253us/sample - loss: 0.3780 - categorical_accuracy: 0.8806 - val_loss: 0.2657 - val_categorical_accuracy: 0.9400
Epoch 14/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.2997 - categorical_accuracy: 0.9155
Epoch 00014: val_loss improved from 0.26568 to 0.24560, saving model to t_weights_1
1600/1600 [==============================] - 0s 258us/sample - loss: 0.3079 - categorical_accuracy: 0.9156 - val_loss: 0.2456 - val_categorical_accuracy: 0.9550
Epoch 15/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.3112 - categorical_accuracy: 0.9208
Epoch 00015: val_loss improved from 0.24560 to 0.22281, saving model to t_weights_1
1600/1600 [==============================] - 0s 242us/sample - loss: 0.3187 - categorical_accuracy: 0.9212 - val_loss: 0.2228 - val_categorical_accuracy: 0.9450
Epoch 16/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.2640 - categorical_accuracy: 0.9353
Epoch 00016: val_loss did not improve from 0.22281
1600/1600 [==============================] - 0s 222us/sample - loss: 0.2571 - categorical_accuracy: 0.9344 - val_loss: 0.2258 - val_categorical_accuracy: 0.9400
Epoch 17/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.2579 - categorical_accuracy: 0.9293
Epoch 00017: val_loss did not improve from 0.22281
1600/1600 [==============================] - 0s 217us/sample - loss: 0.2617 - categorical_accuracy: 0.9281 - val_loss: 0.3019 - val_categorical_accuracy: 0.9150
Epoch 18/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2609 - categorical_accuracy: 0.9343
Epoch 00018: val_loss improved from 0.22281 to 0.20319, saving model to t_weights_1
1600/1600 [==============================] - 0s 268us/sample - loss: 0.2577 - categorical_accuracy: 0.9356 - val_loss: 0.2032 - val_categorical_accuracy: 0.9500
Epoch 19/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2318 - categorical_accuracy: 0.9452
Epoch 00019: val_loss improved from 0.20319 to 0.18421, saving model to t_weights_1
1600/1600 [==============================] - 0s 263us/sample - loss: 0.2326 - categorical_accuracy: 0.9450 - val_loss: 0.1842 - val_categorical_accuracy: 0.9550
Epoch 20/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2084 - categorical_accuracy: 0.9496
Epoch 00020: val_loss improved from 0.18421 to 0.17035, saving model to t_weights_1
1600/1600 [==============================] - 0s 259us/sample - loss: 0.2086 - categorical_accuracy: 0.9500 - val_loss: 0.1703 - val_categorical_accuracy: 0.9550
Epoch 21/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.2067 - categorical_accuracy: 0.9438
Epoch 00021: val_loss did not improve from 0.17035
1600/1600 [==============================] - 0s 203us/sample - loss: 0.2148 - categorical_accuracy: 0.9413 - val_loss: 0.1760 - val_categorical_accuracy: 0.9600
Epoch 22/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.1936 - categorical_accuracy: 0.9489
Epoch 00022: val_loss did not improve from 0.17035
1600/1600 [==============================] - 0s 214us/sample - loss: 0.1945 - categorical_accuracy: 0.9494 - val_loss: 0.1896 - val_categorical_accuracy: 0.9500
Epoch 23/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1738 - categorical_accuracy: 0.9541
Epoch 00023: val_loss improved from 0.17035 to 0.16733, saving model to t_weights_1
1600/1600 [==============================] - 0s 248us/sample - loss: 0.1731 - categorical_accuracy: 0.9544 - val_loss: 0.1673 - val_categorical_accuracy: 0.9600
Epoch 24/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.1737 - categorical_accuracy: 0.9583
Epoch 00024: val_loss did not improve from 0.16733
1600/1600 [==============================] - 0s 213us/sample - loss: 0.1780 - categorical_accuracy: 0.9581 - val_loss: 0.1788 - val_categorical_accuracy: 0.9600
Epoch 25/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1687 - categorical_accuracy: 0.9557
Epoch 00025: val_loss did not improve from 0.16733
1600/1600 [==============================] - 0s 231us/sample - loss: 0.1676 - categorical_accuracy: 0.9563 - val_loss: 0.1717 - val_categorical_accuracy: 0.9550
Epoch 26/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.1638 - categorical_accuracy: 0.9606
Epoch 00026: val_loss did not improve from 0.16733
1600/1600 [==============================] - 0s 215us/sample - loss: 0.1596 - categorical_accuracy: 0.9613 - val_loss: 0.1703 - val_categorical_accuracy: 0.9650
Epoch 27/100
1312/1600 [=======================&gt;......] - ETA: 0s - loss: 0.1595 - categorical_accuracy: 0.9604
Epoch 00027: val_loss did not improve from 0.16733
1600/1600 [==============================] - 0s 225us/sample - loss: 0.1572 - categorical_accuracy: 0.9619 - val_loss: 0.1858 - val_categorical_accuracy: 0.9550
Epoch 28/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.1481 - categorical_accuracy: 0.9666
Epoch 00028: val_loss did not improve from 0.16733
1600/1600 [==============================] - 0s 211us/sample - loss: 0.1501 - categorical_accuracy: 0.9656 - val_loss: 0.1817 - val_categorical_accuracy: 0.9650
0.97 0.1456


nrx: 5 - real: 0 
Train on 9440 samples, validate on 1180 samples
Epoch 1/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 2.2118 - categorical_accuracy: 0.1817
Epoch 00001: val_loss improved from inf to 1.93085, saving model to t_weights_1
9440/9440 [==============================] - 2s 249us/sample - loss: 2.2073 - categorical_accuracy: 0.1839 - val_loss: 1.9308 - val_categorical_accuracy: 0.3356
Epoch 2/100
9184/9440 [============================&gt;.] - ETA: 0s - loss: 1.7545 - categorical_accuracy: 0.3837
Epoch 00002: val_loss improved from 1.93085 to 1.41884, saving model to t_weights_1
9440/9440 [==============================] - 2s 216us/sample - loss: 1.7501 - categorical_accuracy: 0.3869 - val_loss: 1.4188 - val_categorical_accuracy: 0.5161
Epoch 3/100
9088/9440 [===========================&gt;..] - ETA: 0s - loss: 1.4186 - categorical_accuracy: 0.5139
Epoch 00003: val_loss improved from 1.41884 to 1.13640, saving model to t_weights_1
9440/9440 [==============================] - 2s 204us/sample - loss: 1.4157 - categorical_accuracy: 0.5160 - val_loss: 1.1364 - val_categorical_accuracy: 0.6347
Epoch 4/100
9312/9440 [============================&gt;.] - ETA: 0s - loss: 1.1520 - categorical_accuracy: 0.6245
Epoch 00004: val_loss improved from 1.13640 to 0.96151, saving model to t_weights_1
9440/9440 [==============================] - 2s 189us/sample - loss: 1.1520 - categorical_accuracy: 0.6252 - val_loss: 0.9615 - val_categorical_accuracy: 0.6992
Epoch 5/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.9680 - categorical_accuracy: 0.6958
Epoch 00005: val_loss improved from 0.96151 to 0.72094, saving model to t_weights_1
9440/9440 [==============================] - 2s 221us/sample - loss: 0.9663 - categorical_accuracy: 0.6963 - val_loss: 0.7209 - val_categorical_accuracy: 0.7822
Epoch 6/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.7896 - categorical_accuracy: 0.7578
Epoch 00006: val_loss improved from 0.72094 to 0.62304, saving model to t_weights_1
9440/9440 [==============================] - 2s 216us/sample - loss: 0.7915 - categorical_accuracy: 0.7568 - val_loss: 0.6230 - val_categorical_accuracy: 0.8220
Epoch 7/100
9344/9440 [============================&gt;.] - ETA: 0s - loss: 0.7023 - categorical_accuracy: 0.7917
Epoch 00007: val_loss improved from 0.62304 to 0.51442, saving model to t_weights_1
9440/9440 [==============================] - 2s 221us/sample - loss: 0.7012 - categorical_accuracy: 0.7921 - val_loss: 0.5144 - val_categorical_accuracy: 0.8559
Epoch 8/100
9216/9440 [============================&gt;.] - ETA: 0s - loss: 0.6189 - categorical_accuracy: 0.8197
Epoch 00008: val_loss improved from 0.51442 to 0.45719, saving model to t_weights_1
9440/9440 [==============================] - 2s 218us/sample - loss: 0.6148 - categorical_accuracy: 0.8206 - val_loss: 0.4572 - val_categorical_accuracy: 0.8720
Epoch 9/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.5608 - categorical_accuracy: 0.8321
Epoch 00009: val_loss improved from 0.45719 to 0.39819, saving model to t_weights_1
9440/9440 [==============================] - 2s 216us/sample - loss: 0.5610 - categorical_accuracy: 0.8320 - val_loss: 0.3982 - val_categorical_accuracy: 0.8856
Epoch 10/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 0.5008 - categorical_accuracy: 0.8536
Epoch 00010: val_loss improved from 0.39819 to 0.39046, saving model to t_weights_1
9440/9440 [==============================] - 2s 220us/sample - loss: 0.4996 - categorical_accuracy: 0.8541 - val_loss: 0.3905 - val_categorical_accuracy: 0.8873
Epoch 11/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.4453 - categorical_accuracy: 0.8683
Epoch 00011: val_loss improved from 0.39046 to 0.34938, saving model to t_weights_1
9440/9440 [==============================] - 2s 216us/sample - loss: 0.4442 - categorical_accuracy: 0.8686 - val_loss: 0.3494 - val_categorical_accuracy: 0.8941
Epoch 12/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.4211 - categorical_accuracy: 0.8745
Epoch 00012: val_loss did not improve from 0.34938
9440/9440 [==============================] - 2s 216us/sample - loss: 0.4209 - categorical_accuracy: 0.8745 - val_loss: 0.3715 - val_categorical_accuracy: 0.8932
Epoch 13/100
9312/9440 [============================&gt;.] - ETA: 0s - loss: 0.3943 - categorical_accuracy: 0.8796
Epoch 00013: val_loss improved from 0.34938 to 0.34314, saving model to t_weights_1
9440/9440 [==============================] - 2s 221us/sample - loss: 0.3941 - categorical_accuracy: 0.8799 - val_loss: 0.3431 - val_categorical_accuracy: 0.8949
Epoch 14/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.3766 - categorical_accuracy: 0.8858
Epoch 00014: val_loss improved from 0.34314 to 0.30567, saving model to t_weights_1
9440/9440 [==============================] - 2s 217us/sample - loss: 0.3761 - categorical_accuracy: 0.8860 - val_loss: 0.3057 - val_categorical_accuracy: 0.9085
Epoch 15/100
9184/9440 [============================&gt;.] - ETA: 0s - loss: 0.3581 - categorical_accuracy: 0.8893
Epoch 00015: val_loss did not improve from 0.30567
9440/9440 [==============================] - 2s 210us/sample - loss: 0.3574 - categorical_accuracy: 0.8899 - val_loss: 0.3219 - val_categorical_accuracy: 0.9034
Epoch 16/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.3410 - categorical_accuracy: 0.8973
Epoch 00016: val_loss improved from 0.30567 to 0.30379, saving model to t_weights_1
9440/9440 [==============================] - 2s 220us/sample - loss: 0.3405 - categorical_accuracy: 0.8975 - val_loss: 0.3038 - val_categorical_accuracy: 0.9136
Epoch 17/100
9344/9440 [============================&gt;.] - ETA: 0s - loss: 0.3341 - categorical_accuracy: 0.8948
Epoch 00017: val_loss did not improve from 0.30379
9440/9440 [==============================] - 2s 212us/sample - loss: 0.3341 - categorical_accuracy: 0.8949 - val_loss: 0.3051 - val_categorical_accuracy: 0.9119
Epoch 18/100
9280/9440 [============================&gt;.] - ETA: 0s - loss: 0.3155 - categorical_accuracy: 0.9000
Epoch 00018: val_loss improved from 0.30379 to 0.29951, saving model to t_weights_1
9440/9440 [==============================] - 2s 221us/sample - loss: 0.3155 - categorical_accuracy: 0.8998 - val_loss: 0.2995 - val_categorical_accuracy: 0.9195
Epoch 19/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.3109 - categorical_accuracy: 0.9061
Epoch 00019: val_loss did not improve from 0.29951
9440/9440 [==============================] - 2s 215us/sample - loss: 0.3104 - categorical_accuracy: 0.9064 - val_loss: 0.3097 - val_categorical_accuracy: 0.9153
Epoch 20/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.3060 - categorical_accuracy: 0.9033
Epoch 00020: val_loss did not improve from 0.29951
9440/9440 [==============================] - 2s 213us/sample - loss: 0.3057 - categorical_accuracy: 0.9035 - val_loss: 0.3001 - val_categorical_accuracy: 0.9144
Epoch 21/100
9344/9440 [============================&gt;.] - ETA: 0s - loss: 0.2986 - categorical_accuracy: 0.9066
Epoch 00021: val_loss improved from 0.29951 to 0.29572, saving model to t_weights_1
9440/9440 [==============================] - 2s 212us/sample - loss: 0.2980 - categorical_accuracy: 0.9070 - val_loss: 0.2957 - val_categorical_accuracy: 0.9178
Epoch 22/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 0.2783 - categorical_accuracy: 0.9127
Epoch 00022: val_loss did not improve from 0.29572
9440/9440 [==============================] - 2s 208us/sample - loss: 0.2768 - categorical_accuracy: 0.9135 - val_loss: 0.3201 - val_categorical_accuracy: 0.9153
Epoch 23/100
9152/9440 [============================&gt;.] - ETA: 0s - loss: 0.2810 - categorical_accuracy: 0.9135
Epoch 00023: val_loss did not improve from 0.29572
9440/9440 [==============================] - 2s 209us/sample - loss: 0.2815 - categorical_accuracy: 0.9132 - val_loss: 0.3176 - val_categorical_accuracy: 0.9136
Epoch 24/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.2680 - categorical_accuracy: 0.9163
Epoch 00024: val_loss did not improve from 0.29572
9440/9440 [==============================] - 2s 213us/sample - loss: 0.2683 - categorical_accuracy: 0.9163 - val_loss: 0.2985 - val_categorical_accuracy: 0.9195
Epoch 25/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9118
Epoch 00025: val_loss did not improve from 0.29572
9440/9440 [==============================] - 2s 219us/sample - loss: 0.2715 - categorical_accuracy: 0.9120 - val_loss: 0.3004 - val_categorical_accuracy: 0.9237
Epoch 26/100
9312/9440 [============================&gt;.] - ETA: 0s - loss: 0.2640 - categorical_accuracy: 0.9151
Epoch 00026: val_loss did not improve from 0.29572
9440/9440 [==============================] - 2s 214us/sample - loss: 0.2639 - categorical_accuracy: 0.9150 - val_loss: 0.3056 - val_categorical_accuracy: 0.9144
0.9016949 0.2524


nrx: 10 - real: 0 
Train on 17440 samples, validate on 2180 samples
Epoch 1/100
17376/17440 [============================&gt;.] - ETA: 0s - loss: 2.0470 - categorical_accuracy: 0.2454
Epoch 00001: val_loss improved from inf to 1.60304, saving model to t_weights_1
17440/17440 [==============================] - 4s 235us/sample - loss: 2.0462 - categorical_accuracy: 0.2456 - val_loss: 1.6030 - val_categorical_accuracy: 0.4835
Epoch 2/100
17216/17440 [============================&gt;.] - ETA: 0s - loss: 1.4638 - categorical_accuracy: 0.4936
Epoch 00002: val_loss improved from 1.60304 to 1.17026, saving model to t_weights_1
17440/17440 [==============================] - 4s 212us/sample - loss: 1.4609 - categorical_accuracy: 0.4945 - val_loss: 1.1703 - val_categorical_accuracy: 0.6450
Epoch 3/100
17344/17440 [============================&gt;.] - ETA: 0s - loss: 1.1082 - categorical_accuracy: 0.6350
Epoch 00003: val_loss improved from 1.17026 to 0.93096, saving model to t_weights_1
17440/17440 [==============================] - 4s 213us/sample - loss: 1.1074 - categorical_accuracy: 0.6350 - val_loss: 0.9310 - val_categorical_accuracy: 0.6954
Epoch 4/100
17344/17440 [============================&gt;.] - ETA: 0s - loss: 0.8654 - categorical_accuracy: 0.7204
Epoch 00004: val_loss improved from 0.93096 to 0.67499, saving model to t_weights_1
17440/17440 [==============================] - 4s 216us/sample - loss: 0.8653 - categorical_accuracy: 0.7201 - val_loss: 0.6750 - val_categorical_accuracy: 0.7917
Epoch 5/100
17248/17440 [============================&gt;.] - ETA: 0s - loss: 0.6863 - categorical_accuracy: 0.7865
Epoch 00005: val_loss improved from 0.67499 to 0.53768, saving model to t_weights_1
17440/17440 [==============================] - 4s 215us/sample - loss: 0.6860 - categorical_accuracy: 0.7867 - val_loss: 0.5377 - val_categorical_accuracy: 0.8459
Epoch 6/100
17408/17440 [============================&gt;.] - ETA: 0s - loss: 0.5585 - categorical_accuracy: 0.8299
Epoch 00006: val_loss improved from 0.53768 to 0.45158, saving model to t_weights_1
17440/17440 [==============================] - 4s 216us/sample - loss: 0.5583 - categorical_accuracy: 0.8299 - val_loss: 0.4516 - val_categorical_accuracy: 0.8748
Epoch 7/100
17408/17440 [============================&gt;.] - ETA: 0s - loss: 0.4640 - categorical_accuracy: 0.8615
Epoch 00007: val_loss improved from 0.45158 to 0.41432, saving model to t_weights_1
17440/17440 [==============================] - 4s 217us/sample - loss: 0.4638 - categorical_accuracy: 0.8615 - val_loss: 0.4143 - val_categorical_accuracy: 0.8780
Epoch 8/100
17216/17440 [============================&gt;.] - ETA: 0s - loss: 0.4141 - categorical_accuracy: 0.8749
Epoch 00008: val_loss improved from 0.41432 to 0.36880, saving model to t_weights_1
17440/17440 [==============================] - 4s 217us/sample - loss: 0.4138 - categorical_accuracy: 0.8752 - val_loss: 0.3688 - val_categorical_accuracy: 0.8977
Epoch 9/100
17184/17440 [============================&gt;.] - ETA: 0s - loss: 0.3760 - categorical_accuracy: 0.8868
Epoch 00009: val_loss improved from 0.36880 to 0.36648, saving model to t_weights_1
17440/17440 [==============================] - 4s 213us/sample - loss: 0.3748 - categorical_accuracy: 0.8874 - val_loss: 0.3665 - val_categorical_accuracy: 0.8940
Epoch 10/100
17280/17440 [============================&gt;.] - ETA: 0s - loss: 0.3382 - categorical_accuracy: 0.8981
Epoch 00010: val_loss improved from 0.36648 to 0.31477, saving model to t_weights_1
17440/17440 [==============================] - 4s 218us/sample - loss: 0.3383 - categorical_accuracy: 0.8981 - val_loss: 0.3148 - val_categorical_accuracy: 0.9128
Epoch 11/100
17376/17440 [============================&gt;.] - ETA: 0s - loss: 0.3167 - categorical_accuracy: 0.9057
Epoch 00011: val_loss improved from 0.31477 to 0.31434, saving model to t_weights_1
17440/17440 [==============================] - 4s 216us/sample - loss: 0.3167 - categorical_accuracy: 0.9056 - val_loss: 0.3143 - val_categorical_accuracy: 0.9119
Epoch 12/100
17408/17440 [============================&gt;.] - ETA: 0s - loss: 0.3006 - categorical_accuracy: 0.9094
Epoch 00012: val_loss did not improve from 0.31434
17440/17440 [==============================] - 4s 211us/sample - loss: 0.3003 - categorical_accuracy: 0.9095 - val_loss: 0.3320 - val_categorical_accuracy: 0.9087
Epoch 13/100
17216/17440 [============================&gt;.] - ETA: 0s - loss: 0.2864 - categorical_accuracy: 0.9148
Epoch 00013: val_loss did not improve from 0.31434
17440/17440 [==============================] - 4s 212us/sample - loss: 0.2860 - categorical_accuracy: 0.9150 - val_loss: 0.3144 - val_categorical_accuracy: 0.9128
Epoch 14/100
17280/17440 [============================&gt;.] - ETA: 0s - loss: 0.2757 - categorical_accuracy: 0.9166
Epoch 00014: val_loss improved from 0.31434 to 0.30387, saving model to t_weights_1
17440/17440 [==============================] - 4s 217us/sample - loss: 0.2761 - categorical_accuracy: 0.9164 - val_loss: 0.3039 - val_categorical_accuracy: 0.9156
Epoch 15/100
17280/17440 [============================&gt;.] - ETA: 0s - loss: 0.2530 - categorical_accuracy: 0.9242
Epoch 00015: val_loss improved from 0.30387 to 0.28574, saving model to t_weights_1
17440/17440 [==============================] - 4s 217us/sample - loss: 0.2543 - categorical_accuracy: 0.9240 - val_loss: 0.2857 - val_categorical_accuracy: 0.9252
Epoch 16/100
17248/17440 [============================&gt;.] - ETA: 0s - loss: 0.2473 - categorical_accuracy: 0.9258
Epoch 00016: val_loss improved from 0.28574 to 0.28030, saving model to t_weights_1
17440/17440 [==============================] - 4s 204us/sample - loss: 0.2473 - categorical_accuracy: 0.9259 - val_loss: 0.2803 - val_categorical_accuracy: 0.9211
Epoch 17/100
17184/17440 [============================&gt;.] - ETA: 0s - loss: 0.2456 - categorical_accuracy: 0.9257
Epoch 00017: val_loss did not improve from 0.28030
17440/17440 [==============================] - 4s 203us/sample - loss: 0.2463 - categorical_accuracy: 0.9255 - val_loss: 0.2932 - val_categorical_accuracy: 0.9239
Epoch 18/100
17120/17440 [============================&gt;.] - ETA: 0s - loss: 0.2303 - categorical_accuracy: 0.9312
Epoch 00018: val_loss improved from 0.28030 to 0.27678, saving model to t_weights_1
17440/17440 [==============================] - 4s 212us/sample - loss: 0.2292 - categorical_accuracy: 0.9315 - val_loss: 0.2768 - val_categorical_accuracy: 0.9225
Epoch 19/100
17248/17440 [============================&gt;.] - ETA: 0s - loss: 0.2248 - categorical_accuracy: 0.9324
Epoch 00019: val_loss did not improve from 0.27678
17440/17440 [==============================] - 4s 212us/sample - loss: 0.2245 - categorical_accuracy: 0.9324 - val_loss: 0.2945 - val_categorical_accuracy: 0.9225
Epoch 20/100
17376/17440 [============================&gt;.] - ETA: 0s - loss: 0.2258 - categorical_accuracy: 0.9307
Epoch 00020: val_loss did not improve from 0.27678
17440/17440 [==============================] - 4s 213us/sample - loss: 0.2259 - categorical_accuracy: 0.9306 - val_loss: 0.3141 - val_categorical_accuracy: 0.9183
Epoch 21/100
17184/17440 [============================&gt;.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9324
Epoch 00021: val_loss did not improve from 0.27678
17440/17440 [==============================] - 4s 218us/sample - loss: 0.2195 - categorical_accuracy: 0.9322 - val_loss: 0.3126 - val_categorical_accuracy: 0.9183
Epoch 22/100
17280/17440 [============================&gt;.] - ETA: 0s - loss: 0.2111 - categorical_accuracy: 0.9373
Epoch 00022: val_loss did not improve from 0.27678
17440/17440 [==============================] - 4s 218us/sample - loss: 0.2110 - categorical_accuracy: 0.9374 - val_loss: 0.3190 - val_categorical_accuracy: 0.9216
Epoch 23/100
17248/17440 [============================&gt;.] - ETA: 0s - loss: 0.2053 - categorical_accuracy: 0.9373
Epoch 00023: val_loss did not improve from 0.27678
17440/17440 [==============================] - 4s 217us/sample - loss: 0.2050 - categorical_accuracy: 0.9373 - val_loss: 0.3119 - val_categorical_accuracy: 0.9165
0.9229358 0.5632


nrx: 15 - real: 0 
Train on 25120 samples, validate on 3140 samples
Epoch 1/100
25056/25120 [============================&gt;.] - ETA: 0s - loss: 1.9654 - categorical_accuracy: 0.2658
Epoch 00001: val_loss improved from inf to 1.53422, saving model to t_weights_1
25120/25120 [==============================] - 6s 235us/sample - loss: 1.9651 - categorical_accuracy: 0.2660 - val_loss: 1.5342 - val_categorical_accuracy: 0.4580
Epoch 2/100
24896/25120 [============================&gt;.] - ETA: 0s - loss: 1.4060 - categorical_accuracy: 0.4985
Epoch 00002: val_loss improved from 1.53422 to 1.11212, saving model to t_weights_1
25120/25120 [==============================] - 5s 218us/sample - loss: 1.4045 - categorical_accuracy: 0.4990 - val_loss: 1.1121 - val_categorical_accuracy: 0.6414
Epoch 3/100
24992/25120 [============================&gt;.] - ETA: 0s - loss: 1.0871 - categorical_accuracy: 0.6277
Epoch 00003: val_loss improved from 1.11212 to 0.90462, saving model to t_weights_1
25120/25120 [==============================] - 6s 221us/sample - loss: 1.0867 - categorical_accuracy: 0.6280 - val_loss: 0.9046 - val_categorical_accuracy: 0.7086
Epoch 4/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.8980 - categorical_accuracy: 0.7068
Epoch 00004: val_loss improved from 0.90462 to 0.70727, saving model to t_weights_1
25120/25120 [==============================] - 6s 220us/sample - loss: 0.8971 - categorical_accuracy: 0.7071 - val_loss: 0.7073 - val_categorical_accuracy: 0.7838
Epoch 5/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.7561 - categorical_accuracy: 0.7556
Epoch 00005: val_loss improved from 0.70727 to 0.64106, saving model to t_weights_1
25120/25120 [==============================] - 5s 218us/sample - loss: 0.7558 - categorical_accuracy: 0.7555 - val_loss: 0.6411 - val_categorical_accuracy: 0.8035
Epoch 6/100
25056/25120 [============================&gt;.] - ETA: 0s - loss: 0.6351 - categorical_accuracy: 0.8003
Epoch 00006: val_loss improved from 0.64106 to 0.52605, saving model to t_weights_1
25120/25120 [==============================] - 5s 217us/sample - loss: 0.6350 - categorical_accuracy: 0.8003 - val_loss: 0.5261 - val_categorical_accuracy: 0.8414
Epoch 7/100
24992/25120 [============================&gt;.] - ETA: 0s - loss: 0.5638 - categorical_accuracy: 0.8235
Epoch 00007: val_loss improved from 0.52605 to 0.45394, saving model to t_weights_1
25120/25120 [==============================] - 5s 219us/sample - loss: 0.5638 - categorical_accuracy: 0.8236 - val_loss: 0.4539 - val_categorical_accuracy: 0.8656
Epoch 8/100
25088/25120 [============================&gt;.] - ETA: 0s - loss: 0.5049 - categorical_accuracy: 0.8453
Epoch 00008: val_loss improved from 0.45394 to 0.42854, saving model to t_weights_1
25120/25120 [==============================] - 5s 214us/sample - loss: 0.5047 - categorical_accuracy: 0.8454 - val_loss: 0.4285 - val_categorical_accuracy: 0.8745
Epoch 9/100
24896/25120 [============================&gt;.] - ETA: 0s - loss: 0.4763 - categorical_accuracy: 0.8542
Epoch 00009: val_loss did not improve from 0.42854
25120/25120 [==============================] - 5s 218us/sample - loss: 0.4754 - categorical_accuracy: 0.8546 - val_loss: 0.4309 - val_categorical_accuracy: 0.8761
Epoch 10/100
24800/25120 [============================&gt;.] - ETA: 0s - loss: 0.4333 - categorical_accuracy: 0.8641
Epoch 00010: val_loss improved from 0.42854 to 0.38944, saving model to t_weights_1
25120/25120 [==============================] - 6s 220us/sample - loss: 0.4343 - categorical_accuracy: 0.8639 - val_loss: 0.3894 - val_categorical_accuracy: 0.8885
Epoch 11/100
24960/25120 [============================&gt;.] - ETA: 0s - loss: 0.4124 - categorical_accuracy: 0.8718
Epoch 00011: val_loss improved from 0.38944 to 0.36150, saving model to t_weights_1
25120/25120 [==============================] - 6s 220us/sample - loss: 0.4119 - categorical_accuracy: 0.8719 - val_loss: 0.3615 - val_categorical_accuracy: 0.8965
Epoch 12/100
24896/25120 [============================&gt;.] - ETA: 0s - loss: 0.3856 - categorical_accuracy: 0.8790
Epoch 00012: val_loss improved from 0.36150 to 0.36037, saving model to t_weights_1
25120/25120 [==============================] - 6s 220us/sample - loss: 0.3853 - categorical_accuracy: 0.8791 - val_loss: 0.3604 - val_categorical_accuracy: 0.9006
Epoch 13/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.3704 - categorical_accuracy: 0.8832
Epoch 00013: val_loss improved from 0.36037 to 0.32718, saving model to t_weights_1
25120/25120 [==============================] - 5s 219us/sample - loss: 0.3704 - categorical_accuracy: 0.8832 - val_loss: 0.3272 - val_categorical_accuracy: 0.9076
Epoch 14/100
24864/25120 [============================&gt;.] - ETA: 0s - loss: 0.3547 - categorical_accuracy: 0.8909
Epoch 00014: val_loss did not improve from 0.32718
25120/25120 [==============================] - 5s 207us/sample - loss: 0.3539 - categorical_accuracy: 0.8911 - val_loss: 0.3352 - val_categorical_accuracy: 0.9073
Epoch 15/100
24992/25120 [============================&gt;.] - ETA: 0s - loss: 0.3378 - categorical_accuracy: 0.8943
Epoch 00015: val_loss improved from 0.32718 to 0.32038, saving model to t_weights_1
25120/25120 [==============================] - 5s 214us/sample - loss: 0.3374 - categorical_accuracy: 0.8945 - val_loss: 0.3204 - val_categorical_accuracy: 0.9051
Epoch 16/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.3261 - categorical_accuracy: 0.8987
Epoch 00016: val_loss did not improve from 0.32038
25120/25120 [==============================] - 5s 215us/sample - loss: 0.3262 - categorical_accuracy: 0.8985 - val_loss: 0.3275 - val_categorical_accuracy: 0.9041
Epoch 17/100
24896/25120 [============================&gt;.] - ETA: 0s - loss: 0.3208 - categorical_accuracy: 0.9005
Epoch 00017: val_loss did not improve from 0.32038
25120/25120 [==============================] - 5s 217us/sample - loss: 0.3209 - categorical_accuracy: 0.9005 - val_loss: 0.3358 - val_categorical_accuracy: 0.9019
Epoch 18/100
25056/25120 [============================&gt;.] - ETA: 0s - loss: 0.3117 - categorical_accuracy: 0.9007
Epoch 00018: val_loss improved from 0.32038 to 0.30779, saving model to t_weights_1
25120/25120 [==============================] - 5s 216us/sample - loss: 0.3117 - categorical_accuracy: 0.9007 - val_loss: 0.3078 - val_categorical_accuracy: 0.9121
Epoch 19/100
24864/25120 [============================&gt;.] - ETA: 0s - loss: 0.2992 - categorical_accuracy: 0.9062
Epoch 00019: val_loss did not improve from 0.30779
25120/25120 [==============================] - 5s 209us/sample - loss: 0.3000 - categorical_accuracy: 0.9059 - val_loss: 0.3100 - val_categorical_accuracy: 0.9115
Epoch 20/100
25056/25120 [============================&gt;.] - ETA: 0s - loss: 0.2929 - categorical_accuracy: 0.9064
Epoch 00020: val_loss improved from 0.30779 to 0.29874, saving model to t_weights_1
25120/25120 [==============================] - 6s 221us/sample - loss: 0.2926 - categorical_accuracy: 0.9066 - val_loss: 0.2987 - val_categorical_accuracy: 0.9172
Epoch 21/100
24864/25120 [============================&gt;.] - ETA: 0s - loss: 0.2877 - categorical_accuracy: 0.9082
Epoch 00021: val_loss improved from 0.29874 to 0.28977, saving model to t_weights_1
25120/25120 [==============================] - 6s 219us/sample - loss: 0.2880 - categorical_accuracy: 0.9081 - val_loss: 0.2898 - val_categorical_accuracy: 0.9159
Epoch 22/100
24992/25120 [============================&gt;.] - ETA: 0s - loss: 0.2816 - categorical_accuracy: 0.9112
Epoch 00022: val_loss improved from 0.28977 to 0.28946, saving model to t_weights_1
25120/25120 [==============================] - 5s 218us/sample - loss: 0.2814 - categorical_accuracy: 0.9111 - val_loss: 0.2895 - val_categorical_accuracy: 0.9188
Epoch 23/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.2741 - categorical_accuracy: 0.9133
Epoch 00023: val_loss did not improve from 0.28946
25120/25120 [==============================] - 5s 217us/sample - loss: 0.2739 - categorical_accuracy: 0.9133 - val_loss: 0.2930 - val_categorical_accuracy: 0.9207
Epoch 24/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.9150
Epoch 00024: val_loss improved from 0.28946 to 0.28777, saving model to t_weights_1
25120/25120 [==============================] - 5s 218us/sample - loss: 0.2681 - categorical_accuracy: 0.9146 - val_loss: 0.2878 - val_categorical_accuracy: 0.9255
Epoch 25/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9132
Epoch 00025: val_loss did not improve from 0.28777
25120/25120 [==============================] - 5s 217us/sample - loss: 0.2717 - categorical_accuracy: 0.9131 - val_loss: 0.3064 - val_categorical_accuracy: 0.9210
Epoch 26/100
24992/25120 [============================&gt;.] - ETA: 0s - loss: 0.2648 - categorical_accuracy: 0.9177
Epoch 00026: val_loss did not improve from 0.28777
25120/25120 [==============================] - 5s 219us/sample - loss: 0.2642 - categorical_accuracy: 0.9180 - val_loss: 0.2921 - val_categorical_accuracy: 0.9201
Epoch 27/100
25024/25120 [============================&gt;.] - ETA: 0s - loss: 0.2594 - categorical_accuracy: 0.9194
Epoch 00027: val_loss did not improve from 0.28777
25120/25120 [==============================] - 5s 216us/sample - loss: 0.2592 - categorical_accuracy: 0.9195 - val_loss: 0.2907 - val_categorical_accuracy: 0.9188
Epoch 28/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9220
Epoch 00028: val_loss improved from 0.28777 to 0.27580, saving model to t_weights_1
25120/25120 [==============================] - 5s 218us/sample - loss: 0.2508 - categorical_accuracy: 0.9220 - val_loss: 0.2758 - val_categorical_accuracy: 0.9248
Epoch 29/100
24864/25120 [============================&gt;.] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.9208
Epoch 00029: val_loss did not improve from 0.27580
25120/25120 [==============================] - 5s 216us/sample - loss: 0.2493 - categorical_accuracy: 0.9208 - val_loss: 0.2931 - val_categorical_accuracy: 0.9242
Epoch 30/100
24896/25120 [============================&gt;.] - ETA: 0s - loss: 0.2487 - categorical_accuracy: 0.9215
Epoch 00030: val_loss did not improve from 0.27580
25120/25120 [==============================] - 5s 213us/sample - loss: 0.2481 - categorical_accuracy: 0.9218 - val_loss: 0.2849 - val_categorical_accuracy: 0.9258
Epoch 31/100
25088/25120 [============================&gt;.] - ETA: 0s - loss: 0.2448 - categorical_accuracy: 0.9214
Epoch 00031: val_loss did not improve from 0.27580
25120/25120 [==============================] - 5s 217us/sample - loss: 0.2449 - categorical_accuracy: 0.9214 - val_loss: 0.3141 - val_categorical_accuracy: 0.9213
Epoch 32/100
24928/25120 [============================&gt;.] - ETA: 0s - loss: 0.2425 - categorical_accuracy: 0.9215
Epoch 00032: val_loss did not improve from 0.27580
25120/25120 [==============================] - 5s 209us/sample - loss: 0.2423 - categorical_accuracy: 0.9216 - val_loss: 0.2818 - val_categorical_accuracy: 0.9252
Epoch 33/100
25056/25120 [============================&gt;.] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9243
Epoch 00033: val_loss did not improve from 0.27580
25120/25120 [==============================] - 5s 217us/sample - loss: 0.2385 - categorical_accuracy: 0.9244 - val_loss: 0.2921 - val_categorical_accuracy: 0.9248
0.92738855 0.5513


nrx: 20 - real: 0 
Train on 32960 samples, validate on 4120 samples
Epoch 1/100
32672/32960 [============================&gt;.] - ETA: 0s - loss: 1.9248 - categorical_accuracy: 0.2836
Epoch 00001: val_loss improved from inf to 1.50439, saving model to t_weights_1
32960/32960 [==============================] - 8s 231us/sample - loss: 1.9210 - categorical_accuracy: 0.2851 - val_loss: 1.5044 - val_categorical_accuracy: 0.4585
Epoch 2/100
32928/32960 [============================&gt;.] - ETA: 0s - loss: 1.4089 - categorical_accuracy: 0.4967
Epoch 00002: val_loss improved from 1.50439 to 1.12468, saving model to t_weights_1
32960/32960 [==============================] - 7s 220us/sample - loss: 1.4086 - categorical_accuracy: 0.4968 - val_loss: 1.1247 - val_categorical_accuracy: 0.6175
Epoch 3/100
32800/32960 [============================&gt;.] - ETA: 0s - loss: 1.1058 - categorical_accuracy: 0.6136
Epoch 00003: val_loss improved from 1.12468 to 0.83106, saving model to t_weights_1
32960/32960 [==============================] - 7s 218us/sample - loss: 1.1053 - categorical_accuracy: 0.6137 - val_loss: 0.8311 - val_categorical_accuracy: 0.7228
Epoch 4/100
32864/32960 [============================&gt;.] - ETA: 0s - loss: 0.8706 - categorical_accuracy: 0.7068
Epoch 00004: val_loss improved from 0.83106 to 0.64880, saving model to t_weights_1
32960/32960 [==============================] - 7s 219us/sample - loss: 0.8705 - categorical_accuracy: 0.7069 - val_loss: 0.6488 - val_categorical_accuracy: 0.7964
Epoch 5/100
32832/32960 [============================&gt;.] - ETA: 0s - loss: 0.6976 - categorical_accuracy: 0.7765
Epoch 00005: val_loss improved from 0.64880 to 0.54576, saving model to t_weights_1
32960/32960 [==============================] - 7s 220us/sample - loss: 0.6973 - categorical_accuracy: 0.7765 - val_loss: 0.5458 - val_categorical_accuracy: 0.8318
Epoch 6/100
32832/32960 [============================&gt;.] - ETA: 0s - loss: 0.5789 - categorical_accuracy: 0.8198
Epoch 00006: val_loss improved from 0.54576 to 0.47119, saving model to t_weights_1
32960/32960 [==============================] - 7s 214us/sample - loss: 0.5793 - categorical_accuracy: 0.8197 - val_loss: 0.4712 - val_categorical_accuracy: 0.8561
Epoch 7/100
32768/32960 [============================&gt;.] - ETA: 0s - loss: 0.5066 - categorical_accuracy: 0.8421
Epoch 00007: val_loss improved from 0.47119 to 0.40390, saving model to t_weights_1
32960/32960 [==============================] - 7s 219us/sample - loss: 0.5065 - categorical_accuracy: 0.8423 - val_loss: 0.4039 - val_categorical_accuracy: 0.8772
Epoch 8/100
32896/32960 [============================&gt;.] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.8578
Epoch 00008: val_loss improved from 0.40390 to 0.36767, saving model to t_weights_1
32960/32960 [==============================] - 7s 219us/sample - loss: 0.4555 - categorical_accuracy: 0.8579 - val_loss: 0.3677 - val_categorical_accuracy: 0.8886
Epoch 9/100
32928/32960 [============================&gt;.] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8720
Epoch 00009: val_loss improved from 0.36767 to 0.35261, saving model to t_weights_1
32960/32960 [==============================] - 7s 220us/sample - loss: 0.4172 - categorical_accuracy: 0.8720 - val_loss: 0.3526 - val_categorical_accuracy: 0.8939
Epoch 10/100
32736/32960 [============================&gt;.] - ETA: 0s - loss: 0.3896 - categorical_accuracy: 0.8821
Epoch 00010: val_loss did not improve from 0.35261
32960/32960 [==============================] - 7s 218us/sample - loss: 0.3892 - categorical_accuracy: 0.8821 - val_loss: 0.3570 - val_categorical_accuracy: 0.8898
Epoch 11/100
32864/32960 [============================&gt;.] - ETA: 0s - loss: 0.3654 - categorical_accuracy: 0.8881
Epoch 00011: val_loss improved from 0.35261 to 0.33090, saving model to t_weights_1
32960/32960 [==============================] - 7s 220us/sample - loss: 0.3652 - categorical_accuracy: 0.8882 - val_loss: 0.3309 - val_categorical_accuracy: 0.8988
Epoch 12/100
32768/32960 [============================&gt;.] - ETA: 0s - loss: 0.3480 - categorical_accuracy: 0.8929
Epoch 00012: val_loss improved from 0.33090 to 0.31873, saving model to t_weights_1
32960/32960 [==============================] - 7s 220us/sample - loss: 0.3473 - categorical_accuracy: 0.8932 - val_loss: 0.3187 - val_categorical_accuracy: 0.9078
Epoch 13/100
32896/32960 [============================&gt;.] - ETA: 0s - loss: 0.3321 - categorical_accuracy: 0.8992
Epoch 00013: val_loss improved from 0.31873 to 0.30724, saving model to t_weights_1
32960/32960 [==============================] - 7s 221us/sample - loss: 0.3325 - categorical_accuracy: 0.8990 - val_loss: 0.3072 - val_categorical_accuracy: 0.9085
Epoch 14/100
32928/32960 [============================&gt;.] - ETA: 0s - loss: 0.3243 - categorical_accuracy: 0.9005
Epoch 00014: val_loss did not improve from 0.30724
32960/32960 [==============================] - 7s 213us/sample - loss: 0.3244 - categorical_accuracy: 0.9005 - val_loss: 0.3140 - val_categorical_accuracy: 0.9083
Epoch 15/100
32896/32960 [============================&gt;.] - ETA: 0s - loss: 0.3119 - categorical_accuracy: 0.9048
Epoch 00015: val_loss improved from 0.30724 to 0.30488, saving model to t_weights_1
32960/32960 [==============================] - 7s 209us/sample - loss: 0.3119 - categorical_accuracy: 0.9048 - val_loss: 0.3049 - val_categorical_accuracy: 0.9117
Epoch 16/100
32800/32960 [============================&gt;.] - ETA: 0s - loss: 0.3009 - categorical_accuracy: 0.9088
Epoch 00016: val_loss did not improve from 0.30488
32960/32960 [==============================] - 7s 217us/sample - loss: 0.3007 - categorical_accuracy: 0.9090 - val_loss: 0.3092 - val_categorical_accuracy: 0.9097
Epoch 17/100
32896/32960 [============================&gt;.] - ETA: 0s - loss: 0.2939 - categorical_accuracy: 0.9092
Epoch 00017: val_loss improved from 0.30488 to 0.29252, saving model to t_weights_1
32960/32960 [==============================] - 7s 220us/sample - loss: 0.2937 - categorical_accuracy: 0.9092 - val_loss: 0.2925 - val_categorical_accuracy: 0.9155
Epoch 18/100
32704/32960 [============================&gt;.] - ETA: 0s - loss: 0.2834 - categorical_accuracy: 0.9130
Epoch 00018: val_loss improved from 0.29252 to 0.28837, saving model to t_weights_1
32960/32960 [==============================] - 7s 218us/sample - loss: 0.2834 - categorical_accuracy: 0.9131 - val_loss: 0.2884 - val_categorical_accuracy: 0.9150
Epoch 19/100
32896/32960 [============================&gt;.] - ETA: 0s - loss: 0.2755 - categorical_accuracy: 0.9160
Epoch 00019: val_loss did not improve from 0.28837
32960/32960 [==============================] - 7s 218us/sample - loss: 0.2755 - categorical_accuracy: 0.9160 - val_loss: 0.3116 - val_categorical_accuracy: 0.9133
Epoch 20/100
32864/32960 [============================&gt;.] - ETA: 0s - loss: 0.2737 - categorical_accuracy: 0.9166
Epoch 00020: val_loss improved from 0.28837 to 0.27985, saving model to t_weights_1
32960/32960 [==============================] - 7s 219us/sample - loss: 0.2738 - categorical_accuracy: 0.9166 - val_loss: 0.2799 - val_categorical_accuracy: 0.9197
Epoch 21/100
32704/32960 [============================&gt;.] - ETA: 0s - loss: 0.2632 - categorical_accuracy: 0.9196
Epoch 00021: val_loss did not improve from 0.27985
32960/32960 [==============================] - 7s 219us/sample - loss: 0.2630 - categorical_accuracy: 0.9196 - val_loss: 0.2976 - val_categorical_accuracy: 0.9170
Epoch 22/100
32736/32960 [============================&gt;.] - ETA: 0s - loss: 0.2632 - categorical_accuracy: 0.9192
Epoch 00022: val_loss improved from 0.27985 to 0.27817, saving model to t_weights_1
32960/32960 [==============================] - 7s 217us/sample - loss: 0.2629 - categorical_accuracy: 0.9194 - val_loss: 0.2782 - val_categorical_accuracy: 0.9218
Epoch 23/100
32832/32960 [============================&gt;.] - ETA: 0s - loss: 0.2567 - categorical_accuracy: 0.9212
Epoch 00023: val_loss did not improve from 0.27817
32960/32960 [==============================] - 7s 211us/sample - loss: 0.2567 - categorical_accuracy: 0.9212 - val_loss: 0.2832 - val_categorical_accuracy: 0.9233
Epoch 24/100
32864/32960 [============================&gt;.] - ETA: 0s - loss: 0.2498 - categorical_accuracy: 0.9225
Epoch 00024: val_loss improved from 0.27817 to 0.27737, saving model to t_weights_1
32960/32960 [==============================] - 7s 221us/sample - loss: 0.2501 - categorical_accuracy: 0.9225 - val_loss: 0.2774 - val_categorical_accuracy: 0.9221
Epoch 25/100
32832/32960 [============================&gt;.] - ETA: 0s - loss: 0.2496 - categorical_accuracy: 0.9243
Epoch 00025: val_loss did not improve from 0.27737
32960/32960 [==============================] - 7s 218us/sample - loss: 0.2502 - categorical_accuracy: 0.9240 - val_loss: 0.3102 - val_categorical_accuracy: 0.9235
Epoch 26/100
32704/32960 [============================&gt;.] - ETA: 0s - loss: 0.2434 - categorical_accuracy: 0.9251
Epoch 00026: val_loss did not improve from 0.27737
32960/32960 [==============================] - 7s 219us/sample - loss: 0.2439 - categorical_accuracy: 0.9249 - val_loss: 0.2985 - val_categorical_accuracy: 0.9211
Epoch 27/100
32704/32960 [============================&gt;.] - ETA: 0s - loss: 0.2417 - categorical_accuracy: 0.9255
Epoch 00027: val_loss improved from 0.27737 to 0.27701, saving model to t_weights_1
32960/32960 [==============================] - 7s 217us/sample - loss: 0.2423 - categorical_accuracy: 0.9253 - val_loss: 0.2770 - val_categorical_accuracy: 0.9192
Epoch 28/100
32768/32960 [============================&gt;.] - ETA: 0s - loss: 0.2380 - categorical_accuracy: 0.9271
Epoch 00028: val_loss did not improve from 0.27701
32960/32960 [==============================] - 7s 225us/sample - loss: 0.2381 - categorical_accuracy: 0.9270 - val_loss: 0.3211 - val_categorical_accuracy: 0.9194
Epoch 29/100
32832/32960 [============================&gt;.] - ETA: 0s - loss: 0.2314 - categorical_accuracy: 0.9304
Epoch 00029: val_loss did not improve from 0.27701
32960/32960 [==============================] - 7s 224us/sample - loss: 0.2317 - categorical_accuracy: 0.9303 - val_loss: 0.3186 - val_categorical_accuracy: 0.9146
Epoch 30/100
32832/32960 [============================&gt;.] - ETA: 0s - loss: 0.2363 - categorical_accuracy: 0.9290
Epoch 00030: val_loss did not improve from 0.27701
32960/32960 [==============================] - 7s 226us/sample - loss: 0.2361 - categorical_accuracy: 0.9291 - val_loss: 0.3068 - val_categorical_accuracy: 0.9197
Epoch 31/100
32864/32960 [============================&gt;.] - ETA: 0s - loss: 0.2260 - categorical_accuracy: 0.9309
Epoch 00031: val_loss did not improve from 0.27701
32960/32960 [==============================] - 7s 219us/sample - loss: 0.2264 - categorical_accuracy: 0.9306 - val_loss: 0.2797 - val_categorical_accuracy: 0.9245
Epoch 32/100
32736/32960 [============================&gt;.] - ETA: 0s - loss: 0.2344 - categorical_accuracy: 0.9282
Epoch 00032: val_loss did not improve from 0.27701
32960/32960 [==============================] - 7s 227us/sample - loss: 0.2342 - categorical_accuracy: 0.9283 - val_loss: 0.2877 - val_categorical_accuracy: 0.9252
0.9196602 0.5226


nrx: 25 - real: 0 
Train on 40296 samples, validate on 5037 samples
Epoch 1/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 1.8456 - categorical_accuracy: 0.3224
Epoch 00001: val_loss improved from inf to 1.32966, saving model to t_weights_1
40296/40296 [==============================] - 9s 234us/sample - loss: 1.8454 - categorical_accuracy: 0.3225 - val_loss: 1.3297 - val_categorical_accuracy: 0.5682
Epoch 2/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 1.1606 - categorical_accuracy: 0.6038
Epoch 00002: val_loss improved from 1.32966 to 0.82111, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 1.1590 - categorical_accuracy: 0.6046 - val_loss: 0.8211 - val_categorical_accuracy: 0.7213
Epoch 3/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.8075 - categorical_accuracy: 0.7393
Epoch 00003: val_loss improved from 0.82111 to 0.57870, saving model to t_weights_1
40296/40296 [==============================] - 9s 224us/sample - loss: 0.8077 - categorical_accuracy: 0.7392 - val_loss: 0.5787 - val_categorical_accuracy: 0.8241
Epoch 4/100
40160/40296 [============================&gt;.] - ETA: 0s - loss: 0.6261 - categorical_accuracy: 0.8047
Epoch 00004: val_loss improved from 0.57870 to 0.53706, saving model to t_weights_1
40296/40296 [==============================] - 9s 221us/sample - loss: 0.6267 - categorical_accuracy: 0.8045 - val_loss: 0.5371 - val_categorical_accuracy: 0.8451
Epoch 5/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.5228 - categorical_accuracy: 0.8392
Epoch 00005: val_loss improved from 0.53706 to 0.41329, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.5226 - categorical_accuracy: 0.8393 - val_loss: 0.4133 - val_categorical_accuracy: 0.8765
Epoch 6/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.8597
Epoch 00006: val_loss improved from 0.41329 to 0.37650, saving model to t_weights_1
40296/40296 [==============================] - 9s 219us/sample - loss: 0.4634 - categorical_accuracy: 0.8597 - val_loss: 0.3765 - val_categorical_accuracy: 0.8833
Epoch 7/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.4145 - categorical_accuracy: 0.8743
Epoch 00007: val_loss improved from 0.37650 to 0.37297, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.4143 - categorical_accuracy: 0.8744 - val_loss: 0.3730 - val_categorical_accuracy: 0.8847
Epoch 8/100
40128/40296 [============================&gt;.] - ETA: 0s - loss: 0.3825 - categorical_accuracy: 0.8846
Epoch 00008: val_loss improved from 0.37297 to 0.34311, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.3825 - categorical_accuracy: 0.8845 - val_loss: 0.3431 - val_categorical_accuracy: 0.8978
Epoch 9/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.3582 - categorical_accuracy: 0.8902
Epoch 00009: val_loss improved from 0.34311 to 0.33477, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.3582 - categorical_accuracy: 0.8902 - val_loss: 0.3348 - val_categorical_accuracy: 0.9005
Epoch 10/100
40192/40296 [============================&gt;.] - ETA: 0s - loss: 0.3461 - categorical_accuracy: 0.8950
Epoch 00010: val_loss did not improve from 0.33477
40296/40296 [==============================] - 9s 221us/sample - loss: 0.3457 - categorical_accuracy: 0.8951 - val_loss: 0.3356 - val_categorical_accuracy: 0.8991
Epoch 11/100
40032/40296 [============================&gt;.] - ETA: 0s - loss: 0.3212 - categorical_accuracy: 0.9041
Epoch 00011: val_loss improved from 0.33477 to 0.31783, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.3221 - categorical_accuracy: 0.9037 - val_loss: 0.3178 - val_categorical_accuracy: 0.9035
Epoch 12/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.3119 - categorical_accuracy: 0.9045
Epoch 00012: val_loss improved from 0.31783 to 0.30075, saving model to t_weights_1
40296/40296 [==============================] - 9s 224us/sample - loss: 0.3117 - categorical_accuracy: 0.9045 - val_loss: 0.3008 - val_categorical_accuracy: 0.9083
Epoch 13/100
40192/40296 [============================&gt;.] - ETA: 0s - loss: 0.3039 - categorical_accuracy: 0.9076
Epoch 00013: val_loss did not improve from 0.30075
40296/40296 [==============================] - 9s 213us/sample - loss: 0.3038 - categorical_accuracy: 0.9076 - val_loss: 0.3185 - val_categorical_accuracy: 0.9013
Epoch 14/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2984 - categorical_accuracy: 0.9102
Epoch 00014: val_loss did not improve from 0.30075
40296/40296 [==============================] - 9s 213us/sample - loss: 0.2985 - categorical_accuracy: 0.9102 - val_loss: 0.3289 - val_categorical_accuracy: 0.9061
Epoch 15/100
40192/40296 [============================&gt;.] - ETA: 0s - loss: 0.2848 - categorical_accuracy: 0.9133
Epoch 00015: val_loss improved from 0.30075 to 0.29051, saving model to t_weights_1
40296/40296 [==============================] - 9s 218us/sample - loss: 0.2847 - categorical_accuracy: 0.9133 - val_loss: 0.2905 - val_categorical_accuracy: 0.9164
Epoch 16/100
40160/40296 [============================&gt;.] - ETA: 0s - loss: 0.2768 - categorical_accuracy: 0.9159
Epoch 00016: val_loss did not improve from 0.29051
40296/40296 [==============================] - 9s 220us/sample - loss: 0.2769 - categorical_accuracy: 0.9159 - val_loss: 0.3153 - val_categorical_accuracy: 0.9128
Epoch 17/100
40160/40296 [============================&gt;.] - ETA: 0s - loss: 0.2759 - categorical_accuracy: 0.9181
Epoch 00017: val_loss improved from 0.29051 to 0.28985, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.2758 - categorical_accuracy: 0.9182 - val_loss: 0.2899 - val_categorical_accuracy: 0.9168
Epoch 18/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.2651 - categorical_accuracy: 0.9198
Epoch 00018: val_loss improved from 0.28985 to 0.28908, saving model to t_weights_1
40296/40296 [==============================] - 9s 215us/sample - loss: 0.2651 - categorical_accuracy: 0.9198 - val_loss: 0.2891 - val_categorical_accuracy: 0.9200
Epoch 19/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 0.2605 - categorical_accuracy: 0.9221
Epoch 00019: val_loss did not improve from 0.28908
40296/40296 [==============================] - 9s 221us/sample - loss: 0.2609 - categorical_accuracy: 0.9220 - val_loss: 0.2919 - val_categorical_accuracy: 0.9164
Epoch 20/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 0.2518 - categorical_accuracy: 0.9251
Epoch 00020: val_loss did not improve from 0.28908
40296/40296 [==============================] - 9s 216us/sample - loss: 0.2518 - categorical_accuracy: 0.9250 - val_loss: 0.2894 - val_categorical_accuracy: 0.9186
Epoch 21/100
40128/40296 [============================&gt;.] - ETA: 0s - loss: 0.2516 - categorical_accuracy: 0.9244
Epoch 00021: val_loss improved from 0.28908 to 0.28384, saving model to t_weights_1
40296/40296 [==============================] - 9s 224us/sample - loss: 0.2516 - categorical_accuracy: 0.9245 - val_loss: 0.2838 - val_categorical_accuracy: 0.9190
Epoch 22/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2450 - categorical_accuracy: 0.9273
Epoch 00022: val_loss improved from 0.28384 to 0.27110, saving model to t_weights_1
40296/40296 [==============================] - 9s 224us/sample - loss: 0.2450 - categorical_accuracy: 0.9273 - val_loss: 0.2711 - val_categorical_accuracy: 0.9250
Epoch 23/100
40192/40296 [============================&gt;.] - ETA: 0s - loss: 0.2394 - categorical_accuracy: 0.9282
Epoch 00023: val_loss did not improve from 0.27110
40296/40296 [==============================] - 9s 222us/sample - loss: 0.2398 - categorical_accuracy: 0.9280 - val_loss: 0.2744 - val_categorical_accuracy: 0.9277
Epoch 24/100
40160/40296 [============================&gt;.] - ETA: 0s - loss: 0.2383 - categorical_accuracy: 0.9285
Epoch 00024: val_loss did not improve from 0.27110
40296/40296 [==============================] - 9s 221us/sample - loss: 0.2384 - categorical_accuracy: 0.9285 - val_loss: 0.2737 - val_categorical_accuracy: 0.9265
Epoch 25/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.2323 - categorical_accuracy: 0.9307
Epoch 00025: val_loss did not improve from 0.27110
40296/40296 [==============================] - 8s 210us/sample - loss: 0.2323 - categorical_accuracy: 0.9307 - val_loss: 0.2942 - val_categorical_accuracy: 0.9218
Epoch 26/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2339 - categorical_accuracy: 0.9298
Epoch 00026: val_loss did not improve from 0.27110
40296/40296 [==============================] - 9s 221us/sample - loss: 0.2338 - categorical_accuracy: 0.9298 - val_loss: 0.2827 - val_categorical_accuracy: 0.9240
Epoch 27/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2277 - categorical_accuracy: 0.9325
Epoch 00027: val_loss did not improve from 0.27110
40296/40296 [==============================] - 9s 216us/sample - loss: 0.2277 - categorical_accuracy: 0.9325 - val_loss: 0.2779 - val_categorical_accuracy: 0.9269
0.919595 0.7212


nrx: 0 - real: 1 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1600 samples, validate on 200 samples
Epoch 1/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 2.3170 - categorical_accuracy: 0.1420
Epoch 00001: val_loss improved from inf to 2.30388, saving model to t_weights_1
1600/1600 [==============================] - 1s 475us/sample - loss: 2.3149 - categorical_accuracy: 0.1475 - val_loss: 2.3039 - val_categorical_accuracy: 0.1350
Epoch 2/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 2.2251 - categorical_accuracy: 0.2099
Epoch 00002: val_loss improved from 2.30388 to 1.95149, saving model to t_weights_1
1600/1600 [==============================] - 0s 233us/sample - loss: 2.2116 - categorical_accuracy: 0.2200 - val_loss: 1.9515 - val_categorical_accuracy: 0.4800
Epoch 3/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 1.6989 - categorical_accuracy: 0.3699
Epoch 00003: val_loss improved from 1.95149 to 1.16405, saving model to t_weights_1
1600/1600 [==============================] - 0s 265us/sample - loss: 1.6900 - categorical_accuracy: 0.3750 - val_loss: 1.1641 - val_categorical_accuracy: 0.7550
Epoch 4/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 1.1335 - categorical_accuracy: 0.5721
Epoch 00004: val_loss improved from 1.16405 to 0.64884, saving model to t_weights_1
1600/1600 [==============================] - 0s 274us/sample - loss: 1.1271 - categorical_accuracy: 0.5750 - val_loss: 0.6488 - val_categorical_accuracy: 0.8250
Epoch 5/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.8324 - categorical_accuracy: 0.7092
Epoch 00005: val_loss improved from 0.64884 to 0.45378, saving model to t_weights_1
1600/1600 [==============================] - 0s 276us/sample - loss: 0.8294 - categorical_accuracy: 0.7088 - val_loss: 0.4538 - val_categorical_accuracy: 0.8750
Epoch 6/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.6309 - categorical_accuracy: 0.7919
Epoch 00006: val_loss improved from 0.45378 to 0.29122, saving model to t_weights_1
1600/1600 [==============================] - 0s 280us/sample - loss: 0.6214 - categorical_accuracy: 0.7956 - val_loss: 0.2912 - val_categorical_accuracy: 0.9700
Epoch 7/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.4260 - categorical_accuracy: 0.8757
Epoch 00007: val_loss improved from 0.29122 to 0.20413, saving model to t_weights_1
1600/1600 [==============================] - 0s 269us/sample - loss: 0.4228 - categorical_accuracy: 0.8800 - val_loss: 0.2041 - val_categorical_accuracy: 0.9750
Epoch 8/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.3410 - categorical_accuracy: 0.8906
Epoch 00008: val_loss improved from 0.20413 to 0.15161, saving model to t_weights_1
1600/1600 [==============================] - 0s 247us/sample - loss: 0.3382 - categorical_accuracy: 0.8931 - val_loss: 0.1516 - val_categorical_accuracy: 0.9800
Epoch 9/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.2707 - categorical_accuracy: 0.9198
Epoch 00009: val_loss improved from 0.15161 to 0.11997, saving model to t_weights_1
1600/1600 [==============================] - 0s 292us/sample - loss: 0.2667 - categorical_accuracy: 0.9212 - val_loss: 0.1200 - val_categorical_accuracy: 0.9850
Epoch 10/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2731 - categorical_accuracy: 0.9247
Epoch 00010: val_loss improved from 0.11997 to 0.09097, saving model to t_weights_1
1600/1600 [==============================] - 0s 276us/sample - loss: 0.2738 - categorical_accuracy: 0.9250 - val_loss: 0.0910 - val_categorical_accuracy: 0.9900
Epoch 11/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2271 - categorical_accuracy: 0.9426
Epoch 00011: val_loss improved from 0.09097 to 0.06452, saving model to t_weights_1
1600/1600 [==============================] - 0s 278us/sample - loss: 0.2275 - categorical_accuracy: 0.9419 - val_loss: 0.0645 - val_categorical_accuracy: 1.0000
Epoch 12/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1653 - categorical_accuracy: 0.9603
Epoch 00012: val_loss did not improve from 0.06452
1600/1600 [==============================] - 0s 233us/sample - loss: 0.1631 - categorical_accuracy: 0.9606 - val_loss: 0.0667 - val_categorical_accuracy: 0.9900
Epoch 13/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.1434 - categorical_accuracy: 0.9717
Epoch 00013: val_loss did not improve from 0.06452
1600/1600 [==============================] - 0s 217us/sample - loss: 0.1409 - categorical_accuracy: 0.9712 - val_loss: 0.0708 - val_categorical_accuracy: 0.9900
Epoch 14/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.9734
Epoch 00014: val_loss improved from 0.06452 to 0.03672, saving model to t_weights_1
1600/1600 [==============================] - 0s 236us/sample - loss: 0.1217 - categorical_accuracy: 0.9744 - val_loss: 0.0367 - val_categorical_accuracy: 1.0000
Epoch 15/100
1312/1600 [=======================&gt;......] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.9848
Epoch 00015: val_loss improved from 0.03672 to 0.03259, saving model to t_weights_1
1600/1600 [==============================] - 0s 256us/sample - loss: 0.1054 - categorical_accuracy: 0.9837 - val_loss: 0.0326 - val_categorical_accuracy: 1.0000
Epoch 16/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.1025 - categorical_accuracy: 0.9747
Epoch 00016: val_loss did not improve from 0.03259
1600/1600 [==============================] - 0s 222us/sample - loss: 0.1012 - categorical_accuracy: 0.9762 - val_loss: 0.0564 - val_categorical_accuracy: 0.9850
Epoch 17/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0740 - categorical_accuracy: 0.9904
Epoch 00017: val_loss improved from 0.03259 to 0.02608, saving model to t_weights_1
1600/1600 [==============================] - 0s 279us/sample - loss: 0.0872 - categorical_accuracy: 0.9894 - val_loss: 0.0261 - val_categorical_accuracy: 1.0000
Epoch 18/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0958 - categorical_accuracy: 0.9774
Epoch 00018: val_loss did not improve from 0.02608
1600/1600 [==============================] - 0s 239us/sample - loss: 0.0929 - categorical_accuracy: 0.9787 - val_loss: 0.0440 - val_categorical_accuracy: 0.9950
Epoch 19/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0765 - categorical_accuracy: 0.9857
Epoch 00019: val_loss improved from 0.02608 to 0.02230, saving model to t_weights_1
1600/1600 [==============================] - 0s 243us/sample - loss: 0.0764 - categorical_accuracy: 0.9856 - val_loss: 0.0223 - val_categorical_accuracy: 1.0000
Epoch 20/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0741 - categorical_accuracy: 0.9864
Epoch 00020: val_loss did not improve from 0.02230
1600/1600 [==============================] - 0s 207us/sample - loss: 0.0764 - categorical_accuracy: 0.9862 - val_loss: 0.0234 - val_categorical_accuracy: 1.0000
Epoch 21/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0706 - categorical_accuracy: 0.9917
Epoch 00021: val_loss did not improve from 0.02230
1600/1600 [==============================] - 0s 234us/sample - loss: 0.0697 - categorical_accuracy: 0.9919 - val_loss: 0.0256 - val_categorical_accuracy: 1.0000
Epoch 22/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0684 - categorical_accuracy: 0.9909
Epoch 00022: val_loss did not improve from 0.02230
1600/1600 [==============================] - 0s 230us/sample - loss: 0.0678 - categorical_accuracy: 0.9906 - val_loss: 0.0242 - val_categorical_accuracy: 1.0000
Epoch 23/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0654 - categorical_accuracy: 0.9879
Epoch 00023: val_loss did not improve from 0.02230
1600/1600 [==============================] - 0s 216us/sample - loss: 0.0652 - categorical_accuracy: 0.9881 - val_loss: 0.0270 - val_categorical_accuracy: 1.0000
Epoch 24/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0593 - categorical_accuracy: 0.9840
Epoch 00024: val_loss did not improve from 0.02230
1600/1600 [==============================] - 0s 207us/sample - loss: 0.0703 - categorical_accuracy: 0.9825 - val_loss: 0.0548 - val_categorical_accuracy: 0.9900
1.0 0.0907


nrx: 5 - real: 1 
Train on 9120 samples, validate on 1140 samples
Epoch 1/100
9024/9120 [============================&gt;.] - ETA: 0s - loss: 2.2354 - categorical_accuracy: 0.1662
Epoch 00001: val_loss improved from inf to 2.03938, saving model to t_weights_1
9120/9120 [==============================] - 2s 270us/sample - loss: 2.2352 - categorical_accuracy: 0.1668 - val_loss: 2.0394 - val_categorical_accuracy: 0.2851
Epoch 2/100
8832/9120 [============================&gt;.] - ETA: 0s - loss: 1.7760 - categorical_accuracy: 0.3788
Epoch 00002: val_loss improved from 2.03938 to 1.43602, saving model to t_weights_1
9120/9120 [==============================] - 2s 229us/sample - loss: 1.7668 - categorical_accuracy: 0.3828 - val_loss: 1.4360 - val_categorical_accuracy: 0.4816
Epoch 3/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 1.3444 - categorical_accuracy: 0.5261
Epoch 00003: val_loss improved from 1.43602 to 1.09441, saving model to t_weights_1
9120/9120 [==============================] - 2s 235us/sample - loss: 1.3430 - categorical_accuracy: 0.5264 - val_loss: 1.0944 - val_categorical_accuracy: 0.6175
Epoch 4/100
9024/9120 [============================&gt;.] - ETA: 0s - loss: 1.0565 - categorical_accuracy: 0.6308
Epoch 00004: val_loss improved from 1.09441 to 0.80266, saving model to t_weights_1
9120/9120 [==============================] - 2s 231us/sample - loss: 1.0550 - categorical_accuracy: 0.6310 - val_loss: 0.8027 - val_categorical_accuracy: 0.7439
Epoch 5/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.8556 - categorical_accuracy: 0.7016
Epoch 00005: val_loss improved from 0.80266 to 0.69553, saving model to t_weights_1
9120/9120 [==============================] - 2s 226us/sample - loss: 0.8544 - categorical_accuracy: 0.7020 - val_loss: 0.6955 - val_categorical_accuracy: 0.7825
Epoch 6/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.7340 - categorical_accuracy: 0.7487
Epoch 00006: val_loss improved from 0.69553 to 0.59708, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.7329 - categorical_accuracy: 0.7490 - val_loss: 0.5971 - val_categorical_accuracy: 0.8281
Epoch 7/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.6096 - categorical_accuracy: 0.8001
Epoch 00007: val_loss improved from 0.59708 to 0.49501, saving model to t_weights_1
9120/9120 [==============================] - 2s 231us/sample - loss: 0.6076 - categorical_accuracy: 0.8002 - val_loss: 0.4950 - val_categorical_accuracy: 0.8482
Epoch 8/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.5227 - categorical_accuracy: 0.8305
Epoch 00008: val_loss improved from 0.49501 to 0.43543, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.5253 - categorical_accuracy: 0.8296 - val_loss: 0.4354 - val_categorical_accuracy: 0.8728
Epoch 9/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 0.4611 - categorical_accuracy: 0.8525
Epoch 00009: val_loss improved from 0.43543 to 0.37745, saving model to t_weights_1
9120/9120 [==============================] - 2s 233us/sample - loss: 0.4610 - categorical_accuracy: 0.8522 - val_loss: 0.3775 - val_categorical_accuracy: 0.8991
Epoch 10/100
8928/9120 [============================&gt;.] - ETA: 0s - loss: 0.3997 - categorical_accuracy: 0.8763
Epoch 00010: val_loss improved from 0.37745 to 0.33000, saving model to t_weights_1
9120/9120 [==============================] - 2s 231us/sample - loss: 0.3999 - categorical_accuracy: 0.8768 - val_loss: 0.3300 - val_categorical_accuracy: 0.9026
Epoch 11/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.3623 - categorical_accuracy: 0.8925
Epoch 00011: val_loss improved from 0.33000 to 0.30934, saving model to t_weights_1
9120/9120 [==============================] - 2s 235us/sample - loss: 0.3604 - categorical_accuracy: 0.8936 - val_loss: 0.3093 - val_categorical_accuracy: 0.9228
Epoch 12/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.3125 - categorical_accuracy: 0.9135
Epoch 00012: val_loss improved from 0.30934 to 0.30074, saving model to t_weights_1
9120/9120 [==============================] - 2s 228us/sample - loss: 0.3136 - categorical_accuracy: 0.9135 - val_loss: 0.3007 - val_categorical_accuracy: 0.9307
Epoch 13/100
8864/9120 [============================&gt;.] - ETA: 0s - loss: 0.2855 - categorical_accuracy: 0.9181
Epoch 00013: val_loss improved from 0.30074 to 0.25647, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.2848 - categorical_accuracy: 0.9181 - val_loss: 0.2565 - val_categorical_accuracy: 0.9272
Epoch 14/100
9024/9120 [============================&gt;.] - ETA: 0s - loss: 0.2700 - categorical_accuracy: 0.9252
Epoch 00014: val_loss did not improve from 0.25647
9120/9120 [==============================] - 2s 219us/sample - loss: 0.2693 - categorical_accuracy: 0.9254 - val_loss: 0.2624 - val_categorical_accuracy: 0.9368
Epoch 15/100
9024/9120 [============================&gt;.] - ETA: 0s - loss: 0.2517 - categorical_accuracy: 0.9292
Epoch 00015: val_loss improved from 0.25647 to 0.21707, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.2506 - categorical_accuracy: 0.9295 - val_loss: 0.2171 - val_categorical_accuracy: 0.9482
Epoch 16/100
8864/9120 [============================&gt;.] - ETA: 0s - loss: 0.2276 - categorical_accuracy: 0.9411
Epoch 00016: val_loss improved from 0.21707 to 0.20900, saving model to t_weights_1
9120/9120 [==============================] - 2s 231us/sample - loss: 0.2263 - categorical_accuracy: 0.9410 - val_loss: 0.2090 - val_categorical_accuracy: 0.9509
Epoch 17/100
9088/9120 [============================&gt;.] - ETA: 0s - loss: 0.2129 - categorical_accuracy: 0.9444
Epoch 00017: val_loss did not improve from 0.20900
9120/9120 [==============================] - 2s 228us/sample - loss: 0.2131 - categorical_accuracy: 0.9443 - val_loss: 0.2266 - val_categorical_accuracy: 0.9500
Epoch 18/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.2085 - categorical_accuracy: 0.9453
Epoch 00018: val_loss did not improve from 0.20900
9120/9120 [==============================] - 2s 225us/sample - loss: 0.2080 - categorical_accuracy: 0.9452 - val_loss: 0.2282 - val_categorical_accuracy: 0.9500
Epoch 19/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.1899 - categorical_accuracy: 0.9522
Epoch 00019: val_loss did not improve from 0.20900
9120/9120 [==============================] - 2s 201us/sample - loss: 0.1899 - categorical_accuracy: 0.9526 - val_loss: 0.2106 - val_categorical_accuracy: 0.9500
Epoch 20/100
8928/9120 [============================&gt;.] - ETA: 0s - loss: 0.1855 - categorical_accuracy: 0.9522
Epoch 00020: val_loss improved from 0.20900 to 0.20351, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.1849 - categorical_accuracy: 0.9529 - val_loss: 0.2035 - val_categorical_accuracy: 0.9553
Epoch 21/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.1569 - categorical_accuracy: 0.9609
Epoch 00021: val_loss did not improve from 0.20351
9120/9120 [==============================] - 2s 222us/sample - loss: 0.1562 - categorical_accuracy: 0.9613 - val_loss: 0.2153 - val_categorical_accuracy: 0.9535
Epoch 22/100
9088/9120 [============================&gt;.] - ETA: 0s - loss: 0.1437 - categorical_accuracy: 0.9651
Epoch 00022: val_loss did not improve from 0.20351
9120/9120 [==============================] - 2s 224us/sample - loss: 0.1440 - categorical_accuracy: 0.9651 - val_loss: 0.2069 - val_categorical_accuracy: 0.9596
Epoch 23/100
8768/9120 [===========================&gt;..] - ETA: 0s - loss: 0.1442 - categorical_accuracy: 0.9665
Epoch 00023: val_loss improved from 0.20351 to 0.19252, saving model to t_weights_1
9120/9120 [==============================] - 2s 216us/sample - loss: 0.1456 - categorical_accuracy: 0.9667 - val_loss: 0.1925 - val_categorical_accuracy: 0.9623
Epoch 24/100
8864/9120 [============================&gt;.] - ETA: 0s - loss: 0.1463 - categorical_accuracy: 0.9638
Epoch 00024: val_loss did not improve from 0.19252
9120/9120 [==============================] - 2s 196us/sample - loss: 0.1458 - categorical_accuracy: 0.9640 - val_loss: 0.3020 - val_categorical_accuracy: 0.9184
Epoch 25/100
8928/9120 [============================&gt;.] - ETA: 0s - loss: 0.1546 - categorical_accuracy: 0.9643
Epoch 00025: val_loss did not improve from 0.19252
9120/9120 [==============================] - 2s 221us/sample - loss: 0.1545 - categorical_accuracy: 0.9643 - val_loss: 0.2043 - val_categorical_accuracy: 0.9632
Epoch 26/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.1285 - categorical_accuracy: 0.9682
Epoch 00026: val_loss did not improve from 0.19252
9120/9120 [==============================] - 2s 223us/sample - loss: 0.1293 - categorical_accuracy: 0.9681 - val_loss: 0.2168 - val_categorical_accuracy: 0.9544
Epoch 27/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.1345 - categorical_accuracy: 0.9661
Epoch 00027: val_loss improved from 0.19252 to 0.18550, saving model to t_weights_1
9120/9120 [==============================] - 2s 227us/sample - loss: 0.1352 - categorical_accuracy: 0.9657 - val_loss: 0.1855 - val_categorical_accuracy: 0.9649
Epoch 28/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.1308 - categorical_accuracy: 0.9695
Epoch 00028: val_loss did not improve from 0.18550
9120/9120 [==============================] - 2s 222us/sample - loss: 0.1308 - categorical_accuracy: 0.9695 - val_loss: 0.2150 - val_categorical_accuracy: 0.9640
Epoch 29/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.9722
Epoch 00029: val_loss did not improve from 0.18550
9120/9120 [==============================] - 2s 229us/sample - loss: 0.1165 - categorical_accuracy: 0.9721 - val_loss: 0.1890 - val_categorical_accuracy: 0.9667
Epoch 30/100
8864/9120 [============================&gt;.] - ETA: 0s - loss: 0.1153 - categorical_accuracy: 0.9728
Epoch 00030: val_loss did not improve from 0.18550
9120/9120 [==============================] - 2s 223us/sample - loss: 0.1146 - categorical_accuracy: 0.9730 - val_loss: 0.1918 - val_categorical_accuracy: 0.9667
Epoch 31/100
8992/9120 [============================&gt;.] - ETA: 0s - loss: 0.1044 - categorical_accuracy: 0.9785
Epoch 00031: val_loss did not improve from 0.18550
9120/9120 [==============================] - 2s 221us/sample - loss: 0.1054 - categorical_accuracy: 0.9783 - val_loss: 0.2253 - val_categorical_accuracy: 0.9596
Epoch 32/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 0.1215 - categorical_accuracy: 0.9695
Epoch 00032: val_loss did not improve from 0.18550
9120/9120 [==============================] - 2s 220us/sample - loss: 0.1215 - categorical_accuracy: 0.9694 - val_loss: 0.1907 - val_categorical_accuracy: 0.9632
0.97192985 0.2325


nrx: 10 - real: 1 
Train on 16640 samples, validate on 2080 samples
Epoch 1/100
16512/16640 [============================&gt;.] - ETA: 0s - loss: 2.0228 - categorical_accuracy: 0.2610
Epoch 00001: val_loss improved from inf to 1.56836, saving model to t_weights_1
16640/16640 [==============================] - 4s 254us/sample - loss: 2.0197 - categorical_accuracy: 0.2620 - val_loss: 1.5684 - val_categorical_accuracy: 0.4428
Epoch 2/100
16576/16640 [============================&gt;.] - ETA: 0s - loss: 1.5042 - categorical_accuracy: 0.4597
Epoch 00002: val_loss improved from 1.56836 to 1.23147, saving model to t_weights_1
16640/16640 [==============================] - 4s 224us/sample - loss: 1.5042 - categorical_accuracy: 0.4598 - val_loss: 1.2315 - val_categorical_accuracy: 0.5904
Epoch 3/100
16384/16640 [============================&gt;.] - ETA: 0s - loss: 1.2430 - categorical_accuracy: 0.5601
Epoch 00003: val_loss improved from 1.23147 to 0.97370, saving model to t_weights_1
16640/16640 [==============================] - 4s 227us/sample - loss: 1.2410 - categorical_accuracy: 0.5611 - val_loss: 0.9737 - val_categorical_accuracy: 0.6942
Epoch 4/100
16416/16640 [============================&gt;.] - ETA: 0s - loss: 1.0138 - categorical_accuracy: 0.6527
Epoch 00004: val_loss improved from 0.97370 to 0.76890, saving model to t_weights_1
16640/16640 [==============================] - 4s 222us/sample - loss: 1.0132 - categorical_accuracy: 0.6534 - val_loss: 0.7689 - val_categorical_accuracy: 0.7716
Epoch 5/100
16512/16640 [============================&gt;.] - ETA: 0s - loss: 0.8136 - categorical_accuracy: 0.7298
Epoch 00005: val_loss improved from 0.76890 to 0.60450, saving model to t_weights_1
16640/16640 [==============================] - 4s 226us/sample - loss: 0.8140 - categorical_accuracy: 0.7294 - val_loss: 0.6045 - val_categorical_accuracy: 0.8250
Epoch 6/100
16480/16640 [============================&gt;.] - ETA: 0s - loss: 0.6683 - categorical_accuracy: 0.7840
Epoch 00006: val_loss improved from 0.60450 to 0.50101, saving model to t_weights_1
16640/16640 [==============================] - 4s 224us/sample - loss: 0.6686 - categorical_accuracy: 0.7840 - val_loss: 0.5010 - val_categorical_accuracy: 0.8649
Epoch 7/100
16544/16640 [============================&gt;.] - ETA: 0s - loss: 0.5583 - categorical_accuracy: 0.8226
Epoch 00007: val_loss improved from 0.50101 to 0.40495, saving model to t_weights_1
16640/16640 [==============================] - 4s 226us/sample - loss: 0.5578 - categorical_accuracy: 0.8227 - val_loss: 0.4049 - val_categorical_accuracy: 0.8923
Epoch 8/100
16416/16640 [============================&gt;.] - ETA: 0s - loss: 0.4809 - categorical_accuracy: 0.8483
Epoch 00008: val_loss improved from 0.40495 to 0.36743, saving model to t_weights_1
16640/16640 [==============================] - 4s 229us/sample - loss: 0.4797 - categorical_accuracy: 0.8487 - val_loss: 0.3674 - val_categorical_accuracy: 0.9067
Epoch 9/100
16576/16640 [============================&gt;.] - ETA: 0s - loss: 0.4162 - categorical_accuracy: 0.8736
Epoch 00009: val_loss improved from 0.36743 to 0.31708, saving model to t_weights_1
16640/16640 [==============================] - 4s 215us/sample - loss: 0.4162 - categorical_accuracy: 0.8735 - val_loss: 0.3171 - val_categorical_accuracy: 0.9144
Epoch 10/100
16512/16640 [============================&gt;.] - ETA: 0s - loss: 0.3727 - categorical_accuracy: 0.8900
Epoch 00010: val_loss improved from 0.31708 to 0.30454, saving model to t_weights_1
16640/16640 [==============================] - 4s 230us/sample - loss: 0.3720 - categorical_accuracy: 0.8903 - val_loss: 0.3045 - val_categorical_accuracy: 0.9149
Epoch 11/100
16384/16640 [============================&gt;.] - ETA: 0s - loss: 0.3410 - categorical_accuracy: 0.8994
Epoch 00011: val_loss improved from 0.30454 to 0.29501, saving model to t_weights_1
16640/16640 [==============================] - 4s 226us/sample - loss: 0.3404 - categorical_accuracy: 0.8995 - val_loss: 0.2950 - val_categorical_accuracy: 0.9269
Epoch 12/100
16608/16640 [============================&gt;.] - ETA: 0s - loss: 0.3102 - categorical_accuracy: 0.9112
Epoch 00012: val_loss improved from 0.29501 to 0.26980, saving model to t_weights_1
16640/16640 [==============================] - 4s 230us/sample - loss: 0.3105 - categorical_accuracy: 0.9111 - val_loss: 0.2698 - val_categorical_accuracy: 0.9303
Epoch 13/100
16416/16640 [============================&gt;.] - ETA: 0s - loss: 0.2803 - categorical_accuracy: 0.9199
Epoch 00013: val_loss improved from 0.26980 to 0.25555, saving model to t_weights_1
16640/16640 [==============================] - 4s 225us/sample - loss: 0.2799 - categorical_accuracy: 0.9199 - val_loss: 0.2555 - val_categorical_accuracy: 0.9293
Epoch 14/100
16512/16640 [============================&gt;.] - ETA: 0s - loss: 0.2604 - categorical_accuracy: 0.9258
Epoch 00014: val_loss improved from 0.25555 to 0.24554, saving model to t_weights_1
16640/16640 [==============================] - 4s 228us/sample - loss: 0.2601 - categorical_accuracy: 0.9260 - val_loss: 0.2455 - val_categorical_accuracy: 0.9413
Epoch 15/100
16576/16640 [============================&gt;.] - ETA: 0s - loss: 0.2394 - categorical_accuracy: 0.9311
Epoch 00015: val_loss improved from 0.24554 to 0.24169, saving model to t_weights_1
16640/16640 [==============================] - 4s 223us/sample - loss: 0.2397 - categorical_accuracy: 0.9310 - val_loss: 0.2417 - val_categorical_accuracy: 0.9399
Epoch 16/100
16576/16640 [============================&gt;.] - ETA: 0s - loss: 0.2354 - categorical_accuracy: 0.9333
Epoch 00016: val_loss improved from 0.24169 to 0.24092, saving model to t_weights_1
16640/16640 [==============================] - 4s 231us/sample - loss: 0.2357 - categorical_accuracy: 0.9332 - val_loss: 0.2409 - val_categorical_accuracy: 0.9399
Epoch 17/100
16512/16640 [============================&gt;.] - ETA: 0s - loss: 0.2233 - categorical_accuracy: 0.9360
Epoch 00017: val_loss improved from 0.24092 to 0.22868, saving model to t_weights_1
16640/16640 [==============================] - 4s 224us/sample - loss: 0.2238 - categorical_accuracy: 0.9359 - val_loss: 0.2287 - val_categorical_accuracy: 0.9413
Epoch 18/100
16608/16640 [============================&gt;.] - ETA: 0s - loss: 0.2099 - categorical_accuracy: 0.9441
Epoch 00018: val_loss did not improve from 0.22868
16640/16640 [==============================] - 4s 223us/sample - loss: 0.2101 - categorical_accuracy: 0.9440 - val_loss: 0.2645 - val_categorical_accuracy: 0.9380
Epoch 19/100
16608/16640 [============================&gt;.] - ETA: 0s - loss: 0.2115 - categorical_accuracy: 0.9424
Epoch 00019: val_loss improved from 0.22868 to 0.21392, saving model to t_weights_1
16640/16640 [==============================] - 4s 228us/sample - loss: 0.2116 - categorical_accuracy: 0.9422 - val_loss: 0.2139 - val_categorical_accuracy: 0.9481
Epoch 20/100
16544/16640 [============================&gt;.] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.9497
Epoch 00020: val_loss did not improve from 0.21392
16640/16640 [==============================] - 4s 222us/sample - loss: 0.1875 - categorical_accuracy: 0.9498 - val_loss: 0.2147 - val_categorical_accuracy: 0.9524
Epoch 21/100
16512/16640 [============================&gt;.] - ETA: 0s - loss: 0.1805 - categorical_accuracy: 0.9511
Epoch 00021: val_loss did not improve from 0.21392
16640/16640 [==============================] - 4s 222us/sample - loss: 0.1809 - categorical_accuracy: 0.9510 - val_loss: 0.2275 - val_categorical_accuracy: 0.9471
Epoch 22/100
16384/16640 [============================&gt;.] - ETA: 0s - loss: 0.1830 - categorical_accuracy: 0.9495
Epoch 00022: val_loss improved from 0.21392 to 0.19947, saving model to t_weights_1
16640/16640 [==============================] - 4s 226us/sample - loss: 0.1840 - categorical_accuracy: 0.9489 - val_loss: 0.1995 - val_categorical_accuracy: 0.9553
Epoch 23/100
16544/16640 [============================&gt;.] - ETA: 0s - loss: 0.1622 - categorical_accuracy: 0.9561
Epoch 00023: val_loss did not improve from 0.19947
16640/16640 [==============================] - 4s 225us/sample - loss: 0.1621 - categorical_accuracy: 0.9561 - val_loss: 0.2379 - val_categorical_accuracy: 0.9490
Epoch 24/100
16544/16640 [============================&gt;.] - ETA: 0s - loss: 0.1681 - categorical_accuracy: 0.9539
Epoch 00024: val_loss did not improve from 0.19947
16640/16640 [==============================] - 4s 219us/sample - loss: 0.1680 - categorical_accuracy: 0.9540 - val_loss: 0.2083 - val_categorical_accuracy: 0.9543
Epoch 25/100
16480/16640 [============================&gt;.] - ETA: 0s - loss: 0.1561 - categorical_accuracy: 0.9604
Epoch 00025: val_loss did not improve from 0.19947
16640/16640 [==============================] - 4s 215us/sample - loss: 0.1569 - categorical_accuracy: 0.9603 - val_loss: 0.2235 - val_categorical_accuracy: 0.9577
Epoch 26/100
16608/16640 [============================&gt;.] - ETA: 0s - loss: 0.1544 - categorical_accuracy: 0.9601
Epoch 00026: val_loss did not improve from 0.19947
16640/16640 [==============================] - 4s 221us/sample - loss: 0.1544 - categorical_accuracy: 0.9601 - val_loss: 0.2124 - val_categorical_accuracy: 0.9510
Epoch 27/100
16416/16640 [============================&gt;.] - ETA: 0s - loss: 0.1470 - categorical_accuracy: 0.9640
Epoch 00027: val_loss did not improve from 0.19947
16640/16640 [==============================] - 4s 226us/sample - loss: 0.1475 - categorical_accuracy: 0.9640 - val_loss: 0.2142 - val_categorical_accuracy: 0.9534
0.9485577 0.4219


nrx: 15 - real: 1 
Train on 24640 samples, validate on 3080 samples
Epoch 1/100
24480/24640 [============================&gt;.] - ETA: 0s - loss: 1.9360 - categorical_accuracy: 0.2796
Epoch 00001: val_loss improved from inf to 1.48871, saving model to t_weights_1
24640/24640 [==============================] - 6s 241us/sample - loss: 1.9336 - categorical_accuracy: 0.2808 - val_loss: 1.4887 - val_categorical_accuracy: 0.4903
Epoch 2/100
24448/24640 [============================&gt;.] - ETA: 0s - loss: 1.4078 - categorical_accuracy: 0.5000
Epoch 00002: val_loss improved from 1.48871 to 1.23220, saving model to t_weights_1
24640/24640 [==============================] - 5s 222us/sample - loss: 1.4065 - categorical_accuracy: 0.5006 - val_loss: 1.2322 - val_categorical_accuracy: 0.5744
Epoch 3/100
24544/24640 [============================&gt;.] - ETA: 0s - loss: 1.1260 - categorical_accuracy: 0.6125
Epoch 00003: val_loss improved from 1.23220 to 0.96280, saving model to t_weights_1
24640/24640 [==============================] - 5s 221us/sample - loss: 1.1250 - categorical_accuracy: 0.6128 - val_loss: 0.9628 - val_categorical_accuracy: 0.6711
Epoch 4/100
24512/24640 [============================&gt;.] - ETA: 0s - loss: 0.9268 - categorical_accuracy: 0.6883
Epoch 00004: val_loss improved from 0.96280 to 0.84551, saving model to t_weights_1
24640/24640 [==============================] - 6s 224us/sample - loss: 0.9269 - categorical_accuracy: 0.6881 - val_loss: 0.8455 - val_categorical_accuracy: 0.7247
Epoch 5/100
24576/24640 [============================&gt;.] - ETA: 0s - loss: 0.7651 - categorical_accuracy: 0.7480
Epoch 00005: val_loss improved from 0.84551 to 0.62620, saving model to t_weights_1
24640/24640 [==============================] - 5s 207us/sample - loss: 0.7652 - categorical_accuracy: 0.7481 - val_loss: 0.6262 - val_categorical_accuracy: 0.8110
Epoch 6/100
24480/24640 [============================&gt;.] - ETA: 0s - loss: 0.6445 - categorical_accuracy: 0.7916
Epoch 00006: val_loss improved from 0.62620 to 0.52632, saving model to t_weights_1
24640/24640 [==============================] - 6s 225us/sample - loss: 0.6442 - categorical_accuracy: 0.7917 - val_loss: 0.5263 - val_categorical_accuracy: 0.8539
Epoch 7/100
24384/24640 [============================&gt;.] - ETA: 0s - loss: 0.5445 - categorical_accuracy: 0.8270
Epoch 00007: val_loss improved from 0.52632 to 0.46284, saving model to t_weights_1
24640/24640 [==============================] - 5s 223us/sample - loss: 0.5442 - categorical_accuracy: 0.8272 - val_loss: 0.4628 - val_categorical_accuracy: 0.8714
Epoch 8/100
24608/24640 [============================&gt;.] - ETA: 0s - loss: 0.4707 - categorical_accuracy: 0.8530
Epoch 00008: val_loss improved from 0.46284 to 0.36699, saving model to t_weights_1
24640/24640 [==============================] - 5s 223us/sample - loss: 0.4705 - categorical_accuracy: 0.8530 - val_loss: 0.3670 - val_categorical_accuracy: 0.9026
Epoch 9/100
24608/24640 [============================&gt;.] - ETA: 0s - loss: 0.4106 - categorical_accuracy: 0.8744
Epoch 00009: val_loss improved from 0.36699 to 0.34976, saving model to t_weights_1
24640/24640 [==============================] - 6s 224us/sample - loss: 0.4104 - categorical_accuracy: 0.8745 - val_loss: 0.3498 - val_categorical_accuracy: 0.9000
Epoch 10/100
24608/24640 [============================&gt;.] - ETA: 0s - loss: 0.3660 - categorical_accuracy: 0.8895
Epoch 00010: val_loss improved from 0.34976 to 0.31270, saving model to t_weights_1
24640/24640 [==============================] - 5s 217us/sample - loss: 0.3658 - categorical_accuracy: 0.8896 - val_loss: 0.3127 - val_categorical_accuracy: 0.9224
Epoch 11/100
24512/24640 [============================&gt;.] - ETA: 0s - loss: 0.3260 - categorical_accuracy: 0.9049
Epoch 00011: val_loss improved from 0.31270 to 0.30729, saving model to t_weights_1
24640/24640 [==============================] - 5s 223us/sample - loss: 0.3265 - categorical_accuracy: 0.9047 - val_loss: 0.3073 - val_categorical_accuracy: 0.9185
Epoch 12/100
24384/24640 [============================&gt;.] - ETA: 0s - loss: 0.3065 - categorical_accuracy: 0.9126
Epoch 00012: val_loss did not improve from 0.30729
24640/24640 [==============================] - 5s 220us/sample - loss: 0.3064 - categorical_accuracy: 0.9125 - val_loss: 0.3095 - val_categorical_accuracy: 0.9179
Epoch 13/100
24480/24640 [============================&gt;.] - ETA: 0s - loss: 0.2799 - categorical_accuracy: 0.9190
Epoch 00013: val_loss improved from 0.30729 to 0.28011, saving model to t_weights_1
24640/24640 [==============================] - 6s 224us/sample - loss: 0.2793 - categorical_accuracy: 0.9192 - val_loss: 0.2801 - val_categorical_accuracy: 0.9266
Epoch 14/100
24608/24640 [============================&gt;.] - ETA: 0s - loss: 0.2695 - categorical_accuracy: 0.9216
Epoch 00014: val_loss improved from 0.28011 to 0.25157, saving model to t_weights_1
24640/24640 [==============================] - 5s 222us/sample - loss: 0.2696 - categorical_accuracy: 0.9216 - val_loss: 0.2516 - val_categorical_accuracy: 0.9380
Epoch 15/100
24576/24640 [============================&gt;.] - ETA: 0s - loss: 0.2505 - categorical_accuracy: 0.9281
Epoch 00015: val_loss improved from 0.25157 to 0.23096, saving model to t_weights_1
24640/24640 [==============================] - 6s 224us/sample - loss: 0.2503 - categorical_accuracy: 0.9281 - val_loss: 0.2310 - val_categorical_accuracy: 0.9422
Epoch 16/100
24512/24640 [============================&gt;.] - ETA: 0s - loss: 0.2419 - categorical_accuracy: 0.9324
Epoch 00016: val_loss did not improve from 0.23096
24640/24640 [==============================] - 5s 218us/sample - loss: 0.2416 - categorical_accuracy: 0.9325 - val_loss: 0.2530 - val_categorical_accuracy: 0.9396
Epoch 17/100
24512/24640 [============================&gt;.] - ETA: 0s - loss: 0.2274 - categorical_accuracy: 0.9369
Epoch 00017: val_loss did not improve from 0.23096
24640/24640 [==============================] - 5s 220us/sample - loss: 0.2273 - categorical_accuracy: 0.9369 - val_loss: 0.2403 - val_categorical_accuracy: 0.9380
Epoch 18/100
24448/24640 [============================&gt;.] - ETA: 0s - loss: 0.2205 - categorical_accuracy: 0.9398
Epoch 00018: val_loss improved from 0.23096 to 0.22694, saving model to t_weights_1
24640/24640 [==============================] - 6s 226us/sample - loss: 0.2203 - categorical_accuracy: 0.9399 - val_loss: 0.2269 - val_categorical_accuracy: 0.9471
Epoch 19/100
24448/24640 [============================&gt;.] - ETA: 0s - loss: 0.2115 - categorical_accuracy: 0.9405
Epoch 00019: val_loss did not improve from 0.22694
24640/24640 [==============================] - 5s 223us/sample - loss: 0.2111 - categorical_accuracy: 0.9406 - val_loss: 0.2322 - val_categorical_accuracy: 0.9461
Epoch 20/100
24512/24640 [============================&gt;.] - ETA: 0s - loss: 0.2049 - categorical_accuracy: 0.9441
Epoch 00020: val_loss improved from 0.22694 to 0.22656, saving model to t_weights_1
24640/24640 [==============================] - 5s 222us/sample - loss: 0.2049 - categorical_accuracy: 0.9442 - val_loss: 0.2266 - val_categorical_accuracy: 0.9497
Epoch 21/100
24576/24640 [============================&gt;.] - ETA: 0s - loss: 0.1932 - categorical_accuracy: 0.9473
Epoch 00021: val_loss did not improve from 0.22656
24640/24640 [==============================] - 5s 211us/sample - loss: 0.1931 - categorical_accuracy: 0.9474 - val_loss: 0.2445 - val_categorical_accuracy: 0.9464
Epoch 22/100
24448/24640 [============================&gt;.] - ETA: 0s - loss: 0.1885 - categorical_accuracy: 0.9499
Epoch 00022: val_loss did not improve from 0.22656
24640/24640 [==============================] - 5s 222us/sample - loss: 0.1884 - categorical_accuracy: 0.9500 - val_loss: 0.2334 - val_categorical_accuracy: 0.9487
Epoch 23/100
24384/24640 [============================&gt;.] - ETA: 0s - loss: 0.1845 - categorical_accuracy: 0.9494
Epoch 00023: val_loss did not improve from 0.22656
24640/24640 [==============================] - 5s 220us/sample - loss: 0.1845 - categorical_accuracy: 0.9494 - val_loss: 0.2580 - val_categorical_accuracy: 0.9435
Epoch 24/100
24384/24640 [============================&gt;.] - ETA: 0s - loss: 0.1799 - categorical_accuracy: 0.9533
Epoch 00024: val_loss did not improve from 0.22656
24640/24640 [==============================] - 5s 223us/sample - loss: 0.1802 - categorical_accuracy: 0.9531 - val_loss: 0.2279 - val_categorical_accuracy: 0.9555
Epoch 25/100
24384/24640 [============================&gt;.] - ETA: 0s - loss: 0.1681 - categorical_accuracy: 0.9554
Epoch 00025: val_loss improved from 0.22656 to 0.21956, saving model to t_weights_1
24640/24640 [==============================] - 5s 223us/sample - loss: 0.1682 - categorical_accuracy: 0.9553 - val_loss: 0.2196 - val_categorical_accuracy: 0.9536
Epoch 26/100
24576/24640 [============================&gt;.] - ETA: 0s - loss: 0.1666 - categorical_accuracy: 0.9565
Epoch 00026: val_loss did not improve from 0.21956
24640/24640 [==============================] - 5s 220us/sample - loss: 0.1664 - categorical_accuracy: 0.9566 - val_loss: 0.2355 - val_categorical_accuracy: 0.9539
Epoch 27/100
24512/24640 [============================&gt;.] - ETA: 0s - loss: 0.1721 - categorical_accuracy: 0.9550
Epoch 00027: val_loss did not improve from 0.21956
24640/24640 [==============================] - 5s 220us/sample - loss: 0.1721 - categorical_accuracy: 0.9550 - val_loss: 0.2455 - val_categorical_accuracy: 0.9474
Epoch 28/100
24448/24640 [============================&gt;.] - ETA: 0s - loss: 0.1604 - categorical_accuracy: 0.9579
Epoch 00028: val_loss did not improve from 0.21956
24640/24640 [==============================] - 5s 220us/sample - loss: 0.1612 - categorical_accuracy: 0.9578 - val_loss: 0.2510 - val_categorical_accuracy: 0.9442
Epoch 29/100
24544/24640 [============================&gt;.] - ETA: 0s - loss: 0.1612 - categorical_accuracy: 0.9584
Epoch 00029: val_loss did not improve from 0.21956
24640/24640 [==============================] - 5s 198us/sample - loss: 0.1615 - categorical_accuracy: 0.9582 - val_loss: 0.2950 - val_categorical_accuracy: 0.9269
Epoch 30/100
24352/24640 [============================&gt;.] - ETA: 0s - loss: 0.1576 - categorical_accuracy: 0.9595
Epoch 00030: val_loss did not improve from 0.21956
24640/24640 [==============================] - 5s 220us/sample - loss: 0.1580 - categorical_accuracy: 0.9596 - val_loss: 0.2308 - val_categorical_accuracy: 0.9545
0.95681816 0.438


nrx: 20 - real: 1 
Train on 32160 samples, validate on 4020 samples
Epoch 1/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 1.8825 - categorical_accuracy: 0.3120
Epoch 00001: val_loss improved from inf to 1.43005, saving model to t_weights_1
32160/32160 [==============================] - 7s 229us/sample - loss: 1.8801 - categorical_accuracy: 0.3130 - val_loss: 1.4300 - val_categorical_accuracy: 0.5488
Epoch 2/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 1.2745 - categorical_accuracy: 0.5638
Epoch 00002: val_loss improved from 1.43005 to 1.00437, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 1.2736 - categorical_accuracy: 0.5641 - val_loss: 1.0044 - val_categorical_accuracy: 0.6786
Epoch 3/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 0.9080 - categorical_accuracy: 0.6982
Epoch 00003: val_loss improved from 1.00437 to 0.70506, saving model to t_weights_1
32160/32160 [==============================] - 7s 224us/sample - loss: 0.9073 - categorical_accuracy: 0.6985 - val_loss: 0.7051 - val_categorical_accuracy: 0.7796
Epoch 4/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 0.7152 - categorical_accuracy: 0.7698
Epoch 00004: val_loss improved from 0.70506 to 0.55430, saving model to t_weights_1
32160/32160 [==============================] - 7s 224us/sample - loss: 0.7149 - categorical_accuracy: 0.7698 - val_loss: 0.5543 - val_categorical_accuracy: 0.8328
Epoch 5/100
31936/32160 [============================&gt;.] - ETA: 0s - loss: 0.6008 - categorical_accuracy: 0.8093
Epoch 00005: val_loss improved from 0.55430 to 0.49188, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 0.6002 - categorical_accuracy: 0.8096 - val_loss: 0.4919 - val_categorical_accuracy: 0.8522
Epoch 6/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 0.5192 - categorical_accuracy: 0.8384
Epoch 00006: val_loss improved from 0.49188 to 0.40583, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 0.5190 - categorical_accuracy: 0.8385 - val_loss: 0.4058 - val_categorical_accuracy: 0.8828
Epoch 7/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.4621 - categorical_accuracy: 0.8573
Epoch 00007: val_loss improved from 0.40583 to 0.38632, saving model to t_weights_1
32160/32160 [==============================] - 7s 223us/sample - loss: 0.4620 - categorical_accuracy: 0.8574 - val_loss: 0.3863 - val_categorical_accuracy: 0.8843
Epoch 8/100
32032/32160 [============================&gt;.] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8685
Epoch 00008: val_loss improved from 0.38632 to 0.37031, saving model to t_weights_1
32160/32160 [==============================] - 7s 224us/sample - loss: 0.4234 - categorical_accuracy: 0.8686 - val_loss: 0.3703 - val_categorical_accuracy: 0.8925
Epoch 9/100
31936/32160 [============================&gt;.] - ETA: 0s - loss: 0.3909 - categorical_accuracy: 0.8809
Epoch 00009: val_loss improved from 0.37031 to 0.34399, saving model to t_weights_1
32160/32160 [==============================] - 7s 223us/sample - loss: 0.3918 - categorical_accuracy: 0.8808 - val_loss: 0.3440 - val_categorical_accuracy: 0.8990
Epoch 10/100
32096/32160 [============================&gt;.] - ETA: 0s - loss: 0.3643 - categorical_accuracy: 0.8894
Epoch 00010: val_loss improved from 0.34399 to 0.31660, saving model to t_weights_1
32160/32160 [==============================] - 7s 216us/sample - loss: 0.3641 - categorical_accuracy: 0.8894 - val_loss: 0.3166 - val_categorical_accuracy: 0.9085
Epoch 11/100
32032/32160 [============================&gt;.] - ETA: 0s - loss: 0.3454 - categorical_accuracy: 0.8949
Epoch 00011: val_loss improved from 0.31660 to 0.31235, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 0.3451 - categorical_accuracy: 0.8950 - val_loss: 0.3124 - val_categorical_accuracy: 0.9080
Epoch 12/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.3253 - categorical_accuracy: 0.9024
Epoch 00012: val_loss improved from 0.31235 to 0.29046, saving model to t_weights_1
32160/32160 [==============================] - 7s 226us/sample - loss: 0.3251 - categorical_accuracy: 0.9024 - val_loss: 0.2905 - val_categorical_accuracy: 0.9144
Epoch 13/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 0.3143 - categorical_accuracy: 0.9040
Epoch 00013: val_loss did not improve from 0.29046
32160/32160 [==============================] - 7s 222us/sample - loss: 0.3145 - categorical_accuracy: 0.9040 - val_loss: 0.2918 - val_categorical_accuracy: 0.9142
Epoch 14/100
31936/32160 [============================&gt;.] - ETA: 0s - loss: 0.3061 - categorical_accuracy: 0.9085
Epoch 00014: val_loss improved from 0.29046 to 0.28722, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 0.3062 - categorical_accuracy: 0.9085 - val_loss: 0.2872 - val_categorical_accuracy: 0.9174
Epoch 15/100
32096/32160 [============================&gt;.] - ETA: 0s - loss: 0.2891 - categorical_accuracy: 0.9144
Epoch 00015: val_loss improved from 0.28722 to 0.28285, saving model to t_weights_1
32160/32160 [==============================] - 7s 224us/sample - loss: 0.2889 - categorical_accuracy: 0.9144 - val_loss: 0.2828 - val_categorical_accuracy: 0.9204
Epoch 16/100
32128/32160 [============================&gt;.] - ETA: 0s - loss: 0.2782 - categorical_accuracy: 0.9157
Epoch 00016: val_loss did not improve from 0.28285
32160/32160 [==============================] - 7s 222us/sample - loss: 0.2785 - categorical_accuracy: 0.9156 - val_loss: 0.2878 - val_categorical_accuracy: 0.9197
Epoch 17/100
32128/32160 [============================&gt;.] - ETA: 0s - loss: 0.2676 - categorical_accuracy: 0.9198
Epoch 00017: val_loss improved from 0.28285 to 0.27429, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 0.2676 - categorical_accuracy: 0.9197 - val_loss: 0.2743 - val_categorical_accuracy: 0.9214
Epoch 18/100
32064/32160 [============================&gt;.] - ETA: 0s - loss: 0.2628 - categorical_accuracy: 0.9208
Epoch 00018: val_loss did not improve from 0.27429
32160/32160 [==============================] - 7s 219us/sample - loss: 0.2629 - categorical_accuracy: 0.9207 - val_loss: 0.2861 - val_categorical_accuracy: 0.9179
Epoch 19/100
31904/32160 [============================&gt;.] - ETA: 0s - loss: 0.2541 - categorical_accuracy: 0.9245
Epoch 00019: val_loss improved from 0.27429 to 0.26849, saving model to t_weights_1
32160/32160 [==============================] - 7s 226us/sample - loss: 0.2541 - categorical_accuracy: 0.9245 - val_loss: 0.2685 - val_categorical_accuracy: 0.9254
Epoch 20/100
31936/32160 [============================&gt;.] - ETA: 0s - loss: 0.2460 - categorical_accuracy: 0.9271
Epoch 00020: val_loss did not improve from 0.26849
32160/32160 [==============================] - 7s 223us/sample - loss: 0.2457 - categorical_accuracy: 0.9272 - val_loss: 0.2872 - val_categorical_accuracy: 0.9152
Epoch 21/100
31904/32160 [============================&gt;.] - ETA: 0s - loss: 0.2423 - categorical_accuracy: 0.9271
Epoch 00021: val_loss did not improve from 0.26849
32160/32160 [==============================] - 7s 224us/sample - loss: 0.2425 - categorical_accuracy: 0.9271 - val_loss: 0.3013 - val_categorical_accuracy: 0.9194
Epoch 22/100
31904/32160 [============================&gt;.] - ETA: 0s - loss: 0.2375 - categorical_accuracy: 0.9293
Epoch 00022: val_loss improved from 0.26849 to 0.24987, saving model to t_weights_1
32160/32160 [==============================] - 7s 225us/sample - loss: 0.2374 - categorical_accuracy: 0.9294 - val_loss: 0.2499 - val_categorical_accuracy: 0.9311
Epoch 23/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 0.2305 - categorical_accuracy: 0.9324
Epoch 00023: val_loss did not improve from 0.24987
32160/32160 [==============================] - 7s 207us/sample - loss: 0.2307 - categorical_accuracy: 0.9324 - val_loss: 0.2737 - val_categorical_accuracy: 0.9254
Epoch 24/100
32128/32160 [============================&gt;.] - ETA: 0s - loss: 0.2264 - categorical_accuracy: 0.9329
Epoch 00024: val_loss improved from 0.24987 to 0.24955, saving model to t_weights_1
32160/32160 [==============================] - 7s 223us/sample - loss: 0.2264 - categorical_accuracy: 0.9329 - val_loss: 0.2496 - val_categorical_accuracy: 0.9306
Epoch 25/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.2202 - categorical_accuracy: 0.9356
Epoch 00025: val_loss did not improve from 0.24955
32160/32160 [==============================] - 7s 209us/sample - loss: 0.2202 - categorical_accuracy: 0.9355 - val_loss: 0.2606 - val_categorical_accuracy: 0.9318
Epoch 26/100
32064/32160 [============================&gt;.] - ETA: 0s - loss: 0.2154 - categorical_accuracy: 0.9379
Epoch 00026: val_loss did not improve from 0.24955
32160/32160 [==============================] - 7s 223us/sample - loss: 0.2151 - categorical_accuracy: 0.9380 - val_loss: 0.3041 - val_categorical_accuracy: 0.9256
Epoch 27/100
31904/32160 [============================&gt;.] - ETA: 0s - loss: 0.2189 - categorical_accuracy: 0.9362
Epoch 00027: val_loss improved from 0.24955 to 0.24161, saving model to t_weights_1
32160/32160 [==============================] - 7s 219us/sample - loss: 0.2187 - categorical_accuracy: 0.9361 - val_loss: 0.2416 - val_categorical_accuracy: 0.9358
Epoch 28/100
31904/32160 [============================&gt;.] - ETA: 0s - loss: 0.2082 - categorical_accuracy: 0.9390
Epoch 00028: val_loss improved from 0.24161 to 0.24103, saving model to t_weights_1
32160/32160 [==============================] - 7s 224us/sample - loss: 0.2079 - categorical_accuracy: 0.9392 - val_loss: 0.2410 - val_categorical_accuracy: 0.9361
Epoch 29/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.2105 - categorical_accuracy: 0.9379
Epoch 00029: val_loss did not improve from 0.24103
32160/32160 [==============================] - 7s 223us/sample - loss: 0.2100 - categorical_accuracy: 0.9380 - val_loss: 0.2416 - val_categorical_accuracy: 0.9353
Epoch 30/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9418
Epoch 00030: val_loss improved from 0.24103 to 0.24008, saving model to t_weights_1
32160/32160 [==============================] - 7s 226us/sample - loss: 0.2003 - categorical_accuracy: 0.9418 - val_loss: 0.2401 - val_categorical_accuracy: 0.9363
Epoch 31/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9422
Epoch 00031: val_loss did not improve from 0.24008
32160/32160 [==============================] - 7s 222us/sample - loss: 0.1997 - categorical_accuracy: 0.9423 - val_loss: 0.2768 - val_categorical_accuracy: 0.9299
Epoch 32/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.1973 - categorical_accuracy: 0.9428
Epoch 00032: val_loss did not improve from 0.24008
32160/32160 [==============================] - 7s 208us/sample - loss: 0.1971 - categorical_accuracy: 0.9428 - val_loss: 0.2537 - val_categorical_accuracy: 0.9358
Epoch 33/100
31968/32160 [============================&gt;.] - ETA: 0s - loss: 0.1943 - categorical_accuracy: 0.9449
Epoch 00033: val_loss did not improve from 0.24008
32160/32160 [==============================] - 7s 220us/sample - loss: 0.1943 - categorical_accuracy: 0.9449 - val_loss: 0.2433 - val_categorical_accuracy: 0.9371
Epoch 34/100
32128/32160 [============================&gt;.] - ETA: 0s - loss: 0.1951 - categorical_accuracy: 0.9435
Epoch 00034: val_loss did not improve from 0.24008
32160/32160 [==============================] - 7s 222us/sample - loss: 0.1950 - categorical_accuracy: 0.9435 - val_loss: 0.2548 - val_categorical_accuracy: 0.9358
Epoch 35/100
32000/32160 [============================&gt;.] - ETA: 0s - loss: 0.1864 - categorical_accuracy: 0.9470
Epoch 00035: val_loss did not improve from 0.24008
32160/32160 [==============================] - 7s 216us/sample - loss: 0.1862 - categorical_accuracy: 0.9470 - val_loss: 0.2497 - val_categorical_accuracy: 0.9371
0.93955225 0.6864


nrx: 25 - real: 1 
Train on 40136 samples, validate on 5017 samples
Epoch 1/100
39968/40136 [============================&gt;.] - ETA: 0s - loss: 1.8736 - categorical_accuracy: 0.3041
Epoch 00001: val_loss improved from inf to 1.40427, saving model to t_weights_1
40136/40136 [==============================] - 9s 233us/sample - loss: 1.8719 - categorical_accuracy: 0.3048 - val_loss: 1.4043 - val_categorical_accuracy: 0.5087
Epoch 2/100
40096/40136 [============================&gt;.] - ETA: 0s - loss: 1.2305 - categorical_accuracy: 0.5682
Epoch 00002: val_loss improved from 1.40427 to 0.92322, saving model to t_weights_1
40136/40136 [==============================] - 9s 225us/sample - loss: 1.2305 - categorical_accuracy: 0.5683 - val_loss: 0.9232 - val_categorical_accuracy: 0.7060
Epoch 3/100
39936/40136 [============================&gt;.] - ETA: 0s - loss: 0.9024 - categorical_accuracy: 0.6974
Epoch 00003: val_loss improved from 0.92322 to 0.64303, saving model to t_weights_1
40136/40136 [==============================] - 9s 224us/sample - loss: 0.9019 - categorical_accuracy: 0.6977 - val_loss: 0.6430 - val_categorical_accuracy: 0.7909
Epoch 4/100
40096/40136 [============================&gt;.] - ETA: 0s - loss: 0.6901 - categorical_accuracy: 0.7757
Epoch 00004: val_loss improved from 0.64303 to 0.53702, saving model to t_weights_1
40136/40136 [==============================] - 9s 226us/sample - loss: 0.6900 - categorical_accuracy: 0.7757 - val_loss: 0.5370 - val_categorical_accuracy: 0.8318
Epoch 5/100
39968/40136 [============================&gt;.] - ETA: 0s - loss: 0.5657 - categorical_accuracy: 0.8198
Epoch 00005: val_loss improved from 0.53702 to 0.46121, saving model to t_weights_1
40136/40136 [==============================] - 9s 224us/sample - loss: 0.5654 - categorical_accuracy: 0.8199 - val_loss: 0.4612 - val_categorical_accuracy: 0.8603
Epoch 6/100
39904/40136 [============================&gt;.] - ETA: 0s - loss: 0.4883 - categorical_accuracy: 0.8453
Epoch 00006: val_loss improved from 0.46121 to 0.41967, saving model to t_weights_1
40136/40136 [==============================] - 9s 225us/sample - loss: 0.4880 - categorical_accuracy: 0.8453 - val_loss: 0.4197 - val_categorical_accuracy: 0.8722
Epoch 7/100
39904/40136 [============================&gt;.] - ETA: 0s - loss: 0.4373 - categorical_accuracy: 0.8636
Epoch 00007: val_loss improved from 0.41967 to 0.37152, saving model to t_weights_1
40136/40136 [==============================] - 9s 221us/sample - loss: 0.4377 - categorical_accuracy: 0.8635 - val_loss: 0.3715 - val_categorical_accuracy: 0.8848
Epoch 8/100
40032/40136 [============================&gt;.] - ETA: 0s - loss: 0.4028 - categorical_accuracy: 0.8756
Epoch 00008: val_loss improved from 0.37152 to 0.37106, saving model to t_weights_1
40136/40136 [==============================] - 9s 225us/sample - loss: 0.4029 - categorical_accuracy: 0.8756 - val_loss: 0.3711 - val_categorical_accuracy: 0.8872
Epoch 9/100
40000/40136 [============================&gt;.] - ETA: 0s - loss: 0.3679 - categorical_accuracy: 0.8856
Epoch 00009: val_loss improved from 0.37106 to 0.36390, saving model to t_weights_1
40136/40136 [==============================] - 9s 216us/sample - loss: 0.3678 - categorical_accuracy: 0.8856 - val_loss: 0.3639 - val_categorical_accuracy: 0.8910
Epoch 10/100
39936/40136 [============================&gt;.] - ETA: 0s - loss: 0.3543 - categorical_accuracy: 0.8905
Epoch 00010: val_loss improved from 0.36390 to 0.33547, saving model to t_weights_1
40136/40136 [==============================] - 9s 224us/sample - loss: 0.3542 - categorical_accuracy: 0.8906 - val_loss: 0.3355 - val_categorical_accuracy: 0.8993
Epoch 11/100
40064/40136 [============================&gt;.] - ETA: 0s - loss: 0.3371 - categorical_accuracy: 0.8961
Epoch 00011: val_loss improved from 0.33547 to 0.31425, saving model to t_weights_1
40136/40136 [==============================] - 9s 224us/sample - loss: 0.3370 - categorical_accuracy: 0.8960 - val_loss: 0.3142 - val_categorical_accuracy: 0.9039
Epoch 12/100
40032/40136 [============================&gt;.] - ETA: 0s - loss: 0.3217 - categorical_accuracy: 0.9001
Epoch 00012: val_loss improved from 0.31425 to 0.31253, saving model to t_weights_1
40136/40136 [==============================] - 9s 226us/sample - loss: 0.3221 - categorical_accuracy: 0.9000 - val_loss: 0.3125 - val_categorical_accuracy: 0.9057
Epoch 13/100
39904/40136 [============================&gt;.] - ETA: 0s - loss: 0.3114 - categorical_accuracy: 0.9029
Epoch 00013: val_loss improved from 0.31253 to 0.29376, saving model to t_weights_1
40136/40136 [==============================] - 9s 226us/sample - loss: 0.3117 - categorical_accuracy: 0.9029 - val_loss: 0.2938 - val_categorical_accuracy: 0.9115
Epoch 14/100
40032/40136 [============================&gt;.] - ETA: 0s - loss: 0.3028 - categorical_accuracy: 0.9075
Epoch 00014: val_loss improved from 0.29376 to 0.29292, saving model to t_weights_1
40136/40136 [==============================] - 9s 220us/sample - loss: 0.3025 - categorical_accuracy: 0.9077 - val_loss: 0.2929 - val_categorical_accuracy: 0.9123
Epoch 15/100
39968/40136 [============================&gt;.] - ETA: 0s - loss: 0.2916 - categorical_accuracy: 0.9112
Epoch 00015: val_loss did not improve from 0.29292
40136/40136 [==============================] - 9s 224us/sample - loss: 0.2916 - categorical_accuracy: 0.9112 - val_loss: 0.3032 - val_categorical_accuracy: 0.9139
Epoch 16/100
40096/40136 [============================&gt;.] - ETA: 0s - loss: 0.2814 - categorical_accuracy: 0.9143
Epoch 00016: val_loss did not improve from 0.29292
40136/40136 [==============================] - 9s 225us/sample - loss: 0.2816 - categorical_accuracy: 0.9143 - val_loss: 0.3025 - val_categorical_accuracy: 0.9143
Epoch 17/100
40032/40136 [============================&gt;.] - ETA: 0s - loss: 0.2808 - categorical_accuracy: 0.9146
Epoch 00017: val_loss improved from 0.29292 to 0.28302, saving model to t_weights_1
40136/40136 [==============================] - 9s 225us/sample - loss: 0.2806 - categorical_accuracy: 0.9146 - val_loss: 0.2830 - val_categorical_accuracy: 0.9163
Epoch 18/100
40096/40136 [============================&gt;.] - ETA: 0s - loss: 0.2754 - categorical_accuracy: 0.9164
Epoch 00018: val_loss improved from 0.28302 to 0.27371, saving model to t_weights_1
40136/40136 [==============================] - 9s 224us/sample - loss: 0.2755 - categorical_accuracy: 0.9163 - val_loss: 0.2737 - val_categorical_accuracy: 0.9179
Epoch 19/100
40128/40136 [============================&gt;.] - ETA: 0s - loss: 0.2620 - categorical_accuracy: 0.9202
Epoch 00019: val_loss improved from 0.27371 to 0.27258, saving model to t_weights_1
40136/40136 [==============================] - 9s 227us/sample - loss: 0.2620 - categorical_accuracy: 0.9201 - val_loss: 0.2726 - val_categorical_accuracy: 0.9173
Epoch 20/100
40128/40136 [============================&gt;.] - ETA: 0s - loss: 0.2600 - categorical_accuracy: 0.9206
Epoch 00020: val_loss did not improve from 0.27258
40136/40136 [==============================] - 9s 217us/sample - loss: 0.2599 - categorical_accuracy: 0.9206 - val_loss: 0.2753 - val_categorical_accuracy: 0.9209
Epoch 21/100
40000/40136 [============================&gt;.] - ETA: 0s - loss: 0.2539 - categorical_accuracy: 0.9228
Epoch 00021: val_loss did not improve from 0.27258
40136/40136 [==============================] - 9s 223us/sample - loss: 0.2538 - categorical_accuracy: 0.9229 - val_loss: 0.2932 - val_categorical_accuracy: 0.9203
Epoch 22/100
39936/40136 [============================&gt;.] - ETA: 0s - loss: 0.2497 - categorical_accuracy: 0.9232
Epoch 00022: val_loss did not improve from 0.27258
40136/40136 [==============================] - 9s 224us/sample - loss: 0.2497 - categorical_accuracy: 0.9232 - val_loss: 0.2818 - val_categorical_accuracy: 0.9201
Epoch 23/100
40128/40136 [============================&gt;.] - ETA: 0s - loss: 0.2409 - categorical_accuracy: 0.9269
Epoch 00023: val_loss improved from 0.27258 to 0.26309, saving model to t_weights_1
40136/40136 [==============================] - 9s 226us/sample - loss: 0.2409 - categorical_accuracy: 0.9268 - val_loss: 0.2631 - val_categorical_accuracy: 0.9251
Epoch 24/100
40000/40136 [============================&gt;.] - ETA: 0s - loss: 0.2404 - categorical_accuracy: 0.9281
Epoch 00024: val_loss improved from 0.26309 to 0.25901, saving model to t_weights_1
40136/40136 [==============================] - 9s 226us/sample - loss: 0.2403 - categorical_accuracy: 0.9281 - val_loss: 0.2590 - val_categorical_accuracy: 0.9284
Epoch 25/100
40096/40136 [============================&gt;.] - ETA: 0s - loss: 0.2423 - categorical_accuracy: 0.9259
Epoch 00025: val_loss did not improve from 0.25901
40136/40136 [==============================] - 8s 211us/sample - loss: 0.2424 - categorical_accuracy: 0.9259 - val_loss: 0.2648 - val_categorical_accuracy: 0.9274
Epoch 26/100
39968/40136 [============================&gt;.] - ETA: 0s - loss: 0.2312 - categorical_accuracy: 0.9303
Epoch 00026: val_loss did not improve from 0.25901
40136/40136 [==============================] - 9s 220us/sample - loss: 0.2316 - categorical_accuracy: 0.9301 - val_loss: 0.2665 - val_categorical_accuracy: 0.9257
Epoch 27/100
40096/40136 [============================&gt;.] - ETA: 0s - loss: 0.2328 - categorical_accuracy: 0.9294
Epoch 00027: val_loss did not improve from 0.25901
40136/40136 [==============================] - 9s 220us/sample - loss: 0.2327 - categorical_accuracy: 0.9295 - val_loss: 0.2645 - val_categorical_accuracy: 0.9272
Epoch 28/100
39936/40136 [============================&gt;.] - ETA: 0s - loss: 0.2294 - categorical_accuracy: 0.9306
Epoch 00028: val_loss did not improve from 0.25901
40136/40136 [==============================] - 9s 222us/sample - loss: 0.2294 - categorical_accuracy: 0.9306 - val_loss: 0.2774 - val_categorical_accuracy: 0.9257
Epoch 29/100
39936/40136 [============================&gt;.] - ETA: 0s - loss: 0.2276 - categorical_accuracy: 0.9315
Epoch 00029: val_loss did not improve from 0.25901
40136/40136 [==============================] - 9s 223us/sample - loss: 0.2276 - categorical_accuracy: 0.9314 - val_loss: 0.2663 - val_categorical_accuracy: 0.9253
0.9280447 0.7775


nrx: 0 - real: 2 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1600 samples, validate on 200 samples
Epoch 1/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 2.3168 - categorical_accuracy: 0.1370
Epoch 00001: val_loss improved from inf to 2.29227, saving model to t_weights_1
1600/1600 [==============================] - 1s 459us/sample - loss: 2.3160 - categorical_accuracy: 0.1388 - val_loss: 2.2923 - val_categorical_accuracy: 0.2350
Epoch 2/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 2.2217 - categorical_accuracy: 0.2456
Epoch 00002: val_loss improved from 2.29227 to 1.94983, saving model to t_weights_1
1600/1600 [==============================] - 0s 268us/sample - loss: 2.2008 - categorical_accuracy: 0.2519 - val_loss: 1.9498 - val_categorical_accuracy: 0.4050
Epoch 3/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 1.6952 - categorical_accuracy: 0.3939
Epoch 00003: val_loss improved from 1.94983 to 1.15491, saving model to t_weights_1
1600/1600 [==============================] - 0s 282us/sample - loss: 1.6801 - categorical_accuracy: 0.4006 - val_loss: 1.1549 - val_categorical_accuracy: 0.7850
Epoch 4/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 1.1784 - categorical_accuracy: 0.5818
Epoch 00004: val_loss improved from 1.15491 to 0.72999, saving model to t_weights_1
1600/1600 [==============================] - 0s 280us/sample - loss: 1.1693 - categorical_accuracy: 0.5863 - val_loss: 0.7300 - val_categorical_accuracy: 0.9100
Epoch 5/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.7879 - categorical_accuracy: 0.7423
Epoch 00005: val_loss improved from 0.72999 to 0.35894, saving model to t_weights_1
1600/1600 [==============================] - 0s 281us/sample - loss: 0.7844 - categorical_accuracy: 0.7419 - val_loss: 0.3589 - val_categorical_accuracy: 0.9650
Epoch 6/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.5740 - categorical_accuracy: 0.8139
Epoch 00006: val_loss improved from 0.35894 to 0.25572, saving model to t_weights_1
1600/1600 [==============================] - 0s 242us/sample - loss: 0.5661 - categorical_accuracy: 0.8200 - val_loss: 0.2557 - val_categorical_accuracy: 0.9700
Epoch 7/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.4110 - categorical_accuracy: 0.8765
Epoch 00007: val_loss improved from 0.25572 to 0.15284, saving model to t_weights_1
1600/1600 [==============================] - 0s 252us/sample - loss: 0.4016 - categorical_accuracy: 0.8806 - val_loss: 0.1528 - val_categorical_accuracy: 0.9850
Epoch 8/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.3576 - categorical_accuracy: 0.8899
Epoch 00008: val_loss improved from 0.15284 to 0.12894, saving model to t_weights_1
1600/1600 [==============================] - 0s 269us/sample - loss: 0.3485 - categorical_accuracy: 0.8925 - val_loss: 0.1289 - val_categorical_accuracy: 0.9900
Epoch 9/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2966 - categorical_accuracy: 0.9088
Epoch 00009: val_loss improved from 0.12894 to 0.09103, saving model to t_weights_1
1600/1600 [==============================] - 0s 278us/sample - loss: 0.2965 - categorical_accuracy: 0.9094 - val_loss: 0.0910 - val_categorical_accuracy: 0.9950
Epoch 10/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9206
Epoch 00010: val_loss improved from 0.09103 to 0.07102, saving model to t_weights_1
1600/1600 [==============================] - 0s 273us/sample - loss: 0.2510 - categorical_accuracy: 0.9206 - val_loss: 0.0710 - val_categorical_accuracy: 0.9950
Epoch 11/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1892 - categorical_accuracy: 0.9471
Epoch 00011: val_loss improved from 0.07102 to 0.05258, saving model to t_weights_1
1600/1600 [==============================] - 0s 271us/sample - loss: 0.1886 - categorical_accuracy: 0.9475 - val_loss: 0.0526 - val_categorical_accuracy: 1.0000
Epoch 12/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.1773 - categorical_accuracy: 0.9524
Epoch 00012: val_loss did not improve from 0.05258
1600/1600 [==============================] - 0s 203us/sample - loss: 0.1751 - categorical_accuracy: 0.9531 - val_loss: 0.0544 - val_categorical_accuracy: 1.0000
Epoch 13/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1866 - categorical_accuracy: 0.9452
Epoch 00013: val_loss did not improve from 0.05258
1600/1600 [==============================] - 0s 229us/sample - loss: 0.1846 - categorical_accuracy: 0.9463 - val_loss: 0.0716 - val_categorical_accuracy: 0.9900
Epoch 14/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1470 - categorical_accuracy: 0.9643
Epoch 00014: val_loss improved from 0.05258 to 0.03903, saving model to t_weights_1
1600/1600 [==============================] - 0s 272us/sample - loss: 0.1466 - categorical_accuracy: 0.9644 - val_loss: 0.0390 - val_categorical_accuracy: 0.9950
Epoch 15/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1132 - categorical_accuracy: 0.9772
Epoch 00015: val_loss improved from 0.03903 to 0.03348, saving model to t_weights_1
1600/1600 [==============================] - 0s 282us/sample - loss: 0.1137 - categorical_accuracy: 0.9769 - val_loss: 0.0335 - val_categorical_accuracy: 1.0000
Epoch 16/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1078 - categorical_accuracy: 0.9741
Epoch 00016: val_loss did not improve from 0.03348
1600/1600 [==============================] - 0s 237us/sample - loss: 0.1105 - categorical_accuracy: 0.9731 - val_loss: 0.0380 - val_categorical_accuracy: 0.9950
Epoch 17/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0933 - categorical_accuracy: 0.9811
Epoch 00017: val_loss improved from 0.03348 to 0.03150, saving model to t_weights_1
1600/1600 [==============================] - 0s 263us/sample - loss: 0.0928 - categorical_accuracy: 0.9812 - val_loss: 0.0315 - val_categorical_accuracy: 0.9950
Epoch 18/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0944 - categorical_accuracy: 0.9787
Epoch 00018: val_loss improved from 0.03150 to 0.03136, saving model to t_weights_1
1600/1600 [==============================] - 0s 227us/sample - loss: 0.0940 - categorical_accuracy: 0.9787 - val_loss: 0.0314 - val_categorical_accuracy: 1.0000
Epoch 19/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9820
Epoch 00019: val_loss did not improve from 0.03136
1600/1600 [==============================] - 0s 230us/sample - loss: 0.0831 - categorical_accuracy: 0.9819 - val_loss: 0.0340 - val_categorical_accuracy: 1.0000
Epoch 20/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9777
Epoch 00020: val_loss improved from 0.03136 to 0.02585, saving model to t_weights_1
1600/1600 [==============================] - 0s 262us/sample - loss: 0.0903 - categorical_accuracy: 0.9781 - val_loss: 0.0259 - val_categorical_accuracy: 1.0000
Epoch 21/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0670 - categorical_accuracy: 0.9857
Epoch 00021: val_loss did not improve from 0.02585
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0673 - categorical_accuracy: 0.9856 - val_loss: 0.0298 - val_categorical_accuracy: 0.9950
Epoch 22/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0910 - categorical_accuracy: 0.9771
Epoch 00022: val_loss improved from 0.02585 to 0.02572, saving model to t_weights_1
1600/1600 [==============================] - 0s 282us/sample - loss: 0.0903 - categorical_accuracy: 0.9769 - val_loss: 0.0257 - val_categorical_accuracy: 0.9950
Epoch 23/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0701 - categorical_accuracy: 0.9857
Epoch 00023: val_loss did not improve from 0.02572
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0710 - categorical_accuracy: 0.9856 - val_loss: 0.0275 - val_categorical_accuracy: 0.9950
Epoch 24/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0774 - categorical_accuracy: 0.9840
Epoch 00024: val_loss did not improve from 0.02572
1600/1600 [==============================] - 0s 206us/sample - loss: 0.0768 - categorical_accuracy: 0.9844 - val_loss: 0.0279 - val_categorical_accuracy: 0.9950
Epoch 25/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0566 - categorical_accuracy: 0.9901
Epoch 00025: val_loss improved from 0.02572 to 0.02417, saving model to t_weights_1
1600/1600 [==============================] - 0s 247us/sample - loss: 0.0545 - categorical_accuracy: 0.9906 - val_loss: 0.0242 - val_categorical_accuracy: 1.0000
Epoch 26/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0539 - categorical_accuracy: 0.9914
Epoch 00026: val_loss did not improve from 0.02417
1600/1600 [==============================] - 0s 242us/sample - loss: 0.0545 - categorical_accuracy: 0.9906 - val_loss: 0.0245 - val_categorical_accuracy: 1.0000
Epoch 27/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0566 - categorical_accuracy: 0.9911
Epoch 00027: val_loss improved from 0.02417 to 0.02116, saving model to t_weights_1
1600/1600 [==============================] - 0s 289us/sample - loss: 0.0563 - categorical_accuracy: 0.9912 - val_loss: 0.0212 - val_categorical_accuracy: 1.0000
Epoch 28/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0472 - categorical_accuracy: 0.9922
Epoch 00028: val_loss did not improve from 0.02116
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0464 - categorical_accuracy: 0.9925 - val_loss: 0.0212 - val_categorical_accuracy: 1.0000
Epoch 29/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0513 - categorical_accuracy: 0.9898
Epoch 00029: val_loss improved from 0.02116 to 0.01997, saving model to t_weights_1
1600/1600 [==============================] - 0s 280us/sample - loss: 0.0506 - categorical_accuracy: 0.9900 - val_loss: 0.0200 - val_categorical_accuracy: 1.0000
Epoch 30/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0713 - categorical_accuracy: 0.9830
Epoch 00030: val_loss did not improve from 0.01997
1600/1600 [==============================] - 0s 208us/sample - loss: 0.0697 - categorical_accuracy: 0.9837 - val_loss: 0.0243 - val_categorical_accuracy: 1.0000
Epoch 31/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0446 - categorical_accuracy: 0.9937
Epoch 00031: val_loss did not improve from 0.01997
1600/1600 [==============================] - 0s 207us/sample - loss: 0.0443 - categorical_accuracy: 0.9931 - val_loss: 0.0226 - val_categorical_accuracy: 1.0000
Epoch 32/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0412 - categorical_accuracy: 0.9941
Epoch 00032: val_loss did not improve from 0.01997
1600/1600 [==============================] - 0s 237us/sample - loss: 0.0409 - categorical_accuracy: 0.9944 - val_loss: 0.0203 - val_categorical_accuracy: 1.0000
Epoch 33/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0625 - categorical_accuracy: 0.9830
Epoch 00033: val_loss did not improve from 0.01997
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0675 - categorical_accuracy: 0.9825 - val_loss: 0.0248 - val_categorical_accuracy: 0.9950
Epoch 34/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0476 - categorical_accuracy: 0.9928
Epoch 00034: val_loss did not improve from 0.01997
1600/1600 [==============================] - 0s 237us/sample - loss: 0.0476 - categorical_accuracy: 0.9925 - val_loss: 0.0204 - val_categorical_accuracy: 1.0000
1.0 0.15244897959183673


nrx: 5 - real: 2 
Train on 9120 samples, validate on 1140 samples
Epoch 1/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 2.1926 - categorical_accuracy: 0.1875
Epoch 00001: val_loss improved from inf to 1.74718, saving model to t_weights_1
9120/9120 [==============================] - 2s 269us/sample - loss: 2.1842 - categorical_accuracy: 0.1906 - val_loss: 1.7472 - val_categorical_accuracy: 0.3623
Epoch 2/100
8928/9120 [============================&gt;.] - ETA: 0s - loss: 1.6073 - categorical_accuracy: 0.4024
Epoch 00002: val_loss improved from 1.74718 to 1.38935, saving model to t_weights_1
9120/9120 [==============================] - 2s 228us/sample - loss: 1.6032 - categorical_accuracy: 0.4039 - val_loss: 1.3893 - val_categorical_accuracy: 0.5149
Epoch 3/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 1.3385 - categorical_accuracy: 0.4952
Epoch 00003: val_loss improved from 1.38935 to 1.17319, saving model to t_weights_1
9120/9120 [==============================] - 2s 235us/sample - loss: 1.3360 - categorical_accuracy: 0.4959 - val_loss: 1.1732 - val_categorical_accuracy: 0.5921
Epoch 4/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 1.0925 - categorical_accuracy: 0.6064
Epoch 00004: val_loss improved from 1.17319 to 0.96719, saving model to t_weights_1
9120/9120 [==============================] - 2s 233us/sample - loss: 1.0923 - categorical_accuracy: 0.6062 - val_loss: 0.9672 - val_categorical_accuracy: 0.6798
Epoch 5/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.8972 - categorical_accuracy: 0.6915
Epoch 00005: val_loss improved from 0.96719 to 0.79064, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.8968 - categorical_accuracy: 0.6908 - val_loss: 0.7906 - val_categorical_accuracy: 0.7623
Epoch 6/100
8928/9120 [============================&gt;.] - ETA: 0s - loss: 0.7570 - categorical_accuracy: 0.7485
Epoch 00006: val_loss improved from 0.79064 to 0.61153, saving model to t_weights_1
9120/9120 [==============================] - 2s 229us/sample - loss: 0.7534 - categorical_accuracy: 0.7492 - val_loss: 0.6115 - val_categorical_accuracy: 0.8158
Epoch 7/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.6151 - categorical_accuracy: 0.8010
Epoch 00007: val_loss improved from 0.61153 to 0.51135, saving model to t_weights_1
9120/9120 [==============================] - 2s 230us/sample - loss: 0.6140 - categorical_accuracy: 0.8016 - val_loss: 0.5113 - val_categorical_accuracy: 0.8474
Epoch 8/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.5109 - categorical_accuracy: 0.8409
Epoch 00008: val_loss improved from 0.51135 to 0.47562, saving model to t_weights_1
9120/9120 [==============================] - 2s 228us/sample - loss: 0.5087 - categorical_accuracy: 0.8417 - val_loss: 0.4756 - val_categorical_accuracy: 0.8605
Epoch 9/100
9088/9120 [============================&gt;.] - ETA: 0s - loss: 0.4299 - categorical_accuracy: 0.8741
Epoch 00009: val_loss improved from 0.47562 to 0.34058, saving model to t_weights_1
9120/9120 [==============================] - 2s 229us/sample - loss: 0.4292 - categorical_accuracy: 0.8742 - val_loss: 0.3406 - val_categorical_accuracy: 0.9246
Epoch 10/100
8928/9120 [============================&gt;.] - ETA: 0s - loss: 0.3556 - categorical_accuracy: 0.8982
Epoch 00010: val_loss improved from 0.34058 to 0.29269, saving model to t_weights_1
9120/9120 [==============================] - 2s 232us/sample - loss: 0.3548 - categorical_accuracy: 0.8986 - val_loss: 0.2927 - val_categorical_accuracy: 0.9421
Epoch 11/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.3046 - categorical_accuracy: 0.9183
Epoch 00011: val_loss did not improve from 0.29269
9120/9120 [==============================] - 2s 203us/sample - loss: 0.3063 - categorical_accuracy: 0.9184 - val_loss: 0.2951 - val_categorical_accuracy: 0.9404
Epoch 12/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.2807 - categorical_accuracy: 0.9258
Epoch 00012: val_loss improved from 0.29269 to 0.23212, saving model to t_weights_1
9120/9120 [==============================] - 2s 231us/sample - loss: 0.2805 - categorical_accuracy: 0.9255 - val_loss: 0.2321 - val_categorical_accuracy: 0.9579
Epoch 13/100
8864/9120 [============================&gt;.] - ETA: 0s - loss: 0.2388 - categorical_accuracy: 0.9393
Epoch 00013: val_loss did not improve from 0.23212
9120/9120 [==============================] - 2s 223us/sample - loss: 0.2389 - categorical_accuracy: 0.9394 - val_loss: 0.2794 - val_categorical_accuracy: 0.9430
Epoch 14/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 0.2198 - categorical_accuracy: 0.9407
Epoch 00014: val_loss improved from 0.23212 to 0.22895, saving model to t_weights_1
9120/9120 [==============================] - 2s 233us/sample - loss: 0.2203 - categorical_accuracy: 0.9405 - val_loss: 0.2289 - val_categorical_accuracy: 0.9579
Epoch 15/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.2106 - categorical_accuracy: 0.9455
Epoch 00015: val_loss improved from 0.22895 to 0.21399, saving model to t_weights_1
9120/9120 [==============================] - 2s 229us/sample - loss: 0.2097 - categorical_accuracy: 0.9458 - val_loss: 0.2140 - val_categorical_accuracy: 0.9640
Epoch 16/100
8864/9120 [============================&gt;.] - ETA: 0s - loss: 0.1877 - categorical_accuracy: 0.9528
Epoch 00016: val_loss did not improve from 0.21399
9120/9120 [==============================] - 2s 225us/sample - loss: 0.1864 - categorical_accuracy: 0.9532 - val_loss: 0.2329 - val_categorical_accuracy: 0.9570
Epoch 17/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.1879 - categorical_accuracy: 0.9505
Epoch 00017: val_loss improved from 0.21399 to 0.21381, saving model to t_weights_1
9120/9120 [==============================] - 2s 232us/sample - loss: 0.1866 - categorical_accuracy: 0.9510 - val_loss: 0.2138 - val_categorical_accuracy: 0.9632
Epoch 18/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 0.1621 - categorical_accuracy: 0.9602
Epoch 00018: val_loss improved from 0.21381 to 0.20151, saving model to t_weights_1
9120/9120 [==============================] - 2s 229us/sample - loss: 0.1623 - categorical_accuracy: 0.9601 - val_loss: 0.2015 - val_categorical_accuracy: 0.9623
Epoch 19/100
9088/9120 [============================&gt;.] - ETA: 0s - loss: 0.1617 - categorical_accuracy: 0.9594
Epoch 00019: val_loss did not improve from 0.20151
9120/9120 [==============================] - 2s 222us/sample - loss: 0.1617 - categorical_accuracy: 0.9594 - val_loss: 0.2070 - val_categorical_accuracy: 0.9596
Epoch 20/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.1528 - categorical_accuracy: 0.9608
Epoch 00020: val_loss did not improve from 0.20151
9120/9120 [==============================] - 2s 223us/sample - loss: 0.1512 - categorical_accuracy: 0.9615 - val_loss: 0.2436 - val_categorical_accuracy: 0.9535
Epoch 21/100
8896/9120 [============================&gt;.] - ETA: 0s - loss: 0.1529 - categorical_accuracy: 0.9607
Epoch 00021: val_loss did not improve from 0.20151
9120/9120 [==============================] - 2s 222us/sample - loss: 0.1510 - categorical_accuracy: 0.9613 - val_loss: 0.2126 - val_categorical_accuracy: 0.9640
Epoch 22/100
8960/9120 [============================&gt;.] - ETA: 0s - loss: 0.1452 - categorical_accuracy: 0.9618
Epoch 00022: val_loss did not improve from 0.20151
9120/9120 [==============================] - 2s 225us/sample - loss: 0.1454 - categorical_accuracy: 0.9618 - val_loss: 0.2102 - val_categorical_accuracy: 0.9649
Epoch 23/100
9056/9120 [============================&gt;.] - ETA: 0s - loss: 0.1304 - categorical_accuracy: 0.9688
Epoch 00023: val_loss did not improve from 0.20151
9120/9120 [==============================] - 2s 228us/sample - loss: 0.1310 - categorical_accuracy: 0.9685 - val_loss: 0.2045 - val_categorical_accuracy: 0.9684
0.9649123 0.15346938775510205


nrx: 10 - real: 2 
Train on 16936 samples, validate on 2117 samples
Epoch 1/100
16832/16936 [============================&gt;.] - ETA: 0s - loss: 2.0387 - categorical_accuracy: 0.2444
Epoch 00001: val_loss improved from inf to 1.65547, saving model to t_weights_1
16936/16936 [==============================] - 4s 246us/sample - loss: 2.0366 - categorical_accuracy: 0.2452 - val_loss: 1.6555 - val_categorical_accuracy: 0.3807
Epoch 2/100
16864/16936 [============================&gt;.] - ETA: 0s - loss: 1.5445 - categorical_accuracy: 0.4485
Epoch 00002: val_loss improved from 1.65547 to 1.28727, saving model to t_weights_1
16936/16936 [==============================] - 4s 228us/sample - loss: 1.5431 - categorical_accuracy: 0.4489 - val_loss: 1.2873 - val_categorical_accuracy: 0.5569
Epoch 3/100
16864/16936 [============================&gt;.] - ETA: 0s - loss: 1.2493 - categorical_accuracy: 0.5660
Epoch 00003: val_loss improved from 1.28727 to 1.01569, saving model to t_weights_1
16936/16936 [==============================] - 4s 224us/sample - loss: 1.2493 - categorical_accuracy: 0.5658 - val_loss: 1.0157 - val_categorical_accuracy: 0.6920
Epoch 4/100
16896/16936 [============================&gt;.] - ETA: 0s - loss: 1.0174 - categorical_accuracy: 0.6603
Epoch 00004: val_loss improved from 1.01569 to 0.83002, saving model to t_weights_1
16936/16936 [==============================] - 4s 224us/sample - loss: 1.0170 - categorical_accuracy: 0.6605 - val_loss: 0.8300 - val_categorical_accuracy: 0.7364
Epoch 5/100
16864/16936 [============================&gt;.] - ETA: 0s - loss: 0.8557 - categorical_accuracy: 0.7196
Epoch 00005: val_loss improved from 0.83002 to 0.67915, saving model to t_weights_1
16936/16936 [==============================] - 4s 222us/sample - loss: 0.8551 - categorical_accuracy: 0.7199 - val_loss: 0.6791 - val_categorical_accuracy: 0.7931
Epoch 6/100
16704/16936 [============================&gt;.] - ETA: 0s - loss: 0.7164 - categorical_accuracy: 0.7721
Epoch 00006: val_loss improved from 0.67915 to 0.54060, saving model to t_weights_1
16936/16936 [==============================] - 4s 224us/sample - loss: 0.7155 - categorical_accuracy: 0.7723 - val_loss: 0.5406 - val_categorical_accuracy: 0.8389
Epoch 7/100
16896/16936 [============================&gt;.] - ETA: 0s - loss: 0.6202 - categorical_accuracy: 0.8060
Epoch 00007: val_loss improved from 0.54060 to 0.51822, saving model to t_weights_1
16936/16936 [==============================] - 4s 224us/sample - loss: 0.6201 - categorical_accuracy: 0.8060 - val_loss: 0.5182 - val_categorical_accuracy: 0.8441
Epoch 8/100
16928/16936 [============================&gt;.] - ETA: 0s - loss: 0.5551 - categorical_accuracy: 0.8272
Epoch 00008: val_loss improved from 0.51822 to 0.44179, saving model to t_weights_1
16936/16936 [==============================] - 4s 222us/sample - loss: 0.5550 - categorical_accuracy: 0.8272 - val_loss: 0.4418 - val_categorical_accuracy: 0.8772
Epoch 9/100
16704/16936 [============================&gt;.] - ETA: 0s - loss: 0.4935 - categorical_accuracy: 0.8510
Epoch 00009: val_loss improved from 0.44179 to 0.40986, saving model to t_weights_1
16936/16936 [==============================] - 4s 216us/sample - loss: 0.4946 - categorical_accuracy: 0.8507 - val_loss: 0.4099 - val_categorical_accuracy: 0.8781
Epoch 10/100
16832/16936 [============================&gt;.] - ETA: 0s - loss: 0.4603 - categorical_accuracy: 0.8587
Epoch 00010: val_loss improved from 0.40986 to 0.39022, saving model to t_weights_1
16936/16936 [==============================] - 4s 222us/sample - loss: 0.4601 - categorical_accuracy: 0.8589 - val_loss: 0.3902 - val_categorical_accuracy: 0.8914
Epoch 11/100
16832/16936 [============================&gt;.] - ETA: 0s - loss: 0.4305 - categorical_accuracy: 0.8650
Epoch 00011: val_loss improved from 0.39022 to 0.36477, saving model to t_weights_1
16936/16936 [==============================] - 4s 235us/sample - loss: 0.4300 - categorical_accuracy: 0.8652 - val_loss: 0.3648 - val_categorical_accuracy: 0.8980
Epoch 12/100
16736/16936 [============================&gt;.] - ETA: 0s - loss: 0.3986 - categorical_accuracy: 0.8752
Epoch 00012: val_loss improved from 0.36477 to 0.34482, saving model to t_weights_1
16936/16936 [==============================] - 4s 220us/sample - loss: 0.3991 - categorical_accuracy: 0.8756 - val_loss: 0.3448 - val_categorical_accuracy: 0.9017
Epoch 13/100
16800/16936 [============================&gt;.] - ETA: 0s - loss: 0.3822 - categorical_accuracy: 0.8821
Epoch 00013: val_loss improved from 0.34482 to 0.32106, saving model to t_weights_1
16936/16936 [==============================] - 4s 229us/sample - loss: 0.3825 - categorical_accuracy: 0.8821 - val_loss: 0.3211 - val_categorical_accuracy: 0.9145
Epoch 14/100
16768/16936 [============================&gt;.] - ETA: 0s - loss: 0.3550 - categorical_accuracy: 0.8918
Epoch 00014: val_loss did not improve from 0.32106
16936/16936 [==============================] - 4s 220us/sample - loss: 0.3559 - categorical_accuracy: 0.8917 - val_loss: 0.3663 - val_categorical_accuracy: 0.8961
Epoch 15/100
16896/16936 [============================&gt;.] - ETA: 0s - loss: 0.3525 - categorical_accuracy: 0.8913
Epoch 00015: val_loss did not improve from 0.32106
16936/16936 [==============================] - 4s 225us/sample - loss: 0.3520 - categorical_accuracy: 0.8914 - val_loss: 0.3217 - val_categorical_accuracy: 0.9093
Epoch 16/100
16704/16936 [============================&gt;.] - ETA: 0s - loss: 0.3320 - categorical_accuracy: 0.8996
Epoch 00016: val_loss improved from 0.32106 to 0.30780, saving model to t_weights_1
16936/16936 [==============================] - 4s 226us/sample - loss: 0.3310 - categorical_accuracy: 0.9000 - val_loss: 0.3078 - val_categorical_accuracy: 0.9192
Epoch 17/100
16736/16936 [============================&gt;.] - ETA: 0s - loss: 0.3192 - categorical_accuracy: 0.9021
Epoch 00017: val_loss improved from 0.30780 to 0.29384, saving model to t_weights_1
16936/16936 [==============================] - 4s 224us/sample - loss: 0.3193 - categorical_accuracy: 0.9019 - val_loss: 0.2938 - val_categorical_accuracy: 0.9225
Epoch 18/100
16864/16936 [============================&gt;.] - ETA: 0s - loss: 0.3116 - categorical_accuracy: 0.9060
Epoch 00018: val_loss improved from 0.29384 to 0.28100, saving model to t_weights_1
16936/16936 [==============================] - 4s 227us/sample - loss: 0.3116 - categorical_accuracy: 0.9059 - val_loss: 0.2810 - val_categorical_accuracy: 0.9249
Epoch 19/100
16672/16936 [============================&gt;.] - ETA: 0s - loss: 0.3097 - categorical_accuracy: 0.9051
Epoch 00019: val_loss did not improve from 0.28100
16936/16936 [==============================] - 4s 221us/sample - loss: 0.3092 - categorical_accuracy: 0.9053 - val_loss: 0.2899 - val_categorical_accuracy: 0.9244
Epoch 20/100
16800/16936 [============================&gt;.] - ETA: 0s - loss: 0.2961 - categorical_accuracy: 0.9080
Epoch 00020: val_loss did not improve from 0.28100
16936/16936 [==============================] - 4s 225us/sample - loss: 0.2958 - categorical_accuracy: 0.9082 - val_loss: 0.2921 - val_categorical_accuracy: 0.9258
Epoch 21/100
16768/16936 [============================&gt;.] - ETA: 0s - loss: 0.2874 - categorical_accuracy: 0.9109
Epoch 00021: val_loss did not improve from 0.28100
16936/16936 [==============================] - 4s 219us/sample - loss: 0.2877 - categorical_accuracy: 0.9106 - val_loss: 0.3074 - val_categorical_accuracy: 0.9225
Epoch 22/100
16896/16936 [============================&gt;.] - ETA: 0s - loss: 0.2820 - categorical_accuracy: 0.9126
Epoch 00022: val_loss did not improve from 0.28100
16936/16936 [==============================] - 4s 223us/sample - loss: 0.2820 - categorical_accuracy: 0.9126 - val_loss: 0.3074 - val_categorical_accuracy: 0.9211
Epoch 23/100
16768/16936 [============================&gt;.] - ETA: 0s - loss: 0.2801 - categorical_accuracy: 0.9141
Epoch 00023: val_loss did not improve from 0.28100
16936/16936 [==============================] - 4s 218us/sample - loss: 0.2802 - categorical_accuracy: 0.9141 - val_loss: 0.2971 - val_categorical_accuracy: 0.9254
0.9055267 0.3662244897959184


nrx: 15 - real: 2 
Train on 24616 samples, validate on 3077 samples
Epoch 1/100
24416/24616 [============================&gt;.] - ETA: 0s - loss: 1.9664 - categorical_accuracy: 0.2796
Epoch 00001: val_loss improved from inf to 1.64921, saving model to t_weights_1
24616/24616 [==============================] - 6s 232us/sample - loss: 1.9648 - categorical_accuracy: 0.2802 - val_loss: 1.6492 - val_categorical_accuracy: 0.4235
Epoch 2/100
24416/24616 [============================&gt;.] - ETA: 0s - loss: 1.5350 - categorical_accuracy: 0.4574
Epoch 00002: val_loss improved from 1.64921 to 1.34670, saving model to t_weights_1
24616/24616 [==============================] - 6s 226us/sample - loss: 1.5329 - categorical_accuracy: 0.4581 - val_loss: 1.3467 - val_categorical_accuracy: 0.5479
Epoch 3/100
24384/24616 [============================&gt;.] - ETA: 0s - loss: 1.2864 - categorical_accuracy: 0.5573
Epoch 00003: val_loss improved from 1.34670 to 1.09746, saving model to t_weights_1
24616/24616 [==============================] - 6s 225us/sample - loss: 1.2853 - categorical_accuracy: 0.5576 - val_loss: 1.0975 - val_categorical_accuracy: 0.6263
Epoch 4/100
24480/24616 [============================&gt;.] - ETA: 0s - loss: 1.0689 - categorical_accuracy: 0.6459
Epoch 00004: val_loss improved from 1.09746 to 0.88401, saving model to t_weights_1
24616/24616 [==============================] - 5s 222us/sample - loss: 1.0686 - categorical_accuracy: 0.6458 - val_loss: 0.8840 - val_categorical_accuracy: 0.7124
Epoch 5/100
24512/24616 [============================&gt;.] - ETA: 0s - loss: 0.8938 - categorical_accuracy: 0.7102
Epoch 00005: val_loss improved from 0.88401 to 0.69004, saving model to t_weights_1
24616/24616 [==============================] - 6s 225us/sample - loss: 0.8939 - categorical_accuracy: 0.7101 - val_loss: 0.6900 - val_categorical_accuracy: 0.7940
Epoch 6/100
24512/24616 [============================&gt;.] - ETA: 0s - loss: 0.7242 - categorical_accuracy: 0.7733
Epoch 00006: val_loss improved from 0.69004 to 0.53711, saving model to t_weights_1
24616/24616 [==============================] - 6s 228us/sample - loss: 0.7249 - categorical_accuracy: 0.7730 - val_loss: 0.5371 - val_categorical_accuracy: 0.8450
Epoch 7/100
24576/24616 [============================&gt;.] - ETA: 0s - loss: 0.6096 - categorical_accuracy: 0.8110
Epoch 00007: val_loss improved from 0.53711 to 0.45920, saving model to t_weights_1
24616/24616 [==============================] - 6s 225us/sample - loss: 0.6094 - categorical_accuracy: 0.8111 - val_loss: 0.4592 - val_categorical_accuracy: 0.8736
Epoch 8/100
24576/24616 [============================&gt;.] - ETA: 0s - loss: 0.5334 - categorical_accuracy: 0.8379
Epoch 00008: val_loss improved from 0.45920 to 0.40766, saving model to t_weights_1
24616/24616 [==============================] - 5s 223us/sample - loss: 0.5333 - categorical_accuracy: 0.8380 - val_loss: 0.4077 - val_categorical_accuracy: 0.8801
Epoch 9/100
24576/24616 [============================&gt;.] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.8566
Epoch 00009: val_loss improved from 0.40766 to 0.39680, saving model to t_weights_1
24616/24616 [==============================] - 6s 225us/sample - loss: 0.4788 - categorical_accuracy: 0.8567 - val_loss: 0.3968 - val_categorical_accuracy: 0.8882
Epoch 10/100
24608/24616 [============================&gt;.] - ETA: 0s - loss: 0.4344 - categorical_accuracy: 0.8700
Epoch 00010: val_loss improved from 0.39680 to 0.35699, saving model to t_weights_1
24616/24616 [==============================] - 5s 214us/sample - loss: 0.4343 - categorical_accuracy: 0.8701 - val_loss: 0.3570 - val_categorical_accuracy: 0.9064
Epoch 11/100
24544/24616 [============================&gt;.] - ETA: 0s - loss: 0.3985 - categorical_accuracy: 0.8794
Epoch 00011: val_loss improved from 0.35699 to 0.33658, saving model to t_weights_1
24616/24616 [==============================] - 6s 224us/sample - loss: 0.3983 - categorical_accuracy: 0.8795 - val_loss: 0.3366 - val_categorical_accuracy: 0.9032
Epoch 12/100
24576/24616 [============================&gt;.] - ETA: 0s - loss: 0.3807 - categorical_accuracy: 0.8872
Epoch 00012: val_loss improved from 0.33658 to 0.30912, saving model to t_weights_1
24616/24616 [==============================] - 5s 216us/sample - loss: 0.3803 - categorical_accuracy: 0.8874 - val_loss: 0.3091 - val_categorical_accuracy: 0.9155
Epoch 13/100
24480/24616 [============================&gt;.] - ETA: 0s - loss: 0.3490 - categorical_accuracy: 0.8981
Epoch 00013: val_loss improved from 0.30912 to 0.30344, saving model to t_weights_1
24616/24616 [==============================] - 5s 223us/sample - loss: 0.3496 - categorical_accuracy: 0.8982 - val_loss: 0.3034 - val_categorical_accuracy: 0.9149
Epoch 14/100
24480/24616 [============================&gt;.] - ETA: 0s - loss: 0.3384 - categorical_accuracy: 0.8998
Epoch 00014: val_loss did not improve from 0.30344
24616/24616 [==============================] - 5s 223us/sample - loss: 0.3387 - categorical_accuracy: 0.8997 - val_loss: 0.3170 - val_categorical_accuracy: 0.9123
Epoch 15/100
24480/24616 [============================&gt;.] - ETA: 0s - loss: 0.3183 - categorical_accuracy: 0.9053
Epoch 00015: val_loss improved from 0.30344 to 0.29468, saving model to t_weights_1
24616/24616 [==============================] - 6s 226us/sample - loss: 0.3181 - categorical_accuracy: 0.9053 - val_loss: 0.2947 - val_categorical_accuracy: 0.9197
Epoch 16/100
24608/24616 [============================&gt;.] - ETA: 0s - loss: 0.3054 - categorical_accuracy: 0.9097
Epoch 00016: val_loss did not improve from 0.29468
24616/24616 [==============================] - 6s 224us/sample - loss: 0.3055 - categorical_accuracy: 0.9097 - val_loss: 0.3160 - val_categorical_accuracy: 0.9204
Epoch 17/100
24608/24616 [============================&gt;.] - ETA: 0s - loss: 0.2907 - categorical_accuracy: 0.9159
Epoch 00017: val_loss improved from 0.29468 to 0.29284, saving model to t_weights_1
24616/24616 [==============================] - 6s 224us/sample - loss: 0.2906 - categorical_accuracy: 0.9159 - val_loss: 0.2928 - val_categorical_accuracy: 0.9210
Epoch 18/100
24608/24616 [============================&gt;.] - ETA: 0s - loss: 0.2904 - categorical_accuracy: 0.9143
Epoch 00018: val_loss improved from 0.29284 to 0.27044, saving model to t_weights_1
24616/24616 [==============================] - 6s 227us/sample - loss: 0.2903 - categorical_accuracy: 0.9143 - val_loss: 0.2704 - val_categorical_accuracy: 0.9292
Epoch 19/100
24512/24616 [============================&gt;.] - ETA: 0s - loss: 0.2738 - categorical_accuracy: 0.9198
Epoch 00019: val_loss did not improve from 0.27044
24616/24616 [==============================] - 6s 225us/sample - loss: 0.2736 - categorical_accuracy: 0.9198 - val_loss: 0.2798 - val_categorical_accuracy: 0.9305
Epoch 20/100
24512/24616 [============================&gt;.] - ETA: 0s - loss: 0.2751 - categorical_accuracy: 0.9200
Epoch 00020: val_loss did not improve from 0.27044
24616/24616 [==============================] - 6s 224us/sample - loss: 0.2755 - categorical_accuracy: 0.9198 - val_loss: 0.2883 - val_categorical_accuracy: 0.9246
Epoch 21/100
24480/24616 [============================&gt;.] - ETA: 0s - loss: 0.2597 - categorical_accuracy: 0.9239
Epoch 00021: val_loss did not improve from 0.27044
24616/24616 [==============================] - 5s 222us/sample - loss: 0.2596 - categorical_accuracy: 0.9241 - val_loss: 0.2790 - val_categorical_accuracy: 0.9321
Epoch 22/100
24448/24616 [============================&gt;.] - ETA: 0s - loss: 0.2531 - categorical_accuracy: 0.9252
Epoch 00022: val_loss did not improve from 0.27044
24616/24616 [==============================] - 6s 224us/sample - loss: 0.2531 - categorical_accuracy: 0.9252 - val_loss: 0.2706 - val_categorical_accuracy: 0.9259
Epoch 23/100
24352/24616 [============================&gt;.] - ETA: 0s - loss: 0.2583 - categorical_accuracy: 0.9249
Epoch 00023: val_loss improved from 0.27044 to 0.26934, saving model to t_weights_1
24616/24616 [==============================] - 5s 216us/sample - loss: 0.2586 - categorical_accuracy: 0.9250 - val_loss: 0.2693 - val_categorical_accuracy: 0.9366
Epoch 24/100
24544/24616 [============================&gt;.] - ETA: 0s - loss: 0.2413 - categorical_accuracy: 0.9309
Epoch 00024: val_loss improved from 0.26934 to 0.24972, saving model to t_weights_1
24616/24616 [==============================] - 6s 224us/sample - loss: 0.2412 - categorical_accuracy: 0.9309 - val_loss: 0.2497 - val_categorical_accuracy: 0.9386
Epoch 25/100
24416/24616 [============================&gt;.] - ETA: 0s - loss: 0.2385 - categorical_accuracy: 0.9327
Epoch 00025: val_loss did not improve from 0.24972
24616/24616 [==============================] - 5s 221us/sample - loss: 0.2382 - categorical_accuracy: 0.9328 - val_loss: 0.2519 - val_categorical_accuracy: 0.9376
Epoch 26/100
24544/24616 [============================&gt;.] - ETA: 0s - loss: 0.2331 - categorical_accuracy: 0.9340
Epoch 00026: val_loss did not improve from 0.24972
24616/24616 [==============================] - 6s 224us/sample - loss: 0.2335 - categorical_accuracy: 0.9338 - val_loss: 0.2674 - val_categorical_accuracy: 0.9350
Epoch 27/100
24576/24616 [============================&gt;.] - ETA: 0s - loss: 0.2301 - categorical_accuracy: 0.9336
Epoch 00027: val_loss did not improve from 0.24972
24616/24616 [==============================] - 6s 224us/sample - loss: 0.2304 - categorical_accuracy: 0.9335 - val_loss: 0.2620 - val_categorical_accuracy: 0.9363
Epoch 28/100
24512/24616 [============================&gt;.] - ETA: 0s - loss: 0.2215 - categorical_accuracy: 0.9377
Epoch 00028: val_loss did not improve from 0.24972
24616/24616 [==============================] - 6s 225us/sample - loss: 0.2218 - categorical_accuracy: 0.9377 - val_loss: 0.2683 - val_categorical_accuracy: 0.9383
Epoch 29/100
24448/24616 [============================&gt;.] - ETA: 0s - loss: 0.2253 - categorical_accuracy: 0.9358
Epoch 00029: val_loss did not improve from 0.24972
24616/24616 [==============================] - 5s 222us/sample - loss: 0.2252 - categorical_accuracy: 0.9358 - val_loss: 0.2641 - val_categorical_accuracy: 0.9399
0.9359766 0.42989795918367346


nrx: 20 - real: 2 
Train on 32616 samples, validate on 4077 samples
Epoch 1/100
32544/32616 [============================&gt;.] - ETA: 0s - loss: 1.9103 - categorical_accuracy: 0.2847
Epoch 00001: val_loss improved from inf to 1.49684, saving model to t_weights_1
32616/32616 [==============================] - 8s 236us/sample - loss: 1.9096 - categorical_accuracy: 0.2848 - val_loss: 1.4968 - val_categorical_accuracy: 0.4589
Epoch 2/100
32608/32616 [============================&gt;.] - ETA: 0s - loss: 1.4134 - categorical_accuracy: 0.4901
Epoch 00002: val_loss improved from 1.49684 to 1.15168, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 1.4134 - categorical_accuracy: 0.4900 - val_loss: 1.1517 - val_categorical_accuracy: 0.5833
Epoch 3/100
32416/32616 [============================&gt;.] - ETA: 0s - loss: 1.1442 - categorical_accuracy: 0.5976
Epoch 00003: val_loss improved from 1.15168 to 0.90726, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 1.1432 - categorical_accuracy: 0.5979 - val_loss: 0.9073 - val_categorical_accuracy: 0.6883
Epoch 4/100
32384/32616 [============================&gt;.] - ETA: 0s - loss: 0.9437 - categorical_accuracy: 0.6793
Epoch 00004: val_loss improved from 0.90726 to 0.77130, saving model to t_weights_1
32616/32616 [==============================] - 7s 219us/sample - loss: 0.9430 - categorical_accuracy: 0.6795 - val_loss: 0.7713 - val_categorical_accuracy: 0.7501
Epoch 5/100
32480/32616 [============================&gt;.] - ETA: 0s - loss: 0.7893 - categorical_accuracy: 0.7376
Epoch 00005: val_loss improved from 0.77130 to 0.62619, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 0.7892 - categorical_accuracy: 0.7376 - val_loss: 0.6262 - val_categorical_accuracy: 0.8133
Epoch 6/100
32384/32616 [============================&gt;.] - ETA: 0s - loss: 0.6736 - categorical_accuracy: 0.7789
Epoch 00006: val_loss improved from 0.62619 to 0.53084, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 0.6735 - categorical_accuracy: 0.7788 - val_loss: 0.5308 - val_categorical_accuracy: 0.8278
Epoch 7/100
32384/32616 [============================&gt;.] - ETA: 0s - loss: 0.5970 - categorical_accuracy: 0.8056
Epoch 00007: val_loss improved from 0.53084 to 0.44835, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 0.5964 - categorical_accuracy: 0.8056 - val_loss: 0.4483 - val_categorical_accuracy: 0.8624
Epoch 8/100
32416/32616 [============================&gt;.] - ETA: 0s - loss: 0.5334 - categorical_accuracy: 0.8288
Epoch 00008: val_loss improved from 0.44835 to 0.40615, saving model to t_weights_1
32616/32616 [==============================] - 7s 225us/sample - loss: 0.5329 - categorical_accuracy: 0.8289 - val_loss: 0.4061 - val_categorical_accuracy: 0.8791
Epoch 9/100
32576/32616 [============================&gt;.] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.8430
Epoch 00009: val_loss improved from 0.40615 to 0.37962, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 0.4846 - categorical_accuracy: 0.8431 - val_loss: 0.3796 - val_categorical_accuracy: 0.8894
Epoch 10/100
32608/32616 [============================&gt;.] - ETA: 0s - loss: 0.4496 - categorical_accuracy: 0.8576
Epoch 00010: val_loss improved from 0.37962 to 0.36083, saving model to t_weights_1
32616/32616 [==============================] - 7s 227us/sample - loss: 0.4499 - categorical_accuracy: 0.8575 - val_loss: 0.3608 - val_categorical_accuracy: 0.8943
Epoch 11/100
32352/32616 [============================&gt;.] - ETA: 0s - loss: 0.4160 - categorical_accuracy: 0.8697
Epoch 00011: val_loss improved from 0.36083 to 0.35356, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 0.4167 - categorical_accuracy: 0.8695 - val_loss: 0.3536 - val_categorical_accuracy: 0.8953
Epoch 12/100
32288/32616 [============================&gt;.] - ETA: 0s - loss: 0.3961 - categorical_accuracy: 0.8785
Epoch 00012: val_loss improved from 0.35356 to 0.32613, saving model to t_weights_1
32616/32616 [==============================] - 7s 211us/sample - loss: 0.3954 - categorical_accuracy: 0.8786 - val_loss: 0.3261 - val_categorical_accuracy: 0.9058
Epoch 13/100
32608/32616 [============================&gt;.] - ETA: 0s - loss: 0.3711 - categorical_accuracy: 0.8850
Epoch 00013: val_loss improved from 0.32613 to 0.30643, saving model to t_weights_1
32616/32616 [==============================] - 7s 222us/sample - loss: 0.3710 - categorical_accuracy: 0.8851 - val_loss: 0.3064 - val_categorical_accuracy: 0.9129
Epoch 14/100
32384/32616 [============================&gt;.] - ETA: 0s - loss: 0.3566 - categorical_accuracy: 0.8895
Epoch 00014: val_loss improved from 0.30643 to 0.30520, saving model to t_weights_1
32616/32616 [==============================] - 7s 207us/sample - loss: 0.3566 - categorical_accuracy: 0.8895 - val_loss: 0.3052 - val_categorical_accuracy: 0.9164
Epoch 15/100
32544/32616 [============================&gt;.] - ETA: 0s - loss: 0.3439 - categorical_accuracy: 0.8947
Epoch 00015: val_loss improved from 0.30520 to 0.29303, saving model to t_weights_1
32616/32616 [==============================] - 7s 222us/sample - loss: 0.3436 - categorical_accuracy: 0.8948 - val_loss: 0.2930 - val_categorical_accuracy: 0.9203
Epoch 16/100
32512/32616 [============================&gt;.] - ETA: 0s - loss: 0.3271 - categorical_accuracy: 0.9007
Epoch 00016: val_loss did not improve from 0.29303
32616/32616 [==============================] - 7s 221us/sample - loss: 0.3271 - categorical_accuracy: 0.9007 - val_loss: 0.2932 - val_categorical_accuracy: 0.9171
Epoch 17/100
32384/32616 [============================&gt;.] - ETA: 0s - loss: 0.3158 - categorical_accuracy: 0.9026
Epoch 00017: val_loss did not improve from 0.29303
32616/32616 [==============================] - 7s 225us/sample - loss: 0.3156 - categorical_accuracy: 0.9027 - val_loss: 0.2991 - val_categorical_accuracy: 0.9183
Epoch 18/100
32416/32616 [============================&gt;.] - ETA: 0s - loss: 0.3103 - categorical_accuracy: 0.9055
Epoch 00018: val_loss improved from 0.29303 to 0.27739, saving model to t_weights_1
32616/32616 [==============================] - 7s 226us/sample - loss: 0.3104 - categorical_accuracy: 0.9055 - val_loss: 0.2774 - val_categorical_accuracy: 0.9237
Epoch 19/100
32384/32616 [============================&gt;.] - ETA: 0s - loss: 0.3017 - categorical_accuracy: 0.9085
Epoch 00019: val_loss did not improve from 0.27739
32616/32616 [==============================] - 7s 224us/sample - loss: 0.3019 - categorical_accuracy: 0.9084 - val_loss: 0.2996 - val_categorical_accuracy: 0.9127
Epoch 20/100
32544/32616 [============================&gt;.] - ETA: 0s - loss: 0.2927 - categorical_accuracy: 0.9107
Epoch 00020: val_loss improved from 0.27739 to 0.27315, saving model to t_weights_1
32616/32616 [==============================] - 7s 225us/sample - loss: 0.2926 - categorical_accuracy: 0.9107 - val_loss: 0.2731 - val_categorical_accuracy: 0.9218
Epoch 21/100
32512/32616 [============================&gt;.] - ETA: 0s - loss: 0.2825 - categorical_accuracy: 0.9121
Epoch 00021: val_loss improved from 0.27315 to 0.26742, saving model to t_weights_1
32616/32616 [==============================] - 7s 218us/sample - loss: 0.2825 - categorical_accuracy: 0.9122 - val_loss: 0.2674 - val_categorical_accuracy: 0.9269
Epoch 22/100
32416/32616 [============================&gt;.] - ETA: 0s - loss: 0.2779 - categorical_accuracy: 0.9141
Epoch 00022: val_loss did not improve from 0.26742
32616/32616 [==============================] - 7s 214us/sample - loss: 0.2780 - categorical_accuracy: 0.9141 - val_loss: 0.2698 - val_categorical_accuracy: 0.9254
Epoch 23/100
32544/32616 [============================&gt;.] - ETA: 0s - loss: 0.2780 - categorical_accuracy: 0.9153
Epoch 00023: val_loss improved from 0.26742 to 0.25852, saving model to t_weights_1
32616/32616 [==============================] - 7s 225us/sample - loss: 0.2784 - categorical_accuracy: 0.9152 - val_loss: 0.2585 - val_categorical_accuracy: 0.9269
Epoch 24/100
32416/32616 [============================&gt;.] - ETA: 0s - loss: 0.2693 - categorical_accuracy: 0.9188
Epoch 00024: val_loss did not improve from 0.25852
32616/32616 [==============================] - 7s 224us/sample - loss: 0.2702 - categorical_accuracy: 0.9185 - val_loss: 0.2740 - val_categorical_accuracy: 0.9203
Epoch 25/100
32576/32616 [============================&gt;.] - ETA: 0s - loss: 0.2666 - categorical_accuracy: 0.9189
Epoch 00025: val_loss did not improve from 0.25852
32616/32616 [==============================] - 7s 224us/sample - loss: 0.2668 - categorical_accuracy: 0.9188 - val_loss: 0.2658 - val_categorical_accuracy: 0.9269
Epoch 26/100
32480/32616 [============================&gt;.] - ETA: 0s - loss: 0.2620 - categorical_accuracy: 0.9197
Epoch 00026: val_loss did not improve from 0.25852
32616/32616 [==============================] - 7s 225us/sample - loss: 0.2618 - categorical_accuracy: 0.9199 - val_loss: 0.2604 - val_categorical_accuracy: 0.9276
Epoch 27/100
32576/32616 [============================&gt;.] - ETA: 0s - loss: 0.2575 - categorical_accuracy: 0.9230
Epoch 00027: val_loss did not improve from 0.25852
32616/32616 [==============================] - 7s 225us/sample - loss: 0.2576 - categorical_accuracy: 0.9230 - val_loss: 0.2601 - val_categorical_accuracy: 0.9299
Epoch 28/100
32576/32616 [============================&gt;.] - ETA: 0s - loss: 0.2589 - categorical_accuracy: 0.9221
Epoch 00028: val_loss did not improve from 0.25852
32616/32616 [==============================] - 7s 224us/sample - loss: 0.2589 - categorical_accuracy: 0.9222 - val_loss: 0.2748 - val_categorical_accuracy: 0.9235
0.922492 0.4023469387755102


nrx: 25 - real: 2 
Train on 40456 samples, validate on 5057 samples
Epoch 1/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 1.8840 - categorical_accuracy: 0.2932
Epoch 00001: val_loss improved from inf to 1.42099, saving model to t_weights_1
40456/40456 [==============================] - 9s 229us/sample - loss: 1.8821 - categorical_accuracy: 0.2940 - val_loss: 1.4210 - val_categorical_accuracy: 0.5217
Epoch 2/100
40320/40456 [============================&gt;.] - ETA: 0s - loss: 1.1970 - categorical_accuracy: 0.5889
Epoch 00002: val_loss improved from 1.42099 to 0.85154, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 1.1964 - categorical_accuracy: 0.5894 - val_loss: 0.8515 - val_categorical_accuracy: 0.7218
Epoch 3/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.7995 - categorical_accuracy: 0.7391
Epoch 00003: val_loss improved from 0.85154 to 0.60479, saving model to t_weights_1
40456/40456 [==============================] - 9s 223us/sample - loss: 0.7990 - categorical_accuracy: 0.7393 - val_loss: 0.6048 - val_categorical_accuracy: 0.7993
Epoch 4/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.6235 - categorical_accuracy: 0.8013
Epoch 00004: val_loss improved from 0.60479 to 0.50706, saving model to t_weights_1
40456/40456 [==============================] - 9s 213us/sample - loss: 0.6229 - categorical_accuracy: 0.8015 - val_loss: 0.5071 - val_categorical_accuracy: 0.8365
Epoch 5/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.5221 - categorical_accuracy: 0.8394
Epoch 00005: val_loss improved from 0.50706 to 0.41371, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.5221 - categorical_accuracy: 0.8395 - val_loss: 0.4137 - val_categorical_accuracy: 0.8709
Epoch 6/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.4635 - categorical_accuracy: 0.8579
Epoch 00006: val_loss did not improve from 0.41371
40456/40456 [==============================] - 9s 222us/sample - loss: 0.4633 - categorical_accuracy: 0.8579 - val_loss: 0.4227 - val_categorical_accuracy: 0.8730
Epoch 7/100
40192/40456 [============================&gt;.] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8735
Epoch 00007: val_loss improved from 0.41371 to 0.40033, saving model to t_weights_1
40456/40456 [==============================] - 9s 218us/sample - loss: 0.4175 - categorical_accuracy: 0.8735 - val_loss: 0.4003 - val_categorical_accuracy: 0.8770
Epoch 8/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.3877 - categorical_accuracy: 0.8818
Epoch 00008: val_loss improved from 0.40033 to 0.34476, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.3875 - categorical_accuracy: 0.8818 - val_loss: 0.3448 - val_categorical_accuracy: 0.8942
Epoch 9/100
40320/40456 [============================&gt;.] - ETA: 0s - loss: 0.3622 - categorical_accuracy: 0.8912
Epoch 00009: val_loss improved from 0.34476 to 0.32741, saving model to t_weights_1
40456/40456 [==============================] - 9s 222us/sample - loss: 0.3618 - categorical_accuracy: 0.8914 - val_loss: 0.3274 - val_categorical_accuracy: 0.9025
Epoch 10/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.3382 - categorical_accuracy: 0.8978
Epoch 00010: val_loss did not improve from 0.32741
40456/40456 [==============================] - 9s 223us/sample - loss: 0.3384 - categorical_accuracy: 0.8978 - val_loss: 0.3351 - val_categorical_accuracy: 0.9007
Epoch 11/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.3233 - categorical_accuracy: 0.9030
Epoch 00011: val_loss did not improve from 0.32741
40456/40456 [==============================] - 9s 223us/sample - loss: 0.3232 - categorical_accuracy: 0.9030 - val_loss: 0.3573 - val_categorical_accuracy: 0.8910
Epoch 12/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.9064
Epoch 00012: val_loss improved from 0.32741 to 0.30603, saving model to t_weights_1
40456/40456 [==============================] - 9s 223us/sample - loss: 0.3134 - categorical_accuracy: 0.9064 - val_loss: 0.3060 - val_categorical_accuracy: 0.9082
Epoch 13/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.3008 - categorical_accuracy: 0.9106
Epoch 00013: val_loss did not improve from 0.30603
40456/40456 [==============================] - 9s 221us/sample - loss: 0.3003 - categorical_accuracy: 0.9109 - val_loss: 0.3070 - val_categorical_accuracy: 0.9118
Epoch 14/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.2935 - categorical_accuracy: 0.9124
Epoch 00014: val_loss improved from 0.30603 to 0.29265, saving model to t_weights_1
40456/40456 [==============================] - 9s 218us/sample - loss: 0.2935 - categorical_accuracy: 0.9124 - val_loss: 0.2927 - val_categorical_accuracy: 0.9167
Epoch 15/100
40224/40456 [============================&gt;.] - ETA: 0s - loss: 0.2870 - categorical_accuracy: 0.9139
Epoch 00015: val_loss did not improve from 0.29265
40456/40456 [==============================] - 8s 208us/sample - loss: 0.2865 - categorical_accuracy: 0.9140 - val_loss: 0.2952 - val_categorical_accuracy: 0.9140
Epoch 16/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.2762 - categorical_accuracy: 0.9185
Epoch 00016: val_loss improved from 0.29265 to 0.29258, saving model to t_weights_1
40456/40456 [==============================] - 9s 225us/sample - loss: 0.2764 - categorical_accuracy: 0.9184 - val_loss: 0.2926 - val_categorical_accuracy: 0.9185
Epoch 17/100
40224/40456 [============================&gt;.] - ETA: 0s - loss: 0.2721 - categorical_accuracy: 0.9193
Epoch 00017: val_loss did not improve from 0.29258
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2721 - categorical_accuracy: 0.9193 - val_loss: 0.3219 - val_categorical_accuracy: 0.9080
Epoch 18/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.2602 - categorical_accuracy: 0.9233
Epoch 00018: val_loss did not improve from 0.29258
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2601 - categorical_accuracy: 0.9233 - val_loss: 0.2927 - val_categorical_accuracy: 0.9219
Epoch 19/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.2558 - categorical_accuracy: 0.9243
Epoch 00019: val_loss improved from 0.29258 to 0.28990, saving model to t_weights_1
40456/40456 [==============================] - 9s 225us/sample - loss: 0.2562 - categorical_accuracy: 0.9242 - val_loss: 0.2899 - val_categorical_accuracy: 0.9215
Epoch 20/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.2531 - categorical_accuracy: 0.9246
Epoch 00020: val_loss improved from 0.28990 to 0.28906, saving model to t_weights_1
40456/40456 [==============================] - 9s 226us/sample - loss: 0.2530 - categorical_accuracy: 0.9246 - val_loss: 0.2891 - val_categorical_accuracy: 0.9243
Epoch 21/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.2513 - categorical_accuracy: 0.9255
Epoch 00021: val_loss improved from 0.28906 to 0.27337, saving model to t_weights_1
40456/40456 [==============================] - 9s 220us/sample - loss: 0.2515 - categorical_accuracy: 0.9254 - val_loss: 0.2734 - val_categorical_accuracy: 0.9254
Epoch 22/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.2429 - categorical_accuracy: 0.9276
Epoch 00022: val_loss improved from 0.27337 to 0.26675, saving model to t_weights_1
40456/40456 [==============================] - 9s 226us/sample - loss: 0.2429 - categorical_accuracy: 0.9276 - val_loss: 0.2667 - val_categorical_accuracy: 0.9300
Epoch 23/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.2391 - categorical_accuracy: 0.9298
Epoch 00023: val_loss did not improve from 0.26675
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2389 - categorical_accuracy: 0.9299 - val_loss: 0.2859 - val_categorical_accuracy: 0.9221
Epoch 24/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.2327 - categorical_accuracy: 0.9308
Epoch 00024: val_loss did not improve from 0.26675
40456/40456 [==============================] - 9s 222us/sample - loss: 0.2327 - categorical_accuracy: 0.9307 - val_loss: 0.2820 - val_categorical_accuracy: 0.9290
Epoch 25/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.2361 - categorical_accuracy: 0.9297
Epoch 00025: val_loss did not improve from 0.26675
40456/40456 [==============================] - 9s 223us/sample - loss: 0.2361 - categorical_accuracy: 0.9297 - val_loss: 0.2805 - val_categorical_accuracy: 0.9288
Epoch 26/100
40320/40456 [============================&gt;.] - ETA: 0s - loss: 0.2265 - categorical_accuracy: 0.9328
Epoch 00026: val_loss improved from 0.26675 to 0.25896, saving model to t_weights_1
40456/40456 [==============================] - 9s 228us/sample - loss: 0.2264 - categorical_accuracy: 0.9328 - val_loss: 0.2590 - val_categorical_accuracy: 0.9302
Epoch 27/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.2248 - categorical_accuracy: 0.9342
Epoch 00027: val_loss did not improve from 0.25896
40456/40456 [==============================] - 9s 226us/sample - loss: 0.2250 - categorical_accuracy: 0.9341 - val_loss: 0.2709 - val_categorical_accuracy: 0.9298
Epoch 28/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9359
Epoch 00028: val_loss did not improve from 0.25896
40456/40456 [==============================] - 9s 217us/sample - loss: 0.2198 - categorical_accuracy: 0.9358 - val_loss: 0.2789 - val_categorical_accuracy: 0.9278
Epoch 29/100
40224/40456 [============================&gt;.] - ETA: 0s - loss: 0.2181 - categorical_accuracy: 0.9365
Epoch 00029: val_loss did not improve from 0.25896
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2180 - categorical_accuracy: 0.9365 - val_loss: 0.2795 - val_categorical_accuracy: 0.9322
Epoch 30/100
40320/40456 [============================&gt;.] - ETA: 0s - loss: 0.2145 - categorical_accuracy: 0.9378
Epoch 00030: val_loss did not improve from 0.25896
40456/40456 [==============================] - 9s 225us/sample - loss: 0.2151 - categorical_accuracy: 0.9376 - val_loss: 0.3232 - val_categorical_accuracy: 0.9195
Epoch 31/100
40192/40456 [============================&gt;.] - ETA: 0s - loss: 0.2121 - categorical_accuracy: 0.9371
Epoch 00031: val_loss did not improve from 0.25896
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2120 - categorical_accuracy: 0.9371 - val_loss: 0.2660 - val_categorical_accuracy: 0.9324
0.9305913 0.8426530612244898


nrx: 0 - real: 3 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: divide by zero encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1440 samples, validate on 180 samples
Epoch 1/100
1376/1440 [===========================&gt;..] - ETA: 0s - loss: 2.2814 - categorical_accuracy: 0.1315
Epoch 00001: val_loss improved from inf to 2.21202, saving model to t_weights_1
1440/1440 [==============================] - 1s 530us/sample - loss: 2.2773 - categorical_accuracy: 0.1340 - val_loss: 2.2120 - val_categorical_accuracy: 0.1556
Epoch 2/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 2.1784 - categorical_accuracy: 0.2058
Epoch 00002: val_loss improved from 2.21202 to 2.02653, saving model to t_weights_1
1440/1440 [==============================] - 0s 272us/sample - loss: 2.1676 - categorical_accuracy: 0.2132 - val_loss: 2.0265 - val_categorical_accuracy: 0.3167
Epoch 3/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 1.8525 - categorical_accuracy: 0.3703
Epoch 00003: val_loss improved from 2.02653 to 1.43206, saving model to t_weights_1
1440/1440 [==============================] - 0s 277us/sample - loss: 1.8178 - categorical_accuracy: 0.3799 - val_loss: 1.4321 - val_categorical_accuracy: 0.5611
Epoch 4/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 1.4336 - categorical_accuracy: 0.4726
Epoch 00004: val_loss improved from 1.43206 to 1.19024, saving model to t_weights_1
1440/1440 [==============================] - 0s 268us/sample - loss: 1.4168 - categorical_accuracy: 0.4792 - val_loss: 1.1902 - val_categorical_accuracy: 0.5722
Epoch 5/100
1152/1440 [=======================&gt;......] - ETA: 0s - loss: 1.1355 - categorical_accuracy: 0.5990
Epoch 00005: val_loss improved from 1.19024 to 0.88315, saving model to t_weights_1
1440/1440 [==============================] - 0s 244us/sample - loss: 1.1342 - categorical_accuracy: 0.5993 - val_loss: 0.8832 - val_categorical_accuracy: 0.6778
Epoch 6/100
1248/1440 [=========================&gt;....] - ETA: 0s - loss: 0.9651 - categorical_accuracy: 0.6466
Epoch 00006: val_loss improved from 0.88315 to 0.66060, saving model to t_weights_1
1440/1440 [==============================] - 0s 289us/sample - loss: 0.9438 - categorical_accuracy: 0.6611 - val_loss: 0.6606 - val_categorical_accuracy: 0.8333
Epoch 7/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.7977 - categorical_accuracy: 0.7344
Epoch 00007: val_loss improved from 0.66060 to 0.57379, saving model to t_weights_1
1440/1440 [==============================] - 0s 272us/sample - loss: 0.8075 - categorical_accuracy: 0.7271 - val_loss: 0.5738 - val_categorical_accuracy: 0.9000
Epoch 8/100
1248/1440 [=========================&gt;....] - ETA: 0s - loss: 0.6599 - categorical_accuracy: 0.7893
Epoch 00008: val_loss improved from 0.57379 to 0.45219, saving model to t_weights_1
1440/1440 [==============================] - 0s 277us/sample - loss: 0.6600 - categorical_accuracy: 0.7903 - val_loss: 0.4522 - val_categorical_accuracy: 0.8722
Epoch 9/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.5638 - categorical_accuracy: 0.8203
Epoch 00009: val_loss improved from 0.45219 to 0.39130, saving model to t_weights_1
1440/1440 [==============================] - 0s 284us/sample - loss: 0.5775 - categorical_accuracy: 0.8208 - val_loss: 0.3913 - val_categorical_accuracy: 0.9167
Epoch 10/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.4862 - categorical_accuracy: 0.8594
Epoch 00010: val_loss improved from 0.39130 to 0.30888, saving model to t_weights_1
1440/1440 [==============================] - 0s 277us/sample - loss: 0.4999 - categorical_accuracy: 0.8528 - val_loss: 0.3089 - val_categorical_accuracy: 0.9222
Epoch 11/100
1376/1440 [===========================&gt;..] - ETA: 0s - loss: 0.4368 - categorical_accuracy: 0.8823
Epoch 00011: val_loss improved from 0.30888 to 0.25814, saving model to t_weights_1
1440/1440 [==============================] - 0s 239us/sample - loss: 0.4338 - categorical_accuracy: 0.8826 - val_loss: 0.2581 - val_categorical_accuracy: 0.9167
Epoch 12/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.3483 - categorical_accuracy: 0.9062
Epoch 00012: val_loss improved from 0.25814 to 0.21527, saving model to t_weights_1
1440/1440 [==============================] - 0s 273us/sample - loss: 0.3570 - categorical_accuracy: 0.9076 - val_loss: 0.2153 - val_categorical_accuracy: 0.9333
Epoch 13/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.3280 - categorical_accuracy: 0.9162
Epoch 00013: val_loss improved from 0.21527 to 0.20883, saving model to t_weights_1
1440/1440 [==============================] - 0s 275us/sample - loss: 0.3318 - categorical_accuracy: 0.9174 - val_loss: 0.2088 - val_categorical_accuracy: 0.9333
Epoch 14/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.2979 - categorical_accuracy: 0.9245
Epoch 00014: val_loss improved from 0.20883 to 0.16075, saving model to t_weights_1
1440/1440 [==============================] - 0s 265us/sample - loss: 0.2907 - categorical_accuracy: 0.9271 - val_loss: 0.1608 - val_categorical_accuracy: 0.9667
Epoch 15/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.2846 - categorical_accuracy: 0.9375
Epoch 00015: val_loss did not improve from 0.16075
1440/1440 [==============================] - 0s 230us/sample - loss: 0.2898 - categorical_accuracy: 0.9361 - val_loss: 0.1816 - val_categorical_accuracy: 0.9556
Epoch 16/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.9523
Epoch 00016: val_loss improved from 0.16075 to 0.13191, saving model to t_weights_1
1440/1440 [==============================] - 0s 281us/sample - loss: 0.2185 - categorical_accuracy: 0.9549 - val_loss: 0.1319 - val_categorical_accuracy: 0.9667
Epoch 17/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.2392 - categorical_accuracy: 0.9482
Epoch 00017: val_loss did not improve from 0.13191
1440/1440 [==============================] - 0s 223us/sample - loss: 0.2423 - categorical_accuracy: 0.9451 - val_loss: 0.2810 - val_categorical_accuracy: 0.9111
Epoch 18/100
1184/1440 [=======================&gt;......] - ETA: 0s - loss: 0.2321 - categorical_accuracy: 0.9459
Epoch 00018: val_loss improved from 0.13191 to 0.11978, saving model to t_weights_1
1440/1440 [==============================] - 0s 236us/sample - loss: 0.2260 - categorical_accuracy: 0.9472 - val_loss: 0.1198 - val_categorical_accuracy: 0.9667
Epoch 19/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.1671 - categorical_accuracy: 0.9672
Epoch 00019: val_loss improved from 0.11978 to 0.10406, saving model to t_weights_1
1440/1440 [==============================] - 0s 261us/sample - loss: 0.1755 - categorical_accuracy: 0.9667 - val_loss: 0.1041 - val_categorical_accuracy: 0.9833
Epoch 20/100
1344/1440 [===========================&gt;..] - ETA: 0s - loss: 0.1889 - categorical_accuracy: 0.9598
Epoch 00020: val_loss did not improve from 0.10406
1440/1440 [==============================] - 0s 227us/sample - loss: 0.1843 - categorical_accuracy: 0.9604 - val_loss: 0.1171 - val_categorical_accuracy: 0.9556
Epoch 21/100
1248/1440 [=========================&gt;....] - ETA: 0s - loss: 0.1629 - categorical_accuracy: 0.9663
Epoch 00021: val_loss did not improve from 0.10406
1440/1440 [==============================] - 0s 237us/sample - loss: 0.1688 - categorical_accuracy: 0.9653 - val_loss: 0.1304 - val_categorical_accuracy: 0.9667
Epoch 22/100
1216/1440 [========================&gt;.....] - ETA: 0s - loss: 0.1632 - categorical_accuracy: 0.9581
Epoch 00022: val_loss improved from 0.10406 to 0.07210, saving model to t_weights_1
1440/1440 [==============================] - 0s 288us/sample - loss: 0.1543 - categorical_accuracy: 0.9625 - val_loss: 0.0721 - val_categorical_accuracy: 0.9889
Epoch 23/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.1298 - categorical_accuracy: 0.9771
Epoch 00023: val_loss did not improve from 0.07210
1440/1440 [==============================] - 0s 234us/sample - loss: 0.1344 - categorical_accuracy: 0.9729 - val_loss: 0.0885 - val_categorical_accuracy: 0.9889
Epoch 24/100
1376/1440 [===========================&gt;..] - ETA: 0s - loss: 0.1532 - categorical_accuracy: 0.9608
Epoch 00024: val_loss did not improve from 0.07210
1440/1440 [==============================] - 0s 211us/sample - loss: 0.1501 - categorical_accuracy: 0.9625 - val_loss: 0.0765 - val_categorical_accuracy: 0.9833
Epoch 25/100
1408/1440 [============================&gt;.] - ETA: 0s - loss: 0.1116 - categorical_accuracy: 0.9766
Epoch 00025: val_loss did not improve from 0.07210
1440/1440 [==============================] - 0s 209us/sample - loss: 0.1102 - categorical_accuracy: 0.9771 - val_loss: 0.0887 - val_categorical_accuracy: 0.9778
Epoch 26/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.1265 - categorical_accuracy: 0.9703
Epoch 00026: val_loss did not improve from 0.07210
1440/1440 [==============================] - 0s 231us/sample - loss: 0.1307 - categorical_accuracy: 0.9688 - val_loss: 0.0940 - val_categorical_accuracy: 0.9722
Epoch 27/100
1216/1440 [========================&gt;.....] - ETA: 0s - loss: 0.1386 - categorical_accuracy: 0.9712
Epoch 00027: val_loss did not improve from 0.07210
1440/1440 [==============================] - 0s 242us/sample - loss: 0.1304 - categorical_accuracy: 0.9736 - val_loss: 0.1278 - val_categorical_accuracy: 0.9611
0.9722222 0.15448979591836734


nrx: 5 - real: 3 
Train on 9280 samples, validate on 1160 samples
Epoch 1/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 2.1897 - categorical_accuracy: 0.1902
Epoch 00001: val_loss improved from inf to 1.80300, saving model to t_weights_1
9280/9280 [==============================] - 3s 271us/sample - loss: 2.1864 - categorical_accuracy: 0.1908 - val_loss: 1.8030 - val_categorical_accuracy: 0.4069
Epoch 2/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 1.6717 - categorical_accuracy: 0.3943
Epoch 00002: val_loss improved from 1.80300 to 1.38264, saving model to t_weights_1
9280/9280 [==============================] - 2s 194us/sample - loss: 1.6692 - categorical_accuracy: 0.3955 - val_loss: 1.3826 - val_categorical_accuracy: 0.5612
Epoch 3/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 1.4102 - categorical_accuracy: 0.4992
Epoch 00003: val_loss improved from 1.38264 to 1.16308, saving model to t_weights_1
9280/9280 [==============================] - 2s 228us/sample - loss: 1.4073 - categorical_accuracy: 0.5004 - val_loss: 1.1631 - val_categorical_accuracy: 0.6293
Epoch 4/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 1.1997 - categorical_accuracy: 0.5915
Epoch 00004: val_loss improved from 1.16308 to 1.01036, saving model to t_weights_1
9280/9280 [==============================] - 2s 232us/sample - loss: 1.1984 - categorical_accuracy: 0.5923 - val_loss: 1.0104 - val_categorical_accuracy: 0.7026
Epoch 5/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 1.0265 - categorical_accuracy: 0.6641
Epoch 00005: val_loss improved from 1.01036 to 0.85044, saving model to t_weights_1
9280/9280 [==============================] - 2s 232us/sample - loss: 1.0242 - categorical_accuracy: 0.6652 - val_loss: 0.8504 - val_categorical_accuracy: 0.7353
Epoch 6/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.8620 - categorical_accuracy: 0.7262
Epoch 00006: val_loss improved from 0.85044 to 0.68262, saving model to t_weights_1
9280/9280 [==============================] - 2s 209us/sample - loss: 0.8627 - categorical_accuracy: 0.7260 - val_loss: 0.6826 - val_categorical_accuracy: 0.8138
Epoch 7/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.7322 - categorical_accuracy: 0.7732
Epoch 00007: val_loss improved from 0.68262 to 0.56773, saving model to t_weights_1
9280/9280 [==============================] - 2s 224us/sample - loss: 0.7309 - categorical_accuracy: 0.7740 - val_loss: 0.5677 - val_categorical_accuracy: 0.8500
Epoch 8/100
9248/9280 [============================&gt;.] - ETA: 0s - loss: 0.6383 - categorical_accuracy: 0.8075
Epoch 00008: val_loss improved from 0.56773 to 0.49563, saving model to t_weights_1
9280/9280 [==============================] - 2s 235us/sample - loss: 0.6381 - categorical_accuracy: 0.8073 - val_loss: 0.4956 - val_categorical_accuracy: 0.8629
Epoch 9/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.5391 - categorical_accuracy: 0.8411
Epoch 00009: val_loss improved from 0.49563 to 0.41389, saving model to t_weights_1
9280/9280 [==============================] - 2s 234us/sample - loss: 0.5390 - categorical_accuracy: 0.8411 - val_loss: 0.4139 - val_categorical_accuracy: 0.8784
Epoch 10/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 0.4614 - categorical_accuracy: 0.8695
Epoch 00010: val_loss improved from 0.41389 to 0.36091, saving model to t_weights_1
9280/9280 [==============================] - 2s 237us/sample - loss: 0.4624 - categorical_accuracy: 0.8687 - val_loss: 0.3609 - val_categorical_accuracy: 0.8897
Epoch 11/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 0.4187 - categorical_accuracy: 0.8833
Epoch 00011: val_loss improved from 0.36091 to 0.32554, saving model to t_weights_1
9280/9280 [==============================] - 2s 229us/sample - loss: 0.4186 - categorical_accuracy: 0.8841 - val_loss: 0.3255 - val_categorical_accuracy: 0.9147
Epoch 12/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.3721 - categorical_accuracy: 0.9008
Epoch 00012: val_loss improved from 0.32554 to 0.30844, saving model to t_weights_1
9280/9280 [==============================] - 2s 230us/sample - loss: 0.3726 - categorical_accuracy: 0.9004 - val_loss: 0.3084 - val_categorical_accuracy: 0.9181
Epoch 13/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.3381 - categorical_accuracy: 0.9098
Epoch 00013: val_loss improved from 0.30844 to 0.28645, saving model to t_weights_1
9280/9280 [==============================] - 2s 230us/sample - loss: 0.3370 - categorical_accuracy: 0.9102 - val_loss: 0.2864 - val_categorical_accuracy: 0.9328
Epoch 14/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 0.3045 - categorical_accuracy: 0.9170
Epoch 00014: val_loss improved from 0.28645 to 0.25693, saving model to t_weights_1
9280/9280 [==============================] - 2s 232us/sample - loss: 0.3046 - categorical_accuracy: 0.9169 - val_loss: 0.2569 - val_categorical_accuracy: 0.9328
Epoch 15/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.2830 - categorical_accuracy: 0.9235
Epoch 00015: val_loss improved from 0.25693 to 0.23234, saving model to t_weights_1
9280/9280 [==============================] - 2s 223us/sample - loss: 0.2823 - categorical_accuracy: 0.9238 - val_loss: 0.2323 - val_categorical_accuracy: 0.9448
Epoch 16/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.2539 - categorical_accuracy: 0.9334
Epoch 00016: val_loss improved from 0.23234 to 0.20684, saving model to t_weights_1
9280/9280 [==============================] - 2s 235us/sample - loss: 0.2529 - categorical_accuracy: 0.9335 - val_loss: 0.2068 - val_categorical_accuracy: 0.9509
Epoch 17/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 0.2371 - categorical_accuracy: 0.9399
Epoch 00017: val_loss did not improve from 0.20684
9280/9280 [==============================] - 2s 231us/sample - loss: 0.2370 - categorical_accuracy: 0.9399 - val_loss: 0.2199 - val_categorical_accuracy: 0.9397
Epoch 18/100
9248/9280 [============================&gt;.] - ETA: 0s - loss: 0.2137 - categorical_accuracy: 0.9466
Epoch 00018: val_loss did not improve from 0.20684
9280/9280 [==============================] - 2s 225us/sample - loss: 0.2135 - categorical_accuracy: 0.9467 - val_loss: 0.2168 - val_categorical_accuracy: 0.9491
Epoch 19/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.2052 - categorical_accuracy: 0.9475
Epoch 00019: val_loss improved from 0.20684 to 0.18271, saving model to t_weights_1
9280/9280 [==============================] - 2s 234us/sample - loss: 0.2049 - categorical_accuracy: 0.9475 - val_loss: 0.1827 - val_categorical_accuracy: 0.9612
Epoch 20/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.2004 - categorical_accuracy: 0.9475
Epoch 00020: val_loss improved from 0.18271 to 0.17969, saving model to t_weights_1
9280/9280 [==============================] - 2s 236us/sample - loss: 0.2005 - categorical_accuracy: 0.9473 - val_loss: 0.1797 - val_categorical_accuracy: 0.9578
Epoch 21/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.1810 - categorical_accuracy: 0.9549
Epoch 00021: val_loss improved from 0.17969 to 0.17193, saving model to t_weights_1
9280/9280 [==============================] - 2s 230us/sample - loss: 0.1808 - categorical_accuracy: 0.9547 - val_loss: 0.1719 - val_categorical_accuracy: 0.9621
Epoch 22/100
9024/9280 [============================&gt;.] - ETA: 0s - loss: 0.1856 - categorical_accuracy: 0.9548
Epoch 00022: val_loss did not improve from 0.17193
9280/9280 [==============================] - 2s 225us/sample - loss: 0.1856 - categorical_accuracy: 0.9548 - val_loss: 0.1877 - val_categorical_accuracy: 0.9569
Epoch 23/100
9024/9280 [============================&gt;.] - ETA: 0s - loss: 0.1683 - categorical_accuracy: 0.9590
Epoch 00023: val_loss did not improve from 0.17193
9280/9280 [==============================] - 2s 223us/sample - loss: 0.1693 - categorical_accuracy: 0.9587 - val_loss: 0.1764 - val_categorical_accuracy: 0.9586
Epoch 24/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.1658 - categorical_accuracy: 0.9607
Epoch 00024: val_loss did not improve from 0.17193
9280/9280 [==============================] - 2s 231us/sample - loss: 0.1670 - categorical_accuracy: 0.9603 - val_loss: 0.1731 - val_categorical_accuracy: 0.9595
Epoch 25/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.1430 - categorical_accuracy: 0.9665
Epoch 00025: val_loss did not improve from 0.17193
9280/9280 [==============================] - 2s 225us/sample - loss: 0.1434 - categorical_accuracy: 0.9665 - val_loss: 0.1804 - val_categorical_accuracy: 0.9569
Epoch 26/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 0.1411 - categorical_accuracy: 0.9669
Epoch 00026: val_loss improved from 0.17193 to 0.15879, saving model to t_weights_1
9280/9280 [==============================] - 2s 234us/sample - loss: 0.1408 - categorical_accuracy: 0.9668 - val_loss: 0.1588 - val_categorical_accuracy: 0.9681
Epoch 27/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.1359 - categorical_accuracy: 0.9688
Epoch 00027: val_loss did not improve from 0.15879
9280/9280 [==============================] - 2s 227us/sample - loss: 0.1357 - categorical_accuracy: 0.9688 - val_loss: 0.1744 - val_categorical_accuracy: 0.9569
Epoch 28/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.1350 - categorical_accuracy: 0.9682
Epoch 00028: val_loss did not improve from 0.15879
9280/9280 [==============================] - 2s 226us/sample - loss: 0.1346 - categorical_accuracy: 0.9683 - val_loss: 0.1711 - val_categorical_accuracy: 0.9629
Epoch 29/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.1193 - categorical_accuracy: 0.9721
Epoch 00029: val_loss did not improve from 0.15879
9280/9280 [==============================] - 2s 230us/sample - loss: 0.1194 - categorical_accuracy: 0.9721 - val_loss: 0.1800 - val_categorical_accuracy: 0.9612
Epoch 30/100
9056/9280 [============================&gt;.] - ETA: 0s - loss: 0.1197 - categorical_accuracy: 0.9725
Epoch 00030: val_loss did not improve from 0.15879
9280/9280 [==============================] - 2s 223us/sample - loss: 0.1193 - categorical_accuracy: 0.9724 - val_loss: 0.2047 - val_categorical_accuracy: 0.9534
Epoch 31/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.1160 - categorical_accuracy: 0.9723
Epoch 00031: val_loss did not improve from 0.15879
9280/9280 [==============================] - 2s 228us/sample - loss: 0.1163 - categorical_accuracy: 0.9722 - val_loss: 0.1609 - val_categorical_accuracy: 0.9672
0.9534483 0.3006122448979592


nrx: 10 - real: 3 
Train on 16960 samples, validate on 2120 samples
Epoch 1/100
16928/16960 [============================&gt;.] - ETA: 0s - loss: 2.0163 - categorical_accuracy: 0.2450
Epoch 00001: val_loss improved from inf to 1.58465, saving model to t_weights_1
16960/16960 [==============================] - 4s 245us/sample - loss: 2.0155 - categorical_accuracy: 0.2453 - val_loss: 1.5847 - val_categorical_accuracy: 0.4467
Epoch 2/100
16928/16960 [============================&gt;.] - ETA: 0s - loss: 1.4785 - categorical_accuracy: 0.4696
Epoch 00002: val_loss improved from 1.58465 to 1.16686, saving model to t_weights_1
16960/16960 [==============================] - 4s 219us/sample - loss: 1.4781 - categorical_accuracy: 0.4698 - val_loss: 1.1669 - val_categorical_accuracy: 0.6274
Epoch 3/100
16896/16960 [============================&gt;.] - ETA: 0s - loss: 1.1544 - categorical_accuracy: 0.6050
Epoch 00003: val_loss improved from 1.16686 to 0.89769, saving model to t_weights_1
16960/16960 [==============================] - 4s 228us/sample - loss: 1.1530 - categorical_accuracy: 0.6059 - val_loss: 0.8977 - val_categorical_accuracy: 0.7274
Epoch 4/100
16800/16960 [============================&gt;.] - ETA: 0s - loss: 0.9273 - categorical_accuracy: 0.6907
Epoch 00004: val_loss improved from 0.89769 to 0.73264, saving model to t_weights_1
16960/16960 [==============================] - 4s 224us/sample - loss: 0.9261 - categorical_accuracy: 0.6909 - val_loss: 0.7326 - val_categorical_accuracy: 0.7637
Epoch 5/100
16800/16960 [============================&gt;.] - ETA: 0s - loss: 0.7605 - categorical_accuracy: 0.7527
Epoch 00005: val_loss improved from 0.73264 to 0.57448, saving model to t_weights_1
16960/16960 [==============================] - 4s 234us/sample - loss: 0.7602 - categorical_accuracy: 0.7532 - val_loss: 0.5745 - val_categorical_accuracy: 0.8406
Epoch 6/100
16832/16960 [============================&gt;.] - ETA: 0s - loss: 0.6275 - categorical_accuracy: 0.8021
Epoch 00006: val_loss improved from 0.57448 to 0.46145, saving model to t_weights_1
16960/16960 [==============================] - 4s 226us/sample - loss: 0.6264 - categorical_accuracy: 0.8025 - val_loss: 0.4615 - val_categorical_accuracy: 0.8755
Epoch 7/100
16896/16960 [============================&gt;.] - ETA: 0s - loss: 0.5327 - categorical_accuracy: 0.8384
Epoch 00007: val_loss improved from 0.46145 to 0.40072, saving model to t_weights_1
16960/16960 [==============================] - 4s 232us/sample - loss: 0.5325 - categorical_accuracy: 0.8385 - val_loss: 0.4007 - val_categorical_accuracy: 0.8925
Epoch 8/100
16736/16960 [============================&gt;.] - ETA: 0s - loss: 0.4666 - categorical_accuracy: 0.8620
Epoch 00008: val_loss improved from 0.40072 to 0.34044, saving model to t_weights_1
16960/16960 [==============================] - 4s 230us/sample - loss: 0.4671 - categorical_accuracy: 0.8617 - val_loss: 0.3404 - val_categorical_accuracy: 0.9085
Epoch 9/100
16864/16960 [============================&gt;.] - ETA: 0s - loss: 0.4018 - categorical_accuracy: 0.8827
Epoch 00009: val_loss improved from 0.34044 to 0.31927, saving model to t_weights_1
16960/16960 [==============================] - 4s 227us/sample - loss: 0.4028 - categorical_accuracy: 0.8821 - val_loss: 0.3193 - val_categorical_accuracy: 0.9151
Epoch 10/100
16736/16960 [============================&gt;.] - ETA: 0s - loss: 0.3650 - categorical_accuracy: 0.8923
Epoch 00010: val_loss did not improve from 0.31927
16960/16960 [==============================] - 4s 227us/sample - loss: 0.3652 - categorical_accuracy: 0.8921 - val_loss: 0.3405 - val_categorical_accuracy: 0.9123
Epoch 11/100
16928/16960 [============================&gt;.] - ETA: 0s - loss: 0.3290 - categorical_accuracy: 0.9064
Epoch 00011: val_loss improved from 0.31927 to 0.28265, saving model to t_weights_1
16960/16960 [==============================] - 4s 230us/sample - loss: 0.3291 - categorical_accuracy: 0.9064 - val_loss: 0.2826 - val_categorical_accuracy: 0.9241
Epoch 12/100
16896/16960 [============================&gt;.] - ETA: 0s - loss: 0.3053 - categorical_accuracy: 0.9131
Epoch 00012: val_loss improved from 0.28265 to 0.26251, saving model to t_weights_1
16960/16960 [==============================] - 4s 233us/sample - loss: 0.3054 - categorical_accuracy: 0.9132 - val_loss: 0.2625 - val_categorical_accuracy: 0.9325
Epoch 13/100
16736/16960 [============================&gt;.] - ETA: 0s - loss: 0.2812 - categorical_accuracy: 0.9207
Epoch 00013: val_loss improved from 0.26251 to 0.25115, saving model to t_weights_1
16960/16960 [==============================] - 4s 226us/sample - loss: 0.2810 - categorical_accuracy: 0.9208 - val_loss: 0.2512 - val_categorical_accuracy: 0.9344
Epoch 14/100
16768/16960 [============================&gt;.] - ETA: 0s - loss: 0.2651 - categorical_accuracy: 0.9266
Epoch 00014: val_loss did not improve from 0.25115
16960/16960 [==============================] - 4s 226us/sample - loss: 0.2641 - categorical_accuracy: 0.9266 - val_loss: 0.2636 - val_categorical_accuracy: 0.9330
Epoch 15/100
16704/16960 [============================&gt;.] - ETA: 0s - loss: 0.2509 - categorical_accuracy: 0.9288
Epoch 00015: val_loss improved from 0.25115 to 0.23540, saving model to t_weights_1
16960/16960 [==============================] - 4s 232us/sample - loss: 0.2507 - categorical_accuracy: 0.9287 - val_loss: 0.2354 - val_categorical_accuracy: 0.9401
Epoch 16/100
16896/16960 [============================&gt;.] - ETA: 0s - loss: 0.2374 - categorical_accuracy: 0.9319
Epoch 00016: val_loss did not improve from 0.23540
16960/16960 [==============================] - 4s 225us/sample - loss: 0.2375 - categorical_accuracy: 0.9318 - val_loss: 0.2360 - val_categorical_accuracy: 0.9368
Epoch 17/100
16928/16960 [============================&gt;.] - ETA: 0s - loss: 0.2305 - categorical_accuracy: 0.9353
Epoch 00017: val_loss did not improve from 0.23540
16960/16960 [==============================] - 4s 215us/sample - loss: 0.2305 - categorical_accuracy: 0.9353 - val_loss: 0.2403 - val_categorical_accuracy: 0.9425
Epoch 18/100
16800/16960 [============================&gt;.] - ETA: 0s - loss: 0.2152 - categorical_accuracy: 0.9393
Epoch 00018: val_loss improved from 0.23540 to 0.23489, saving model to t_weights_1
16960/16960 [==============================] - 4s 223us/sample - loss: 0.2154 - categorical_accuracy: 0.9390 - val_loss: 0.2349 - val_categorical_accuracy: 0.9415
Epoch 19/100
16928/16960 [============================&gt;.] - ETA: 0s - loss: 0.2161 - categorical_accuracy: 0.9381
Epoch 00019: val_loss improved from 0.23489 to 0.22990, saving model to t_weights_1
16960/16960 [==============================] - 4s 232us/sample - loss: 0.2160 - categorical_accuracy: 0.9381 - val_loss: 0.2299 - val_categorical_accuracy: 0.9377
Epoch 20/100
16896/16960 [============================&gt;.] - ETA: 0s - loss: 0.1958 - categorical_accuracy: 0.9449
Epoch 00020: val_loss improved from 0.22990 to 0.21135, saving model to t_weights_1
16960/16960 [==============================] - 4s 228us/sample - loss: 0.1957 - categorical_accuracy: 0.9449 - val_loss: 0.2114 - val_categorical_accuracy: 0.9486
Epoch 21/100
16672/16960 [============================&gt;.] - ETA: 0s - loss: 0.1941 - categorical_accuracy: 0.9444
Epoch 00021: val_loss did not improve from 0.21135
16960/16960 [==============================] - 4s 227us/sample - loss: 0.1939 - categorical_accuracy: 0.9445 - val_loss: 0.2129 - val_categorical_accuracy: 0.9519
Epoch 22/100
16800/16960 [============================&gt;.] - ETA: 0s - loss: 0.1859 - categorical_accuracy: 0.9472
Epoch 00022: val_loss did not improve from 0.21135
16960/16960 [==============================] - 4s 227us/sample - loss: 0.1855 - categorical_accuracy: 0.9473 - val_loss: 0.2199 - val_categorical_accuracy: 0.9509
Epoch 23/100
16672/16960 [============================&gt;.] - ETA: 0s - loss: 0.1819 - categorical_accuracy: 0.9486
Epoch 00023: val_loss did not improve from 0.21135
16960/16960 [==============================] - 4s 226us/sample - loss: 0.1815 - categorical_accuracy: 0.9488 - val_loss: 0.2198 - val_categorical_accuracy: 0.9528
Epoch 24/100
16768/16960 [============================&gt;.] - ETA: 0s - loss: 0.1733 - categorical_accuracy: 0.9507
Epoch 00024: val_loss did not improve from 0.21135
16960/16960 [==============================] - 4s 231us/sample - loss: 0.1727 - categorical_accuracy: 0.9509 - val_loss: 0.2233 - val_categorical_accuracy: 0.9505
Epoch 25/100
16736/16960 [============================&gt;.] - ETA: 0s - loss: 0.1730 - categorical_accuracy: 0.9512
Epoch 00025: val_loss did not improve from 0.21135
16960/16960 [==============================] - 4s 223us/sample - loss: 0.1728 - categorical_accuracy: 0.9515 - val_loss: 0.2229 - val_categorical_accuracy: 0.9509
0.9466981 0.2642857142857143


nrx: 15 - real: 3 
Train on 24936 samples, validate on 3117 samples
Epoch 1/100
24832/24936 [============================&gt;.] - ETA: 0s - loss: 1.9065 - categorical_accuracy: 0.2985
Epoch 00001: val_loss improved from inf to 1.39857, saving model to t_weights_1
24936/24936 [==============================] - 6s 223us/sample - loss: 1.9045 - categorical_accuracy: 0.2992 - val_loss: 1.3986 - val_categorical_accuracy: 0.5287
Epoch 2/100
24928/24936 [============================&gt;.] - ETA: 0s - loss: 1.3064 - categorical_accuracy: 0.5462
Epoch 00002: val_loss improved from 1.39857 to 0.96388, saving model to t_weights_1
24936/24936 [==============================] - 6s 227us/sample - loss: 1.3065 - categorical_accuracy: 0.5462 - val_loss: 0.9639 - val_categorical_accuracy: 0.6907
Epoch 3/100
24832/24936 [============================&gt;.] - ETA: 0s - loss: 0.9527 - categorical_accuracy: 0.6811
Epoch 00003: val_loss improved from 0.96388 to 0.67365, saving model to t_weights_1
24936/24936 [==============================] - 5s 212us/sample - loss: 0.9520 - categorical_accuracy: 0.6814 - val_loss: 0.6736 - val_categorical_accuracy: 0.7902
Epoch 4/100
24736/24936 [============================&gt;.] - ETA: 0s - loss: 0.7126 - categorical_accuracy: 0.7711
Epoch 00004: val_loss improved from 0.67365 to 0.50996, saving model to t_weights_1
24936/24936 [==============================] - 6s 228us/sample - loss: 0.7118 - categorical_accuracy: 0.7713 - val_loss: 0.5100 - val_categorical_accuracy: 0.8415
Epoch 5/100
24864/24936 [============================&gt;.] - ETA: 0s - loss: 0.5712 - categorical_accuracy: 0.8204
Epoch 00005: val_loss improved from 0.50996 to 0.42823, saving model to t_weights_1
24936/24936 [==============================] - 6s 221us/sample - loss: 0.5711 - categorical_accuracy: 0.8204 - val_loss: 0.4282 - val_categorical_accuracy: 0.8726
Epoch 6/100
24768/24936 [============================&gt;.] - ETA: 0s - loss: 0.4765 - categorical_accuracy: 0.8571
Epoch 00006: val_loss improved from 0.42823 to 0.36588, saving model to t_weights_1
24936/24936 [==============================] - 6s 228us/sample - loss: 0.4760 - categorical_accuracy: 0.8571 - val_loss: 0.3659 - val_categorical_accuracy: 0.8877
Epoch 7/100
24832/24936 [============================&gt;.] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.8746
Epoch 00007: val_loss improved from 0.36588 to 0.30419, saving model to t_weights_1
24936/24936 [==============================] - 6s 229us/sample - loss: 0.4094 - categorical_accuracy: 0.8747 - val_loss: 0.3042 - val_categorical_accuracy: 0.9115
Epoch 8/100
24736/24936 [============================&gt;.] - ETA: 0s - loss: 0.3691 - categorical_accuracy: 0.8925
Epoch 00008: val_loss did not improve from 0.30419
24936/24936 [==============================] - 6s 229us/sample - loss: 0.3689 - categorical_accuracy: 0.8925 - val_loss: 0.3042 - val_categorical_accuracy: 0.9102
Epoch 9/100
24928/24936 [============================&gt;.] - ETA: 0s - loss: 0.3365 - categorical_accuracy: 0.9004
Epoch 00009: val_loss improved from 0.30419 to 0.28161, saving model to t_weights_1
24936/24936 [==============================] - 6s 231us/sample - loss: 0.3365 - categorical_accuracy: 0.9005 - val_loss: 0.2816 - val_categorical_accuracy: 0.9147
Epoch 10/100
24704/24936 [============================&gt;.] - ETA: 0s - loss: 0.3013 - categorical_accuracy: 0.9128
Epoch 00010: val_loss improved from 0.28161 to 0.26097, saving model to t_weights_1
24936/24936 [==============================] - 6s 228us/sample - loss: 0.3016 - categorical_accuracy: 0.9127 - val_loss: 0.2610 - val_categorical_accuracy: 0.9224
Epoch 11/100
24704/24936 [============================&gt;.] - ETA: 0s - loss: 0.2878 - categorical_accuracy: 0.9160
Epoch 00011: val_loss improved from 0.26097 to 0.25319, saving model to t_weights_1
24936/24936 [==============================] - 6s 230us/sample - loss: 0.2876 - categorical_accuracy: 0.9163 - val_loss: 0.2532 - val_categorical_accuracy: 0.9265
Epoch 12/100
24928/24936 [============================&gt;.] - ETA: 0s - loss: 0.2669 - categorical_accuracy: 0.9244
Epoch 00012: val_loss improved from 0.25319 to 0.21573, saving model to t_weights_1
24936/24936 [==============================] - 5s 209us/sample - loss: 0.2668 - categorical_accuracy: 0.9244 - val_loss: 0.2157 - val_categorical_accuracy: 0.9397
Epoch 13/100
24928/24936 [============================&gt;.] - ETA: 0s - loss: 0.2598 - categorical_accuracy: 0.9252
Epoch 00013: val_loss did not improve from 0.21573
24936/24936 [==============================] - 6s 227us/sample - loss: 0.2597 - categorical_accuracy: 0.9252 - val_loss: 0.2158 - val_categorical_accuracy: 0.9429
Epoch 14/100
24704/24936 [============================&gt;.] - ETA: 0s - loss: 0.2390 - categorical_accuracy: 0.9303
Epoch 00014: val_loss improved from 0.21573 to 0.21046, saving model to t_weights_1
24936/24936 [==============================] - 6s 229us/sample - loss: 0.2386 - categorical_accuracy: 0.9305 - val_loss: 0.2105 - val_categorical_accuracy: 0.9432
Epoch 15/100
24832/24936 [============================&gt;.] - ETA: 0s - loss: 0.2309 - categorical_accuracy: 0.9325
Epoch 00015: val_loss did not improve from 0.21046
24936/24936 [==============================] - 6s 228us/sample - loss: 0.2306 - categorical_accuracy: 0.9326 - val_loss: 0.2183 - val_categorical_accuracy: 0.9461
Epoch 16/100
24864/24936 [============================&gt;.] - ETA: 0s - loss: 0.2251 - categorical_accuracy: 0.9356
Epoch 00016: val_loss did not improve from 0.21046
24936/24936 [==============================] - 5s 220us/sample - loss: 0.2251 - categorical_accuracy: 0.9356 - val_loss: 0.2223 - val_categorical_accuracy: 0.9435
Epoch 17/100
24864/24936 [============================&gt;.] - ETA: 0s - loss: 0.2155 - categorical_accuracy: 0.9389
Epoch 00017: val_loss did not improve from 0.21046
24936/24936 [==============================] - 6s 225us/sample - loss: 0.2158 - categorical_accuracy: 0.9389 - val_loss: 0.2132 - val_categorical_accuracy: 0.9461
Epoch 18/100
24864/24936 [============================&gt;.] - ETA: 0s - loss: 0.2023 - categorical_accuracy: 0.9428
Epoch 00018: val_loss improved from 0.21046 to 0.20583, saving model to t_weights_1
24936/24936 [==============================] - 6s 232us/sample - loss: 0.2021 - categorical_accuracy: 0.9428 - val_loss: 0.2058 - val_categorical_accuracy: 0.9474
Epoch 19/100
24928/24936 [============================&gt;.] - ETA: 0s - loss: 0.2039 - categorical_accuracy: 0.9419
Epoch 00019: val_loss did not improve from 0.20583
24936/24936 [==============================] - 6s 227us/sample - loss: 0.2039 - categorical_accuracy: 0.9419 - val_loss: 0.2145 - val_categorical_accuracy: 0.9467
Epoch 20/100
24704/24936 [============================&gt;.] - ETA: 0s - loss: 0.1940 - categorical_accuracy: 0.9446
Epoch 00020: val_loss did not improve from 0.20583
24936/24936 [==============================] - 6s 225us/sample - loss: 0.1944 - categorical_accuracy: 0.9445 - val_loss: 0.2089 - val_categorical_accuracy: 0.9477
Epoch 21/100
24736/24936 [============================&gt;.] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9489
Epoch 00021: val_loss improved from 0.20583 to 0.20564, saving model to t_weights_1
24936/24936 [==============================] - 6s 230us/sample - loss: 0.1883 - categorical_accuracy: 0.9489 - val_loss: 0.2056 - val_categorical_accuracy: 0.9471
Epoch 22/100
24736/24936 [============================&gt;.] - ETA: 0s - loss: 0.1864 - categorical_accuracy: 0.9473
Epoch 00022: val_loss did not improve from 0.20564
24936/24936 [==============================] - 6s 228us/sample - loss: 0.1865 - categorical_accuracy: 0.9471 - val_loss: 0.2076 - val_categorical_accuracy: 0.9512
Epoch 23/100
24928/24936 [============================&gt;.] - ETA: 0s - loss: 0.1809 - categorical_accuracy: 0.9498
Epoch 00023: val_loss improved from 0.20564 to 0.19599, saving model to t_weights_1
24936/24936 [==============================] - 6s 227us/sample - loss: 0.1809 - categorical_accuracy: 0.9498 - val_loss: 0.1960 - val_categorical_accuracy: 0.9532
Epoch 24/100
24896/24936 [============================&gt;.] - ETA: 0s - loss: 0.1785 - categorical_accuracy: 0.9510
Epoch 00024: val_loss did not improve from 0.19599
24936/24936 [==============================] - 6s 228us/sample - loss: 0.1785 - categorical_accuracy: 0.9510 - val_loss: 0.2163 - val_categorical_accuracy: 0.9461
Epoch 25/100
24832/24936 [============================&gt;.] - ETA: 0s - loss: 0.1779 - categorical_accuracy: 0.9508
Epoch 00025: val_loss did not improve from 0.19599
24936/24936 [==============================] - 6s 229us/sample - loss: 0.1777 - categorical_accuracy: 0.9509 - val_loss: 0.2006 - val_categorical_accuracy: 0.9512
Epoch 26/100
24736/24936 [============================&gt;.] - ETA: 0s - loss: 0.1660 - categorical_accuracy: 0.9535
Epoch 00026: val_loss did not improve from 0.19599
24936/24936 [==============================] - 6s 222us/sample - loss: 0.1660 - categorical_accuracy: 0.9534 - val_loss: 0.2259 - val_categorical_accuracy: 0.9423
Epoch 27/100
24864/24936 [============================&gt;.] - ETA: 0s - loss: 0.1658 - categorical_accuracy: 0.9532
Epoch 00027: val_loss did not improve from 0.19599
24936/24936 [==============================] - 5s 219us/sample - loss: 0.1661 - categorical_accuracy: 0.9531 - val_loss: 0.2122 - val_categorical_accuracy: 0.9506
Epoch 28/100
24800/24936 [============================&gt;.] - ETA: 0s - loss: 0.1618 - categorical_accuracy: 0.9550
Epoch 00028: val_loss did not improve from 0.19599
24936/24936 [==============================] - 6s 230us/sample - loss: 0.1618 - categorical_accuracy: 0.9550 - val_loss: 0.2080 - val_categorical_accuracy: 0.9538
0.946102 0.4014285714285714


nrx: 20 - real: 3 
Train on 32456 samples, validate on 4057 samples
Epoch 1/100
32448/32456 [============================&gt;.] - ETA: 0s - loss: 1.9271 - categorical_accuracy: 0.2766
Epoch 00001: val_loss improved from inf to 1.59246, saving model to t_weights_1
32456/32456 [==============================] - 7s 225us/sample - loss: 1.9269 - categorical_accuracy: 0.2767 - val_loss: 1.5925 - val_categorical_accuracy: 0.4420
Epoch 2/100
32352/32456 [============================&gt;.] - ETA: 0s - loss: 1.4787 - categorical_accuracy: 0.4672
Epoch 00002: val_loss improved from 1.59246 to 1.22679, saving model to t_weights_1
32456/32456 [==============================] - 7s 224us/sample - loss: 1.4783 - categorical_accuracy: 0.4676 - val_loss: 1.2268 - val_categorical_accuracy: 0.5864
Epoch 3/100
32256/32456 [============================&gt;.] - ETA: 0s - loss: 1.1522 - categorical_accuracy: 0.6033
Epoch 00003: val_loss improved from 1.22679 to 0.94027, saving model to t_weights_1
32456/32456 [==============================] - 7s 226us/sample - loss: 1.1515 - categorical_accuracy: 0.6033 - val_loss: 0.9403 - val_categorical_accuracy: 0.7064
Epoch 4/100
32320/32456 [============================&gt;.] - ETA: 0s - loss: 0.8970 - categorical_accuracy: 0.7000
Epoch 00004: val_loss improved from 0.94027 to 0.68235, saving model to t_weights_1
32456/32456 [==============================] - 7s 227us/sample - loss: 0.8963 - categorical_accuracy: 0.7003 - val_loss: 0.6823 - val_categorical_accuracy: 0.7747
Epoch 5/100
32352/32456 [============================&gt;.] - ETA: 0s - loss: 0.7141 - categorical_accuracy: 0.7677
Epoch 00005: val_loss improved from 0.68235 to 0.55277, saving model to t_weights_1
32456/32456 [==============================] - 7s 227us/sample - loss: 0.7145 - categorical_accuracy: 0.7675 - val_loss: 0.5528 - val_categorical_accuracy: 0.8329
Epoch 6/100
32352/32456 [============================&gt;.] - ETA: 0s - loss: 0.5883 - categorical_accuracy: 0.8148
Epoch 00006: val_loss improved from 0.55277 to 0.45512, saving model to t_weights_1
32456/32456 [==============================] - 7s 227us/sample - loss: 0.5884 - categorical_accuracy: 0.8148 - val_loss: 0.4551 - val_categorical_accuracy: 0.8642
Epoch 7/100
32384/32456 [============================&gt;.] - ETA: 0s - loss: 0.5075 - categorical_accuracy: 0.8424
Epoch 00007: val_loss improved from 0.45512 to 0.37219, saving model to t_weights_1
32456/32456 [==============================] - 7s 219us/sample - loss: 0.5076 - categorical_accuracy: 0.8425 - val_loss: 0.3722 - val_categorical_accuracy: 0.8913
Epoch 8/100
32416/32456 [============================&gt;.] - ETA: 0s - loss: 0.4479 - categorical_accuracy: 0.8639
Epoch 00008: val_loss improved from 0.37219 to 0.34992, saving model to t_weights_1
32456/32456 [==============================] - 7s 227us/sample - loss: 0.4478 - categorical_accuracy: 0.8640 - val_loss: 0.3499 - val_categorical_accuracy: 0.8980
Epoch 9/100
32288/32456 [============================&gt;.] - ETA: 0s - loss: 0.4015 - categorical_accuracy: 0.8789
Epoch 00009: val_loss improved from 0.34992 to 0.33690, saving model to t_weights_1
32456/32456 [==============================] - 7s 225us/sample - loss: 0.4013 - categorical_accuracy: 0.8791 - val_loss: 0.3369 - val_categorical_accuracy: 0.9051
Epoch 10/100
32448/32456 [============================&gt;.] - ETA: 0s - loss: 0.3648 - categorical_accuracy: 0.8893
Epoch 00010: val_loss improved from 0.33690 to 0.29426, saving model to t_weights_1
32456/32456 [==============================] - 7s 226us/sample - loss: 0.3648 - categorical_accuracy: 0.8893 - val_loss: 0.2943 - val_categorical_accuracy: 0.9187
Epoch 11/100
32384/32456 [============================&gt;.] - ETA: 0s - loss: 0.3405 - categorical_accuracy: 0.8974
Epoch 00011: val_loss improved from 0.29426 to 0.29015, saving model to t_weights_1
32456/32456 [==============================] - 7s 226us/sample - loss: 0.3404 - categorical_accuracy: 0.8974 - val_loss: 0.2901 - val_categorical_accuracy: 0.9196
Epoch 12/100
32352/32456 [============================&gt;.] - ETA: 0s - loss: 0.3193 - categorical_accuracy: 0.9071
Epoch 00012: val_loss improved from 0.29015 to 0.27607, saving model to t_weights_1
32456/32456 [==============================] - 7s 226us/sample - loss: 0.3195 - categorical_accuracy: 0.9070 - val_loss: 0.2761 - val_categorical_accuracy: 0.9243
Epoch 13/100
32384/32456 [============================&gt;.] - ETA: 0s - loss: 0.2989 - categorical_accuracy: 0.9130
Epoch 00013: val_loss improved from 0.27607 to 0.27166, saving model to t_weights_1
32456/32456 [==============================] - 7s 225us/sample - loss: 0.2992 - categorical_accuracy: 0.9130 - val_loss: 0.2717 - val_categorical_accuracy: 0.9288
Epoch 14/100
32352/32456 [============================&gt;.] - ETA: 0s - loss: 0.2850 - categorical_accuracy: 0.9170
Epoch 00014: val_loss improved from 0.27166 to 0.24868, saving model to t_weights_1
32456/32456 [==============================] - 7s 226us/sample - loss: 0.2856 - categorical_accuracy: 0.9168 - val_loss: 0.2487 - val_categorical_accuracy: 0.9349
Epoch 15/100
32224/32456 [============================&gt;.] - ETA: 0s - loss: 0.2704 - categorical_accuracy: 0.9227
Epoch 00015: val_loss did not improve from 0.24868
32456/32456 [==============================] - 7s 226us/sample - loss: 0.2702 - categorical_accuracy: 0.9226 - val_loss: 0.2556 - val_categorical_accuracy: 0.9352
Epoch 16/100
32384/32456 [============================&gt;.] - ETA: 0s - loss: 0.2569 - categorical_accuracy: 0.9260
Epoch 00016: val_loss did not improve from 0.24868
32456/32456 [==============================] - 7s 220us/sample - loss: 0.2569 - categorical_accuracy: 0.9260 - val_loss: 0.2535 - val_categorical_accuracy: 0.9384
Epoch 17/100
32288/32456 [============================&gt;.] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.9282
Epoch 00017: val_loss did not improve from 0.24868
32456/32456 [==============================] - 7s 222us/sample - loss: 0.2492 - categorical_accuracy: 0.9283 - val_loss: 0.2854 - val_categorical_accuracy: 0.9201
Epoch 18/100
32288/32456 [============================&gt;.] - ETA: 0s - loss: 0.2447 - categorical_accuracy: 0.9292
Epoch 00018: val_loss improved from 0.24868 to 0.23941, saving model to t_weights_1
32456/32456 [==============================] - 7s 207us/sample - loss: 0.2448 - categorical_accuracy: 0.9292 - val_loss: 0.2394 - val_categorical_accuracy: 0.9408
Epoch 19/100
32416/32456 [============================&gt;.] - ETA: 0s - loss: 0.2364 - categorical_accuracy: 0.9311
Epoch 00019: val_loss improved from 0.23941 to 0.23281, saving model to t_weights_1
32456/32456 [==============================] - 7s 222us/sample - loss: 0.2365 - categorical_accuracy: 0.9310 - val_loss: 0.2328 - val_categorical_accuracy: 0.9431
Epoch 20/100
32256/32456 [============================&gt;.] - ETA: 0s - loss: 0.2293 - categorical_accuracy: 0.9356
Epoch 00020: val_loss improved from 0.23281 to 0.22642, saving model to t_weights_1
32456/32456 [==============================] - 7s 224us/sample - loss: 0.2293 - categorical_accuracy: 0.9356 - val_loss: 0.2264 - val_categorical_accuracy: 0.9440
Epoch 21/100
32320/32456 [============================&gt;.] - ETA: 0s - loss: 0.2243 - categorical_accuracy: 0.9358
Epoch 00021: val_loss did not improve from 0.22642
32456/32456 [==============================] - 7s 220us/sample - loss: 0.2244 - categorical_accuracy: 0.9358 - val_loss: 0.2291 - val_categorical_accuracy: 0.9438
Epoch 22/100
32288/32456 [============================&gt;.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9371
Epoch 00022: val_loss did not improve from 0.22642
32456/32456 [==============================] - 7s 223us/sample - loss: 0.2194 - categorical_accuracy: 0.9371 - val_loss: 0.2297 - val_categorical_accuracy: 0.9436
Epoch 23/100
32352/32456 [============================&gt;.] - ETA: 0s - loss: 0.2147 - categorical_accuracy: 0.9395
Epoch 00023: val_loss did not improve from 0.22642
32456/32456 [==============================] - 7s 221us/sample - loss: 0.2145 - categorical_accuracy: 0.9395 - val_loss: 0.2428 - val_categorical_accuracy: 0.9440
Epoch 24/100
32448/32456 [============================&gt;.] - ETA: 0s - loss: 0.2102 - categorical_accuracy: 0.9418
Epoch 00024: val_loss improved from 0.22642 to 0.22489, saving model to t_weights_1
32456/32456 [==============================] - 7s 219us/sample - loss: 0.2103 - categorical_accuracy: 0.9418 - val_loss: 0.2249 - val_categorical_accuracy: 0.9458
Epoch 25/100
32288/32456 [============================&gt;.] - ETA: 0s - loss: 0.2026 - categorical_accuracy: 0.9421
Epoch 00025: val_loss did not improve from 0.22489
32456/32456 [==============================] - 7s 222us/sample - loss: 0.2032 - categorical_accuracy: 0.9419 - val_loss: 0.2786 - val_categorical_accuracy: 0.9416
Epoch 26/100
32384/32456 [============================&gt;.] - ETA: 0s - loss: 0.2017 - categorical_accuracy: 0.9433
Epoch 00026: val_loss did not improve from 0.22489
32456/32456 [==============================] - 7s 223us/sample - loss: 0.2019 - categorical_accuracy: 0.9432 - val_loss: 0.2543 - val_categorical_accuracy: 0.9416
Epoch 27/100
32320/32456 [============================&gt;.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9437
Epoch 00027: val_loss did not improve from 0.22489
32456/32456 [==============================] - 7s 223us/sample - loss: 0.1997 - categorical_accuracy: 0.9439 - val_loss: 0.2265 - val_categorical_accuracy: 0.9482
Epoch 28/100
32288/32456 [============================&gt;.] - ETA: 0s - loss: 0.1891 - categorical_accuracy: 0.9473
Epoch 00028: val_loss did not improve from 0.22489
32456/32456 [==============================] - 7s 223us/sample - loss: 0.1890 - categorical_accuracy: 0.9473 - val_loss: 0.2610 - val_categorical_accuracy: 0.9438
Epoch 29/100
32256/32456 [============================&gt;.] - ETA: 0s - loss: 0.1906 - categorical_accuracy: 0.9472
Epoch 00029: val_loss did not improve from 0.22489
32456/32456 [==============================] - 7s 221us/sample - loss: 0.1911 - categorical_accuracy: 0.9472 - val_loss: 0.2539 - val_categorical_accuracy: 0.9475
0.9327089 0.5624489795918367


nrx: 25 - real: 3 
Train on 40456 samples, validate on 5057 samples
Epoch 1/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 1.8552 - categorical_accuracy: 0.3132
Epoch 00001: val_loss improved from inf to 1.43255, saving model to t_weights_1
40456/40456 [==============================] - 9s 234us/sample - loss: 1.8534 - categorical_accuracy: 0.3139 - val_loss: 1.4325 - val_categorical_accuracy: 0.4940
Epoch 2/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 1.3059 - categorical_accuracy: 0.5346
Epoch 00002: val_loss improved from 1.43255 to 1.07776, saving model to t_weights_1
40456/40456 [==============================] - 9s 222us/sample - loss: 1.3059 - categorical_accuracy: 0.5346 - val_loss: 1.0778 - val_categorical_accuracy: 0.6488
Epoch 3/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.9957 - categorical_accuracy: 0.6618
Epoch 00003: val_loss improved from 1.07776 to 0.78111, saving model to t_weights_1
40456/40456 [==============================] - 9s 220us/sample - loss: 0.9947 - categorical_accuracy: 0.6623 - val_loss: 0.7811 - val_categorical_accuracy: 0.7558
Epoch 4/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.7824 - categorical_accuracy: 0.7466
Epoch 00004: val_loss improved from 0.78111 to 0.59556, saving model to t_weights_1
40456/40456 [==============================] - 9s 225us/sample - loss: 0.7824 - categorical_accuracy: 0.7466 - val_loss: 0.5956 - val_categorical_accuracy: 0.8098
Epoch 5/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.6230 - categorical_accuracy: 0.8011
Epoch 00005: val_loss improved from 0.59556 to 0.49403, saving model to t_weights_1
40456/40456 [==============================] - 9s 225us/sample - loss: 0.6230 - categorical_accuracy: 0.8010 - val_loss: 0.4940 - val_categorical_accuracy: 0.8462
Epoch 6/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.5151 - categorical_accuracy: 0.8407
Epoch 00006: val_loss improved from 0.49403 to 0.44229, saving model to t_weights_1
40456/40456 [==============================] - 9s 226us/sample - loss: 0.5151 - categorical_accuracy: 0.8407 - val_loss: 0.4423 - val_categorical_accuracy: 0.8582
Epoch 7/100
40320/40456 [============================&gt;.] - ETA: 0s - loss: 0.4541 - categorical_accuracy: 0.8608
Epoch 00007: val_loss improved from 0.44229 to 0.36561, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.4540 - categorical_accuracy: 0.8609 - val_loss: 0.3656 - val_categorical_accuracy: 0.8904
Epoch 8/100
40192/40456 [============================&gt;.] - ETA: 0s - loss: 0.4045 - categorical_accuracy: 0.8747
Epoch 00008: val_loss improved from 0.36561 to 0.33431, saving model to t_weights_1
40456/40456 [==============================] - 9s 223us/sample - loss: 0.4042 - categorical_accuracy: 0.8749 - val_loss: 0.3343 - val_categorical_accuracy: 0.9003
Epoch 9/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.3682 - categorical_accuracy: 0.8901
Epoch 00009: val_loss did not improve from 0.33431
40456/40456 [==============================] - 9s 217us/sample - loss: 0.3682 - categorical_accuracy: 0.8901 - val_loss: 0.3362 - val_categorical_accuracy: 0.8980
Epoch 10/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.3478 - categorical_accuracy: 0.8955
Epoch 00010: val_loss improved from 0.33431 to 0.30834, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.3478 - categorical_accuracy: 0.8955 - val_loss: 0.3083 - val_categorical_accuracy: 0.9073
Epoch 11/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.3235 - categorical_accuracy: 0.9031
Epoch 00011: val_loss improved from 0.30834 to 0.29105, saving model to t_weights_1
40456/40456 [==============================] - 9s 211us/sample - loss: 0.3236 - categorical_accuracy: 0.9030 - val_loss: 0.2911 - val_categorical_accuracy: 0.9175
Epoch 12/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.3108 - categorical_accuracy: 0.9074
Epoch 00012: val_loss improved from 0.29105 to 0.28258, saving model to t_weights_1
40456/40456 [==============================] - 9s 222us/sample - loss: 0.3111 - categorical_accuracy: 0.9074 - val_loss: 0.2826 - val_categorical_accuracy: 0.9183
Epoch 13/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.2994 - categorical_accuracy: 0.9128
Epoch 00013: val_loss did not improve from 0.28258
40456/40456 [==============================] - 9s 222us/sample - loss: 0.2991 - categorical_accuracy: 0.9129 - val_loss: 0.3139 - val_categorical_accuracy: 0.9106
Epoch 14/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.2817 - categorical_accuracy: 0.9180
Epoch 00014: val_loss improved from 0.28258 to 0.27895, saving model to t_weights_1
40456/40456 [==============================] - 9s 222us/sample - loss: 0.2820 - categorical_accuracy: 0.9179 - val_loss: 0.2790 - val_categorical_accuracy: 0.9221
Epoch 15/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9204
Epoch 00015: val_loss improved from 0.27895 to 0.27257, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2719 - categorical_accuracy: 0.9203 - val_loss: 0.2726 - val_categorical_accuracy: 0.9258
Epoch 16/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.2652 - categorical_accuracy: 0.9229
Epoch 00016: val_loss improved from 0.27257 to 0.27195, saving model to t_weights_1
40456/40456 [==============================] - 9s 218us/sample - loss: 0.2650 - categorical_accuracy: 0.9230 - val_loss: 0.2719 - val_categorical_accuracy: 0.9217
Epoch 17/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.2552 - categorical_accuracy: 0.9264
Epoch 00017: val_loss improved from 0.27195 to 0.25643, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2553 - categorical_accuracy: 0.9263 - val_loss: 0.2564 - val_categorical_accuracy: 0.9316
Epoch 18/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.2463 - categorical_accuracy: 0.9295
Epoch 00018: val_loss did not improve from 0.25643
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2463 - categorical_accuracy: 0.9295 - val_loss: 0.2769 - val_categorical_accuracy: 0.9270
Epoch 19/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.2398 - categorical_accuracy: 0.9315
Epoch 00019: val_loss did not improve from 0.25643
40456/40456 [==============================] - 9s 222us/sample - loss: 0.2399 - categorical_accuracy: 0.9315 - val_loss: 0.2616 - val_categorical_accuracy: 0.9347
Epoch 20/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.2297 - categorical_accuracy: 0.9335
Epoch 00020: val_loss did not improve from 0.25643
40456/40456 [==============================] - 9s 222us/sample - loss: 0.2295 - categorical_accuracy: 0.9336 - val_loss: 0.2785 - val_categorical_accuracy: 0.9266
Epoch 21/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.2321 - categorical_accuracy: 0.9340
Epoch 00021: val_loss did not improve from 0.25643
40456/40456 [==============================] - 9s 223us/sample - loss: 0.2325 - categorical_accuracy: 0.9340 - val_loss: 0.2756 - val_categorical_accuracy: 0.9278
Epoch 22/100
40224/40456 [============================&gt;.] - ETA: 0s - loss: 0.2201 - categorical_accuracy: 0.9370
Epoch 00022: val_loss improved from 0.25643 to 0.24427, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2206 - categorical_accuracy: 0.9369 - val_loss: 0.2443 - val_categorical_accuracy: 0.9379
Epoch 23/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.2180 - categorical_accuracy: 0.9384
Epoch 00023: val_loss did not improve from 0.24427
40456/40456 [==============================] - 9s 217us/sample - loss: 0.2181 - categorical_accuracy: 0.9384 - val_loss: 0.2631 - val_categorical_accuracy: 0.9349
Epoch 24/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.2134 - categorical_accuracy: 0.9395
Epoch 00024: val_loss did not improve from 0.24427
40456/40456 [==============================] - 9s 224us/sample - loss: 0.2135 - categorical_accuracy: 0.9395 - val_loss: 0.2545 - val_categorical_accuracy: 0.9361
Epoch 25/100
40288/40456 [============================&gt;.] - ETA: 0s - loss: 0.2118 - categorical_accuracy: 0.9418
Epoch 00025: val_loss improved from 0.24427 to 0.24344, saving model to t_weights_1
40456/40456 [==============================] - 9s 223us/sample - loss: 0.2117 - categorical_accuracy: 0.9419 - val_loss: 0.2434 - val_categorical_accuracy: 0.9387
Epoch 26/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.2027 - categorical_accuracy: 0.9428
Epoch 00026: val_loss did not improve from 0.24344
40456/40456 [==============================] - 9s 221us/sample - loss: 0.2030 - categorical_accuracy: 0.9428 - val_loss: 0.2683 - val_categorical_accuracy: 0.9343
Epoch 27/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9446
Epoch 00027: val_loss improved from 0.24344 to 0.24229, saving model to t_weights_1
40456/40456 [==============================] - 9s 224us/sample - loss: 0.1999 - categorical_accuracy: 0.9446 - val_loss: 0.2423 - val_categorical_accuracy: 0.9425
Epoch 28/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.1951 - categorical_accuracy: 0.9448
Epoch 00028: val_loss did not improve from 0.24229
40456/40456 [==============================] - 9s 221us/sample - loss: 0.1950 - categorical_accuracy: 0.9448 - val_loss: 0.2649 - val_categorical_accuracy: 0.9375
Epoch 29/100
40448/40456 [============================&gt;.] - ETA: 0s - loss: 0.1916 - categorical_accuracy: 0.9466
Epoch 00029: val_loss did not improve from 0.24229
40456/40456 [==============================] - 9s 221us/sample - loss: 0.1916 - categorical_accuracy: 0.9466 - val_loss: 0.2555 - val_categorical_accuracy: 0.9403
Epoch 30/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.1912 - categorical_accuracy: 0.9473
Epoch 00030: val_loss improved from 0.24229 to 0.23799, saving model to t_weights_1
40456/40456 [==============================] - 9s 220us/sample - loss: 0.1911 - categorical_accuracy: 0.9472 - val_loss: 0.2380 - val_categorical_accuracy: 0.9405
Epoch 31/100
40416/40456 [============================&gt;.] - ETA: 0s - loss: 0.1869 - categorical_accuracy: 0.9488
Epoch 00031: val_loss did not improve from 0.23799
40456/40456 [==============================] - 9s 222us/sample - loss: 0.1869 - categorical_accuracy: 0.9487 - val_loss: 0.2611 - val_categorical_accuracy: 0.9397
Epoch 32/100
40352/40456 [============================&gt;.] - ETA: 0s - loss: 0.1853 - categorical_accuracy: 0.9493
Epoch 00032: val_loss did not improve from 0.23799
40456/40456 [==============================] - 9s 221us/sample - loss: 0.1854 - categorical_accuracy: 0.9493 - val_loss: 0.2577 - val_categorical_accuracy: 0.9371
Epoch 33/100
40384/40456 [============================&gt;.] - ETA: 0s - loss: 0.1818 - categorical_accuracy: 0.9492
Epoch 00033: val_loss did not improve from 0.23799
40456/40456 [==============================] - 9s 224us/sample - loss: 0.1821 - categorical_accuracy: 0.9491 - val_loss: 0.2487 - val_categorical_accuracy: 0.9444
Epoch 34/100
40320/40456 [============================&gt;.] - ETA: 0s - loss: 0.1788 - categorical_accuracy: 0.9517
Epoch 00034: val_loss did not improve from 0.23799
40456/40456 [==============================] - 9s 223us/sample - loss: 0.1787 - categorical_accuracy: 0.9518 - val_loss: 0.2386 - val_categorical_accuracy: 0.9432
Epoch 35/100
40256/40456 [============================&gt;.] - ETA: 0s - loss: 0.1727 - categorical_accuracy: 0.9530
Epoch 00035: val_loss did not improve from 0.23799
40456/40456 [==============================] - 9s 220us/sample - loss: 0.1733 - categorical_accuracy: 0.9528 - val_loss: 0.2471 - val_categorical_accuracy: 0.9438
0.94680643 0.6004081632653061


nrx: 0 - real: 4 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1600 samples, validate on 200 samples
Epoch 1/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 2.3116 - categorical_accuracy: 0.1556
Epoch 00001: val_loss improved from inf to 2.28646, saving model to t_weights_1
1600/1600 [==============================] - 1s 479us/sample - loss: 2.3097 - categorical_accuracy: 0.1600 - val_loss: 2.2865 - val_categorical_accuracy: 0.1500
Epoch 2/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 2.1333 - categorical_accuracy: 0.2362
Epoch 00002: val_loss improved from 2.28646 to 1.71905, saving model to t_weights_1
1600/1600 [==============================] - 0s 262us/sample - loss: 2.0916 - categorical_accuracy: 0.2425 - val_loss: 1.7190 - val_categorical_accuracy: 0.3800
Epoch 3/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 1.5043 - categorical_accuracy: 0.4260
Epoch 00003: val_loss improved from 1.71905 to 1.13674, saving model to t_weights_1
1600/1600 [==============================] - 0s 276us/sample - loss: 1.4982 - categorical_accuracy: 0.4263 - val_loss: 1.1367 - val_categorical_accuracy: 0.7250
Epoch 4/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 1.0578 - categorical_accuracy: 0.6122
Epoch 00004: val_loss improved from 1.13674 to 0.72906, saving model to t_weights_1
1600/1600 [==============================] - 0s 273us/sample - loss: 1.0512 - categorical_accuracy: 0.6156 - val_loss: 0.7291 - val_categorical_accuracy: 0.8350
Epoch 5/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.7767 - categorical_accuracy: 0.7245
Epoch 00005: val_loss improved from 0.72906 to 0.59130, saving model to t_weights_1
1600/1600 [==============================] - 0s 260us/sample - loss: 0.7741 - categorical_accuracy: 0.7256 - val_loss: 0.5913 - val_categorical_accuracy: 0.8700
Epoch 6/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.5532 - categorical_accuracy: 0.8125
Epoch 00006: val_loss improved from 0.59130 to 0.35973, saving model to t_weights_1
1600/1600 [==============================] - 0s 223us/sample - loss: 0.5495 - categorical_accuracy: 0.8131 - val_loss: 0.3597 - val_categorical_accuracy: 0.9400
Epoch 7/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.4048 - categorical_accuracy: 0.8641
Epoch 00007: val_loss improved from 0.35973 to 0.29009, saving model to t_weights_1
1600/1600 [==============================] - 0s 260us/sample - loss: 0.4065 - categorical_accuracy: 0.8675 - val_loss: 0.2901 - val_categorical_accuracy: 0.9550
Epoch 8/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.3188 - categorical_accuracy: 0.8992
Epoch 00008: val_loss improved from 0.29009 to 0.21346, saving model to t_weights_1
1600/1600 [==============================] - 0s 271us/sample - loss: 0.3156 - categorical_accuracy: 0.9006 - val_loss: 0.2135 - val_categorical_accuracy: 0.9300
Epoch 9/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2701 - categorical_accuracy: 0.9114
Epoch 00009: val_loss improved from 0.21346 to 0.18155, saving model to t_weights_1
1600/1600 [==============================] - 0s 280us/sample - loss: 0.2713 - categorical_accuracy: 0.9112 - val_loss: 0.1815 - val_categorical_accuracy: 0.9700
Epoch 10/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2169 - categorical_accuracy: 0.9445
Epoch 00010: val_loss improved from 0.18155 to 0.14211, saving model to t_weights_1
1600/1600 [==============================] - 0s 280us/sample - loss: 0.2169 - categorical_accuracy: 0.9425 - val_loss: 0.1421 - val_categorical_accuracy: 0.9750
Epoch 11/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1710 - categorical_accuracy: 0.9570
Epoch 00011: val_loss improved from 0.14211 to 0.14080, saving model to t_weights_1
1600/1600 [==============================] - 0s 270us/sample - loss: 0.1784 - categorical_accuracy: 0.9550 - val_loss: 0.1408 - val_categorical_accuracy: 0.9600
Epoch 12/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1587 - categorical_accuracy: 0.9555
Epoch 00012: val_loss improved from 0.14080 to 0.10955, saving model to t_weights_1
1600/1600 [==============================] - 0s 240us/sample - loss: 0.1575 - categorical_accuracy: 0.9563 - val_loss: 0.1095 - val_categorical_accuracy: 0.9850
Epoch 13/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.1358 - categorical_accuracy: 0.9725
Epoch 00013: val_loss did not improve from 0.10955
1600/1600 [==============================] - 0s 221us/sample - loss: 0.1350 - categorical_accuracy: 0.9719 - val_loss: 0.1437 - val_categorical_accuracy: 0.9800
Epoch 14/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.1165 - categorical_accuracy: 0.9715
Epoch 00014: val_loss improved from 0.10955 to 0.09884, saving model to t_weights_1
1600/1600 [==============================] - 0s 244us/sample - loss: 0.1169 - categorical_accuracy: 0.9712 - val_loss: 0.0988 - val_categorical_accuracy: 0.9800
Epoch 15/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.1261 - categorical_accuracy: 0.9647
Epoch 00015: val_loss did not improve from 0.09884
1600/1600 [==============================] - 0s 199us/sample - loss: 0.1265 - categorical_accuracy: 0.9656 - val_loss: 0.1019 - val_categorical_accuracy: 0.9900
Epoch 16/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0835 - categorical_accuracy: 0.9851
Epoch 00016: val_loss improved from 0.09884 to 0.08600, saving model to t_weights_1
1600/1600 [==============================] - 0s 221us/sample - loss: 0.0821 - categorical_accuracy: 0.9850 - val_loss: 0.0860 - val_categorical_accuracy: 0.9900
Epoch 17/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0742 - categorical_accuracy: 0.9854
Epoch 00017: val_loss improved from 0.08600 to 0.07595, saving model to t_weights_1
1600/1600 [==============================] - 0s 237us/sample - loss: 0.0776 - categorical_accuracy: 0.9850 - val_loss: 0.0759 - val_categorical_accuracy: 0.9900
Epoch 18/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0764 - categorical_accuracy: 0.9830
Epoch 00018: val_loss improved from 0.07595 to 0.05960, saving model to t_weights_1
1600/1600 [==============================] - 0s 242us/sample - loss: 0.0801 - categorical_accuracy: 0.9806 - val_loss: 0.0596 - val_categorical_accuracy: 0.9900
Epoch 19/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9757
Epoch 00019: val_loss did not improve from 0.05960
1600/1600 [==============================] - 0s 214us/sample - loss: 0.0932 - categorical_accuracy: 0.9750 - val_loss: 0.0829 - val_categorical_accuracy: 0.9900
Epoch 20/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0685 - categorical_accuracy: 0.9834
Epoch 00020: val_loss did not improve from 0.05960
1600/1600 [==============================] - 0s 234us/sample - loss: 0.0677 - categorical_accuracy: 0.9837 - val_loss: 0.0639 - val_categorical_accuracy: 0.9900
Epoch 21/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0667 - categorical_accuracy: 0.9866
Epoch 00021: val_loss did not improve from 0.05960
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0659 - categorical_accuracy: 0.9869 - val_loss: 0.0787 - val_categorical_accuracy: 0.9900
Epoch 22/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0597 - categorical_accuracy: 0.9915
Epoch 00022: val_loss did not improve from 0.05960
1600/1600 [==============================] - 0s 234us/sample - loss: 0.0589 - categorical_accuracy: 0.9919 - val_loss: 0.0744 - val_categorical_accuracy: 0.9900
Epoch 23/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0466 - categorical_accuracy: 0.9943
Epoch 00023: val_loss did not improve from 0.05960
1600/1600 [==============================] - 0s 232us/sample - loss: 0.0462 - categorical_accuracy: 0.9944 - val_loss: 0.0819 - val_categorical_accuracy: 0.9900
0.995 0.18948979591836734


nrx: 5 - real: 4 
Train on 9416 samples, validate on 1177 samples
Epoch 1/100
9280/9416 [============================&gt;.] - ETA: 0s - loss: 2.1694 - categorical_accuracy: 0.2004
Epoch 00001: val_loss improved from inf to 1.78121, saving model to t_weights_1
9416/9416 [==============================] - 3s 267us/sample - loss: 2.1653 - categorical_accuracy: 0.2025 - val_loss: 1.7812 - val_categorical_accuracy: 0.3815
Epoch 2/100
9344/9416 [============================&gt;.] - ETA: 0s - loss: 1.6214 - categorical_accuracy: 0.4270
Epoch 00002: val_loss improved from 1.78121 to 1.36346, saving model to t_weights_1
9416/9416 [==============================] - 2s 226us/sample - loss: 1.6198 - categorical_accuracy: 0.4277 - val_loss: 1.3635 - val_categorical_accuracy: 0.5752
Epoch 3/100
9152/9416 [============================&gt;.] - ETA: 0s - loss: 1.3030 - categorical_accuracy: 0.5561
Epoch 00003: val_loss improved from 1.36346 to 1.06205, saving model to t_weights_1
9416/9416 [==============================] - 2s 229us/sample - loss: 1.3029 - categorical_accuracy: 0.5560 - val_loss: 1.0621 - val_categorical_accuracy: 0.7043
Epoch 4/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 1.0420 - categorical_accuracy: 0.6480
Epoch 00004: val_loss improved from 1.06205 to 0.89397, saving model to t_weights_1
9416/9416 [==============================] - 2s 232us/sample - loss: 1.0401 - categorical_accuracy: 0.6488 - val_loss: 0.8940 - val_categorical_accuracy: 0.7341
Epoch 5/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.8366 - categorical_accuracy: 0.7246
Epoch 00005: val_loss improved from 0.89397 to 0.67078, saving model to t_weights_1
9416/9416 [==============================] - 2s 235us/sample - loss: 0.8347 - categorical_accuracy: 0.7254 - val_loss: 0.6708 - val_categorical_accuracy: 0.8233
Epoch 6/100
9376/9416 [============================&gt;.] - ETA: 0s - loss: 0.6940 - categorical_accuracy: 0.7771
Epoch 00006: val_loss improved from 0.67078 to 0.51202, saving model to t_weights_1
9416/9416 [==============================] - 2s 233us/sample - loss: 0.6940 - categorical_accuracy: 0.7771 - val_loss: 0.5120 - val_categorical_accuracy: 0.8811
Epoch 7/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.5634 - categorical_accuracy: 0.8197
Epoch 00007: val_loss improved from 0.51202 to 0.43157, saving model to t_weights_1
9416/9416 [==============================] - 2s 228us/sample - loss: 0.5629 - categorical_accuracy: 0.8200 - val_loss: 0.4316 - val_categorical_accuracy: 0.9099
Epoch 8/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.4832 - categorical_accuracy: 0.8540
Epoch 00008: val_loss improved from 0.43157 to 0.39175, saving model to t_weights_1
9416/9416 [==============================] - 2s 229us/sample - loss: 0.4826 - categorical_accuracy: 0.8541 - val_loss: 0.3918 - val_categorical_accuracy: 0.9057
Epoch 9/100
9408/9416 [============================&gt;.] - ETA: 0s - loss: 0.4259 - categorical_accuracy: 0.8700
Epoch 00009: val_loss improved from 0.39175 to 0.32164, saving model to t_weights_1
9416/9416 [==============================] - 2s 232us/sample - loss: 0.4256 - categorical_accuracy: 0.8701 - val_loss: 0.3216 - val_categorical_accuracy: 0.9252
Epoch 10/100
9184/9416 [============================&gt;.] - ETA: 0s - loss: 0.3781 - categorical_accuracy: 0.8898
Epoch 00010: val_loss improved from 0.32164 to 0.29934, saving model to t_weights_1
9416/9416 [==============================] - 2s 231us/sample - loss: 0.3780 - categorical_accuracy: 0.8898 - val_loss: 0.2993 - val_categorical_accuracy: 0.9329
Epoch 11/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.3527 - categorical_accuracy: 0.8923
Epoch 00011: val_loss did not improve from 0.29934
9416/9416 [==============================] - 2s 221us/sample - loss: 0.3509 - categorical_accuracy: 0.8933 - val_loss: 0.3280 - val_categorical_accuracy: 0.9227
Epoch 12/100
9312/9416 [============================&gt;.] - ETA: 0s - loss: 0.3102 - categorical_accuracy: 0.9098
Epoch 00012: val_loss improved from 0.29934 to 0.27079, saving model to t_weights_1
9416/9416 [==============================] - 2s 231us/sample - loss: 0.3115 - categorical_accuracy: 0.9094 - val_loss: 0.2708 - val_categorical_accuracy: 0.9388
Epoch 13/100
9280/9416 [============================&gt;.] - ETA: 0s - loss: 0.2859 - categorical_accuracy: 0.9154
Epoch 00013: val_loss did not improve from 0.27079
9416/9416 [==============================] - 2s 226us/sample - loss: 0.2874 - categorical_accuracy: 0.9148 - val_loss: 0.2778 - val_categorical_accuracy: 0.9320
Epoch 14/100
9312/9416 [============================&gt;.] - ETA: 0s - loss: 0.2867 - categorical_accuracy: 0.9149
Epoch 00014: val_loss improved from 0.27079 to 0.25703, saving model to t_weights_1
9416/9416 [==============================] - 2s 236us/sample - loss: 0.2865 - categorical_accuracy: 0.9149 - val_loss: 0.2570 - val_categorical_accuracy: 0.9465
Epoch 15/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.2440 - categorical_accuracy: 0.9284
Epoch 00015: val_loss improved from 0.25703 to 0.25381, saving model to t_weights_1
9416/9416 [==============================] - 2s 229us/sample - loss: 0.2429 - categorical_accuracy: 0.9287 - val_loss: 0.2538 - val_categorical_accuracy: 0.9414
Epoch 16/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.2358 - categorical_accuracy: 0.9281
Epoch 00016: val_loss improved from 0.25381 to 0.23319, saving model to t_weights_1
9416/9416 [==============================] - 2s 230us/sample - loss: 0.2347 - categorical_accuracy: 0.9286 - val_loss: 0.2332 - val_categorical_accuracy: 0.9482
Epoch 17/100
9184/9416 [============================&gt;.] - ETA: 0s - loss: 0.2322 - categorical_accuracy: 0.9299
Epoch 00017: val_loss did not improve from 0.23319
9416/9416 [==============================] - 2s 223us/sample - loss: 0.2322 - categorical_accuracy: 0.9299 - val_loss: 0.2381 - val_categorical_accuracy: 0.9431
Epoch 18/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.2207 - categorical_accuracy: 0.9339
Epoch 00018: val_loss did not improve from 0.23319
9416/9416 [==============================] - 2s 223us/sample - loss: 0.2215 - categorical_accuracy: 0.9340 - val_loss: 0.2851 - val_categorical_accuracy: 0.9320
Epoch 19/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.2133 - categorical_accuracy: 0.9378
Epoch 00019: val_loss did not improve from 0.23319
9416/9416 [==============================] - 2s 221us/sample - loss: 0.2142 - categorical_accuracy: 0.9371 - val_loss: 0.2422 - val_categorical_accuracy: 0.9465
Epoch 20/100
9152/9416 [============================&gt;.] - ETA: 0s - loss: 0.2108 - categorical_accuracy: 0.9356
Epoch 00020: val_loss did not improve from 0.23319
9416/9416 [==============================] - 2s 223us/sample - loss: 0.2119 - categorical_accuracy: 0.9350 - val_loss: 0.2404 - val_categorical_accuracy: 0.9456
Epoch 21/100
9312/9416 [============================&gt;.] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9398
Epoch 00021: val_loss did not improve from 0.23319
9416/9416 [==============================] - 2s 225us/sample - loss: 0.2003 - categorical_accuracy: 0.9395 - val_loss: 0.2527 - val_categorical_accuracy: 0.9516
0.9379779 0.25112244897959185


nrx: 10 - real: 4 
Train on 17256 samples, validate on 2157 samples
Epoch 1/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 2.0457 - categorical_accuracy: 0.2370
Epoch 00001: val_loss improved from inf to 1.56823, saving model to t_weights_1
17256/17256 [==============================] - 4s 243us/sample - loss: 2.0448 - categorical_accuracy: 0.2373 - val_loss: 1.5682 - val_categorical_accuracy: 0.4775
Epoch 2/100
17024/17256 [============================&gt;.] - ETA: 0s - loss: 1.5310 - categorical_accuracy: 0.4564
Epoch 00002: val_loss improved from 1.56823 to 1.19382, saving model to t_weights_1
17256/17256 [==============================] - 4s 225us/sample - loss: 1.5289 - categorical_accuracy: 0.4569 - val_loss: 1.1938 - val_categorical_accuracy: 0.6208
Epoch 3/100
17152/17256 [============================&gt;.] - ETA: 0s - loss: 1.2092 - categorical_accuracy: 0.5805
Epoch 00003: val_loss improved from 1.19382 to 0.97840, saving model to t_weights_1
17256/17256 [==============================] - 4s 209us/sample - loss: 1.2097 - categorical_accuracy: 0.5803 - val_loss: 0.9784 - val_categorical_accuracy: 0.6764
Epoch 4/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 1.0021 - categorical_accuracy: 0.6623
Epoch 00004: val_loss improved from 0.97840 to 0.83837, saving model to t_weights_1
17256/17256 [==============================] - 4s 224us/sample - loss: 1.0021 - categorical_accuracy: 0.6623 - val_loss: 0.8384 - val_categorical_accuracy: 0.7399
Epoch 5/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.8323 - categorical_accuracy: 0.7293
Epoch 00005: val_loss improved from 0.83837 to 0.66200, saving model to t_weights_1
17256/17256 [==============================] - 4s 223us/sample - loss: 0.8321 - categorical_accuracy: 0.7294 - val_loss: 0.6620 - val_categorical_accuracy: 0.7974
Epoch 6/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.7063 - categorical_accuracy: 0.7781
Epoch 00006: val_loss improved from 0.66200 to 0.54009, saving model to t_weights_1
17256/17256 [==============================] - 4s 220us/sample - loss: 0.7066 - categorical_accuracy: 0.7781 - val_loss: 0.5401 - val_categorical_accuracy: 0.8340
Epoch 7/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.5993 - categorical_accuracy: 0.8097
Epoch 00007: val_loss improved from 0.54009 to 0.46327, saving model to t_weights_1
17256/17256 [==============================] - 4s 228us/sample - loss: 0.5989 - categorical_accuracy: 0.8099 - val_loss: 0.4633 - val_categorical_accuracy: 0.8605
Epoch 8/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 0.5255 - categorical_accuracy: 0.8354
Epoch 00008: val_loss improved from 0.46327 to 0.43107, saving model to t_weights_1
17256/17256 [==============================] - 4s 223us/sample - loss: 0.5254 - categorical_accuracy: 0.8354 - val_loss: 0.4311 - val_categorical_accuracy: 0.8725
Epoch 9/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.4674 - categorical_accuracy: 0.8581
Epoch 00009: val_loss improved from 0.43107 to 0.37756, saving model to t_weights_1
17256/17256 [==============================] - 4s 227us/sample - loss: 0.4674 - categorical_accuracy: 0.8581 - val_loss: 0.3776 - val_categorical_accuracy: 0.8920
Epoch 10/100
17152/17256 [============================&gt;.] - ETA: 0s - loss: 0.4239 - categorical_accuracy: 0.8729
Epoch 00010: val_loss did not improve from 0.37756
17256/17256 [==============================] - 4s 220us/sample - loss: 0.4243 - categorical_accuracy: 0.8728 - val_loss: 0.3863 - val_categorical_accuracy: 0.8924
Epoch 11/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.3964 - categorical_accuracy: 0.8804
Epoch 00011: val_loss improved from 0.37756 to 0.32143, saving model to t_weights_1
17256/17256 [==============================] - 4s 222us/sample - loss: 0.3960 - categorical_accuracy: 0.8805 - val_loss: 0.3214 - val_categorical_accuracy: 0.9128
Epoch 12/100
17056/17256 [============================&gt;.] - ETA: 0s - loss: 0.3620 - categorical_accuracy: 0.8909
Epoch 00012: val_loss improved from 0.32143 to 0.30770, saving model to t_weights_1
17256/17256 [==============================] - 4s 226us/sample - loss: 0.3613 - categorical_accuracy: 0.8914 - val_loss: 0.3077 - val_categorical_accuracy: 0.9133
Epoch 13/100
17088/17256 [============================&gt;.] - ETA: 0s - loss: 0.3497 - categorical_accuracy: 0.8923
Epoch 00013: val_loss improved from 0.30770 to 0.30638, saving model to t_weights_1
17256/17256 [==============================] - 4s 224us/sample - loss: 0.3495 - categorical_accuracy: 0.8923 - val_loss: 0.3064 - val_categorical_accuracy: 0.9152
Epoch 14/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.3260 - categorical_accuracy: 0.9026
Epoch 00014: val_loss improved from 0.30638 to 0.30323, saving model to t_weights_1
17256/17256 [==============================] - 4s 228us/sample - loss: 0.3270 - categorical_accuracy: 0.9024 - val_loss: 0.3032 - val_categorical_accuracy: 0.9207
Epoch 15/100
17088/17256 [============================&gt;.] - ETA: 0s - loss: 0.3089 - categorical_accuracy: 0.9073
Epoch 00015: val_loss improved from 0.30323 to 0.29880, saving model to t_weights_1
17256/17256 [==============================] - 4s 220us/sample - loss: 0.3099 - categorical_accuracy: 0.9069 - val_loss: 0.2988 - val_categorical_accuracy: 0.9179
Epoch 16/100
17152/17256 [============================&gt;.] - ETA: 0s - loss: 0.2964 - categorical_accuracy: 0.9121
Epoch 00016: val_loss improved from 0.29880 to 0.28412, saving model to t_weights_1
17256/17256 [==============================] - 4s 227us/sample - loss: 0.2962 - categorical_accuracy: 0.9123 - val_loss: 0.2841 - val_categorical_accuracy: 0.9179
Epoch 17/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.2914 - categorical_accuracy: 0.9132
Epoch 00017: val_loss improved from 0.28412 to 0.27426, saving model to t_weights_1
17256/17256 [==============================] - 4s 224us/sample - loss: 0.2912 - categorical_accuracy: 0.9131 - val_loss: 0.2743 - val_categorical_accuracy: 0.9240
Epoch 18/100
17024/17256 [============================&gt;.] - ETA: 0s - loss: 0.2766 - categorical_accuracy: 0.9171
Epoch 00018: val_loss did not improve from 0.27426
17256/17256 [==============================] - 4s 218us/sample - loss: 0.2766 - categorical_accuracy: 0.9168 - val_loss: 0.2996 - val_categorical_accuracy: 0.9175
Epoch 19/100
17056/17256 [============================&gt;.] - ETA: 0s - loss: 0.2803 - categorical_accuracy: 0.9164
Epoch 00019: val_loss improved from 0.27426 to 0.27030, saving model to t_weights_1
17256/17256 [==============================] - 4s 219us/sample - loss: 0.2802 - categorical_accuracy: 0.9163 - val_loss: 0.2703 - val_categorical_accuracy: 0.9263
Epoch 20/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.2592 - categorical_accuracy: 0.9221
Epoch 00020: val_loss did not improve from 0.27030
17256/17256 [==============================] - 4s 221us/sample - loss: 0.2594 - categorical_accuracy: 0.9219 - val_loss: 0.2842 - val_categorical_accuracy: 0.9286
Epoch 21/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.2502 - categorical_accuracy: 0.9250
Epoch 00021: val_loss did not improve from 0.27030
17256/17256 [==============================] - 4s 223us/sample - loss: 0.2501 - categorical_accuracy: 0.9250 - val_loss: 0.2715 - val_categorical_accuracy: 0.9268
Epoch 22/100
17056/17256 [============================&gt;.] - ETA: 0s - loss: 0.2552 - categorical_accuracy: 0.9233
Epoch 00022: val_loss improved from 0.27030 to 0.26295, saving model to t_weights_1
17256/17256 [==============================] - 4s 222us/sample - loss: 0.2553 - categorical_accuracy: 0.9234 - val_loss: 0.2629 - val_categorical_accuracy: 0.9309
Epoch 23/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.2438 - categorical_accuracy: 0.9261
Epoch 00023: val_loss did not improve from 0.26295
17256/17256 [==============================] - 4s 223us/sample - loss: 0.2440 - categorical_accuracy: 0.9260 - val_loss: 0.2741 - val_categorical_accuracy: 0.9277
Epoch 24/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 0.2380 - categorical_accuracy: 0.9293
Epoch 00024: val_loss improved from 0.26295 to 0.24627, saving model to t_weights_1
17256/17256 [==============================] - 4s 224us/sample - loss: 0.2380 - categorical_accuracy: 0.9294 - val_loss: 0.2463 - val_categorical_accuracy: 0.9314
Epoch 25/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.2290 - categorical_accuracy: 0.9320
Epoch 00025: val_loss did not improve from 0.24627
17256/17256 [==============================] - 4s 218us/sample - loss: 0.2291 - categorical_accuracy: 0.9320 - val_loss: 0.2971 - val_categorical_accuracy: 0.9277
Epoch 26/100
17056/17256 [============================&gt;.] - ETA: 0s - loss: 0.2337 - categorical_accuracy: 0.9297
Epoch 00026: val_loss did not improve from 0.24627
17256/17256 [==============================] - 4s 222us/sample - loss: 0.2335 - categorical_accuracy: 0.9298 - val_loss: 0.2647 - val_categorical_accuracy: 0.9332
Epoch 27/100
17056/17256 [============================&gt;.] - ETA: 0s - loss: 0.2259 - categorical_accuracy: 0.9309
Epoch 00027: val_loss did not improve from 0.24627
17256/17256 [==============================] - 4s 221us/sample - loss: 0.2253 - categorical_accuracy: 0.9312 - val_loss: 0.2558 - val_categorical_accuracy: 0.9360
Epoch 28/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.2285 - categorical_accuracy: 0.9330
Epoch 00028: val_loss did not improve from 0.24627
17256/17256 [==============================] - 4s 223us/sample - loss: 0.2288 - categorical_accuracy: 0.9328 - val_loss: 0.2702 - val_categorical_accuracy: 0.9309
Epoch 29/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.2170 - categorical_accuracy: 0.9335
Epoch 00029: val_loss did not improve from 0.24627
17256/17256 [==============================] - 4s 220us/sample - loss: 0.2166 - categorical_accuracy: 0.9336 - val_loss: 0.2831 - val_categorical_accuracy: 0.9268
0.94112194 0.2436734693877551


nrx: 15 - real: 4 
Train on 25096 samples, validate on 3137 samples
Epoch 1/100
24896/25096 [============================&gt;.] - ETA: 0s - loss: 1.9143 - categorical_accuracy: 0.2809
Epoch 00001: val_loss improved from inf to 1.52526, saving model to t_weights_1
25096/25096 [==============================] - 6s 239us/sample - loss: 1.9117 - categorical_accuracy: 0.2819 - val_loss: 1.5253 - val_categorical_accuracy: 0.4523
Epoch 2/100
24928/25096 [============================&gt;.] - ETA: 0s - loss: 1.4716 - categorical_accuracy: 0.4579
Epoch 00002: val_loss improved from 1.52526 to 1.25462, saving model to t_weights_1
25096/25096 [==============================] - 6s 225us/sample - loss: 1.4706 - categorical_accuracy: 0.4582 - val_loss: 1.2546 - val_categorical_accuracy: 0.5958
Epoch 3/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 1.2360 - categorical_accuracy: 0.5681
Epoch 00003: val_loss improved from 1.25462 to 1.01848, saving model to t_weights_1
25096/25096 [==============================] - 6s 220us/sample - loss: 1.2356 - categorical_accuracy: 0.5685 - val_loss: 1.0185 - val_categorical_accuracy: 0.6662
Epoch 4/100
24864/25096 [============================&gt;.] - ETA: 0s - loss: 1.0479 - categorical_accuracy: 0.6422
Epoch 00004: val_loss improved from 1.01848 to 0.88149, saving model to t_weights_1
25096/25096 [==============================] - 6s 224us/sample - loss: 1.0481 - categorical_accuracy: 0.6420 - val_loss: 0.8815 - val_categorical_accuracy: 0.7233
Epoch 5/100
24896/25096 [============================&gt;.] - ETA: 0s - loss: 0.9009 - categorical_accuracy: 0.6986
Epoch 00005: val_loss improved from 0.88149 to 0.78427, saving model to t_weights_1
25096/25096 [==============================] - 6s 223us/sample - loss: 0.9011 - categorical_accuracy: 0.6987 - val_loss: 0.7843 - val_categorical_accuracy: 0.7427
Epoch 6/100
24928/25096 [============================&gt;.] - ETA: 0s - loss: 0.7703 - categorical_accuracy: 0.7455
Epoch 00006: val_loss improved from 0.78427 to 0.60372, saving model to t_weights_1
25096/25096 [==============================] - 6s 222us/sample - loss: 0.7691 - categorical_accuracy: 0.7459 - val_loss: 0.6037 - val_categorical_accuracy: 0.8215
Epoch 7/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.6675 - categorical_accuracy: 0.7883
Epoch 00007: val_loss improved from 0.60372 to 0.52421, saving model to t_weights_1
25096/25096 [==============================] - 6s 223us/sample - loss: 0.6671 - categorical_accuracy: 0.7886 - val_loss: 0.5242 - val_categorical_accuracy: 0.8441
Epoch 8/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.5771 - categorical_accuracy: 0.8207
Epoch 00008: val_loss improved from 0.52421 to 0.44581, saving model to t_weights_1
25096/25096 [==============================] - 6s 225us/sample - loss: 0.5770 - categorical_accuracy: 0.8207 - val_loss: 0.4458 - val_categorical_accuracy: 0.8757
Epoch 9/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.5060 - categorical_accuracy: 0.8460
Epoch 00009: val_loss improved from 0.44581 to 0.39695, saving model to t_weights_1
25096/25096 [==============================] - 6s 223us/sample - loss: 0.5057 - categorical_accuracy: 0.8460 - val_loss: 0.3970 - val_categorical_accuracy: 0.8932
Epoch 10/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.4461 - categorical_accuracy: 0.8680
Epoch 00010: val_loss improved from 0.39695 to 0.36648, saving model to t_weights_1
25096/25096 [==============================] - 6s 219us/sample - loss: 0.4460 - categorical_accuracy: 0.8680 - val_loss: 0.3665 - val_categorical_accuracy: 0.8996
Epoch 11/100
24864/25096 [============================&gt;.] - ETA: 0s - loss: 0.4050 - categorical_accuracy: 0.8771
Epoch 00011: val_loss improved from 0.36648 to 0.34515, saving model to t_weights_1
25096/25096 [==============================] - 6s 221us/sample - loss: 0.4056 - categorical_accuracy: 0.8770 - val_loss: 0.3451 - val_categorical_accuracy: 0.8980
Epoch 12/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.3768 - categorical_accuracy: 0.8869
Epoch 00012: val_loss improved from 0.34515 to 0.33826, saving model to t_weights_1
25096/25096 [==============================] - 6s 225us/sample - loss: 0.3765 - categorical_accuracy: 0.8872 - val_loss: 0.3383 - val_categorical_accuracy: 0.9079
Epoch 13/100
24864/25096 [============================&gt;.] - ETA: 0s - loss: 0.3418 - categorical_accuracy: 0.8987
Epoch 00013: val_loss improved from 0.33826 to 0.30443, saving model to t_weights_1
25096/25096 [==============================] - 6s 224us/sample - loss: 0.3416 - categorical_accuracy: 0.8987 - val_loss: 0.3044 - val_categorical_accuracy: 0.9142
Epoch 14/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.3280 - categorical_accuracy: 0.9039
Epoch 00014: val_loss improved from 0.30443 to 0.27987, saving model to t_weights_1
25096/25096 [==============================] - 5s 212us/sample - loss: 0.3278 - categorical_accuracy: 0.9039 - val_loss: 0.2799 - val_categorical_accuracy: 0.9238
Epoch 15/100
24896/25096 [============================&gt;.] - ETA: 0s - loss: 0.2992 - categorical_accuracy: 0.9129
Epoch 00015: val_loss improved from 0.27987 to 0.27564, saving model to t_weights_1
25096/25096 [==============================] - 6s 223us/sample - loss: 0.2991 - categorical_accuracy: 0.9129 - val_loss: 0.2756 - val_categorical_accuracy: 0.9248
Epoch 16/100
24864/25096 [============================&gt;.] - ETA: 0s - loss: 0.2947 - categorical_accuracy: 0.9140
Epoch 00016: val_loss did not improve from 0.27564
25096/25096 [==============================] - 6s 222us/sample - loss: 0.2952 - categorical_accuracy: 0.9140 - val_loss: 0.3074 - val_categorical_accuracy: 0.9216
Epoch 17/100
24864/25096 [============================&gt;.] - ETA: 0s - loss: 0.2769 - categorical_accuracy: 0.9189
Epoch 00017: val_loss improved from 0.27564 to 0.26656, saving model to t_weights_1
25096/25096 [==============================] - 6s 225us/sample - loss: 0.2764 - categorical_accuracy: 0.9192 - val_loss: 0.2666 - val_categorical_accuracy: 0.9289
Epoch 18/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.2645 - categorical_accuracy: 0.9232
Epoch 00018: val_loss improved from 0.26656 to 0.26076, saving model to t_weights_1
25096/25096 [==============================] - 6s 220us/sample - loss: 0.2644 - categorical_accuracy: 0.9233 - val_loss: 0.2608 - val_categorical_accuracy: 0.9343
Epoch 19/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.2533 - categorical_accuracy: 0.9253
Epoch 00019: val_loss improved from 0.26076 to 0.26009, saving model to t_weights_1
25096/25096 [==============================] - 6s 224us/sample - loss: 0.2529 - categorical_accuracy: 0.9254 - val_loss: 0.2601 - val_categorical_accuracy: 0.9318
Epoch 20/100
25056/25096 [============================&gt;.] - ETA: 0s - loss: 0.2412 - categorical_accuracy: 0.9300
Epoch 00020: val_loss did not improve from 0.26009
25096/25096 [==============================] - 6s 221us/sample - loss: 0.2412 - categorical_accuracy: 0.9300 - val_loss: 0.2682 - val_categorical_accuracy: 0.9264
Epoch 21/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.2350 - categorical_accuracy: 0.9315
Epoch 00021: val_loss did not improve from 0.26009
25096/25096 [==============================] - 6s 221us/sample - loss: 0.2347 - categorical_accuracy: 0.9315 - val_loss: 0.2752 - val_categorical_accuracy: 0.9327
Epoch 22/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.2304 - categorical_accuracy: 0.9331
Epoch 00022: val_loss did not improve from 0.26009
25096/25096 [==============================] - 6s 220us/sample - loss: 0.2308 - categorical_accuracy: 0.9330 - val_loss: 0.2640 - val_categorical_accuracy: 0.9331
Epoch 23/100
24928/25096 [============================&gt;.] - ETA: 0s - loss: 0.2229 - categorical_accuracy: 0.9368
Epoch 00023: val_loss did not improve from 0.26009
25096/25096 [==============================] - 6s 221us/sample - loss: 0.2229 - categorical_accuracy: 0.9367 - val_loss: 0.2641 - val_categorical_accuracy: 0.9347
Epoch 24/100
24928/25096 [============================&gt;.] - ETA: 0s - loss: 0.2214 - categorical_accuracy: 0.9358
Epoch 00024: val_loss did not improve from 0.26009
25096/25096 [==============================] - 6s 221us/sample - loss: 0.2214 - categorical_accuracy: 0.9358 - val_loss: 0.2736 - val_categorical_accuracy: 0.9369
0.93465096 0.3486734693877551


nrx: 20 - real: 4 
Train on 32936 samples, validate on 4117 samples
Epoch 1/100
32896/32936 [============================&gt;.] - ETA: 0s - loss: 1.8792 - categorical_accuracy: 0.2937
Epoch 00001: val_loss improved from inf to 1.48137, saving model to t_weights_1
32936/32936 [==============================] - 8s 237us/sample - loss: 1.8788 - categorical_accuracy: 0.2938 - val_loss: 1.4814 - val_categorical_accuracy: 0.4889
Epoch 2/100
32864/32936 [============================&gt;.] - ETA: 0s - loss: 1.3711 - categorical_accuracy: 0.5041
Epoch 00002: val_loss improved from 1.48137 to 1.17268, saving model to t_weights_1
32936/32936 [==============================] - 7s 225us/sample - loss: 1.3712 - categorical_accuracy: 0.5040 - val_loss: 1.1727 - val_categorical_accuracy: 0.6094
Epoch 3/100
32896/32936 [============================&gt;.] - ETA: 0s - loss: 1.0822 - categorical_accuracy: 0.6217
Epoch 00003: val_loss improved from 1.17268 to 0.87536, saving model to t_weights_1
32936/32936 [==============================] - 7s 225us/sample - loss: 1.0824 - categorical_accuracy: 0.6217 - val_loss: 0.8754 - val_categorical_accuracy: 0.7148
Epoch 4/100
32896/32936 [============================&gt;.] - ETA: 0s - loss: 0.8784 - categorical_accuracy: 0.7060
Epoch 00004: val_loss improved from 0.87536 to 0.68312, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.8783 - categorical_accuracy: 0.7059 - val_loss: 0.6831 - val_categorical_accuracy: 0.7819
Epoch 5/100
32768/32936 [============================&gt;.] - ETA: 0s - loss: 0.7435 - categorical_accuracy: 0.7537
Epoch 00005: val_loss improved from 0.68312 to 0.58328, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.7430 - categorical_accuracy: 0.7540 - val_loss: 0.5833 - val_categorical_accuracy: 0.8237
Epoch 6/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.6368 - categorical_accuracy: 0.7925
Epoch 00006: val_loss improved from 0.58328 to 0.49972, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.6358 - categorical_accuracy: 0.7930 - val_loss: 0.4997 - val_categorical_accuracy: 0.8494
Epoch 7/100
32800/32936 [============================&gt;.] - ETA: 0s - loss: 0.5634 - categorical_accuracy: 0.8210
Epoch 00007: val_loss improved from 0.49972 to 0.48817, saving model to t_weights_1
32936/32936 [==============================] - 7s 225us/sample - loss: 0.5636 - categorical_accuracy: 0.8210 - val_loss: 0.4882 - val_categorical_accuracy: 0.8487
Epoch 8/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.5030 - categorical_accuracy: 0.8436
Epoch 00008: val_loss improved from 0.48817 to 0.41715, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.5024 - categorical_accuracy: 0.8437 - val_loss: 0.4171 - val_categorical_accuracy: 0.8817
Epoch 9/100
32704/32936 [============================&gt;.] - ETA: 0s - loss: 0.4482 - categorical_accuracy: 0.8614
Epoch 00009: val_loss improved from 0.41715 to 0.36531, saving model to t_weights_1
32936/32936 [==============================] - 7s 219us/sample - loss: 0.4484 - categorical_accuracy: 0.8612 - val_loss: 0.3653 - val_categorical_accuracy: 0.8934
Epoch 10/100
32864/32936 [============================&gt;.] - ETA: 0s - loss: 0.4165 - categorical_accuracy: 0.8735
Epoch 00010: val_loss improved from 0.36531 to 0.33477, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.4162 - categorical_accuracy: 0.8736 - val_loss: 0.3348 - val_categorical_accuracy: 0.9055
Epoch 11/100
32768/32936 [============================&gt;.] - ETA: 0s - loss: 0.3815 - categorical_accuracy: 0.8839
Epoch 00011: val_loss improved from 0.33477 to 0.32398, saving model to t_weights_1
32936/32936 [==============================] - 7s 225us/sample - loss: 0.3816 - categorical_accuracy: 0.8838 - val_loss: 0.3240 - val_categorical_accuracy: 0.9121
Epoch 12/100
32704/32936 [============================&gt;.] - ETA: 0s - loss: 0.3544 - categorical_accuracy: 0.8934
Epoch 00012: val_loss improved from 0.32398 to 0.31982, saving model to t_weights_1
32936/32936 [==============================] - 7s 224us/sample - loss: 0.3548 - categorical_accuracy: 0.8932 - val_loss: 0.3198 - val_categorical_accuracy: 0.9104
Epoch 13/100
32832/32936 [============================&gt;.] - ETA: 0s - loss: 0.3396 - categorical_accuracy: 0.8974
Epoch 00013: val_loss improved from 0.31982 to 0.29967, saving model to t_weights_1
32936/32936 [==============================] - 7s 224us/sample - loss: 0.3393 - categorical_accuracy: 0.8975 - val_loss: 0.2997 - val_categorical_accuracy: 0.9196
Epoch 14/100
32864/32936 [============================&gt;.] - ETA: 0s - loss: 0.3152 - categorical_accuracy: 0.9044
Epoch 00014: val_loss did not improve from 0.29967
32936/32936 [==============================] - 7s 223us/sample - loss: 0.3154 - categorical_accuracy: 0.9044 - val_loss: 0.3257 - val_categorical_accuracy: 0.9116
Epoch 15/100
32768/32936 [============================&gt;.] - ETA: 0s - loss: 0.3072 - categorical_accuracy: 0.9083
Epoch 00015: val_loss improved from 0.29967 to 0.27474, saving model to t_weights_1
32936/32936 [==============================] - 7s 224us/sample - loss: 0.3075 - categorical_accuracy: 0.9082 - val_loss: 0.2747 - val_categorical_accuracy: 0.9281
Epoch 16/100
32768/32936 [============================&gt;.] - ETA: 0s - loss: 0.2919 - categorical_accuracy: 0.9117
Epoch 00016: val_loss did not improve from 0.27474
32936/32936 [==============================] - 7s 223us/sample - loss: 0.2922 - categorical_accuracy: 0.9117 - val_loss: 0.2800 - val_categorical_accuracy: 0.9247
Epoch 17/100
32928/32936 [============================&gt;.] - ETA: 0s - loss: 0.2820 - categorical_accuracy: 0.9144
Epoch 00017: val_loss improved from 0.27474 to 0.27109, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.2822 - categorical_accuracy: 0.9144 - val_loss: 0.2711 - val_categorical_accuracy: 0.9266
Epoch 18/100
32864/32936 [============================&gt;.] - ETA: 0s - loss: 0.2752 - categorical_accuracy: 0.9160
Epoch 00018: val_loss did not improve from 0.27109
32936/32936 [==============================] - 7s 224us/sample - loss: 0.2754 - categorical_accuracy: 0.9159 - val_loss: 0.2818 - val_categorical_accuracy: 0.9264
Epoch 19/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.2670 - categorical_accuracy: 0.9204
Epoch 00019: val_loss improved from 0.27109 to 0.26303, saving model to t_weights_1
32936/32936 [==============================] - 7s 226us/sample - loss: 0.2669 - categorical_accuracy: 0.9204 - val_loss: 0.2630 - val_categorical_accuracy: 0.9334
Epoch 20/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.2581 - categorical_accuracy: 0.9212
Epoch 00020: val_loss did not improve from 0.26303
32936/32936 [==============================] - 7s 223us/sample - loss: 0.2581 - categorical_accuracy: 0.9212 - val_loss: 0.2877 - val_categorical_accuracy: 0.9211
Epoch 21/100
32896/32936 [============================&gt;.] - ETA: 0s - loss: 0.2519 - categorical_accuracy: 0.9259
Epoch 00021: val_loss did not improve from 0.26303
32936/32936 [==============================] - 7s 222us/sample - loss: 0.2518 - categorical_accuracy: 0.9259 - val_loss: 0.2634 - val_categorical_accuracy: 0.9344
Epoch 22/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.2426 - categorical_accuracy: 0.9274
Epoch 00022: val_loss improved from 0.26303 to 0.25468, saving model to t_weights_1
32936/32936 [==============================] - 7s 225us/sample - loss: 0.2422 - categorical_accuracy: 0.9276 - val_loss: 0.2547 - val_categorical_accuracy: 0.9371
Epoch 23/100
32800/32936 [============================&gt;.] - ETA: 0s - loss: 0.2378 - categorical_accuracy: 0.9299
Epoch 00023: val_loss did not improve from 0.25468
32936/32936 [==============================] - 7s 223us/sample - loss: 0.2386 - categorical_accuracy: 0.9298 - val_loss: 0.2663 - val_categorical_accuracy: 0.9359
Epoch 24/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.2368 - categorical_accuracy: 0.9304
Epoch 00024: val_loss did not improve from 0.25468
32936/32936 [==============================] - 7s 223us/sample - loss: 0.2368 - categorical_accuracy: 0.9304 - val_loss: 0.2722 - val_categorical_accuracy: 0.9334
Epoch 25/100
32736/32936 [============================&gt;.] - ETA: 0s - loss: 0.2257 - categorical_accuracy: 0.9326
Epoch 00025: val_loss did not improve from 0.25468
32936/32936 [==============================] - 7s 219us/sample - loss: 0.2260 - categorical_accuracy: 0.9326 - val_loss: 0.2884 - val_categorical_accuracy: 0.9334
Epoch 26/100
32704/32936 [============================&gt;.] - ETA: 0s - loss: 0.2255 - categorical_accuracy: 0.9333
Epoch 00026: val_loss did not improve from 0.25468
32936/32936 [==============================] - 7s 224us/sample - loss: 0.2255 - categorical_accuracy: 0.9332 - val_loss: 0.2825 - val_categorical_accuracy: 0.9361
Epoch 27/100
32864/32936 [============================&gt;.] - ETA: 0s - loss: 0.2229 - categorical_accuracy: 0.9349
Epoch 00027: val_loss did not improve from 0.25468
32936/32936 [==============================] - 7s 224us/sample - loss: 0.2230 - categorical_accuracy: 0.9348 - val_loss: 0.2593 - val_categorical_accuracy: 0.9376
0.94219095 0.45418367346938776


nrx: 25 - real: 4 
Train on 40296 samples, validate on 5037 samples
Epoch 1/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 1.8182 - categorical_accuracy: 0.3347
Epoch 00001: val_loss improved from inf to 1.41952, saving model to t_weights_1
40296/40296 [==============================] - 9s 231us/sample - loss: 1.8165 - categorical_accuracy: 0.3353 - val_loss: 1.4195 - val_categorical_accuracy: 0.4793
Epoch 2/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 1.2572 - categorical_accuracy: 0.5615
Epoch 00002: val_loss improved from 1.41952 to 0.95304, saving model to t_weights_1
40296/40296 [==============================] - 9s 220us/sample - loss: 1.2575 - categorical_accuracy: 0.5616 - val_loss: 0.9530 - val_categorical_accuracy: 0.6871
Epoch 3/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.9129 - categorical_accuracy: 0.6972
Epoch 00003: val_loss improved from 0.95304 to 0.67986, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.9128 - categorical_accuracy: 0.6973 - val_loss: 0.6799 - val_categorical_accuracy: 0.7951
Epoch 4/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.7115 - categorical_accuracy: 0.7694
Epoch 00004: val_loss improved from 0.67986 to 0.54568, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.7115 - categorical_accuracy: 0.7694 - val_loss: 0.5457 - val_categorical_accuracy: 0.8318
Epoch 5/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.5931 - categorical_accuracy: 0.8078
Epoch 00005: val_loss improved from 0.54568 to 0.44708, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.5934 - categorical_accuracy: 0.8077 - val_loss: 0.4471 - val_categorical_accuracy: 0.8628
Epoch 6/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.5164 - categorical_accuracy: 0.8366
Epoch 00006: val_loss improved from 0.44708 to 0.39130, saving model to t_weights_1
40296/40296 [==============================] - 9s 221us/sample - loss: 0.5163 - categorical_accuracy: 0.8367 - val_loss: 0.3913 - val_categorical_accuracy: 0.8829
Epoch 7/100
40192/40296 [============================&gt;.] - ETA: 0s - loss: 0.4495 - categorical_accuracy: 0.8595
Epoch 00007: val_loss improved from 0.39130 to 0.37494, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.4497 - categorical_accuracy: 0.8594 - val_loss: 0.3749 - val_categorical_accuracy: 0.8884
Epoch 8/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.4062 - categorical_accuracy: 0.8733
Epoch 00008: val_loss improved from 0.37494 to 0.33561, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.4061 - categorical_accuracy: 0.8733 - val_loss: 0.3356 - val_categorical_accuracy: 0.8980
Epoch 9/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.3758 - categorical_accuracy: 0.8844
Epoch 00009: val_loss improved from 0.33561 to 0.31646, saving model to t_weights_1
40296/40296 [==============================] - 9s 221us/sample - loss: 0.3758 - categorical_accuracy: 0.8844 - val_loss: 0.3165 - val_categorical_accuracy: 0.9063
Epoch 10/100
40128/40296 [============================&gt;.] - ETA: 0s - loss: 0.3499 - categorical_accuracy: 0.8910
Epoch 00010: val_loss improved from 0.31646 to 0.30736, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.3498 - categorical_accuracy: 0.8912 - val_loss: 0.3074 - val_categorical_accuracy: 0.9073
Epoch 11/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.3362 - categorical_accuracy: 0.8973
Epoch 00011: val_loss improved from 0.30736 to 0.29442, saving model to t_weights_1
40296/40296 [==============================] - 9s 222us/sample - loss: 0.3361 - categorical_accuracy: 0.8973 - val_loss: 0.2944 - val_categorical_accuracy: 0.9154
Epoch 12/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 0.3137 - categorical_accuracy: 0.9030
Epoch 00012: val_loss improved from 0.29442 to 0.27830, saving model to t_weights_1
40296/40296 [==============================] - 9s 218us/sample - loss: 0.3136 - categorical_accuracy: 0.9031 - val_loss: 0.2783 - val_categorical_accuracy: 0.9190
Epoch 13/100
40128/40296 [============================&gt;.] - ETA: 0s - loss: 0.3032 - categorical_accuracy: 0.9069
Epoch 00013: val_loss improved from 0.27830 to 0.27696, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.3037 - categorical_accuracy: 0.9068 - val_loss: 0.2770 - val_categorical_accuracy: 0.9180
Epoch 14/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2863 - categorical_accuracy: 0.9126
Epoch 00014: val_loss improved from 0.27696 to 0.26966, saving model to t_weights_1
40296/40296 [==============================] - 9s 221us/sample - loss: 0.2863 - categorical_accuracy: 0.9126 - val_loss: 0.2697 - val_categorical_accuracy: 0.9218
Epoch 15/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.2822 - categorical_accuracy: 0.9141
Epoch 00015: val_loss improved from 0.26966 to 0.26706, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.2822 - categorical_accuracy: 0.9141 - val_loss: 0.2671 - val_categorical_accuracy: 0.9236
Epoch 16/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2756 - categorical_accuracy: 0.9163
Epoch 00016: val_loss did not improve from 0.26706
40296/40296 [==============================] - 9s 220us/sample - loss: 0.2756 - categorical_accuracy: 0.9163 - val_loss: 0.2678 - val_categorical_accuracy: 0.9206
Epoch 17/100
40160/40296 [============================&gt;.] - ETA: 0s - loss: 0.2665 - categorical_accuracy: 0.9193
Epoch 00017: val_loss did not improve from 0.26706
40296/40296 [==============================] - 9s 219us/sample - loss: 0.2666 - categorical_accuracy: 0.9193 - val_loss: 0.2974 - val_categorical_accuracy: 0.9166
Epoch 18/100
40064/40296 [============================&gt;.] - ETA: 0s - loss: 0.2552 - categorical_accuracy: 0.9222
Epoch 00018: val_loss improved from 0.26706 to 0.24701, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.2553 - categorical_accuracy: 0.9223 - val_loss: 0.2470 - val_categorical_accuracy: 0.9297
Epoch 19/100
40160/40296 [============================&gt;.] - ETA: 0s - loss: 0.2541 - categorical_accuracy: 0.9243
Epoch 00019: val_loss did not improve from 0.24701
40296/40296 [==============================] - 9s 220us/sample - loss: 0.2541 - categorical_accuracy: 0.9243 - val_loss: 0.2727 - val_categorical_accuracy: 0.9277
Epoch 20/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.2408 - categorical_accuracy: 0.9269
Epoch 00020: val_loss improved from 0.24701 to 0.24434, saving model to t_weights_1
40296/40296 [==============================] - 9s 223us/sample - loss: 0.2410 - categorical_accuracy: 0.9269 - val_loss: 0.2443 - val_categorical_accuracy: 0.9297
Epoch 21/100
40288/40296 [============================&gt;.] - ETA: 0s - loss: 0.2414 - categorical_accuracy: 0.9266
Epoch 00021: val_loss did not improve from 0.24434
40296/40296 [==============================] - 9s 219us/sample - loss: 0.2414 - categorical_accuracy: 0.9266 - val_loss: 0.2472 - val_categorical_accuracy: 0.9339
Epoch 22/100
40256/40296 [============================&gt;.] - ETA: 0s - loss: 0.2343 - categorical_accuracy: 0.9305
Epoch 00022: val_loss improved from 0.24434 to 0.24009, saving model to t_weights_1
40296/40296 [==============================] - 9s 221us/sample - loss: 0.2343 - categorical_accuracy: 0.9305 - val_loss: 0.2401 - val_categorical_accuracy: 0.9327
Epoch 23/100
40096/40296 [============================&gt;.] - ETA: 0s - loss: 0.2315 - categorical_accuracy: 0.9318
Epoch 00023: val_loss did not improve from 0.24009
40296/40296 [==============================] - 9s 221us/sample - loss: 0.2313 - categorical_accuracy: 0.9318 - val_loss: 0.2522 - val_categorical_accuracy: 0.9329
Epoch 24/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.2242 - categorical_accuracy: 0.9336
Epoch 00024: val_loss did not improve from 0.24009
40296/40296 [==============================] - 9s 220us/sample - loss: 0.2248 - categorical_accuracy: 0.9335 - val_loss: 0.2436 - val_categorical_accuracy: 0.9359
Epoch 25/100
40128/40296 [============================&gt;.] - ETA: 0s - loss: 0.2201 - categorical_accuracy: 0.9342
Epoch 00025: val_loss did not improve from 0.24009
40296/40296 [==============================] - 9s 220us/sample - loss: 0.2201 - categorical_accuracy: 0.9341 - val_loss: 0.2748 - val_categorical_accuracy: 0.9261
Epoch 26/100
40224/40296 [============================&gt;.] - ETA: 0s - loss: 0.2227 - categorical_accuracy: 0.9331
Epoch 00026: val_loss did not improve from 0.24009
40296/40296 [==============================] - 9s 217us/sample - loss: 0.2227 - categorical_accuracy: 0.9331 - val_loss: 0.2509 - val_categorical_accuracy: 0.9327
Epoch 27/100
40032/40296 [============================&gt;.] - ETA: 0s - loss: 0.2150 - categorical_accuracy: 0.9365
Epoch 00027: val_loss did not improve from 0.24009
40296/40296 [==============================] - 9s 220us/sample - loss: 0.2143 - categorical_accuracy: 0.9368 - val_loss: 0.2601 - val_categorical_accuracy: 0.9349
0.9388525 0.633061224489796
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nrx_list</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[11]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[0, 5, 10, 15, 20, 25]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nrx_list</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">smTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">smTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">capsize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nrx_list</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">capsize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Same Rx(s)&#39;</span><span class="p">,</span><span class="s1">&#39;Diff. Rx&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;N Train Rx&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Class. Accuracy&#39;</span><span class="p">)</span>
<span class="c1">#plt.xticks(range(0,len(nrx_list),2))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.14654571428571428, 0.23802081632653058, 0.3718567346938776, 0.43385999999999997, 0.525595918367347, 0.7149644897959183]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nrx_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">real_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smTest_results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dfTestBal_results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;1-10&#39;, &#39;11-1&#39;, &#39;14-10&#39;, &#39;14-7&#39;, &#39;17-11&#39;, &#39;20-15&#39;, &#39;20-19&#39;, &#39;7-11&#39;, &#39;7-14&#39;, &#39;8-20&#39;]
[0, 5, 10, 15, 20, 25]
[0, 1, 2, 3, 4]
[[0.97, 0.9016949, 0.9229358, 0.92738855, 0.9196602, 0.919595], [1.0, 0.97192985, 0.9485577, 0.95681816, 0.93955225, 0.9280447], [1.0, 0.9649123, 0.9055267, 0.9359766, 0.922492, 0.9305913], [0.9722222, 0.9534483, 0.9466981, 0.946102, 0.9327089, 0.94680643], [0.995, 0.9379779, 0.94112194, 0.93465096, 0.94219095, 0.9388525]]
[[0.1456, 0.2524, 0.5632, 0.5513, 0.5226, 0.7212], [0.0907, 0.2325, 0.4219, 0.438, 0.6864, 0.7775], [0.15244897959183673, 0.15346938775510205, 0.3662244897959184, 0.42989795918367346, 0.4023469387755102, 0.8426530612244898], [0.15448979591836734, 0.3006122448979592, 0.2642857142857143, 0.4014285714285714, 0.5624489795918367, 0.6004081632653061], [0.18948979591836734, 0.25112244897959185, 0.2436734693877551, 0.3486734693877551, 0.45418367346938776, 0.633061224489796]]
[[0.1456, 0.2524, 0.5632, 0.5513, 0.5226, 0.7212], [0.0907, 0.2325, 0.4219, 0.438, 0.6864, 0.7775], [0.14975, 0.15175, 0.353375, 0.420875, 0.396125, 0.845625], [0.155375, 0.29675, 0.260625, 0.403, 0.565125, 0.596625], [0.190875, 0.247875, 0.245125, 0.349375, 0.457, 0.641125]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[&#39;19-20&#39;, &#39;24-13&#39;, &#39;19-2&#39;, &#39;1-20&#39;, &#39;20-20&#39;, &#39;20-1&#39;, &#39;7-7&#39;, &#39;3-19&#39;, &#39;23-6&#39;, &#39;2-19&#39;, &#39;24-5&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;24-6&#39;, &#39;24-16&#39;, &#39;1-19&#39;, &#39;8-8&#39;, &#39;18-19&#39;, &#39;13-7&#39;, &#39;23-3&#39;, &#39;8-14&#39;, &#39;23-5&#39;, &#39;19-19&#39;, &#39;18-2&#39;, &#39;7-14&#39;, &#39;13-14&#39;, &#39;1-1&#39;, &#39;23-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;], [&#39;1-1&#39;, &#39;23-1&#39;, &#39;24-6&#39;, &#39;8-8&#39;, &#39;1-19&#39;, &#39;23-3&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;19-19&#39;, &#39;13-14&#39;, &#39;23-6&#39;, &#39;7-7&#39;, &#39;19-1&#39;, &#39;20-1&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;8-14&#39;, &#39;19-2&#39;, &#39;14-7&#39;, &#39;1-20&#39;, &#39;13-7&#39;, &#39;24-5&#39;, &#39;18-2&#39;, &#39;2-19&#39;, &#39;24-13&#39;, &#39;19-20&#39;, &#39;3-19&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;, &#39;23-7&#39;, &#39;18-19&#39;], [&#39;24-5&#39;, &#39;23-7&#39;, &#39;18-19&#39;, &#39;23-3&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;2-1&#39;, &#39;13-7&#39;, &#39;19-19&#39;, &#39;19-2&#39;, &#39;18-2&#39;, &#39;1-20&#39;, &#39;20-1&#39;, &#39;24-16&#39;, &#39;3-19&#39;, &#39;1-19&#39;, &#39;24-13&#39;, &#39;23-6&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;1-1&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;7-7&#39;, &#39;2-19&#39;, &#39;23-5&#39;, &#39;8-8&#39;, &#39;19-20&#39;, &#39;13-14&#39;, &#39;7-14&#39;, &#39;23-1&#39;], [&#39;1-20&#39;, &#39;1-19&#39;, &#39;20-19&#39;, &#39;23-7&#39;, &#39;2-1&#39;, &#39;20-1&#39;, &#39;19-19&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;3-19&#39;, &#39;8-8&#39;, &#39;7-7&#39;, &#39;13-7&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;18-2&#39;, &#39;8-7&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;18-19&#39;, &#39;24-6&#39;, &#39;19-1&#39;, &#39;13-14&#39;, &#39;2-19&#39;, &#39;19-20&#39;, &#39;24-5&#39;, &#39;23-3&#39;, &#39;19-2&#39;, &#39;8-14&#39;, &#39;23-6&#39;, &#39;24-13&#39;, &#39;1-1&#39;], [&#39;18-19&#39;, &#39;20-1&#39;, &#39;13-14&#39;, &#39;18-2&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;13-7&#39;, &#39;19-20&#39;, &#39;2-19&#39;, &#39;19-19&#39;, &#39;19-1&#39;, &#39;1-20&#39;, &#39;24-5&#39;, &#39;20-19&#39;, &#39;8-7&#39;, &#39;23-1&#39;, &#39;7-7&#39;, &#39;8-8&#39;, &#39;2-1&#39;, &#39;1-19&#39;, &#39;3-19&#39;, &#39;23-3&#39;, &#39;23-6&#39;, &#39;23-5&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;24-16&#39;, &#39;7-14&#39;, &#39;1-1&#39;, &#39;19-2&#39;, &#39;24-13&#39;, &#39;23-7&#39;]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
