<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>d011_ManyRx_nrx_eq</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload

<span class="o">%</span><span class="k">autoreload</span> 2
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">os.path</span>

<span class="kn">import</span> <span class="nn">scipy</span><span class="o">,</span><span class="nn">scipy.spatial</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>

<span class="kn">from</span>  <span class="nn">data_utilities</span> <span class="k">import</span> <span class="o">*</span>
<span class="c1"># from definitions import *</span>
<span class="c1"># from run_train_eval_net import run_train_eval_net,run_eval_net</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">GPU</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_DEVICE_ORDER&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;PCI_BUS_ID&quot;</span>   
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">GPU</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">&#39;ManyRx&#39;</span>
<span class="n">dataset_path</span><span class="o">=</span><span class="s1">&#39;../../orbit_rf_dataset/data/compact_pkl_datasets/&#39;</span>

<span class="n">compact_dataset</span> <span class="o">=</span> <span class="n">load_compact_pkl_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span><span class="n">dataset_name</span><span class="p">)</span>

<span class="n">tx_list</span> <span class="o">=</span> <span class="n">compact_dataset</span><span class="p">[</span><span class="s1">&#39;tx_list&#39;</span><span class="p">]</span>
<span class="n">rx_list</span> <span class="o">=</span> <span class="n">compact_dataset</span><span class="p">[</span><span class="s1">&#39;rx_list&#39;</span><span class="p">]</span>

<span class="n">equalized</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">capture_date_list</span> <span class="o">=</span> <span class="n">compact_dataset</span><span class="p">[</span><span class="s1">&#39;capture_date_list&#39;</span><span class="p">]</span>
<span class="n">capture_date</span> <span class="o">=</span> <span class="n">capture_date_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">n_tx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)</span>
<span class="n">n_rx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">rx_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n_tx</span><span class="p">,</span><span class="n">n_rx</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>10 32
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_real</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">rx_list_real</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_real</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">rx_list</span><span class="p">)</span>
    <span class="n">rx_list_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">rx_list</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[&#39;19-20&#39;, &#39;24-13&#39;, &#39;19-2&#39;, &#39;1-20&#39;, &#39;20-20&#39;, &#39;20-1&#39;, &#39;7-7&#39;, &#39;3-19&#39;, &#39;23-6&#39;, &#39;2-19&#39;, &#39;24-5&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;24-6&#39;, &#39;24-16&#39;, &#39;1-19&#39;, &#39;8-8&#39;, &#39;18-19&#39;, &#39;13-7&#39;, &#39;23-3&#39;, &#39;8-14&#39;, &#39;23-5&#39;, &#39;19-19&#39;, &#39;18-2&#39;, &#39;7-14&#39;, &#39;13-14&#39;, &#39;1-1&#39;, &#39;23-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;], [&#39;1-1&#39;, &#39;23-1&#39;, &#39;24-6&#39;, &#39;8-8&#39;, &#39;1-19&#39;, &#39;23-3&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;19-19&#39;, &#39;13-14&#39;, &#39;23-6&#39;, &#39;7-7&#39;, &#39;19-1&#39;, &#39;20-1&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;8-14&#39;, &#39;19-2&#39;, &#39;14-7&#39;, &#39;1-20&#39;, &#39;13-7&#39;, &#39;24-5&#39;, &#39;18-2&#39;, &#39;2-19&#39;, &#39;24-13&#39;, &#39;19-20&#39;, &#39;3-19&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;, &#39;23-7&#39;, &#39;18-19&#39;], [&#39;24-5&#39;, &#39;23-7&#39;, &#39;18-19&#39;, &#39;23-3&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;2-1&#39;, &#39;13-7&#39;, &#39;19-19&#39;, &#39;19-2&#39;, &#39;18-2&#39;, &#39;1-20&#39;, &#39;20-1&#39;, &#39;24-16&#39;, &#39;3-19&#39;, &#39;1-19&#39;, &#39;24-13&#39;, &#39;23-6&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;1-1&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;7-7&#39;, &#39;2-19&#39;, &#39;23-5&#39;, &#39;8-8&#39;, &#39;19-20&#39;, &#39;13-14&#39;, &#39;7-14&#39;, &#39;23-1&#39;], [&#39;1-20&#39;, &#39;1-19&#39;, &#39;20-19&#39;, &#39;23-7&#39;, &#39;2-1&#39;, &#39;20-1&#39;, &#39;19-19&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;3-19&#39;, &#39;8-8&#39;, &#39;7-7&#39;, &#39;13-7&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;18-2&#39;, &#39;8-7&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;18-19&#39;, &#39;24-6&#39;, &#39;19-1&#39;, &#39;13-14&#39;, &#39;2-19&#39;, &#39;19-20&#39;, &#39;24-5&#39;, &#39;23-3&#39;, &#39;19-2&#39;, &#39;8-14&#39;, &#39;23-6&#39;, &#39;24-13&#39;, &#39;1-1&#39;], [&#39;18-19&#39;, &#39;20-1&#39;, &#39;13-14&#39;, &#39;18-2&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;13-7&#39;, &#39;19-20&#39;, &#39;2-19&#39;, &#39;19-19&#39;, &#39;19-1&#39;, &#39;1-20&#39;, &#39;24-5&#39;, &#39;20-19&#39;, &#39;8-7&#39;, &#39;23-1&#39;, &#39;7-7&#39;, &#39;8-8&#39;, &#39;2-1&#39;, &#39;1-19&#39;, &#39;3-19&#39;, &#39;23-3&#39;, &#39;23-6&#39;, &#39;23-5&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;24-16&#39;, &#39;7-14&#39;, &#39;1-1&#39;, &#39;19-2&#39;, &#39;24-13&#39;, &#39;23-7&#39;]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="k">import</span> <span class="n">regularizers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)])
/home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> <span class="k">def</span> <span class="nf">create_net</span><span class="p">():</span>


    <span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1">#x = resnet(x,64,(3,2),&#39;6&#39;)</span>
    <span class="c1">#x = MaxPool2D((2,2))(x)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>



    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># x = Dropout(0.3)(x)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n_tx</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ops</span> <span class="o">=</span> <span class="n">x</span>

    <span class="n">classifier</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">ops</span><span class="p">)</span>
    <span class="n">classifier</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;categorical_accuracy&#39;</span><span class="p">],</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0005</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">classifier</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">create_net</span><span class="p">()</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /home/samer/miniconda3/envs/mod_framework/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: &#34;model&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 2)]          0         
_________________________________________________________________
reshape (Reshape)            (None, 256, 2, 1)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 256, 2, 8)         56        
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 128, 2, 8)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 128, 2, 16)        784       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 64, 2, 16)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 64, 2, 16)         1552      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 1, 16)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 1, 32)         1568      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 16, 1, 32)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 1, 16)         1552      
_________________________________________________________________
flatten (Flatten)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 100)               25700     
_________________________________________________________________
dense_1 (Dense)              (None, 80)                8080      
_________________________________________________________________
dropout (Dropout)            (None, 80)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                810       
=================================================================
Total params: 40,102
Trainable params: 40,102
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_test</span><span class="p">(</span><span class="n">classifier</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sig_dfTest</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="n">txidNum_dfTest</span><span class="p">)</span>

    <span class="n">test_indx</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">indx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)):</span>
        <span class="n">cls_indx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">txidNum_dfTest</span> <span class="o">==</span> <span class="n">indx</span><span class="p">)</span>
        <span class="n">test_indx</span> <span class="o">=</span> <span class="n">test_indx</span> <span class="o">+</span> <span class="p">(</span><span class="n">cls_indx</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">n_test_samples</span><span class="p">],)</span>
    <span class="n">test_indx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_indx</span><span class="p">)</span> 
    <span class="n">acc_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">test_indx</span><span class="p">,:],</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="n">txidNum_dfTest</span><span class="p">[</span><span class="n">test_indx</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">acc</span><span class="p">,</span><span class="n">acc_bal</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_test_rx</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">n_test_rx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[9]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[0, 5, 10, 15, 20, 25]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">TRAIN</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">continue_training</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">nreal</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">real_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nreal</span><span class="p">))</span>
<span class="n">nrx_list</span> <span class="o">=</span>  <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">n_test_rx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span> 

<span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">smTest_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dfTest_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dfTestBal_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">real</span> <span class="ow">in</span> <span class="n">real_list</span><span class="p">:</span>
    <span class="n">rx_list</span> <span class="o">=</span> <span class="n">rx_list_real</span><span class="p">[</span><span class="n">real</span><span class="p">]</span>
    <span class="n">rx_test_list</span> <span class="o">=</span> <span class="n">rx_list</span><span class="p">[</span><span class="o">-</span><span class="n">n_test_rx</span><span class="p">:]</span>
    <span class="n">test_dataset</span> <span class="o">=</span>  <span class="n">merge_compact_dataset</span><span class="p">(</span><span class="n">compact_dataset</span><span class="p">,</span><span class="n">capture_date</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span><span class="n">rx_test_list</span><span class="p">,</span><span class="n">equalized</span><span class="o">=</span><span class="n">equalized</span><span class="p">)</span>
    <span class="n">test_augset_dfRx</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">prepare_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span><span class="n">val_frac</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">test_frac</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="p">[</span><span class="n">sig_dfTest</span><span class="p">,</span><span class="n">txidNum_dfTest</span><span class="p">,</span><span class="n">txid_dfTest</span><span class="p">,</span><span class="n">cls_weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_augset_dfRx</span>

    <span class="n">cnt</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">txidNum_dfTest</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">n_test_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="n">smTest_results_real</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dfTest_results_real</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dfTestBal_results_real</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">nrx</span> <span class="ow">in</span> <span class="n">nrx_list</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">);</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;nrx: </span><span class="si">{}</span><span class="s2"> - real: </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nrx</span><span class="p">,</span><span class="n">real</span><span class="p">))</span>
        <span class="n">fname_w</span> <span class="o">=</span> <span class="s1">&#39;weights/d011_</span><span class="si">{:02d}</span><span class="s1">_</span><span class="si">{:02d}</span><span class="s1">.hd5&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nrx</span><span class="p">,</span><span class="n">real</span><span class="p">)</span>
        <span class="n">rx_train_list</span><span class="o">=</span> <span class="n">rx_list</span><span class="p">[:</span><span class="n">nrx</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">dataset</span> <span class="o">=</span>  <span class="n">merge_compact_dataset</span><span class="p">(</span><span class="n">compact_dataset</span><span class="p">,</span><span class="n">capture_date</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span><span class="n">rx_train_list</span><span class="p">,</span><span class="n">equalized</span><span class="o">=</span><span class="n">equalized</span><span class="p">)</span>

        <span class="n">train_augset</span><span class="p">,</span><span class="n">val_augset</span><span class="p">,</span><span class="n">test_augset_smRx</span> <span class="o">=</span>  <span class="n">prepare_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">tx_list</span><span class="p">,</span>
                                                            <span class="n">val_frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">test_frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="p">[</span><span class="n">sig_train</span><span class="p">,</span><span class="n">txidNum_train</span><span class="p">,</span><span class="n">txid_train</span><span class="p">,</span><span class="n">cls_weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_augset</span>
        <span class="p">[</span><span class="n">sig_valid</span><span class="p">,</span><span class="n">txidNum_valid</span><span class="p">,</span><span class="n">txid_valid</span><span class="p">,</span><span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_augset</span>
        <span class="p">[</span><span class="n">sig_smTest</span><span class="p">,</span><span class="n">txidNum_smTest</span><span class="p">,</span><span class="n">txid_smTest</span><span class="p">,</span><span class="n">cls_weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_augset_smRx</span>
        
        <span class="k">if</span> <span class="n">continue_training</span><span class="p">:</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname_w</span><span class="p">)</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname_w</span><span class="o">+</span><span class="s1">&#39;.index&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skip</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">classifier</span> <span class="o">=</span> <span class="n">create_net</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">TRAIN</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">skip</span><span class="p">:</span>
            <span class="n">filepath</span> <span class="o">=</span> <span class="s1">&#39;t_weights_&#39;</span><span class="o">+</span><span class="n">GPU</span>
            <span class="n">c</span><span class="o">=</span><span class="p">[</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
              <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>  <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">)]</span>
            <span class="n">history</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sig_train</span><span class="p">,</span><span class="n">txid_train</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="n">cls_weights</span><span class="p">,</span>
                                     <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">sig_valid</span> <span class="p">,</span> <span class="n">txid_valid</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">)</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">fname_w</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">fname_w</span><span class="p">)</span><span class="o">.</span><span class="n">expect_partial</span><span class="p">()</span>

        <span class="n">smTest_r</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">sig_smTest</span><span class="p">,</span><span class="n">txid_smTest</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1">#     dfTest_r = classifier.evaluate(sig_dfTest,txid_dfTest)[1]</span>
        <span class="n">dfTest_r</span><span class="p">,</span><span class="n">dfTestBal_r</span> <span class="o">=</span> <span class="n">evaluate_test</span><span class="p">(</span><span class="n">classifier</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">smTest_r</span><span class="p">,</span><span class="n">dfTest_r</span><span class="p">)</span>
        <span class="n">smTest_results_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smTest_r</span><span class="p">)</span>
        <span class="n">dfTest_results_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTest_r</span><span class="p">)</span>
        <span class="n">dfTestBal_results_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTestBal_r</span><span class="p">)</span>
        <span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
    <span class="n">smTest_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smTest_results_real</span><span class="p">)</span>
    <span class="n">dfTest_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTest_results_real</span><span class="p">)</span>
    <span class="n">dfTestBal_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfTestBal_results_real</span><span class="p">)</span>    
    
    
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>

nrx: 0 - real: 0 
0.93 0.3165


nrx: 5 - real: 0 
Train on 9440 samples, validate on 1180 samples
Epoch 1/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 1.8050 - categorical_accuracy: 0.3344
Epoch 00001: val_loss improved from inf to 1.14972, saving model to t_weights_0
9440/9440 [==============================] - 2s 261us/sample - loss: 1.8019 - categorical_accuracy: 0.3357 - val_loss: 1.1497 - val_categorical_accuracy: 0.6212
Epoch 2/100
9216/9440 [============================&gt;.] - ETA: 0s - loss: 1.0347 - categorical_accuracy: 0.6133
Epoch 00002: val_loss improved from 1.14972 to 0.76160, saving model to t_weights_0
9440/9440 [==============================] - 2s 215us/sample - loss: 1.0334 - categorical_accuracy: 0.6140 - val_loss: 0.7616 - val_categorical_accuracy: 0.7449
Epoch 3/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.7896 - categorical_accuracy: 0.7061
Epoch 00003: val_loss improved from 0.76160 to 0.57286, saving model to t_weights_0
9440/9440 [==============================] - 2s 219us/sample - loss: 0.7895 - categorical_accuracy: 0.7060 - val_loss: 0.5729 - val_categorical_accuracy: 0.7907
Epoch 4/100
9152/9440 [============================&gt;.] - ETA: 0s - loss: 0.6543 - categorical_accuracy: 0.7626
Epoch 00004: val_loss improved from 0.57286 to 0.50889, saving model to t_weights_0
9440/9440 [==============================] - 2s 214us/sample - loss: 0.6572 - categorical_accuracy: 0.7626 - val_loss: 0.5089 - val_categorical_accuracy: 0.8288
Epoch 5/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 0.5721 - categorical_accuracy: 0.8033
Epoch 00005: val_loss improved from 0.50889 to 0.43221, saving model to t_weights_0
9440/9440 [==============================] - 2s 211us/sample - loss: 0.5687 - categorical_accuracy: 0.8051 - val_loss: 0.4322 - val_categorical_accuracy: 0.8500
Epoch 6/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.5020 - categorical_accuracy: 0.8285
Epoch 00006: val_loss improved from 0.43221 to 0.39560, saving model to t_weights_0
9440/9440 [==============================] - 2s 208us/sample - loss: 0.5026 - categorical_accuracy: 0.8283 - val_loss: 0.3956 - val_categorical_accuracy: 0.8669
Epoch 7/100
9120/9440 [===========================&gt;..] - ETA: 0s - loss: 0.4620 - categorical_accuracy: 0.8418
Epoch 00007: val_loss improved from 0.39560 to 0.39190, saving model to t_weights_0
9440/9440 [==============================] - 2s 207us/sample - loss: 0.4625 - categorical_accuracy: 0.8413 - val_loss: 0.3919 - val_categorical_accuracy: 0.8627
Epoch 8/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.4236 - categorical_accuracy: 0.8573
Epoch 00008: val_loss improved from 0.39190 to 0.35144, saving model to t_weights_0
9440/9440 [==============================] - 2s 209us/sample - loss: 0.4230 - categorical_accuracy: 0.8576 - val_loss: 0.3514 - val_categorical_accuracy: 0.8788
Epoch 9/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 0.3951 - categorical_accuracy: 0.8683
Epoch 00009: val_loss improved from 0.35144 to 0.33348, saving model to t_weights_0
9440/9440 [==============================] - 2s 213us/sample - loss: 0.3969 - categorical_accuracy: 0.8673 - val_loss: 0.3335 - val_categorical_accuracy: 0.8915
Epoch 10/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.3786 - categorical_accuracy: 0.8747
Epoch 00010: val_loss improved from 0.33348 to 0.31532, saving model to t_weights_0
9440/9440 [==============================] - 2s 206us/sample - loss: 0.3782 - categorical_accuracy: 0.8746 - val_loss: 0.3153 - val_categorical_accuracy: 0.8847
Epoch 11/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 0.3625 - categorical_accuracy: 0.8801
Epoch 00011: val_loss did not improve from 0.31532
9440/9440 [==============================] - 2s 197us/sample - loss: 0.3615 - categorical_accuracy: 0.8804 - val_loss: 0.3202 - val_categorical_accuracy: 0.8907
Epoch 12/100
9312/9440 [============================&gt;.] - ETA: 0s - loss: 0.3437 - categorical_accuracy: 0.8857
Epoch 00012: val_loss improved from 0.31532 to 0.30655, saving model to t_weights_0
9440/9440 [==============================] - 2s 176us/sample - loss: 0.3427 - categorical_accuracy: 0.8864 - val_loss: 0.3066 - val_categorical_accuracy: 0.8915
Epoch 13/100
9184/9440 [============================&gt;.] - ETA: 0s - loss: 0.3252 - categorical_accuracy: 0.8944
Epoch 00013: val_loss improved from 0.30655 to 0.30419, saving model to t_weights_0
9440/9440 [==============================] - 2s 206us/sample - loss: 0.3246 - categorical_accuracy: 0.8946 - val_loss: 0.3042 - val_categorical_accuracy: 0.8941
Epoch 14/100
9280/9440 [============================&gt;.] - ETA: 0s - loss: 0.3170 - categorical_accuracy: 0.8958
Epoch 00014: val_loss improved from 0.30419 to 0.29632, saving model to t_weights_0
9440/9440 [==============================] - 2s 215us/sample - loss: 0.3173 - categorical_accuracy: 0.8954 - val_loss: 0.2963 - val_categorical_accuracy: 0.9008
Epoch 15/100
9248/9440 [============================&gt;.] - ETA: 0s - loss: 0.3064 - categorical_accuracy: 0.8982
Epoch 00015: val_loss did not improve from 0.29632
9440/9440 [==============================] - 2s 207us/sample - loss: 0.3055 - categorical_accuracy: 0.8985 - val_loss: 0.3063 - val_categorical_accuracy: 0.8992
Epoch 16/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.2982 - categorical_accuracy: 0.9062
Epoch 00016: val_loss did not improve from 0.29632
9440/9440 [==============================] - 2s 206us/sample - loss: 0.2982 - categorical_accuracy: 0.9061 - val_loss: 0.3036 - val_categorical_accuracy: 0.8949
Epoch 17/100
9408/9440 [============================&gt;.] - ETA: 0s - loss: 0.2919 - categorical_accuracy: 0.9035
Epoch 00017: val_loss improved from 0.29632 to 0.28050, saving model to t_weights_0
9440/9440 [==============================] - 2s 216us/sample - loss: 0.2923 - categorical_accuracy: 0.9034 - val_loss: 0.2805 - val_categorical_accuracy: 0.9042
Epoch 18/100
9184/9440 [============================&gt;.] - ETA: 0s - loss: 0.2767 - categorical_accuracy: 0.9109
Epoch 00018: val_loss did not improve from 0.28050
9440/9440 [==============================] - 2s 211us/sample - loss: 0.2776 - categorical_accuracy: 0.9110 - val_loss: 0.2886 - val_categorical_accuracy: 0.9068
Epoch 19/100
9216/9440 [============================&gt;.] - ETA: 0s - loss: 0.2689 - categorical_accuracy: 0.9109
Epoch 00019: val_loss did not improve from 0.28050
9440/9440 [==============================] - 2s 170us/sample - loss: 0.2697 - categorical_accuracy: 0.9107 - val_loss: 0.3065 - val_categorical_accuracy: 0.8958
Epoch 20/100
9344/9440 [============================&gt;.] - ETA: 0s - loss: 0.2614 - categorical_accuracy: 0.9189
Epoch 00020: val_loss did not improve from 0.28050
9440/9440 [==============================] - 2s 195us/sample - loss: 0.2617 - categorical_accuracy: 0.9185 - val_loss: 0.2868 - val_categorical_accuracy: 0.9051
Epoch 21/100
9376/9440 [============================&gt;.] - ETA: 0s - loss: 0.2624 - categorical_accuracy: 0.9189
Epoch 00021: val_loss did not improve from 0.28050
9440/9440 [==============================] - 2s 198us/sample - loss: 0.2616 - categorical_accuracy: 0.9191 - val_loss: 0.2986 - val_categorical_accuracy: 0.9051
Epoch 22/100
9184/9440 [============================&gt;.] - ETA: 0s - loss: 0.2506 - categorical_accuracy: 0.9202
Epoch 00022: val_loss did not improve from 0.28050
9440/9440 [==============================] - 2s 213us/sample - loss: 0.2497 - categorical_accuracy: 0.9207 - val_loss: 0.2840 - val_categorical_accuracy: 0.9025
0.8940678 0.5837


nrx: 10 - real: 0 
Train on 17166 samples, validate on 2145 samples
Epoch 1/100
17088/17166 [============================&gt;.] - ETA: 0s - loss: 1.4893 - categorical_accuracy: 0.4150
Epoch 00001: val_loss improved from inf to 0.81506, saving model to t_weights_0
17166/17166 [==============================] - 4s 240us/sample - loss: 1.4869 - categorical_accuracy: 0.4158 - val_loss: 0.8151 - val_categorical_accuracy: 0.6862
Epoch 2/100
17152/17166 [============================&gt;.] - ETA: 0s - loss: 0.8199 - categorical_accuracy: 0.6533
Epoch 00002: val_loss improved from 0.81506 to 0.60583, saving model to t_weights_0
17166/17166 [==============================] - 4s 216us/sample - loss: 0.8197 - categorical_accuracy: 0.6534 - val_loss: 0.6058 - val_categorical_accuracy: 0.7781
Epoch 3/100
16928/17166 [============================&gt;.] - ETA: 0s - loss: 0.6364 - categorical_accuracy: 0.7538
Epoch 00003: val_loss improved from 0.60583 to 0.46922, saving model to t_weights_0
17166/17166 [==============================] - 4s 214us/sample - loss: 0.6350 - categorical_accuracy: 0.7549 - val_loss: 0.4692 - val_categorical_accuracy: 0.8289
Epoch 4/100
16960/17166 [============================&gt;.] - ETA: 0s - loss: 0.5023 - categorical_accuracy: 0.8210
Epoch 00004: val_loss improved from 0.46922 to 0.36184, saving model to t_weights_0
17166/17166 [==============================] - 4s 217us/sample - loss: 0.5017 - categorical_accuracy: 0.8213 - val_loss: 0.3618 - val_categorical_accuracy: 0.8769
Epoch 5/100
16928/17166 [============================&gt;.] - ETA: 0s - loss: 0.4158 - categorical_accuracy: 0.8546
Epoch 00005: val_loss improved from 0.36184 to 0.30658, saving model to t_weights_0
17166/17166 [==============================] - 4s 216us/sample - loss: 0.4161 - categorical_accuracy: 0.8545 - val_loss: 0.3066 - val_categorical_accuracy: 0.9068
Epoch 6/100
17088/17166 [============================&gt;.] - ETA: 0s - loss: 0.3536 - categorical_accuracy: 0.8801
Epoch 00006: val_loss improved from 0.30658 to 0.28113, saving model to t_weights_0
17166/17166 [==============================] - 4s 215us/sample - loss: 0.3533 - categorical_accuracy: 0.8802 - val_loss: 0.2811 - val_categorical_accuracy: 0.9100
Epoch 7/100
17088/17166 [============================&gt;.] - ETA: 0s - loss: 0.3166 - categorical_accuracy: 0.8969
Epoch 00007: val_loss improved from 0.28113 to 0.24298, saving model to t_weights_0
17166/17166 [==============================] - 4s 218us/sample - loss: 0.3167 - categorical_accuracy: 0.8970 - val_loss: 0.2430 - val_categorical_accuracy: 0.9249
Epoch 8/100
17024/17166 [============================&gt;.] - ETA: 0s - loss: 0.2844 - categorical_accuracy: 0.9090
Epoch 00008: val_loss improved from 0.24298 to 0.23658, saving model to t_weights_0
17166/17166 [==============================] - 4s 216us/sample - loss: 0.2842 - categorical_accuracy: 0.9091 - val_loss: 0.2366 - val_categorical_accuracy: 0.9268
Epoch 9/100
16992/17166 [============================&gt;.] - ETA: 0s - loss: 0.2708 - categorical_accuracy: 0.9138
Epoch 00009: val_loss did not improve from 0.23658
17166/17166 [==============================] - 4s 215us/sample - loss: 0.2706 - categorical_accuracy: 0.9138 - val_loss: 0.2380 - val_categorical_accuracy: 0.9254
Epoch 10/100
17120/17166 [============================&gt;.] - ETA: 0s - loss: 0.2530 - categorical_accuracy: 0.9207
Epoch 00010: val_loss did not improve from 0.23658
17166/17166 [==============================] - 4s 209us/sample - loss: 0.2529 - categorical_accuracy: 0.9207 - val_loss: 0.2441 - val_categorical_accuracy: 0.9249
Epoch 11/100
16992/17166 [============================&gt;.] - ETA: 0s - loss: 0.2459 - categorical_accuracy: 0.9205
Epoch 00011: val_loss did not improve from 0.23658
17166/17166 [==============================] - 4s 211us/sample - loss: 0.2455 - categorical_accuracy: 0.9204 - val_loss: 0.2367 - val_categorical_accuracy: 0.9273
Epoch 12/100
16960/17166 [============================&gt;.] - ETA: 0s - loss: 0.2343 - categorical_accuracy: 0.9265
Epoch 00012: val_loss improved from 0.23658 to 0.22365, saving model to t_weights_0
17166/17166 [==============================] - 4s 217us/sample - loss: 0.2348 - categorical_accuracy: 0.9265 - val_loss: 0.2236 - val_categorical_accuracy: 0.9282
Epoch 13/100
17088/17166 [============================&gt;.] - ETA: 0s - loss: 0.2277 - categorical_accuracy: 0.9274
Epoch 00013: val_loss improved from 0.22365 to 0.21300, saving model to t_weights_0
17166/17166 [==============================] - 3s 198us/sample - loss: 0.2273 - categorical_accuracy: 0.9276 - val_loss: 0.2130 - val_categorical_accuracy: 0.9315
Epoch 14/100
17056/17166 [============================&gt;.] - ETA: 0s - loss: 0.2266 - categorical_accuracy: 0.9278
Epoch 00014: val_loss did not improve from 0.21300
17166/17166 [==============================] - 4s 213us/sample - loss: 0.2262 - categorical_accuracy: 0.9279 - val_loss: 0.2135 - val_categorical_accuracy: 0.9319
Epoch 15/100
17120/17166 [============================&gt;.] - ETA: 0s - loss: 0.2080 - categorical_accuracy: 0.9357
Epoch 00015: val_loss did not improve from 0.21300
17166/17166 [==============================] - 4s 209us/sample - loss: 0.2080 - categorical_accuracy: 0.9356 - val_loss: 0.2132 - val_categorical_accuracy: 0.9347
Epoch 16/100
16928/17166 [============================&gt;.] - ETA: 0s - loss: 0.2035 - categorical_accuracy: 0.9365
Epoch 00016: val_loss improved from 0.21300 to 0.20825, saving model to t_weights_0
17166/17166 [==============================] - 4s 214us/sample - loss: 0.2029 - categorical_accuracy: 0.9368 - val_loss: 0.2082 - val_categorical_accuracy: 0.9338
Epoch 17/100
16928/17166 [============================&gt;.] - ETA: 0s - loss: 0.2031 - categorical_accuracy: 0.9358
Epoch 00017: val_loss improved from 0.20825 to 0.20611, saving model to t_weights_0
17166/17166 [==============================] - 4s 214us/sample - loss: 0.2026 - categorical_accuracy: 0.9361 - val_loss: 0.2061 - val_categorical_accuracy: 0.9413
Epoch 18/100
17024/17166 [============================&gt;.] - ETA: 0s - loss: 0.1900 - categorical_accuracy: 0.9394
Epoch 00018: val_loss improved from 0.20611 to 0.19506, saving model to t_weights_0
17166/17166 [==============================] - 4s 218us/sample - loss: 0.1903 - categorical_accuracy: 0.9394 - val_loss: 0.1951 - val_categorical_accuracy: 0.9394
Epoch 19/100
17120/17166 [============================&gt;.] - ETA: 0s - loss: 0.2020 - categorical_accuracy: 0.9363
Epoch 00019: val_loss did not improve from 0.19506
17166/17166 [==============================] - 4s 211us/sample - loss: 0.2019 - categorical_accuracy: 0.9363 - val_loss: 0.2123 - val_categorical_accuracy: 0.9361
Epoch 20/100
16960/17166 [============================&gt;.] - ETA: 0s - loss: 0.1858 - categorical_accuracy: 0.9428
Epoch 00020: val_loss did not improve from 0.19506
17166/17166 [==============================] - 4s 213us/sample - loss: 0.1856 - categorical_accuracy: 0.9429 - val_loss: 0.2101 - val_categorical_accuracy: 0.9385
Epoch 21/100
17024/17166 [============================&gt;.] - ETA: 0s - loss: 0.1847 - categorical_accuracy: 0.9407
Epoch 00021: val_loss improved from 0.19506 to 0.18772, saving model to t_weights_0
17166/17166 [==============================] - 4s 218us/sample - loss: 0.1849 - categorical_accuracy: 0.9408 - val_loss: 0.1877 - val_categorical_accuracy: 0.9422
Epoch 22/100
17024/17166 [============================&gt;.] - ETA: 0s - loss: 0.1792 - categorical_accuracy: 0.9455
Epoch 00022: val_loss did not improve from 0.18772
17166/17166 [==============================] - 4s 212us/sample - loss: 0.1796 - categorical_accuracy: 0.9453 - val_loss: 0.2077 - val_categorical_accuracy: 0.9375
Epoch 23/100
16960/17166 [============================&gt;.] - ETA: 0s - loss: 0.1797 - categorical_accuracy: 0.9436
Epoch 00023: val_loss did not improve from 0.18772
17166/17166 [==============================] - 4s 213us/sample - loss: 0.1798 - categorical_accuracy: 0.9437 - val_loss: 0.1951 - val_categorical_accuracy: 0.9399
Epoch 24/100
16896/17166 [============================&gt;.] - ETA: 0s - loss: 0.1768 - categorical_accuracy: 0.9466
Epoch 00024: val_loss improved from 0.18772 to 0.18302, saving model to t_weights_0
17166/17166 [==============================] - 4s 215us/sample - loss: 0.1766 - categorical_accuracy: 0.9466 - val_loss: 0.1830 - val_categorical_accuracy: 0.9464
Epoch 25/100
17056/17166 [============================&gt;.] - ETA: 0s - loss: 0.1651 - categorical_accuracy: 0.9489
Epoch 00025: val_loss did not improve from 0.18302
17166/17166 [==============================] - 4s 212us/sample - loss: 0.1656 - categorical_accuracy: 0.9488 - val_loss: 0.2135 - val_categorical_accuracy: 0.9427
Epoch 26/100
16960/17166 [============================&gt;.] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9463
Epoch 00026: val_loss did not improve from 0.18302
17166/17166 [==============================] - 4s 213us/sample - loss: 0.1706 - categorical_accuracy: 0.9464 - val_loss: 0.2185 - val_categorical_accuracy: 0.9389
Epoch 27/100
17024/17166 [============================&gt;.] - ETA: 0s - loss: 0.1607 - categorical_accuracy: 0.9504
Epoch 00027: val_loss did not improve from 0.18302
17166/17166 [==============================] - 4s 215us/sample - loss: 0.1609 - categorical_accuracy: 0.9504 - val_loss: 0.2004 - val_categorical_accuracy: 0.9455
Epoch 28/100
17024/17166 [============================&gt;.] - ETA: 0s - loss: 0.1649 - categorical_accuracy: 0.9512
Epoch 00028: val_loss did not improve from 0.18302
17166/17166 [==============================] - 4s 212us/sample - loss: 0.1647 - categorical_accuracy: 0.9514 - val_loss: 0.2063 - val_categorical_accuracy: 0.9450
Epoch 29/100
17120/17166 [============================&gt;.] - ETA: 0s - loss: 0.1534 - categorical_accuracy: 0.9532
Epoch 00029: val_loss did not improve from 0.18302
17166/17166 [==============================] - 4s 212us/sample - loss: 0.1537 - categorical_accuracy: 0.9531 - val_loss: 0.2402 - val_categorical_accuracy: 0.9389
0.93426573 0.767


nrx: 15 - real: 0 
Train on 24865 samples, validate on 3107 samples
Epoch 1/100
24832/24865 [============================&gt;.] - ETA: 0s - loss: 1.2657 - categorical_accuracy: 0.4987
Epoch 00001: val_loss improved from inf to 0.78266, saving model to t_weights_0
24865/24865 [==============================] - 6s 233us/sample - loss: 1.2652 - categorical_accuracy: 0.4989 - val_loss: 0.7827 - val_categorical_accuracy: 0.6714
Epoch 2/100
24704/24865 [============================&gt;.] - ETA: 0s - loss: 0.6812 - categorical_accuracy: 0.7290
Epoch 00002: val_loss improved from 0.78266 to 0.50917, saving model to t_weights_0
24865/24865 [==============================] - 5s 212us/sample - loss: 0.6801 - categorical_accuracy: 0.7295 - val_loss: 0.5092 - val_categorical_accuracy: 0.8233
Epoch 3/100
24864/24865 [============================&gt;.] - ETA: 0s - loss: 0.5113 - categorical_accuracy: 0.8103
Epoch 00003: val_loss improved from 0.50917 to 0.40397, saving model to t_weights_0
24865/24865 [==============================] - 5s 219us/sample - loss: 0.5113 - categorical_accuracy: 0.8103 - val_loss: 0.4040 - val_categorical_accuracy: 0.8677
Epoch 4/100
24832/24865 [============================&gt;.] - ETA: 0s - loss: 0.4130 - categorical_accuracy: 0.8598
Epoch 00004: val_loss improved from 0.40397 to 0.33989, saving model to t_weights_0
24865/24865 [==============================] - 5s 220us/sample - loss: 0.4128 - categorical_accuracy: 0.8599 - val_loss: 0.3399 - val_categorical_accuracy: 0.8825
Epoch 5/100
24800/24865 [============================&gt;.] - ETA: 0s - loss: 0.3358 - categorical_accuracy: 0.8919
Epoch 00005: val_loss improved from 0.33989 to 0.28053, saving model to t_weights_0
24865/24865 [==============================] - 5s 205us/sample - loss: 0.3356 - categorical_accuracy: 0.8920 - val_loss: 0.2805 - val_categorical_accuracy: 0.9057
Epoch 6/100
24768/24865 [============================&gt;.] - ETA: 0s - loss: 0.2918 - categorical_accuracy: 0.9081
Epoch 00006: val_loss improved from 0.28053 to 0.25762, saving model to t_weights_0
24865/24865 [==============================] - 5s 218us/sample - loss: 0.2921 - categorical_accuracy: 0.9080 - val_loss: 0.2576 - val_categorical_accuracy: 0.9186
Epoch 7/100
24864/24865 [============================&gt;.] - ETA: 0s - loss: 0.2665 - categorical_accuracy: 0.9159
Epoch 00007: val_loss did not improve from 0.25762
24865/24865 [==============================] - 5s 217us/sample - loss: 0.2665 - categorical_accuracy: 0.9159 - val_loss: 0.2610 - val_categorical_accuracy: 0.9170
Epoch 8/100
24768/24865 [============================&gt;.] - ETA: 0s - loss: 0.2527 - categorical_accuracy: 0.9214
Epoch 00008: val_loss improved from 0.25762 to 0.24281, saving model to t_weights_0
24865/24865 [==============================] - 5s 218us/sample - loss: 0.2526 - categorical_accuracy: 0.9212 - val_loss: 0.2428 - val_categorical_accuracy: 0.9195
Epoch 9/100
24736/24865 [============================&gt;.] - ETA: 0s - loss: 0.2407 - categorical_accuracy: 0.9237
Epoch 00009: val_loss improved from 0.24281 to 0.23220, saving model to t_weights_0
24865/24865 [==============================] - 5s 220us/sample - loss: 0.2405 - categorical_accuracy: 0.9238 - val_loss: 0.2322 - val_categorical_accuracy: 0.9240
Epoch 10/100
24864/24865 [============================&gt;.] - ETA: 0s - loss: 0.2295 - categorical_accuracy: 0.9265
Epoch 00010: val_loss improved from 0.23220 to 0.22533, saving model to t_weights_0
24865/24865 [==============================] - 5s 221us/sample - loss: 0.2295 - categorical_accuracy: 0.9265 - val_loss: 0.2253 - val_categorical_accuracy: 0.9260
Epoch 11/100
24800/24865 [============================&gt;.] - ETA: 0s - loss: 0.2187 - categorical_accuracy: 0.9308
Epoch 00011: val_loss did not improve from 0.22533
24865/24865 [==============================] - 5s 217us/sample - loss: 0.2186 - categorical_accuracy: 0.9308 - val_loss: 0.2457 - val_categorical_accuracy: 0.9211
Epoch 12/100
24736/24865 [============================&gt;.] - ETA: 0s - loss: 0.2127 - categorical_accuracy: 0.9331
Epoch 00012: val_loss improved from 0.22533 to 0.22124, saving model to t_weights_0
24865/24865 [==============================] - 5s 217us/sample - loss: 0.2129 - categorical_accuracy: 0.9330 - val_loss: 0.2212 - val_categorical_accuracy: 0.9298
Epoch 13/100
24864/24865 [============================&gt;.] - ETA: 0s - loss: 0.2022 - categorical_accuracy: 0.9379
Epoch 00013: val_loss did not improve from 0.22124
24865/24865 [==============================] - 5s 211us/sample - loss: 0.2022 - categorical_accuracy: 0.9379 - val_loss: 0.2252 - val_categorical_accuracy: 0.9314
Epoch 14/100
24800/24865 [============================&gt;.] - ETA: 0s - loss: 0.1994 - categorical_accuracy: 0.9377
Epoch 00014: val_loss improved from 0.22124 to 0.20600, saving model to t_weights_0
24865/24865 [==============================] - 5s 220us/sample - loss: 0.1992 - categorical_accuracy: 0.9378 - val_loss: 0.2060 - val_categorical_accuracy: 0.9314
Epoch 15/100
24768/24865 [============================&gt;.] - ETA: 0s - loss: 0.1994 - categorical_accuracy: 0.9384
Epoch 00015: val_loss did not improve from 0.20600
24865/24865 [==============================] - 5s 218us/sample - loss: 0.1994 - categorical_accuracy: 0.9384 - val_loss: 0.2172 - val_categorical_accuracy: 0.9331
Epoch 16/100
24640/24865 [============================&gt;.] - ETA: 0s - loss: 0.1885 - categorical_accuracy: 0.9408
Epoch 00016: val_loss did not improve from 0.20600
24865/24865 [==============================] - 5s 218us/sample - loss: 0.1889 - categorical_accuracy: 0.9406 - val_loss: 0.2285 - val_categorical_accuracy: 0.9327
Epoch 17/100
24736/24865 [============================&gt;.] - ETA: 0s - loss: 0.1829 - categorical_accuracy: 0.9427
Epoch 00017: val_loss did not improve from 0.20600
24865/24865 [==============================] - 5s 214us/sample - loss: 0.1832 - categorical_accuracy: 0.9426 - val_loss: 0.2116 - val_categorical_accuracy: 0.9334
Epoch 18/100
24672/24865 [============================&gt;.] - ETA: 0s - loss: 0.1826 - categorical_accuracy: 0.9439
Epoch 00018: val_loss did not improve from 0.20600
24865/24865 [==============================] - 5s 215us/sample - loss: 0.1829 - categorical_accuracy: 0.9437 - val_loss: 0.2245 - val_categorical_accuracy: 0.9282
Epoch 19/100
24736/24865 [============================&gt;.] - ETA: 0s - loss: 0.1765 - categorical_accuracy: 0.9461
Epoch 00019: val_loss did not improve from 0.20600
24865/24865 [==============================] - 5s 217us/sample - loss: 0.1762 - categorical_accuracy: 0.9462 - val_loss: 0.2208 - val_categorical_accuracy: 0.9308
0.9349855 0.8163


nrx: 20 - real: 0 
Train on 32573 samples, validate on 4071 samples
Epoch 1/100
32448/32573 [============================&gt;.] - ETA: 0s - loss: 1.2643 - categorical_accuracy: 0.4879
Epoch 00001: val_loss improved from inf to 0.79917, saving model to t_weights_0
32573/32573 [==============================] - 8s 233us/sample - loss: 1.2626 - categorical_accuracy: 0.4885 - val_loss: 0.7992 - val_categorical_accuracy: 0.6667
Epoch 2/100
32352/32573 [============================&gt;.] - ETA: 0s - loss: 0.7572 - categorical_accuracy: 0.6876
Epoch 00002: val_loss improved from 0.79917 to 0.58964, saving model to t_weights_0
32573/32573 [==============================] - 7s 220us/sample - loss: 0.7565 - categorical_accuracy: 0.6879 - val_loss: 0.5896 - val_categorical_accuracy: 0.7740
Epoch 3/100
32480/32573 [============================&gt;.] - ETA: 0s - loss: 0.5600 - categorical_accuracy: 0.7885
Epoch 00003: val_loss improved from 0.58964 to 0.42346, saving model to t_weights_0
32573/32573 [==============================] - 7s 220us/sample - loss: 0.5601 - categorical_accuracy: 0.7886 - val_loss: 0.4235 - val_categorical_accuracy: 0.8543
Epoch 4/100
32320/32573 [============================&gt;.] - ETA: 0s - loss: 0.4362 - categorical_accuracy: 0.8477
Epoch 00004: val_loss improved from 0.42346 to 0.33782, saving model to t_weights_0
32573/32573 [==============================] - 7s 215us/sample - loss: 0.4360 - categorical_accuracy: 0.8478 - val_loss: 0.3378 - val_categorical_accuracy: 0.8828
Epoch 5/100
32352/32573 [============================&gt;.] - ETA: 0s - loss: 0.3626 - categorical_accuracy: 0.8797
Epoch 00005: val_loss improved from 0.33782 to 0.32118, saving model to t_weights_0
32573/32573 [==============================] - 7s 220us/sample - loss: 0.3621 - categorical_accuracy: 0.8800 - val_loss: 0.3212 - val_categorical_accuracy: 0.8978
Epoch 6/100
32416/32573 [============================&gt;.] - ETA: 0s - loss: 0.3223 - categorical_accuracy: 0.8936
Epoch 00006: val_loss improved from 0.32118 to 0.29476, saving model to t_weights_0
32573/32573 [==============================] - 7s 219us/sample - loss: 0.3223 - categorical_accuracy: 0.8937 - val_loss: 0.2948 - val_categorical_accuracy: 0.8981
Epoch 7/100
32448/32573 [============================&gt;.] - ETA: 0s - loss: 0.3010 - categorical_accuracy: 0.9017
Epoch 00007: val_loss improved from 0.29476 to 0.26002, saving model to t_weights_0
32573/32573 [==============================] - 7s 221us/sample - loss: 0.3012 - categorical_accuracy: 0.9015 - val_loss: 0.2600 - val_categorical_accuracy: 0.9150
Epoch 8/100
32320/32573 [============================&gt;.] - ETA: 0s - loss: 0.2797 - categorical_accuracy: 0.9088
Epoch 00008: val_loss did not improve from 0.26002
32573/32573 [==============================] - 7s 220us/sample - loss: 0.2800 - categorical_accuracy: 0.9087 - val_loss: 0.2683 - val_categorical_accuracy: 0.9086
Epoch 9/100
32512/32573 [============================&gt;.] - ETA: 0s - loss: 0.2683 - categorical_accuracy: 0.9138
Epoch 00009: val_loss improved from 0.26002 to 0.24813, saving model to t_weights_0
32573/32573 [==============================] - 7s 222us/sample - loss: 0.2685 - categorical_accuracy: 0.9138 - val_loss: 0.2481 - val_categorical_accuracy: 0.9175
Epoch 10/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.2566 - categorical_accuracy: 0.9181
Epoch 00010: val_loss did not improve from 0.24813
32573/32573 [==============================] - 7s 219us/sample - loss: 0.2570 - categorical_accuracy: 0.9181 - val_loss: 0.2548 - val_categorical_accuracy: 0.9167
Epoch 11/100
32352/32573 [============================&gt;.] - ETA: 0s - loss: 0.2477 - categorical_accuracy: 0.9208
Epoch 00011: val_loss improved from 0.24813 to 0.23596, saving model to t_weights_0
32573/32573 [==============================] - 7s 220us/sample - loss: 0.2476 - categorical_accuracy: 0.9209 - val_loss: 0.2360 - val_categorical_accuracy: 0.9241
Epoch 12/100
32480/32573 [============================&gt;.] - ETA: 0s - loss: 0.2451 - categorical_accuracy: 0.9216
Epoch 00012: val_loss improved from 0.23596 to 0.22256, saving model to t_weights_0
32573/32573 [==============================] - 7s 215us/sample - loss: 0.2449 - categorical_accuracy: 0.9216 - val_loss: 0.2226 - val_categorical_accuracy: 0.9270
Epoch 13/100
32320/32573 [============================&gt;.] - ETA: 0s - loss: 0.2334 - categorical_accuracy: 0.9256
Epoch 00013: val_loss did not improve from 0.22256
32573/32573 [==============================] - 7s 219us/sample - loss: 0.2331 - categorical_accuracy: 0.9257 - val_loss: 0.2256 - val_categorical_accuracy: 0.9270
Epoch 14/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.2266 - categorical_accuracy: 0.9275
Epoch 00014: val_loss improved from 0.22256 to 0.21944, saving model to t_weights_0
32573/32573 [==============================] - 7s 216us/sample - loss: 0.2268 - categorical_accuracy: 0.9275 - val_loss: 0.2194 - val_categorical_accuracy: 0.9302
Epoch 15/100
32416/32573 [============================&gt;.] - ETA: 0s - loss: 0.2254 - categorical_accuracy: 0.9287
Epoch 00015: val_loss did not improve from 0.21944
32573/32573 [==============================] - 7s 208us/sample - loss: 0.2252 - categorical_accuracy: 0.9288 - val_loss: 0.2272 - val_categorical_accuracy: 0.9295
Epoch 16/100
32544/32573 [============================&gt;.] - ETA: 0s - loss: 0.2195 - categorical_accuracy: 0.9317
Epoch 00016: val_loss did not improve from 0.21944
32573/32573 [==============================] - 7s 217us/sample - loss: 0.2194 - categorical_accuracy: 0.9317 - val_loss: 0.2262 - val_categorical_accuracy: 0.9278
Epoch 17/100
32256/32573 [============================&gt;.] - ETA: 0s - loss: 0.2151 - categorical_accuracy: 0.9322
Epoch 00017: val_loss did not improve from 0.21944
32573/32573 [==============================] - 7s 219us/sample - loss: 0.2144 - categorical_accuracy: 0.9325 - val_loss: 0.2197 - val_categorical_accuracy: 0.9268
Epoch 18/100
32448/32573 [============================&gt;.] - ETA: 0s - loss: 0.2071 - categorical_accuracy: 0.9350
Epoch 00018: val_loss did not improve from 0.21944
32573/32573 [==============================] - 7s 217us/sample - loss: 0.2072 - categorical_accuracy: 0.9350 - val_loss: 0.2204 - val_categorical_accuracy: 0.9312
Epoch 19/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.2055 - categorical_accuracy: 0.9361
Epoch 00019: val_loss improved from 0.21944 to 0.21271, saving model to t_weights_0
32573/32573 [==============================] - 7s 220us/sample - loss: 0.2051 - categorical_accuracy: 0.9361 - val_loss: 0.2127 - val_categorical_accuracy: 0.9339
Epoch 20/100
32448/32573 [============================&gt;.] - ETA: 0s - loss: 0.1990 - categorical_accuracy: 0.9385
Epoch 00020: val_loss did not improve from 0.21271
32573/32573 [==============================] - 7s 218us/sample - loss: 0.1990 - categorical_accuracy: 0.9384 - val_loss: 0.2158 - val_categorical_accuracy: 0.9339
Epoch 21/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.1961 - categorical_accuracy: 0.9387
Epoch 00021: val_loss improved from 0.21271 to 0.20902, saving model to t_weights_0
32573/32573 [==============================] - 7s 214us/sample - loss: 0.1961 - categorical_accuracy: 0.9386 - val_loss: 0.2090 - val_categorical_accuracy: 0.9339
Epoch 22/100
32512/32573 [============================&gt;.] - ETA: 0s - loss: 0.1927 - categorical_accuracy: 0.9397
Epoch 00022: val_loss did not improve from 0.20902
32573/32573 [==============================] - 7s 217us/sample - loss: 0.1927 - categorical_accuracy: 0.9397 - val_loss: 0.2151 - val_categorical_accuracy: 0.9337
Epoch 23/100
32544/32573 [============================&gt;.] - ETA: 0s - loss: 0.1878 - categorical_accuracy: 0.9412
Epoch 00023: val_loss did not improve from 0.20902
32573/32573 [==============================] - 7s 218us/sample - loss: 0.1878 - categorical_accuracy: 0.9412 - val_loss: 0.2333 - val_categorical_accuracy: 0.9307
Epoch 24/100
32352/32573 [============================&gt;.] - ETA: 0s - loss: 0.1867 - categorical_accuracy: 0.9428
Epoch 00024: val_loss improved from 0.20902 to 0.20344, saving model to t_weights_0
32573/32573 [==============================] - 7s 221us/sample - loss: 0.1867 - categorical_accuracy: 0.9428 - val_loss: 0.2034 - val_categorical_accuracy: 0.9376
Epoch 25/100
32448/32573 [============================&gt;.] - ETA: 0s - loss: 0.1814 - categorical_accuracy: 0.9439
Epoch 00025: val_loss did not improve from 0.20344
32573/32573 [==============================] - 7s 219us/sample - loss: 0.1810 - categorical_accuracy: 0.9440 - val_loss: 0.2130 - val_categorical_accuracy: 0.9354
Epoch 26/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.1795 - categorical_accuracy: 0.9444
Epoch 00026: val_loss did not improve from 0.20344
32573/32573 [==============================] - 7s 218us/sample - loss: 0.1795 - categorical_accuracy: 0.9444 - val_loss: 0.2239 - val_categorical_accuracy: 0.9344
Epoch 27/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.1774 - categorical_accuracy: 0.9471
Epoch 00027: val_loss did not improve from 0.20344
32573/32573 [==============================] - 7s 219us/sample - loss: 0.1775 - categorical_accuracy: 0.9471 - val_loss: 0.2199 - val_categorical_accuracy: 0.9349
Epoch 28/100
32384/32573 [============================&gt;.] - ETA: 0s - loss: 0.1706 - categorical_accuracy: 0.9479
Epoch 00028: val_loss did not improve from 0.20344
32573/32573 [==============================] - 7s 218us/sample - loss: 0.1703 - categorical_accuracy: 0.9480 - val_loss: 0.2182 - val_categorical_accuracy: 0.9342
Epoch 29/100
32416/32573 [============================&gt;.] - ETA: 0s - loss: 0.1687 - categorical_accuracy: 0.9482
Epoch 00029: val_loss did not improve from 0.20344
32573/32573 [==============================] - 7s 214us/sample - loss: 0.1689 - categorical_accuracy: 0.9482 - val_loss: 0.2121 - val_categorical_accuracy: 0.9374
0.9390813 0.8418


nrx: 25 - real: 0 
Train on 39923 samples, validate on 4990 samples
Epoch 1/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 1.1676 - categorical_accuracy: 0.5176
Epoch 00001: val_loss improved from inf to 0.68589, saving model to t_weights_0
39923/39923 [==============================] - 9s 231us/sample - loss: 1.1668 - categorical_accuracy: 0.5178 - val_loss: 0.6859 - val_categorical_accuracy: 0.7008
Epoch 2/100
39744/39923 [============================&gt;.] - ETA: 0s - loss: 0.6784 - categorical_accuracy: 0.7221
Epoch 00002: val_loss improved from 0.68589 to 0.48305, saving model to t_weights_0
39923/39923 [==============================] - 9s 215us/sample - loss: 0.6777 - categorical_accuracy: 0.7224 - val_loss: 0.4830 - val_categorical_accuracy: 0.8192
Epoch 3/100
39680/39923 [============================&gt;.] - ETA: 0s - loss: 0.4856 - categorical_accuracy: 0.8226
Epoch 00003: val_loss improved from 0.48305 to 0.36749, saving model to t_weights_0
39923/39923 [==============================] - 9s 216us/sample - loss: 0.4852 - categorical_accuracy: 0.8228 - val_loss: 0.3675 - val_categorical_accuracy: 0.8699
Epoch 4/100
39648/39923 [============================&gt;.] - ETA: 0s - loss: 0.3890 - categorical_accuracy: 0.8662
Epoch 00004: val_loss improved from 0.36749 to 0.29612, saving model to t_weights_0
39923/39923 [==============================] - 9s 216us/sample - loss: 0.3892 - categorical_accuracy: 0.8661 - val_loss: 0.2961 - val_categorical_accuracy: 0.8960
Epoch 5/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.3350 - categorical_accuracy: 0.8886
Epoch 00005: val_loss improved from 0.29612 to 0.26882, saving model to t_weights_0
39923/39923 [==============================] - 9s 217us/sample - loss: 0.3351 - categorical_accuracy: 0.8886 - val_loss: 0.2688 - val_categorical_accuracy: 0.9136
Epoch 6/100
39680/39923 [============================&gt;.] - ETA: 0s - loss: 0.2971 - categorical_accuracy: 0.9037
Epoch 00006: val_loss improved from 0.26882 to 0.26189, saving model to t_weights_0
39923/39923 [==============================] - 9s 215us/sample - loss: 0.2969 - categorical_accuracy: 0.9037 - val_loss: 0.2619 - val_categorical_accuracy: 0.9132
Epoch 7/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.2745 - categorical_accuracy: 0.9114
Epoch 00007: val_loss improved from 0.26189 to 0.23654, saving model to t_weights_0
39923/39923 [==============================] - 8s 212us/sample - loss: 0.2746 - categorical_accuracy: 0.9114 - val_loss: 0.2365 - val_categorical_accuracy: 0.9216
Epoch 8/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.2585 - categorical_accuracy: 0.9175
Epoch 00008: val_loss improved from 0.23654 to 0.22317, saving model to t_weights_0
39923/39923 [==============================] - 9s 214us/sample - loss: 0.2584 - categorical_accuracy: 0.9176 - val_loss: 0.2232 - val_categorical_accuracy: 0.9309
Epoch 9/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.2446 - categorical_accuracy: 0.9232
Epoch 00009: val_loss did not improve from 0.22317
39923/39923 [==============================] - 9s 215us/sample - loss: 0.2446 - categorical_accuracy: 0.9233 - val_loss: 0.2248 - val_categorical_accuracy: 0.9259
Epoch 10/100
39712/39923 [============================&gt;.] - ETA: 0s - loss: 0.2358 - categorical_accuracy: 0.9249
Epoch 00010: val_loss did not improve from 0.22317
39923/39923 [==============================] - 8s 213us/sample - loss: 0.2355 - categorical_accuracy: 0.9249 - val_loss: 0.2358 - val_categorical_accuracy: 0.9242
Epoch 11/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.2239 - categorical_accuracy: 0.9293
Epoch 00011: val_loss improved from 0.22317 to 0.21209, saving model to t_weights_0
39923/39923 [==============================] - 9s 220us/sample - loss: 0.2238 - categorical_accuracy: 0.9293 - val_loss: 0.2121 - val_categorical_accuracy: 0.9325
Epoch 12/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.2170 - categorical_accuracy: 0.9315
Epoch 00012: val_loss improved from 0.21209 to 0.20891, saving model to t_weights_0
39923/39923 [==============================] - 9s 221us/sample - loss: 0.2170 - categorical_accuracy: 0.9314 - val_loss: 0.2089 - val_categorical_accuracy: 0.9387
Epoch 13/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.2100 - categorical_accuracy: 0.9332
Epoch 00013: val_loss did not improve from 0.20891
39923/39923 [==============================] - 9s 221us/sample - loss: 0.2099 - categorical_accuracy: 0.9333 - val_loss: 0.2118 - val_categorical_accuracy: 0.9373
Epoch 14/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.2052 - categorical_accuracy: 0.9352
Epoch 00014: val_loss improved from 0.20891 to 0.19428, saving model to t_weights_0
39923/39923 [==============================] - 9s 218us/sample - loss: 0.2051 - categorical_accuracy: 0.9352 - val_loss: 0.1943 - val_categorical_accuracy: 0.9413
Epoch 15/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.1998 - categorical_accuracy: 0.9376
Epoch 00015: val_loss did not improve from 0.19428
39923/39923 [==============================] - 8s 211us/sample - loss: 0.1997 - categorical_accuracy: 0.9376 - val_loss: 0.2031 - val_categorical_accuracy: 0.9373
Epoch 16/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.1937 - categorical_accuracy: 0.9397
Epoch 00016: val_loss improved from 0.19428 to 0.19291, saving model to t_weights_0
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1937 - categorical_accuracy: 0.9397 - val_loss: 0.1929 - val_categorical_accuracy: 0.9421
Epoch 17/100
39776/39923 [============================&gt;.] - ETA: 0s - loss: 0.1915 - categorical_accuracy: 0.9407
Epoch 00017: val_loss improved from 0.19291 to 0.19253, saving model to t_weights_0
39923/39923 [==============================] - 9s 223us/sample - loss: 0.1921 - categorical_accuracy: 0.9405 - val_loss: 0.1925 - val_categorical_accuracy: 0.9417
Epoch 18/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.1864 - categorical_accuracy: 0.9429
Epoch 00018: val_loss did not improve from 0.19253
39923/39923 [==============================] - 9s 221us/sample - loss: 0.1865 - categorical_accuracy: 0.9429 - val_loss: 0.2037 - val_categorical_accuracy: 0.9387
Epoch 19/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.1854 - categorical_accuracy: 0.9438
Epoch 00019: val_loss improved from 0.19253 to 0.19123, saving model to t_weights_0
39923/39923 [==============================] - 9s 220us/sample - loss: 0.1853 - categorical_accuracy: 0.9438 - val_loss: 0.1912 - val_categorical_accuracy: 0.9429
Epoch 20/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.1801 - categorical_accuracy: 0.9457
Epoch 00020: val_loss did not improve from 0.19123
39923/39923 [==============================] - 9s 219us/sample - loss: 0.1800 - categorical_accuracy: 0.9457 - val_loss: 0.1974 - val_categorical_accuracy: 0.9439
Epoch 21/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.1771 - categorical_accuracy: 0.9461
Epoch 00021: val_loss did not improve from 0.19123
39923/39923 [==============================] - 9s 217us/sample - loss: 0.1770 - categorical_accuracy: 0.9461 - val_loss: 0.1967 - val_categorical_accuracy: 0.9445
Epoch 22/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.1747 - categorical_accuracy: 0.9466
Epoch 00022: val_loss did not improve from 0.19123
39923/39923 [==============================] - 9s 219us/sample - loss: 0.1746 - categorical_accuracy: 0.9467 - val_loss: 0.1991 - val_categorical_accuracy: 0.9423
Epoch 23/100
39680/39923 [============================&gt;.] - ETA: 0s - loss: 0.1678 - categorical_accuracy: 0.9484
Epoch 00023: val_loss did not improve from 0.19123
39923/39923 [==============================] - 9s 221us/sample - loss: 0.1680 - categorical_accuracy: 0.9483 - val_loss: 0.2081 - val_categorical_accuracy: 0.9399
Epoch 24/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.1651 - categorical_accuracy: 0.9496
Epoch 00024: val_loss improved from 0.19123 to 0.18928, saving model to t_weights_0
39923/39923 [==============================] - 9s 221us/sample - loss: 0.1652 - categorical_accuracy: 0.9496 - val_loss: 0.1893 - val_categorical_accuracy: 0.9447
Epoch 25/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.1649 - categorical_accuracy: 0.9494
Epoch 00025: val_loss did not improve from 0.18928
39923/39923 [==============================] - 9s 220us/sample - loss: 0.1648 - categorical_accuracy: 0.9494 - val_loss: 0.1946 - val_categorical_accuracy: 0.9467
Epoch 26/100
39776/39923 [============================&gt;.] - ETA: 0s - loss: 0.1619 - categorical_accuracy: 0.9506
Epoch 00026: val_loss did not improve from 0.18928
39923/39923 [==============================] - 9s 221us/sample - loss: 0.1621 - categorical_accuracy: 0.9505 - val_loss: 0.2145 - val_categorical_accuracy: 0.9411
Epoch 27/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.1584 - categorical_accuracy: 0.9521
Epoch 00027: val_loss did not improve from 0.18928
39923/39923 [==============================] - 9s 220us/sample - loss: 0.1585 - categorical_accuracy: 0.9521 - val_loss: 0.2026 - val_categorical_accuracy: 0.9397
Epoch 28/100
39712/39923 [============================&gt;.] - ETA: 0s - loss: 0.1552 - categorical_accuracy: 0.9538
Epoch 00028: val_loss did not improve from 0.18928
39923/39923 [==============================] - 9s 215us/sample - loss: 0.1549 - categorical_accuracy: 0.9540 - val_loss: 0.2153 - val_categorical_accuracy: 0.9407
Epoch 29/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.1529 - categorical_accuracy: 0.9531
Epoch 00029: val_loss did not improve from 0.18928
39923/39923 [==============================] - 9s 220us/sample - loss: 0.1533 - categorical_accuracy: 0.9530 - val_loss: 0.1955 - val_categorical_accuracy: 0.9479
0.9486974 0.8252


nrx: 0 - real: 1 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1600 samples, validate on 200 samples
Epoch 1/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 2.2664 - categorical_accuracy: 0.1890
Epoch 00001: val_loss improved from inf to 2.06093, saving model to t_weights_0
1600/1600 [==============================] - 1s 514us/sample - loss: 2.2499 - categorical_accuracy: 0.2050 - val_loss: 2.0609 - val_categorical_accuracy: 0.4850
Epoch 2/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 1.7373 - categorical_accuracy: 0.3914
Epoch 00002: val_loss improved from 2.06093 to 1.06915, saving model to t_weights_0
1600/1600 [==============================] - 0s 264us/sample - loss: 1.6636 - categorical_accuracy: 0.4112 - val_loss: 1.0691 - val_categorical_accuracy: 0.7700
Epoch 3/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 1.0713 - categorical_accuracy: 0.5989
Epoch 00003: val_loss improved from 1.06915 to 0.73259, saving model to t_weights_0
1600/1600 [==============================] - 0s 264us/sample - loss: 1.0688 - categorical_accuracy: 0.5994 - val_loss: 0.7326 - val_categorical_accuracy: 0.7450
Epoch 4/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.7943 - categorical_accuracy: 0.6936
Epoch 00004: val_loss improved from 0.73259 to 0.50972, saving model to t_weights_0
1600/1600 [==============================] - 0s 243us/sample - loss: 0.7840 - categorical_accuracy: 0.6975 - val_loss: 0.5097 - val_categorical_accuracy: 0.8950
Epoch 5/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.5788 - categorical_accuracy: 0.7704
Epoch 00005: val_loss improved from 0.50972 to 0.36205, saving model to t_weights_0
1600/1600 [==============================] - 0s 277us/sample - loss: 0.5769 - categorical_accuracy: 0.7706 - val_loss: 0.3621 - val_categorical_accuracy: 0.9700
Epoch 6/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.4619 - categorical_accuracy: 0.8342
Epoch 00006: val_loss improved from 0.36205 to 0.28176, saving model to t_weights_0
1600/1600 [==============================] - 0s 278us/sample - loss: 0.4575 - categorical_accuracy: 0.8363 - val_loss: 0.2818 - val_categorical_accuracy: 0.9400
Epoch 7/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.3490 - categorical_accuracy: 0.8939
Epoch 00007: val_loss improved from 0.28176 to 0.18321, saving model to t_weights_0
1600/1600 [==============================] - 0s 266us/sample - loss: 0.3521 - categorical_accuracy: 0.8931 - val_loss: 0.1832 - val_categorical_accuracy: 0.9800
Epoch 8/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.2719 - categorical_accuracy: 0.9238
Epoch 00008: val_loss improved from 0.18321 to 0.11851, saving model to t_weights_0
1600/1600 [==============================] - 0s 265us/sample - loss: 0.2668 - categorical_accuracy: 0.9262 - val_loss: 0.1185 - val_categorical_accuracy: 0.9850
Epoch 9/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.2006 - categorical_accuracy: 0.9411
Epoch 00009: val_loss improved from 0.11851 to 0.08507, saving model to t_weights_0
1600/1600 [==============================] - 0s 250us/sample - loss: 0.1997 - categorical_accuracy: 0.9431 - val_loss: 0.0851 - val_categorical_accuracy: 0.9850
Epoch 10/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.1619 - categorical_accuracy: 0.9620
Epoch 00010: val_loss improved from 0.08507 to 0.06045, saving model to t_weights_0
1600/1600 [==============================] - 0s 235us/sample - loss: 0.1562 - categorical_accuracy: 0.9650 - val_loss: 0.0605 - val_categorical_accuracy: 0.9900
Epoch 11/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1432 - categorical_accuracy: 0.9656
Epoch 00011: val_loss improved from 0.06045 to 0.05722, saving model to t_weights_0
1600/1600 [==============================] - 0s 269us/sample - loss: 0.1435 - categorical_accuracy: 0.9656 - val_loss: 0.0572 - val_categorical_accuracy: 0.9900
Epoch 12/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1205 - categorical_accuracy: 0.9681
Epoch 00012: val_loss improved from 0.05722 to 0.05455, saving model to t_weights_0
1600/1600 [==============================] - 0s 271us/sample - loss: 0.1206 - categorical_accuracy: 0.9681 - val_loss: 0.0546 - val_categorical_accuracy: 0.9900
Epoch 13/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1088 - categorical_accuracy: 0.9745
Epoch 00013: val_loss improved from 0.05455 to 0.04386, saving model to t_weights_0
1600/1600 [==============================] - 0s 273us/sample - loss: 0.1072 - categorical_accuracy: 0.9750 - val_loss: 0.0439 - val_categorical_accuracy: 0.9950
Epoch 14/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0992 - categorical_accuracy: 0.9785
Epoch 00014: val_loss did not improve from 0.04386
1600/1600 [==============================] - 0s 234us/sample - loss: 0.1019 - categorical_accuracy: 0.9756 - val_loss: 0.0767 - val_categorical_accuracy: 0.9750
Epoch 15/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0986 - categorical_accuracy: 0.9805
Epoch 00015: val_loss improved from 0.04386 to 0.02926, saving model to t_weights_0
1600/1600 [==============================] - 0s 272us/sample - loss: 0.0973 - categorical_accuracy: 0.9806 - val_loss: 0.0293 - val_categorical_accuracy: 0.9950
Epoch 16/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0736 - categorical_accuracy: 0.9905
Epoch 00016: val_loss improved from 0.02926 to 0.02762, saving model to t_weights_0
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0728 - categorical_accuracy: 0.9900 - val_loss: 0.0276 - val_categorical_accuracy: 0.9950
Epoch 17/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0649 - categorical_accuracy: 0.9866
Epoch 00017: val_loss improved from 0.02762 to 0.02505, saving model to t_weights_0
1600/1600 [==============================] - 0s 272us/sample - loss: 0.0650 - categorical_accuracy: 0.9869 - val_loss: 0.0250 - val_categorical_accuracy: 1.0000
Epoch 18/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0597 - categorical_accuracy: 0.9927
Epoch 00018: val_loss improved from 0.02505 to 0.02095, saving model to t_weights_0
1600/1600 [==============================] - 0s 280us/sample - loss: 0.0601 - categorical_accuracy: 0.9919 - val_loss: 0.0209 - val_categorical_accuracy: 1.0000
Epoch 19/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0499 - categorical_accuracy: 0.9900
Epoch 00019: val_loss improved from 0.02095 to 0.01982, saving model to t_weights_0
1600/1600 [==============================] - 0s 279us/sample - loss: 0.0501 - categorical_accuracy: 0.9906 - val_loss: 0.0198 - val_categorical_accuracy: 1.0000
Epoch 20/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0519 - categorical_accuracy: 0.9889
Epoch 00020: val_loss did not improve from 0.01982
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0526 - categorical_accuracy: 0.9887 - val_loss: 0.0203 - val_categorical_accuracy: 1.0000
Epoch 21/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0591 - categorical_accuracy: 0.9896
Epoch 00021: val_loss did not improve from 0.01982
1600/1600 [==============================] - 0s 220us/sample - loss: 0.0578 - categorical_accuracy: 0.9900 - val_loss: 0.0209 - val_categorical_accuracy: 1.0000
Epoch 22/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0442 - categorical_accuracy: 0.9937
Epoch 00022: val_loss improved from 0.01982 to 0.01860, saving model to t_weights_0
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0443 - categorical_accuracy: 0.9931 - val_loss: 0.0186 - val_categorical_accuracy: 1.0000
Epoch 23/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0429 - categorical_accuracy: 0.9935
Epoch 00023: val_loss did not improve from 0.01860
1600/1600 [==============================] - 0s 230us/sample - loss: 0.0429 - categorical_accuracy: 0.9937 - val_loss: 0.0192 - val_categorical_accuracy: 1.0000
Epoch 24/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0390 - categorical_accuracy: 0.9941
Epoch 00024: val_loss did not improve from 0.01860
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0394 - categorical_accuracy: 0.9944 - val_loss: 0.0216 - val_categorical_accuracy: 0.9950
Epoch 25/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0387 - categorical_accuracy: 0.9962
Epoch 00025: val_loss did not improve from 0.01860
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0384 - categorical_accuracy: 0.9962 - val_loss: 0.0190 - val_categorical_accuracy: 1.0000
Epoch 26/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0356 - categorical_accuracy: 0.9953
Epoch 00026: val_loss improved from 0.01860 to 0.01785, saving model to t_weights_0
1600/1600 [==============================] - 0s 279us/sample - loss: 0.0351 - categorical_accuracy: 0.9956 - val_loss: 0.0178 - val_categorical_accuracy: 1.0000
Epoch 27/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0387 - categorical_accuracy: 0.9933
Epoch 00027: val_loss improved from 0.01785 to 0.01762, saving model to t_weights_0
1600/1600 [==============================] - 0s 261us/sample - loss: 0.0364 - categorical_accuracy: 0.9944 - val_loss: 0.0176 - val_categorical_accuracy: 1.0000
Epoch 28/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0394 - categorical_accuracy: 0.9959
Epoch 00028: val_loss did not improve from 0.01762
1600/1600 [==============================] - 0s 204us/sample - loss: 0.0384 - categorical_accuracy: 0.9962 - val_loss: 0.0189 - val_categorical_accuracy: 1.0000
Epoch 29/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0389 - categorical_accuracy: 0.9926
Epoch 00029: val_loss did not improve from 0.01762
1600/1600 [==============================] - 0s 229us/sample - loss: 0.0393 - categorical_accuracy: 0.9931 - val_loss: 0.0178 - val_categorical_accuracy: 1.0000
Epoch 30/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0325 - categorical_accuracy: 0.9963
Epoch 00030: val_loss did not improve from 0.01762
1600/1600 [==============================] - 0s 231us/sample - loss: 0.0312 - categorical_accuracy: 0.9969 - val_loss: 0.0185 - val_categorical_accuracy: 1.0000
Epoch 31/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0331 - categorical_accuracy: 0.9954
Epoch 00031: val_loss improved from 0.01762 to 0.01757, saving model to t_weights_0
1600/1600 [==============================] - 0s 275us/sample - loss: 0.0334 - categorical_accuracy: 0.9950 - val_loss: 0.0176 - val_categorical_accuracy: 1.0000
Epoch 32/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0321 - categorical_accuracy: 0.9947
Epoch 00032: val_loss did not improve from 0.01757
1600/1600 [==============================] - 0s 232us/sample - loss: 0.0321 - categorical_accuracy: 0.9950 - val_loss: 0.0180 - val_categorical_accuracy: 1.0000
Epoch 33/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0323 - categorical_accuracy: 0.9968
Epoch 00033: val_loss improved from 0.01757 to 0.01745, saving model to t_weights_0
1600/1600 [==============================] - 0s 272us/sample - loss: 0.0322 - categorical_accuracy: 0.9969 - val_loss: 0.0175 - val_categorical_accuracy: 1.0000
Epoch 34/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0279 - categorical_accuracy: 0.9979
Epoch 00034: val_loss improved from 0.01745 to 0.01743, saving model to t_weights_0
1600/1600 [==============================] - 0s 243us/sample - loss: 0.0271 - categorical_accuracy: 0.9981 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 35/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0252 - categorical_accuracy: 0.9981
Epoch 00035: val_loss improved from 0.01743 to 0.01742, saving model to t_weights_0
1600/1600 [==============================] - 0s 267us/sample - loss: 0.0250 - categorical_accuracy: 0.9981 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 36/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0274 - categorical_accuracy: 0.9967
Epoch 00036: val_loss improved from 0.01742 to 0.01741, saving model to t_weights_0
1600/1600 [==============================] - 0s 276us/sample - loss: 0.0272 - categorical_accuracy: 0.9969 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 37/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0291 - categorical_accuracy: 0.9974
Epoch 00037: val_loss improved from 0.01741 to 0.01738, saving model to t_weights_0
1600/1600 [==============================] - 0s 269us/sample - loss: 0.0290 - categorical_accuracy: 0.9975 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 38/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0262 - categorical_accuracy: 0.9980
Epoch 00038: val_loss did not improve from 0.01738
1600/1600 [==============================] - 0s 237us/sample - loss: 0.0262 - categorical_accuracy: 0.9981 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 39/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0248 - categorical_accuracy: 0.9980
Epoch 00039: val_loss did not improve from 0.01738
1600/1600 [==============================] - 0s 233us/sample - loss: 0.0246 - categorical_accuracy: 0.9981 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 40/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0261 - categorical_accuracy: 0.9958
Epoch 00040: val_loss did not improve from 0.01738
1600/1600 [==============================] - 0s 203us/sample - loss: 0.0260 - categorical_accuracy: 0.9962 - val_loss: 0.0176 - val_categorical_accuracy: 1.0000
Epoch 41/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0262 - categorical_accuracy: 0.9985
Epoch 00041: val_loss improved from 0.01738 to 0.01730, saving model to t_weights_0
1600/1600 [==============================] - 0s 263us/sample - loss: 0.0264 - categorical_accuracy: 0.9981 - val_loss: 0.0173 - val_categorical_accuracy: 1.0000
Epoch 42/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0288 - categorical_accuracy: 0.9949
Epoch 00042: val_loss did not improve from 0.01730
1600/1600 [==============================] - 0s 232us/sample - loss: 0.0290 - categorical_accuracy: 0.9950 - val_loss: 0.0174 - val_categorical_accuracy: 1.0000
Epoch 43/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.9987
Epoch 00043: val_loss did not improve from 0.01730
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0222 - categorical_accuracy: 0.9987 - val_loss: 0.0173 - val_categorical_accuracy: 1.0000
Epoch 44/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0229 - categorical_accuracy: 0.9980
Epoch 00044: val_loss did not improve from 0.01730
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0231 - categorical_accuracy: 0.9981 - val_loss: 0.0206 - val_categorical_accuracy: 1.0000
Epoch 45/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0265 - categorical_accuracy: 0.9968
Epoch 00045: val_loss improved from 0.01730 to 0.01729, saving model to t_weights_0
1600/1600 [==============================] - 0s 279us/sample - loss: 0.0263 - categorical_accuracy: 0.9969 - val_loss: 0.0173 - val_categorical_accuracy: 1.0000
Epoch 46/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0228 - categorical_accuracy: 0.9979
Epoch 00046: val_loss did not improve from 0.01729
1600/1600 [==============================] - 0s 207us/sample - loss: 0.0234 - categorical_accuracy: 0.9975 - val_loss: 0.0197 - val_categorical_accuracy: 1.0000
Epoch 47/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0212 - categorical_accuracy: 1.0000
Epoch 00047: val_loss improved from 0.01729 to 0.01723, saving model to t_weights_0
1600/1600 [==============================] - 0s 243us/sample - loss: 0.0212 - categorical_accuracy: 1.0000 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000
Epoch 48/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0209 - categorical_accuracy: 1.0000
Epoch 00048: val_loss improved from 0.01723 to 0.01721, saving model to t_weights_0
1600/1600 [==============================] - 0s 269us/sample - loss: 0.0208 - categorical_accuracy: 1.0000 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000
Epoch 49/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0243 - categorical_accuracy: 0.9987
Epoch 00049: val_loss did not improve from 0.01721
1600/1600 [==============================] - 0s 234us/sample - loss: 0.0248 - categorical_accuracy: 0.9981 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000
Epoch 50/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0239 - categorical_accuracy: 0.9981
Epoch 00050: val_loss did not improve from 0.01721
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0238 - categorical_accuracy: 0.9981 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000
Epoch 51/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0232 - categorical_accuracy: 0.9980
Epoch 00051: val_loss improved from 0.01721 to 0.01719, saving model to t_weights_0
1600/1600 [==============================] - 0s 280us/sample - loss: 0.0231 - categorical_accuracy: 0.9981 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000
Epoch 52/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9981
Epoch 00052: val_loss did not improve from 0.01719
1600/1600 [==============================] - 0s 193us/sample - loss: 0.0241 - categorical_accuracy: 0.9981 - val_loss: 0.0229 - val_categorical_accuracy: 0.9950
Epoch 53/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0243 - categorical_accuracy: 0.9980
Epoch 00053: val_loss did not improve from 0.01719
1600/1600 [==============================] - 0s 195us/sample - loss: 0.0245 - categorical_accuracy: 0.9981 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000
Epoch 54/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0208 - categorical_accuracy: 0.9993
Epoch 00054: val_loss improved from 0.01719 to 0.01712, saving model to t_weights_0
1600/1600 [==============================] - 0s 284us/sample - loss: 0.0217 - categorical_accuracy: 0.9987 - val_loss: 0.0171 - val_categorical_accuracy: 1.0000
Epoch 55/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0206 - categorical_accuracy: 0.9987
Epoch 00055: val_loss improved from 0.01712 to 0.01710, saving model to t_weights_0
1600/1600 [==============================] - 0s 280us/sample - loss: 0.0207 - categorical_accuracy: 0.9987 - val_loss: 0.0171 - val_categorical_accuracy: 1.0000
Epoch 56/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0207 - categorical_accuracy: 1.0000
Epoch 00056: val_loss improved from 0.01710 to 0.01708, saving model to t_weights_0
1600/1600 [==============================] - 0s 277us/sample - loss: 0.0211 - categorical_accuracy: 1.0000 - val_loss: 0.0171 - val_categorical_accuracy: 1.0000
Epoch 57/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0196 - categorical_accuracy: 1.0000
Epoch 00057: val_loss improved from 0.01708 to 0.01708, saving model to t_weights_0
1600/1600 [==============================] - 0s 283us/sample - loss: 0.0196 - categorical_accuracy: 1.0000 - val_loss: 0.0171 - val_categorical_accuracy: 1.0000
Epoch 58/100
1312/1600 [=======================&gt;......] - ETA: 0s - loss: 0.0222 - categorical_accuracy: 0.9977
Epoch 00058: val_loss improved from 0.01708 to 0.01703, saving model to t_weights_0
1600/1600 [==============================] - 0s 254us/sample - loss: 0.0215 - categorical_accuracy: 0.9981 - val_loss: 0.0170 - val_categorical_accuracy: 1.0000
Epoch 59/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0199 - categorical_accuracy: 0.9993
Epoch 00059: val_loss improved from 0.01703 to 0.01700, saving model to t_weights_0
1600/1600 [==============================] - 0s 260us/sample - loss: 0.0200 - categorical_accuracy: 0.9994 - val_loss: 0.0170 - val_categorical_accuracy: 1.0000
Epoch 60/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0211 - categorical_accuracy: 0.9973
Epoch 00060: val_loss improved from 0.01700 to 0.01698, saving model to t_weights_0
1600/1600 [==============================] - 0s 279us/sample - loss: 0.0210 - categorical_accuracy: 0.9975 - val_loss: 0.0170 - val_categorical_accuracy: 1.0000
Epoch 61/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0193 - categorical_accuracy: 1.0000
Epoch 00061: val_loss improved from 0.01698 to 0.01694, saving model to t_weights_0
1600/1600 [==============================] - 0s 275us/sample - loss: 0.0193 - categorical_accuracy: 1.0000 - val_loss: 0.0169 - val_categorical_accuracy: 1.0000
Epoch 62/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0313 - categorical_accuracy: 0.9970
Epoch 00062: val_loss did not improve from 0.01694
1600/1600 [==============================] - 0s 227us/sample - loss: 0.0306 - categorical_accuracy: 0.9975 - val_loss: 0.0171 - val_categorical_accuracy: 1.0000
Epoch 63/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0207 - categorical_accuracy: 0.9993
Epoch 00063: val_loss did not improve from 0.01694
1600/1600 [==============================] - 0s 234us/sample - loss: 0.0213 - categorical_accuracy: 0.9987 - val_loss: 0.0170 - val_categorical_accuracy: 1.0000
Epoch 64/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0256 - categorical_accuracy: 0.9979
Epoch 00064: val_loss did not improve from 0.01694
1600/1600 [==============================] - 0s 207us/sample - loss: 0.0254 - categorical_accuracy: 0.9981 - val_loss: 0.0170 - val_categorical_accuracy: 1.0000
Epoch 65/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0203 - categorical_accuracy: 0.9993
Epoch 00065: val_loss improved from 0.01694 to 0.01694, saving model to t_weights_0
1600/1600 [==============================] - 0s 252us/sample - loss: 0.0218 - categorical_accuracy: 0.9987 - val_loss: 0.0169 - val_categorical_accuracy: 1.0000
Epoch 66/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0221 - categorical_accuracy: 0.9980
Epoch 00066: val_loss did not improve from 0.01694
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0220 - categorical_accuracy: 0.9981 - val_loss: 0.0177 - val_categorical_accuracy: 1.0000
Epoch 67/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0210 - categorical_accuracy: 1.0000
Epoch 00067: val_loss improved from 0.01694 to 0.01689, saving model to t_weights_0
1600/1600 [==============================] - 0s 290us/sample - loss: 0.0213 - categorical_accuracy: 1.0000 - val_loss: 0.0169 - val_categorical_accuracy: 1.0000
Epoch 68/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0185 - categorical_accuracy: 1.0000
Epoch 00068: val_loss improved from 0.01689 to 0.01685, saving model to t_weights_0
1600/1600 [==============================] - 0s 284us/sample - loss: 0.0190 - categorical_accuracy: 1.0000 - val_loss: 0.0168 - val_categorical_accuracy: 1.0000
Epoch 69/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0194 - categorical_accuracy: 0.9993
Epoch 00069: val_loss improved from 0.01685 to 0.01683, saving model to t_weights_0
1600/1600 [==============================] - 0s 282us/sample - loss: 0.0194 - categorical_accuracy: 0.9994 - val_loss: 0.0168 - val_categorical_accuracy: 1.0000
Epoch 70/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0187 - categorical_accuracy: 1.0000
Epoch 00070: val_loss improved from 0.01683 to 0.01678, saving model to t_weights_0
1600/1600 [==============================] - 0s 245us/sample - loss: 0.0186 - categorical_accuracy: 1.0000 - val_loss: 0.0168 - val_categorical_accuracy: 1.0000
Epoch 71/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0191 - categorical_accuracy: 1.0000
Epoch 00071: val_loss improved from 0.01678 to 0.01673, saving model to t_weights_0
1600/1600 [==============================] - 0s 256us/sample - loss: 0.0193 - categorical_accuracy: 1.0000 - val_loss: 0.0167 - val_categorical_accuracy: 1.0000
Epoch 72/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0178 - categorical_accuracy: 1.0000
Epoch 00072: val_loss improved from 0.01673 to 0.01669, saving model to t_weights_0
1600/1600 [==============================] - 0s 274us/sample - loss: 0.0178 - categorical_accuracy: 1.0000 - val_loss: 0.0167 - val_categorical_accuracy: 1.0000
Epoch 73/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0220 - categorical_accuracy: 0.9987
Epoch 00073: val_loss improved from 0.01669 to 0.01664, saving model to t_weights_0
1600/1600 [==============================] - 0s 271us/sample - loss: 0.0240 - categorical_accuracy: 0.9975 - val_loss: 0.0166 - val_categorical_accuracy: 1.0000
Epoch 74/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0227 - categorical_accuracy: 0.9979
Epoch 00074: val_loss did not improve from 0.01664
1600/1600 [==============================] - 0s 221us/sample - loss: 0.0221 - categorical_accuracy: 0.9981 - val_loss: 0.0168 - val_categorical_accuracy: 1.0000
Epoch 75/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0425 - categorical_accuracy: 0.9922
Epoch 00075: val_loss did not improve from 0.01664
1600/1600 [==============================] - 0s 237us/sample - loss: 0.0415 - categorical_accuracy: 0.9925 - val_loss: 0.0170 - val_categorical_accuracy: 1.0000
Epoch 76/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0301 - categorical_accuracy: 0.9964
Epoch 00076: val_loss did not improve from 0.01664
1600/1600 [==============================] - 0s 214us/sample - loss: 0.0285 - categorical_accuracy: 0.9969 - val_loss: 0.0167 - val_categorical_accuracy: 1.0000
Epoch 77/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0193 - categorical_accuracy: 0.9993
Epoch 00077: val_loss did not improve from 0.01664
1600/1600 [==============================] - 0s 209us/sample - loss: 0.0199 - categorical_accuracy: 0.9987 - val_loss: 0.0167 - val_categorical_accuracy: 1.0000
Epoch 78/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0193 - categorical_accuracy: 0.9993
Epoch 00078: val_loss did not improve from 0.01664
1600/1600 [==============================] - 0s 237us/sample - loss: 0.0192 - categorical_accuracy: 0.9994 - val_loss: 0.0167 - val_categorical_accuracy: 1.0000
1.0 0.3539


nrx: 5 - real: 1 
Train on 9009 samples, validate on 1125 samples
Epoch 1/100
8960/9009 [============================&gt;.] - ETA: 0s - loss: 1.6362 - categorical_accuracy: 0.3883
Epoch 00001: val_loss improved from inf to 0.88399, saving model to t_weights_0
9009/9009 [==============================] - 2s 274us/sample - loss: 1.6337 - categorical_accuracy: 0.3893 - val_loss: 0.8840 - val_categorical_accuracy: 0.6764
Epoch 2/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.8113 - categorical_accuracy: 0.6790
Epoch 00002: val_loss improved from 0.88399 to 0.56511, saving model to t_weights_0
9009/9009 [==============================] - 2s 229us/sample - loss: 0.8104 - categorical_accuracy: 0.6794 - val_loss: 0.5651 - val_categorical_accuracy: 0.7698
Epoch 3/100
8864/9009 [============================&gt;.] - ETA: 0s - loss: 0.5195 - categorical_accuracy: 0.8017
Epoch 00003: val_loss improved from 0.56511 to 0.38535, saving model to t_weights_0
9009/9009 [==============================] - 2s 228us/sample - loss: 0.5186 - categorical_accuracy: 0.8028 - val_loss: 0.3853 - val_categorical_accuracy: 0.8542
Epoch 4/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.3476 - categorical_accuracy: 0.8832
Epoch 00004: val_loss improved from 0.38535 to 0.24309, saving model to t_weights_0
9009/9009 [==============================] - 2s 231us/sample - loss: 0.3472 - categorical_accuracy: 0.8837 - val_loss: 0.2431 - val_categorical_accuracy: 0.9333
Epoch 5/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.2445 - categorical_accuracy: 0.9328
Epoch 00005: val_loss improved from 0.24309 to 0.18485, saving model to t_weights_0
9009/9009 [==============================] - 2s 230us/sample - loss: 0.2442 - categorical_accuracy: 0.9327 - val_loss: 0.1848 - val_categorical_accuracy: 0.9502
Epoch 6/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.9512
Epoch 00006: val_loss did not improve from 0.18485
9009/9009 [==============================] - 2s 198us/sample - loss: 0.1883 - categorical_accuracy: 0.9508 - val_loss: 0.1897 - val_categorical_accuracy: 0.9422
Epoch 7/100
8992/9009 [============================&gt;.] - ETA: 0s - loss: 0.1575 - categorical_accuracy: 0.9616
Epoch 00007: val_loss improved from 0.18485 to 0.13537, saving model to t_weights_0
9009/9009 [==============================] - 2s 236us/sample - loss: 0.1574 - categorical_accuracy: 0.9617 - val_loss: 0.1354 - val_categorical_accuracy: 0.9636
Epoch 8/100
8864/9009 [============================&gt;.] - ETA: 0s - loss: 0.1312 - categorical_accuracy: 0.9689
Epoch 00008: val_loss improved from 0.13537 to 0.13038, saving model to t_weights_0
9009/9009 [==============================] - 2s 233us/sample - loss: 0.1306 - categorical_accuracy: 0.9689 - val_loss: 0.1304 - val_categorical_accuracy: 0.9707
Epoch 9/100
8864/9009 [============================&gt;.] - ETA: 0s - loss: 0.1137 - categorical_accuracy: 0.9728
Epoch 00009: val_loss improved from 0.13038 to 0.10389, saving model to t_weights_0
9009/9009 [==============================] - 2s 231us/sample - loss: 0.1135 - categorical_accuracy: 0.9728 - val_loss: 0.1039 - val_categorical_accuracy: 0.9751
Epoch 10/100
8832/9009 [============================&gt;.] - ETA: 0s - loss: 0.1120 - categorical_accuracy: 0.9742
Epoch 00010: val_loss did not improve from 0.10389
9009/9009 [==============================] - 2s 222us/sample - loss: 0.1115 - categorical_accuracy: 0.9742 - val_loss: 0.1215 - val_categorical_accuracy: 0.9724
Epoch 11/100
8960/9009 [============================&gt;.] - ETA: 0s - loss: 0.0977 - categorical_accuracy: 0.9779
Epoch 00011: val_loss did not improve from 0.10389
9009/9009 [==============================] - 2s 223us/sample - loss: 0.0977 - categorical_accuracy: 0.9779 - val_loss: 0.2172 - val_categorical_accuracy: 0.9244
Epoch 12/100
8832/9009 [============================&gt;.] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9826
Epoch 00012: val_loss did not improve from 0.10389
9009/9009 [==============================] - 2s 223us/sample - loss: 0.0822 - categorical_accuracy: 0.9824 - val_loss: 0.1103 - val_categorical_accuracy: 0.9778
Epoch 13/100
8928/9009 [============================&gt;.] - ETA: 0s - loss: 0.0808 - categorical_accuracy: 0.9830
Epoch 00013: val_loss did not improve from 0.10389
9009/9009 [==============================] - 2s 230us/sample - loss: 0.0810 - categorical_accuracy: 0.9828 - val_loss: 0.1187 - val_categorical_accuracy: 0.9707
Epoch 14/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.0762 - categorical_accuracy: 0.9845
Epoch 00014: val_loss improved from 0.10389 to 0.09983, saving model to t_weights_0
9009/9009 [==============================] - 2s 232us/sample - loss: 0.0759 - categorical_accuracy: 0.9845 - val_loss: 0.0998 - val_categorical_accuracy: 0.9760
Epoch 15/100
8768/9009 [============================&gt;.] - ETA: 0s - loss: 0.0720 - categorical_accuracy: 0.9857
Epoch 00015: val_loss did not improve from 0.09983
9009/9009 [==============================] - 2s 222us/sample - loss: 0.0712 - categorical_accuracy: 0.9860 - val_loss: 0.0999 - val_categorical_accuracy: 0.9822
Epoch 16/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.0670 - categorical_accuracy: 0.9862
Epoch 00016: val_loss did not improve from 0.09983
9009/9009 [==============================] - 2s 222us/sample - loss: 0.0669 - categorical_accuracy: 0.9861 - val_loss: 0.1014 - val_categorical_accuracy: 0.9787
Epoch 17/100
8960/9009 [============================&gt;.] - ETA: 0s - loss: 0.0657 - categorical_accuracy: 0.9867
Epoch 00017: val_loss improved from 0.09983 to 0.09208, saving model to t_weights_0
9009/9009 [==============================] - 2s 228us/sample - loss: 0.0655 - categorical_accuracy: 0.9868 - val_loss: 0.0921 - val_categorical_accuracy: 0.9822
Epoch 18/100
8800/9009 [============================&gt;.] - ETA: 0s - loss: 0.0608 - categorical_accuracy: 0.9884
Epoch 00018: val_loss did not improve from 0.09208
9009/9009 [==============================] - 2s 222us/sample - loss: 0.0615 - categorical_accuracy: 0.9880 - val_loss: 0.0955 - val_categorical_accuracy: 0.9822
Epoch 19/100
8960/9009 [============================&gt;.] - ETA: 0s - loss: 0.0584 - categorical_accuracy: 0.9898
Epoch 00019: val_loss improved from 0.09208 to 0.08865, saving model to t_weights_0
9009/9009 [==============================] - 2s 235us/sample - loss: 0.0583 - categorical_accuracy: 0.9899 - val_loss: 0.0887 - val_categorical_accuracy: 0.9796
Epoch 20/100
8896/9009 [============================&gt;.] - ETA: 0s - loss: 0.0593 - categorical_accuracy: 0.9890
Epoch 00020: val_loss did not improve from 0.08865
9009/9009 [==============================] - 2s 221us/sample - loss: 0.0589 - categorical_accuracy: 0.9891 - val_loss: 0.0916 - val_categorical_accuracy: 0.9858
Epoch 21/100
8864/9009 [============================&gt;.] - ETA: 0s - loss: 0.0591 - categorical_accuracy: 0.9876
Epoch 00021: val_loss did not improve from 0.08865
9009/9009 [==============================] - 2s 223us/sample - loss: 0.0588 - categorical_accuracy: 0.9878 - val_loss: 0.1046 - val_categorical_accuracy: 0.9813
Epoch 22/100
8800/9009 [============================&gt;.] - ETA: 0s - loss: 0.0448 - categorical_accuracy: 0.9930
Epoch 00022: val_loss improved from 0.08865 to 0.08764, saving model to t_weights_0
9009/9009 [==============================] - 2s 230us/sample - loss: 0.0452 - categorical_accuracy: 0.9928 - val_loss: 0.0876 - val_categorical_accuracy: 0.9804
Epoch 23/100
8960/9009 [============================&gt;.] - ETA: 0s - loss: 0.0506 - categorical_accuracy: 0.9923
Epoch 00023: val_loss did not improve from 0.08764
9009/9009 [==============================] - 2s 220us/sample - loss: 0.0505 - categorical_accuracy: 0.9923 - val_loss: 0.1061 - val_categorical_accuracy: 0.9813
Epoch 24/100
8992/9009 [============================&gt;.] - ETA: 0s - loss: 0.0470 - categorical_accuracy: 0.9921
Epoch 00024: val_loss did not improve from 0.08764
9009/9009 [==============================] - 2s 226us/sample - loss: 0.0470 - categorical_accuracy: 0.9921 - val_loss: 0.0977 - val_categorical_accuracy: 0.9822
Epoch 25/100
8928/9009 [============================&gt;.] - ETA: 0s - loss: 0.0489 - categorical_accuracy: 0.9918
Epoch 00025: val_loss did not improve from 0.08764
9009/9009 [==============================] - 2s 228us/sample - loss: 0.0487 - categorical_accuracy: 0.9919 - val_loss: 0.0925 - val_categorical_accuracy: 0.9867
Epoch 26/100
8864/9009 [============================&gt;.] - ETA: 0s - loss: 0.0500 - categorical_accuracy: 0.9921
Epoch 00026: val_loss did not improve from 0.08764
9009/9009 [==============================] - 2s 223us/sample - loss: 0.0507 - categorical_accuracy: 0.9919 - val_loss: 0.1007 - val_categorical_accuracy: 0.9822
Epoch 27/100
8992/9009 [============================&gt;.] - ETA: 0s - loss: 0.0435 - categorical_accuracy: 0.9935
Epoch 00027: val_loss did not improve from 0.08764
9009/9009 [==============================] - 2s 223us/sample - loss: 0.0435 - categorical_accuracy: 0.9936 - val_loss: 0.0924 - val_categorical_accuracy: 0.9840
0.9813333 0.6334


nrx: 10 - real: 1 
Train on 16377 samples, validate on 2046 samples
Epoch 1/100
16128/16377 [============================&gt;.] - ETA: 0s - loss: 1.2832 - categorical_accuracy: 0.4854
Epoch 00001: val_loss improved from inf to 0.63253, saving model to t_weights_0
16377/16377 [==============================] - 4s 251us/sample - loss: 1.2753 - categorical_accuracy: 0.4880 - val_loss: 0.6325 - val_categorical_accuracy: 0.7302
Epoch 2/100
16288/16377 [============================&gt;.] - ETA: 0s - loss: 0.6047 - categorical_accuracy: 0.7471
Epoch 00002: val_loss improved from 0.63253 to 0.42589, saving model to t_weights_0
16377/16377 [==============================] - 4s 225us/sample - loss: 0.6040 - categorical_accuracy: 0.7476 - val_loss: 0.4259 - val_categorical_accuracy: 0.8480
Epoch 3/100
16352/16377 [============================&gt;.] - ETA: 0s - loss: 0.3933 - categorical_accuracy: 0.8550
Epoch 00003: val_loss improved from 0.42589 to 0.25367, saving model to t_weights_0
16377/16377 [==============================] - 4s 226us/sample - loss: 0.3934 - categorical_accuracy: 0.8550 - val_loss: 0.2537 - val_categorical_accuracy: 0.9242
Epoch 4/100
16128/16377 [============================&gt;.] - ETA: 0s - loss: 0.2821 - categorical_accuracy: 0.9071
Epoch 00004: val_loss improved from 0.25367 to 0.17151, saving model to t_weights_0
16377/16377 [==============================] - 4s 219us/sample - loss: 0.2812 - categorical_accuracy: 0.9076 - val_loss: 0.1715 - val_categorical_accuracy: 0.9550
Epoch 5/100
16288/16377 [============================&gt;.] - ETA: 0s - loss: 0.2042 - categorical_accuracy: 0.9408
Epoch 00005: val_loss improved from 0.17151 to 0.13941, saving model to t_weights_0
16377/16377 [==============================] - 4s 218us/sample - loss: 0.2046 - categorical_accuracy: 0.9406 - val_loss: 0.1394 - val_categorical_accuracy: 0.9638
Epoch 6/100
16160/16377 [============================&gt;.] - ETA: 0s - loss: 0.1687 - categorical_accuracy: 0.9522
Epoch 00006: val_loss did not improve from 0.13941
16377/16377 [==============================] - 4s 220us/sample - loss: 0.1685 - categorical_accuracy: 0.9523 - val_loss: 0.1463 - val_categorical_accuracy: 0.9516
Epoch 7/100
16128/16377 [============================&gt;.] - ETA: 0s - loss: 0.1442 - categorical_accuracy: 0.9623
Epoch 00007: val_loss improved from 0.13941 to 0.11249, saving model to t_weights_0
16377/16377 [==============================] - 3s 208us/sample - loss: 0.1439 - categorical_accuracy: 0.9627 - val_loss: 0.1125 - val_categorical_accuracy: 0.9663
Epoch 8/100
16224/16377 [============================&gt;.] - ETA: 0s - loss: 0.1259 - categorical_accuracy: 0.9670
Epoch 00008: val_loss improved from 0.11249 to 0.09344, saving model to t_weights_0
16377/16377 [==============================] - 4s 221us/sample - loss: 0.1255 - categorical_accuracy: 0.9670 - val_loss: 0.0934 - val_categorical_accuracy: 0.9726
Epoch 9/100
16224/16377 [============================&gt;.] - ETA: 0s - loss: 0.1140 - categorical_accuracy: 0.9700
Epoch 00009: val_loss improved from 0.09344 to 0.09301, saving model to t_weights_0
16377/16377 [==============================] - 4s 224us/sample - loss: 0.1143 - categorical_accuracy: 0.9700 - val_loss: 0.0930 - val_categorical_accuracy: 0.9741
Epoch 10/100
16032/16377 [============================&gt;.] - ETA: 0s - loss: 0.0968 - categorical_accuracy: 0.9753
Epoch 00010: val_loss did not improve from 0.09301
16377/16377 [==============================] - 3s 200us/sample - loss: 0.0969 - categorical_accuracy: 0.9753 - val_loss: 0.1000 - val_categorical_accuracy: 0.9741
Epoch 11/100
16352/16377 [============================&gt;.] - ETA: 0s - loss: 0.0890 - categorical_accuracy: 0.9791
Epoch 00011: val_loss improved from 0.09301 to 0.08904, saving model to t_weights_0
16377/16377 [==============================] - 3s 213us/sample - loss: 0.0891 - categorical_accuracy: 0.9791 - val_loss: 0.0890 - val_categorical_accuracy: 0.9800
Epoch 12/100
16128/16377 [============================&gt;.] - ETA: 0s - loss: 0.0866 - categorical_accuracy: 0.9793
Epoch 00012: val_loss improved from 0.08904 to 0.08214, saving model to t_weights_0
16377/16377 [==============================] - 4s 225us/sample - loss: 0.0860 - categorical_accuracy: 0.9795 - val_loss: 0.0821 - val_categorical_accuracy: 0.9790
Epoch 13/100
16256/16377 [============================&gt;.] - ETA: 0s - loss: 0.0791 - categorical_accuracy: 0.9815
Epoch 00013: val_loss did not improve from 0.08214
16377/16377 [==============================] - 4s 220us/sample - loss: 0.0790 - categorical_accuracy: 0.9815 - val_loss: 0.0963 - val_categorical_accuracy: 0.9804
Epoch 14/100
16256/16377 [============================&gt;.] - ETA: 0s - loss: 0.0760 - categorical_accuracy: 0.9828
Epoch 00014: val_loss improved from 0.08214 to 0.07445, saving model to t_weights_0
16377/16377 [==============================] - 4s 227us/sample - loss: 0.0757 - categorical_accuracy: 0.9830 - val_loss: 0.0744 - val_categorical_accuracy: 0.9839
Epoch 15/100
16352/16377 [============================&gt;.] - ETA: 0s - loss: 0.0695 - categorical_accuracy: 0.9850
Epoch 00015: val_loss improved from 0.07445 to 0.07171, saving model to t_weights_0
16377/16377 [==============================] - 4s 227us/sample - loss: 0.0694 - categorical_accuracy: 0.9850 - val_loss: 0.0717 - val_categorical_accuracy: 0.9868
Epoch 16/100
16192/16377 [============================&gt;.] - ETA: 0s - loss: 0.0662 - categorical_accuracy: 0.9865
Epoch 00016: val_loss did not improve from 0.07171
16377/16377 [==============================] - 4s 224us/sample - loss: 0.0663 - categorical_accuracy: 0.9864 - val_loss: 0.0973 - val_categorical_accuracy: 0.9746
Epoch 17/100
16224/16377 [============================&gt;.] - ETA: 0s - loss: 0.0661 - categorical_accuracy: 0.9866
Epoch 00017: val_loss did not improve from 0.07171
16377/16377 [==============================] - 4s 224us/sample - loss: 0.0661 - categorical_accuracy: 0.9866 - val_loss: 0.0746 - val_categorical_accuracy: 0.9848
Epoch 18/100
16224/16377 [============================&gt;.] - ETA: 0s - loss: 0.0623 - categorical_accuracy: 0.9872
Epoch 00018: val_loss improved from 0.07171 to 0.06677, saving model to t_weights_0
16377/16377 [==============================] - 4s 227us/sample - loss: 0.0622 - categorical_accuracy: 0.9874 - val_loss: 0.0668 - val_categorical_accuracy: 0.9868
Epoch 19/100
16192/16377 [============================&gt;.] - ETA: 0s - loss: 0.0569 - categorical_accuracy: 0.9898
Epoch 00019: val_loss did not improve from 0.06677
16377/16377 [==============================] - 4s 222us/sample - loss: 0.0567 - categorical_accuracy: 0.9898 - val_loss: 0.0720 - val_categorical_accuracy: 0.9888
Epoch 20/100
16256/16377 [============================&gt;.] - ETA: 0s - loss: 0.0543 - categorical_accuracy: 0.9891
Epoch 00020: val_loss did not improve from 0.06677
16377/16377 [==============================] - 4s 223us/sample - loss: 0.0542 - categorical_accuracy: 0.9891 - val_loss: 0.0705 - val_categorical_accuracy: 0.9844
Epoch 21/100
16128/16377 [============================&gt;.] - ETA: 0s - loss: 0.0549 - categorical_accuracy: 0.9891
Epoch 00021: val_loss did not improve from 0.06677
16377/16377 [==============================] - 3s 213us/sample - loss: 0.0550 - categorical_accuracy: 0.9891 - val_loss: 0.0863 - val_categorical_accuracy: 0.9824
Epoch 22/100
16192/16377 [============================&gt;.] - ETA: 0s - loss: 0.0513 - categorical_accuracy: 0.9913
Epoch 00022: val_loss did not improve from 0.06677
16377/16377 [==============================] - 4s 224us/sample - loss: 0.0513 - categorical_accuracy: 0.9913 - val_loss: 0.0764 - val_categorical_accuracy: 0.9858
Epoch 23/100
16224/16377 [============================&gt;.] - ETA: 0s - loss: 0.0460 - categorical_accuracy: 0.9931
Epoch 00023: val_loss did not improve from 0.06677
16377/16377 [==============================] - 4s 221us/sample - loss: 0.0460 - categorical_accuracy: 0.9931 - val_loss: 0.0695 - val_categorical_accuracy: 0.9878
0.98435974 0.6731


nrx: 15 - real: 1 
Train on 24377 samples, validate on 3046 samples
Epoch 1/100
24224/24377 [============================&gt;.] - ETA: 0s - loss: 1.1619 - categorical_accuracy: 0.5177
Epoch 00001: val_loss improved from inf to 0.67190, saving model to t_weights_0
24377/24377 [==============================] - 6s 242us/sample - loss: 1.1592 - categorical_accuracy: 0.5185 - val_loss: 0.6719 - val_categorical_accuracy: 0.7127
Epoch 2/100
24256/24377 [============================&gt;.] - ETA: 0s - loss: 0.6069 - categorical_accuracy: 0.7458
Epoch 00002: val_loss improved from 0.67190 to 0.40793, saving model to t_weights_0
24377/24377 [==============================] - 5s 225us/sample - loss: 0.6063 - categorical_accuracy: 0.7461 - val_loss: 0.4079 - val_categorical_accuracy: 0.8726
Epoch 3/100
24352/24377 [============================&gt;.] - ETA: 0s - loss: 0.3832 - categorical_accuracy: 0.8710
Epoch 00003: val_loss improved from 0.40793 to 0.23092, saving model to t_weights_0
24377/24377 [==============================] - 5s 223us/sample - loss: 0.3833 - categorical_accuracy: 0.8710 - val_loss: 0.2309 - val_categorical_accuracy: 0.9360
Epoch 4/100
24320/24377 [============================&gt;.] - ETA: 0s - loss: 0.2599 - categorical_accuracy: 0.9219
Epoch 00004: val_loss improved from 0.23092 to 0.19473, saving model to t_weights_0
24377/24377 [==============================] - 5s 211us/sample - loss: 0.2600 - categorical_accuracy: 0.9218 - val_loss: 0.1947 - val_categorical_accuracy: 0.9435
Epoch 5/100
24288/24377 [============================&gt;.] - ETA: 0s - loss: 0.2040 - categorical_accuracy: 0.9419
Epoch 00005: val_loss improved from 0.19473 to 0.16300, saving model to t_weights_0
24377/24377 [==============================] - 5s 224us/sample - loss: 0.2040 - categorical_accuracy: 0.9418 - val_loss: 0.1630 - val_categorical_accuracy: 0.9547
Epoch 6/100
24288/24377 [============================&gt;.] - ETA: 0s - loss: 0.1737 - categorical_accuracy: 0.9517
Epoch 00006: val_loss improved from 0.16300 to 0.16287, saving model to t_weights_0
24377/24377 [==============================] - 5s 225us/sample - loss: 0.1736 - categorical_accuracy: 0.9517 - val_loss: 0.1629 - val_categorical_accuracy: 0.9567
Epoch 7/100
24160/24377 [============================&gt;.] - ETA: 0s - loss: 0.1536 - categorical_accuracy: 0.9581
Epoch 00007: val_loss improved from 0.16287 to 0.13918, saving model to t_weights_0
24377/24377 [==============================] - 5s 224us/sample - loss: 0.1540 - categorical_accuracy: 0.9578 - val_loss: 0.1392 - val_categorical_accuracy: 0.9665
Epoch 8/100
24224/24377 [============================&gt;.] - ETA: 0s - loss: 0.1391 - categorical_accuracy: 0.9629
Epoch 00008: val_loss improved from 0.13918 to 0.13177, saving model to t_weights_0
24377/24377 [==============================] - 5s 222us/sample - loss: 0.1396 - categorical_accuracy: 0.9628 - val_loss: 0.1318 - val_categorical_accuracy: 0.9685
Epoch 9/100
24288/24377 [============================&gt;.] - ETA: 0s - loss: 0.1269 - categorical_accuracy: 0.9670
Epoch 00009: val_loss improved from 0.13177 to 0.12148, saving model to t_weights_0
24377/24377 [==============================] - 6s 226us/sample - loss: 0.1268 - categorical_accuracy: 0.9670 - val_loss: 0.1215 - val_categorical_accuracy: 0.9714
Epoch 10/100
24128/24377 [============================&gt;.] - ETA: 0s - loss: 0.1248 - categorical_accuracy: 0.9668
Epoch 00010: val_loss did not improve from 0.12148
24377/24377 [==============================] - 5s 216us/sample - loss: 0.1245 - categorical_accuracy: 0.9669 - val_loss: 0.1235 - val_categorical_accuracy: 0.9701
Epoch 11/100
24320/24377 [============================&gt;.] - ETA: 0s - loss: 0.1122 - categorical_accuracy: 0.9717
Epoch 00011: val_loss improved from 0.12148 to 0.11861, saving model to t_weights_0
24377/24377 [==============================] - 5s 226us/sample - loss: 0.1128 - categorical_accuracy: 0.9716 - val_loss: 0.1186 - val_categorical_accuracy: 0.9724
Epoch 12/100
24192/24377 [============================&gt;.] - ETA: 0s - loss: 0.1045 - categorical_accuracy: 0.9741
Epoch 00012: val_loss improved from 0.11861 to 0.10575, saving model to t_weights_0
24377/24377 [==============================] - 5s 223us/sample - loss: 0.1043 - categorical_accuracy: 0.9742 - val_loss: 0.1057 - val_categorical_accuracy: 0.9750
Epoch 13/100
24288/24377 [============================&gt;.] - ETA: 0s - loss: 0.0996 - categorical_accuracy: 0.9748
Epoch 00013: val_loss did not improve from 0.10575
24377/24377 [==============================] - 5s 222us/sample - loss: 0.0995 - categorical_accuracy: 0.9749 - val_loss: 0.1148 - val_categorical_accuracy: 0.9728
Epoch 14/100
24192/24377 [============================&gt;.] - ETA: 0s - loss: 0.0938 - categorical_accuracy: 0.9781
Epoch 00014: val_loss improved from 0.10575 to 0.10202, saving model to t_weights_0
24377/24377 [==============================] - 5s 225us/sample - loss: 0.0937 - categorical_accuracy: 0.9781 - val_loss: 0.1020 - val_categorical_accuracy: 0.9796
Epoch 15/100
24192/24377 [============================&gt;.] - ETA: 0s - loss: 0.0911 - categorical_accuracy: 0.9785
Epoch 00015: val_loss did not improve from 0.10202
24377/24377 [==============================] - 5s 223us/sample - loss: 0.0911 - categorical_accuracy: 0.9784 - val_loss: 0.1198 - val_categorical_accuracy: 0.9767
Epoch 16/100
24288/24377 [============================&gt;.] - ETA: 0s - loss: 0.0867 - categorical_accuracy: 0.9792
Epoch 00016: val_loss did not improve from 0.10202
24377/24377 [==============================] - 5s 221us/sample - loss: 0.0869 - categorical_accuracy: 0.9792 - val_loss: 0.1055 - val_categorical_accuracy: 0.9783
Epoch 17/100
24256/24377 [============================&gt;.] - ETA: 0s - loss: 0.0851 - categorical_accuracy: 0.9797
Epoch 00017: val_loss did not improve from 0.10202
24377/24377 [==============================] - 5s 220us/sample - loss: 0.0850 - categorical_accuracy: 0.9798 - val_loss: 0.1048 - val_categorical_accuracy: 0.9813
Epoch 18/100
24224/24377 [============================&gt;.] - ETA: 0s - loss: 0.0766 - categorical_accuracy: 0.9830
Epoch 00018: val_loss improved from 0.10202 to 0.09776, saving model to t_weights_0
24377/24377 [==============================] - 5s 225us/sample - loss: 0.0768 - categorical_accuracy: 0.9830 - val_loss: 0.0978 - val_categorical_accuracy: 0.9839
Epoch 19/100
24224/24377 [============================&gt;.] - ETA: 0s - loss: 0.0771 - categorical_accuracy: 0.9829
Epoch 00019: val_loss did not improve from 0.09776
24377/24377 [==============================] - 5s 223us/sample - loss: 0.0770 - categorical_accuracy: 0.9829 - val_loss: 0.0978 - val_categorical_accuracy: 0.9806
Epoch 20/100
24160/24377 [============================&gt;.] - ETA: 0s - loss: 0.0687 - categorical_accuracy: 0.9857
Epoch 00020: val_loss did not improve from 0.09776
24377/24377 [==============================] - 5s 224us/sample - loss: 0.0691 - categorical_accuracy: 0.9855 - val_loss: 0.1146 - val_categorical_accuracy: 0.9793
Epoch 21/100
24256/24377 [============================&gt;.] - ETA: 0s - loss: 0.0649 - categorical_accuracy: 0.9871
Epoch 00021: val_loss did not improve from 0.09776
24377/24377 [==============================] - 5s 212us/sample - loss: 0.0652 - categorical_accuracy: 0.9870 - val_loss: 0.1011 - val_categorical_accuracy: 0.9826
Epoch 22/100
24224/24377 [============================&gt;.] - ETA: 0s - loss: 0.0644 - categorical_accuracy: 0.9862
Epoch 00022: val_loss improved from 0.09776 to 0.09242, saving model to t_weights_0
24377/24377 [==============================] - 5s 224us/sample - loss: 0.0643 - categorical_accuracy: 0.9863 - val_loss: 0.0924 - val_categorical_accuracy: 0.9862
Epoch 23/100
24096/24377 [============================&gt;.] - ETA: 0s - loss: 0.0644 - categorical_accuracy: 0.9865
Epoch 00023: val_loss did not improve from 0.09242
24377/24377 [==============================] - 5s 205us/sample - loss: 0.0645 - categorical_accuracy: 0.9864 - val_loss: 0.1011 - val_categorical_accuracy: 0.9819
Epoch 24/100
24288/24377 [============================&gt;.] - ETA: 0s - loss: 0.0605 - categorical_accuracy: 0.9886
Epoch 00024: val_loss did not improve from 0.09242
24377/24377 [==============================] - 5s 221us/sample - loss: 0.0604 - categorical_accuracy: 0.9886 - val_loss: 0.1043 - val_categorical_accuracy: 0.9829
Epoch 25/100
24160/24377 [============================&gt;.] - ETA: 0s - loss: 0.0622 - categorical_accuracy: 0.9871
Epoch 00025: val_loss did not improve from 0.09242
24377/24377 [==============================] - 5s 222us/sample - loss: 0.0624 - categorical_accuracy: 0.9871 - val_loss: 0.1068 - val_categorical_accuracy: 0.9829
Epoch 26/100
24256/24377 [============================&gt;.] - ETA: 0s - loss: 0.0525 - categorical_accuracy: 0.9916
Epoch 00026: val_loss did not improve from 0.09242
24377/24377 [==============================] - 5s 223us/sample - loss: 0.0527 - categorical_accuracy: 0.9915 - val_loss: 0.1224 - val_categorical_accuracy: 0.9780
Epoch 27/100
24256/24377 [============================&gt;.] - ETA: 0s - loss: 0.0555 - categorical_accuracy: 0.9902
Epoch 00027: val_loss did not improve from 0.09242
24377/24377 [==============================] - 5s 220us/sample - loss: 0.0557 - categorical_accuracy: 0.9900 - val_loss: 0.1140 - val_categorical_accuracy: 0.9813
0.97603416 0.8027


nrx: 20 - real: 1 
Train on 31911 samples, validate on 3988 samples
Epoch 1/100
31744/31911 [============================&gt;.] - ETA: 0s - loss: 1.1698 - categorical_accuracy: 0.5193
Epoch 00001: val_loss improved from inf to 0.69705, saving model to t_weights_0
31911/31911 [==============================] - 8s 240us/sample - loss: 1.1681 - categorical_accuracy: 0.5202 - val_loss: 0.6971 - val_categorical_accuracy: 0.7019
Epoch 2/100
31808/31911 [============================&gt;.] - ETA: 0s - loss: 0.6363 - categorical_accuracy: 0.7480
Epoch 00002: val_loss improved from 0.69705 to 0.47479, saving model to t_weights_0
31911/31911 [==============================] - 7s 225us/sample - loss: 0.6358 - categorical_accuracy: 0.7481 - val_loss: 0.4748 - val_categorical_accuracy: 0.8310
Epoch 3/100
31776/31911 [============================&gt;.] - ETA: 0s - loss: 0.4482 - categorical_accuracy: 0.8406
Epoch 00003: val_loss improved from 0.47479 to 0.33407, saving model to t_weights_0
31911/31911 [==============================] - 7s 224us/sample - loss: 0.4482 - categorical_accuracy: 0.8405 - val_loss: 0.3341 - val_categorical_accuracy: 0.8899
Epoch 4/100
31840/31911 [============================&gt;.] - ETA: 0s - loss: 0.3395 - categorical_accuracy: 0.8871
Epoch 00004: val_loss improved from 0.33407 to 0.29945, saving model to t_weights_0
31911/31911 [==============================] - 7s 219us/sample - loss: 0.3395 - categorical_accuracy: 0.8871 - val_loss: 0.2994 - val_categorical_accuracy: 0.8974
Epoch 5/100
31840/31911 [============================&gt;.] - ETA: 0s - loss: 0.2801 - categorical_accuracy: 0.9100
Epoch 00005: val_loss improved from 0.29945 to 0.25646, saving model to t_weights_0
31911/31911 [==============================] - 7s 225us/sample - loss: 0.2801 - categorical_accuracy: 0.9101 - val_loss: 0.2565 - val_categorical_accuracy: 0.9178
Epoch 6/100
31840/31911 [============================&gt;.] - ETA: 0s - loss: 0.2547 - categorical_accuracy: 0.9197
Epoch 00006: val_loss improved from 0.25646 to 0.23629, saving model to t_weights_0
31911/31911 [==============================] - 7s 225us/sample - loss: 0.2545 - categorical_accuracy: 0.9197 - val_loss: 0.2363 - val_categorical_accuracy: 0.9258
Epoch 7/100
31744/31911 [============================&gt;.] - ETA: 0s - loss: 0.2324 - categorical_accuracy: 0.9286
Epoch 00007: val_loss improved from 0.23629 to 0.22043, saving model to t_weights_0
31911/31911 [==============================] - 7s 225us/sample - loss: 0.2325 - categorical_accuracy: 0.9285 - val_loss: 0.2204 - val_categorical_accuracy: 0.9318
Epoch 8/100
31840/31911 [============================&gt;.] - ETA: 0s - loss: 0.2173 - categorical_accuracy: 0.9326
Epoch 00008: val_loss improved from 0.22043 to 0.21281, saving model to t_weights_0
31911/31911 [==============================] - 7s 223us/sample - loss: 0.2173 - categorical_accuracy: 0.9327 - val_loss: 0.2128 - val_categorical_accuracy: 0.9356
Epoch 9/100
31808/31911 [============================&gt;.] - ETA: 0s - loss: 0.2077 - categorical_accuracy: 0.9368
Epoch 00009: val_loss improved from 0.21281 to 0.20817, saving model to t_weights_0
31911/31911 [==============================] - 7s 226us/sample - loss: 0.2077 - categorical_accuracy: 0.9368 - val_loss: 0.2082 - val_categorical_accuracy: 0.9356
Epoch 10/100
31776/31911 [============================&gt;.] - ETA: 0s - loss: 0.2012 - categorical_accuracy: 0.9380
Epoch 00010: val_loss did not improve from 0.20817
31911/31911 [==============================] - 7s 223us/sample - loss: 0.2009 - categorical_accuracy: 0.9382 - val_loss: 0.2187 - val_categorical_accuracy: 0.9325
Epoch 11/100
31680/31911 [============================&gt;.] - ETA: 0s - loss: 0.1878 - categorical_accuracy: 0.9435
Epoch 00011: val_loss improved from 0.20817 to 0.20416, saving model to t_weights_0
31911/31911 [==============================] - 7s 226us/sample - loss: 0.1878 - categorical_accuracy: 0.9435 - val_loss: 0.2042 - val_categorical_accuracy: 0.9383
Epoch 12/100
31744/31911 [============================&gt;.] - ETA: 0s - loss: 0.1857 - categorical_accuracy: 0.9432
Epoch 00012: val_loss did not improve from 0.20416
31911/31911 [==============================] - 7s 213us/sample - loss: 0.1862 - categorical_accuracy: 0.9431 - val_loss: 0.2102 - val_categorical_accuracy: 0.9351
Epoch 13/100
31872/31911 [============================&gt;.] - ETA: 0s - loss: 0.1819 - categorical_accuracy: 0.9450
Epoch 00013: val_loss improved from 0.20416 to 0.20009, saving model to t_weights_0
31911/31911 [==============================] - 7s 227us/sample - loss: 0.1818 - categorical_accuracy: 0.9451 - val_loss: 0.2001 - val_categorical_accuracy: 0.9388
Epoch 14/100
31712/31911 [============================&gt;.] - ETA: 0s - loss: 0.1742 - categorical_accuracy: 0.9477
Epoch 00014: val_loss did not improve from 0.20009
31911/31911 [==============================] - 7s 223us/sample - loss: 0.1741 - categorical_accuracy: 0.9478 - val_loss: 0.2058 - val_categorical_accuracy: 0.9391
Epoch 15/100
31904/31911 [============================&gt;.] - ETA: 0s - loss: 0.1699 - categorical_accuracy: 0.9498
Epoch 00015: val_loss did not improve from 0.20009
31911/31911 [==============================] - 7s 225us/sample - loss: 0.1698 - categorical_accuracy: 0.9498 - val_loss: 0.2154 - val_categorical_accuracy: 0.9383
Epoch 16/100
31808/31911 [============================&gt;.] - ETA: 0s - loss: 0.1629 - categorical_accuracy: 0.9514
Epoch 00016: val_loss did not improve from 0.20009
31911/31911 [==============================] - 7s 222us/sample - loss: 0.1628 - categorical_accuracy: 0.9514 - val_loss: 0.2149 - val_categorical_accuracy: 0.9366
Epoch 17/100
31744/31911 [============================&gt;.] - ETA: 0s - loss: 0.1570 - categorical_accuracy: 0.9531
Epoch 00017: val_loss did not improve from 0.20009
31911/31911 [==============================] - 7s 221us/sample - loss: 0.1573 - categorical_accuracy: 0.9530 - val_loss: 0.2039 - val_categorical_accuracy: 0.9398
Epoch 18/100
31744/31911 [============================&gt;.] - ETA: 0s - loss: 0.1597 - categorical_accuracy: 0.9533
Epoch 00018: val_loss did not improve from 0.20009
31911/31911 [==============================] - 7s 222us/sample - loss: 0.1599 - categorical_accuracy: 0.9531 - val_loss: 0.2323 - val_categorical_accuracy: 0.9341
0.95185554 0.8417


nrx: 25 - real: 1 
Train on 39887 samples, validate on 4985 samples
Epoch 1/100
39776/39887 [============================&gt;.] - ETA: 0s - loss: 1.1458 - categorical_accuracy: 0.5294
Epoch 00001: val_loss improved from inf to 0.65440, saving model to t_weights_0
39887/39887 [==============================] - 9s 220us/sample - loss: 1.1446 - categorical_accuracy: 0.5299 - val_loss: 0.6544 - val_categorical_accuracy: 0.7519
Epoch 2/100
39648/39887 [============================&gt;.] - ETA: 0s - loss: 0.6073 - categorical_accuracy: 0.7744
Epoch 00002: val_loss improved from 0.65440 to 0.43493, saving model to t_weights_0
39887/39887 [==============================] - 9s 217us/sample - loss: 0.6070 - categorical_accuracy: 0.7744 - val_loss: 0.4349 - val_categorical_accuracy: 0.8544
Epoch 3/100
39840/39887 [============================&gt;.] - ETA: 0s - loss: 0.4397 - categorical_accuracy: 0.8496
Epoch 00003: val_loss improved from 0.43493 to 0.34408, saving model to t_weights_0
39887/39887 [==============================] - 9s 222us/sample - loss: 0.4397 - categorical_accuracy: 0.8496 - val_loss: 0.3441 - val_categorical_accuracy: 0.8826
Epoch 4/100
39712/39887 [============================&gt;.] - ETA: 0s - loss: 0.3545 - categorical_accuracy: 0.8845
Epoch 00004: val_loss improved from 0.34408 to 0.30056, saving model to t_weights_0
39887/39887 [==============================] - 9s 225us/sample - loss: 0.3543 - categorical_accuracy: 0.8846 - val_loss: 0.3006 - val_categorical_accuracy: 0.8979
Epoch 5/100
39744/39887 [============================&gt;.] - ETA: 0s - loss: 0.3156 - categorical_accuracy: 0.8983
Epoch 00005: val_loss did not improve from 0.30056
39887/39887 [==============================] - 9s 220us/sample - loss: 0.3153 - categorical_accuracy: 0.8985 - val_loss: 0.3203 - val_categorical_accuracy: 0.8913
Epoch 6/100
39680/39887 [============================&gt;.] - ETA: 0s - loss: 0.2882 - categorical_accuracy: 0.9072
Epoch 00006: val_loss improved from 0.30056 to 0.25113, saving model to t_weights_0
39887/39887 [==============================] - 9s 222us/sample - loss: 0.2884 - categorical_accuracy: 0.9071 - val_loss: 0.2511 - val_categorical_accuracy: 0.9186
Epoch 7/100
39712/39887 [============================&gt;.] - ETA: 0s - loss: 0.2637 - categorical_accuracy: 0.9158
Epoch 00007: val_loss improved from 0.25113 to 0.24766, saving model to t_weights_0
39887/39887 [==============================] - 9s 224us/sample - loss: 0.2639 - categorical_accuracy: 0.9158 - val_loss: 0.2477 - val_categorical_accuracy: 0.9186
Epoch 8/100
39744/39887 [============================&gt;.] - ETA: 0s - loss: 0.2515 - categorical_accuracy: 0.9215
Epoch 00008: val_loss improved from 0.24766 to 0.24416, saving model to t_weights_0
39887/39887 [==============================] - 9s 223us/sample - loss: 0.2513 - categorical_accuracy: 0.9215 - val_loss: 0.2442 - val_categorical_accuracy: 0.9220
Epoch 9/100
39744/39887 [============================&gt;.] - ETA: 0s - loss: 0.2373 - categorical_accuracy: 0.9261
Epoch 00009: val_loss did not improve from 0.24416
39887/39887 [==============================] - 9s 218us/sample - loss: 0.2370 - categorical_accuracy: 0.9262 - val_loss: 0.2463 - val_categorical_accuracy: 0.9230
Epoch 10/100
39808/39887 [============================&gt;.] - ETA: 0s - loss: 0.2316 - categorical_accuracy: 0.9270
Epoch 00010: val_loss improved from 0.24416 to 0.22740, saving model to t_weights_0
39887/39887 [==============================] - 9s 224us/sample - loss: 0.2319 - categorical_accuracy: 0.9269 - val_loss: 0.2274 - val_categorical_accuracy: 0.9296
Epoch 11/100
39648/39887 [============================&gt;.] - ETA: 0s - loss: 0.2256 - categorical_accuracy: 0.9285
Epoch 00011: val_loss did not improve from 0.22740
39887/39887 [==============================] - 9s 222us/sample - loss: 0.2255 - categorical_accuracy: 0.9286 - val_loss: 0.2324 - val_categorical_accuracy: 0.9286
Epoch 12/100
39776/39887 [============================&gt;.] - ETA: 0s - loss: 0.2162 - categorical_accuracy: 0.9323
Epoch 00012: val_loss did not improve from 0.22740
39887/39887 [==============================] - 9s 222us/sample - loss: 0.2161 - categorical_accuracy: 0.9324 - val_loss: 0.2287 - val_categorical_accuracy: 0.9274
Epoch 13/100
39872/39887 [============================&gt;.] - ETA: 0s - loss: 0.2098 - categorical_accuracy: 0.9329
Epoch 00013: val_loss improved from 0.22740 to 0.22661, saving model to t_weights_0
39887/39887 [==============================] - 9s 223us/sample - loss: 0.2098 - categorical_accuracy: 0.9329 - val_loss: 0.2266 - val_categorical_accuracy: 0.9306
Epoch 14/100
39712/39887 [============================&gt;.] - ETA: 0s - loss: 0.2034 - categorical_accuracy: 0.9373
Epoch 00014: val_loss improved from 0.22661 to 0.21479, saving model to t_weights_0
39887/39887 [==============================] - 9s 222us/sample - loss: 0.2034 - categorical_accuracy: 0.9374 - val_loss: 0.2148 - val_categorical_accuracy: 0.9340
Epoch 15/100
39712/39887 [============================&gt;.] - ETA: 0s - loss: 0.1983 - categorical_accuracy: 0.9381
Epoch 00015: val_loss did not improve from 0.21479
39887/39887 [==============================] - 9s 222us/sample - loss: 0.1983 - categorical_accuracy: 0.9380 - val_loss: 0.2215 - val_categorical_accuracy: 0.9320
Epoch 16/100
39648/39887 [============================&gt;.] - ETA: 0s - loss: 0.1917 - categorical_accuracy: 0.9395
Epoch 00016: val_loss did not improve from 0.21479
39887/39887 [==============================] - 9s 217us/sample - loss: 0.1915 - categorical_accuracy: 0.9397 - val_loss: 0.2209 - val_categorical_accuracy: 0.9326
Epoch 17/100
39712/39887 [============================&gt;.] - ETA: 0s - loss: 0.1883 - categorical_accuracy: 0.9415
Epoch 00017: val_loss did not improve from 0.21479
39887/39887 [==============================] - 9s 223us/sample - loss: 0.1884 - categorical_accuracy: 0.9415 - val_loss: 0.2474 - val_categorical_accuracy: 0.9252
Epoch 18/100
39744/39887 [============================&gt;.] - ETA: 0s - loss: 0.1845 - categorical_accuracy: 0.9430
Epoch 00018: val_loss did not improve from 0.21479
39887/39887 [==============================] - 9s 220us/sample - loss: 0.1843 - categorical_accuracy: 0.9431 - val_loss: 0.2450 - val_categorical_accuracy: 0.9294
Epoch 19/100
39776/39887 [============================&gt;.] - ETA: 0s - loss: 0.1803 - categorical_accuracy: 0.9439
Epoch 00019: val_loss did not improve from 0.21479
39887/39887 [==============================] - 9s 222us/sample - loss: 0.1803 - categorical_accuracy: 0.9439 - val_loss: 0.2154 - val_categorical_accuracy: 0.9360
0.9362086 0.8553


nrx: 0 - real: 2 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1600 samples, validate on 200 samples
Epoch 1/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 2.2804 - categorical_accuracy: 0.1875
Epoch 00001: val_loss improved from inf to 2.14947, saving model to t_weights_0
1600/1600 [==============================] - 1s 485us/sample - loss: 2.2741 - categorical_accuracy: 0.1988 - val_loss: 2.1495 - val_categorical_accuracy: 0.4900
Epoch 2/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 1.8347 - categorical_accuracy: 0.4906
Epoch 00002: val_loss improved from 2.14947 to 1.11775, saving model to t_weights_0
1600/1600 [==============================] - 0s 252us/sample - loss: 1.7612 - categorical_accuracy: 0.5056 - val_loss: 1.1177 - val_categorical_accuracy: 0.7200
Epoch 3/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.9990 - categorical_accuracy: 0.6577
Epoch 00003: val_loss improved from 1.11775 to 0.49500, saving model to t_weights_0
1600/1600 [==============================] - 0s 267us/sample - loss: 0.9564 - categorical_accuracy: 0.6744 - val_loss: 0.4950 - val_categorical_accuracy: 0.9150
Epoch 4/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.5645 - categorical_accuracy: 0.8087
Epoch 00004: val_loss improved from 0.49500 to 0.27688, saving model to t_weights_0
1600/1600 [==============================] - 0s 271us/sample - loss: 0.5619 - categorical_accuracy: 0.8100 - val_loss: 0.2769 - val_categorical_accuracy: 0.9200
Epoch 5/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.3736 - categorical_accuracy: 0.8833
Epoch 00005: val_loss improved from 0.27688 to 0.21449, saving model to t_weights_0
1600/1600 [==============================] - 0s 258us/sample - loss: 0.3772 - categorical_accuracy: 0.8794 - val_loss: 0.2145 - val_categorical_accuracy: 0.9550
Epoch 6/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.2885 - categorical_accuracy: 0.9042
Epoch 00006: val_loss improved from 0.21449 to 0.12137, saving model to t_weights_0
1600/1600 [==============================] - 0s 227us/sample - loss: 0.2833 - categorical_accuracy: 0.9056 - val_loss: 0.1214 - val_categorical_accuracy: 0.9950
Epoch 7/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.2362 - categorical_accuracy: 0.9286
Epoch 00007: val_loss improved from 0.12137 to 0.09761, saving model to t_weights_0
1600/1600 [==============================] - 0s 273us/sample - loss: 0.2361 - categorical_accuracy: 0.9294 - val_loss: 0.0976 - val_categorical_accuracy: 0.9900
Epoch 8/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1834 - categorical_accuracy: 0.9479
Epoch 00008: val_loss did not improve from 0.09761
1600/1600 [==============================] - 0s 233us/sample - loss: 0.1861 - categorical_accuracy: 0.9481 - val_loss: 0.1216 - val_categorical_accuracy: 0.9700
Epoch 9/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1627 - categorical_accuracy: 0.9611
Epoch 00009: val_loss improved from 0.09761 to 0.05860, saving model to t_weights_0
1600/1600 [==============================] - 0s 267us/sample - loss: 0.1610 - categorical_accuracy: 0.9619 - val_loss: 0.0586 - val_categorical_accuracy: 0.9950
Epoch 10/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.1225 - categorical_accuracy: 0.9719
Epoch 00010: val_loss improved from 0.05860 to 0.04732, saving model to t_weights_0
1600/1600 [==============================] - 0s 278us/sample - loss: 0.1230 - categorical_accuracy: 0.9712 - val_loss: 0.0473 - val_categorical_accuracy: 0.9950
Epoch 11/100
1312/1600 [=======================&gt;......] - ETA: 0s - loss: 0.1297 - categorical_accuracy: 0.9688
Epoch 00011: val_loss improved from 0.04732 to 0.04057, saving model to t_weights_0
1600/1600 [==============================] - 0s 261us/sample - loss: 0.1248 - categorical_accuracy: 0.9694 - val_loss: 0.0406 - val_categorical_accuracy: 0.9950
Epoch 12/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.1046 - categorical_accuracy: 0.9751
Epoch 00012: val_loss improved from 0.04057 to 0.03244, saving model to t_weights_0
1600/1600 [==============================] - 0s 239us/sample - loss: 0.1025 - categorical_accuracy: 0.9762 - val_loss: 0.0324 - val_categorical_accuracy: 1.0000
Epoch 13/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0937 - categorical_accuracy: 0.9770
Epoch 00013: val_loss did not improve from 0.03244
1600/1600 [==============================] - 0s 231us/sample - loss: 0.0930 - categorical_accuracy: 0.9769 - val_loss: 0.0367 - val_categorical_accuracy: 0.9950
Epoch 14/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0892 - categorical_accuracy: 0.9834
Epoch 00014: val_loss improved from 0.03244 to 0.02895, saving model to t_weights_0
1600/1600 [==============================] - 0s 271us/sample - loss: 0.0902 - categorical_accuracy: 0.9831 - val_loss: 0.0289 - val_categorical_accuracy: 1.0000
Epoch 15/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0787 - categorical_accuracy: 0.9818
Epoch 00015: val_loss improved from 0.02895 to 0.02805, saving model to t_weights_0
1600/1600 [==============================] - 0s 279us/sample - loss: 0.0814 - categorical_accuracy: 0.9806 - val_loss: 0.0280 - val_categorical_accuracy: 0.9950
Epoch 16/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0809 - categorical_accuracy: 0.9831
Epoch 00016: val_loss did not improve from 0.02805
1600/1600 [==============================] - 0s 232us/sample - loss: 0.0795 - categorical_accuracy: 0.9837 - val_loss: 0.0321 - val_categorical_accuracy: 0.9950
Epoch 17/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0734 - categorical_accuracy: 0.9831
Epoch 00017: val_loss improved from 0.02805 to 0.02471, saving model to t_weights_0
1600/1600 [==============================] - 0s 267us/sample - loss: 0.0722 - categorical_accuracy: 0.9837 - val_loss: 0.0247 - val_categorical_accuracy: 1.0000
Epoch 18/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0569 - categorical_accuracy: 0.9880
Epoch 00018: val_loss did not improve from 0.02471
1600/1600 [==============================] - 0s 200us/sample - loss: 0.0565 - categorical_accuracy: 0.9887 - val_loss: 0.0312 - val_categorical_accuracy: 0.9950
Epoch 19/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0559 - categorical_accuracy: 0.9884
Epoch 00019: val_loss did not improve from 0.02471
1600/1600 [==============================] - 0s 225us/sample - loss: 0.0572 - categorical_accuracy: 0.9869 - val_loss: 0.0276 - val_categorical_accuracy: 0.9950
Epoch 20/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0552 - categorical_accuracy: 0.9870
Epoch 00020: val_loss improved from 0.02471 to 0.02237, saving model to t_weights_0
1600/1600 [==============================] - 0s 266us/sample - loss: 0.0545 - categorical_accuracy: 0.9875 - val_loss: 0.0224 - val_categorical_accuracy: 1.0000
Epoch 21/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0513 - categorical_accuracy: 0.9898
Epoch 00021: val_loss improved from 0.02237 to 0.02225, saving model to t_weights_0
1600/1600 [==============================] - 0s 275us/sample - loss: 0.0519 - categorical_accuracy: 0.9894 - val_loss: 0.0222 - val_categorical_accuracy: 1.0000
Epoch 22/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0458 - categorical_accuracy: 0.9940
Epoch 00022: val_loss improved from 0.02225 to 0.02053, saving model to t_weights_0
1600/1600 [==============================] - 0s 265us/sample - loss: 0.0458 - categorical_accuracy: 0.9937 - val_loss: 0.0205 - val_categorical_accuracy: 1.0000
Epoch 23/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0514 - categorical_accuracy: 0.9885
Epoch 00023: val_loss did not improve from 0.02053
1600/1600 [==============================] - 0s 228us/sample - loss: 0.0511 - categorical_accuracy: 0.9887 - val_loss: 0.0368 - val_categorical_accuracy: 0.9950
Epoch 24/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0443 - categorical_accuracy: 0.9933
Epoch 00024: val_loss improved from 0.02053 to 0.02016, saving model to t_weights_0
1600/1600 [==============================] - 0s 250us/sample - loss: 0.0434 - categorical_accuracy: 0.9931 - val_loss: 0.0202 - val_categorical_accuracy: 1.0000
Epoch 25/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0430 - categorical_accuracy: 0.9929
Epoch 00025: val_loss did not improve from 0.02016
1600/1600 [==============================] - 0s 219us/sample - loss: 0.0405 - categorical_accuracy: 0.9937 - val_loss: 0.0268 - val_categorical_accuracy: 0.9950
Epoch 26/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0361 - categorical_accuracy: 0.9948
Epoch 00026: val_loss did not improve from 0.02016
1600/1600 [==============================] - 0s 225us/sample - loss: 0.0375 - categorical_accuracy: 0.9950 - val_loss: 0.0227 - val_categorical_accuracy: 1.0000
Epoch 27/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0376 - categorical_accuracy: 0.9948
Epoch 00027: val_loss did not improve from 0.02016
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0371 - categorical_accuracy: 0.9950 - val_loss: 0.0223 - val_categorical_accuracy: 0.9950
Epoch 28/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0370 - categorical_accuracy: 0.9967
Epoch 00028: val_loss improved from 0.02016 to 0.01884, saving model to t_weights_0
1600/1600 [==============================] - 0s 284us/sample - loss: 0.0370 - categorical_accuracy: 0.9962 - val_loss: 0.0188 - val_categorical_accuracy: 1.0000
Epoch 29/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0346 - categorical_accuracy: 0.9962
Epoch 00029: val_loss improved from 0.01884 to 0.01852, saving model to t_weights_0
1600/1600 [==============================] - 0s 277us/sample - loss: 0.0352 - categorical_accuracy: 0.9956 - val_loss: 0.0185 - val_categorical_accuracy: 1.0000
Epoch 30/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.0339 - categorical_accuracy: 0.9925
Epoch 00030: val_loss did not improve from 0.01852
1600/1600 [==============================] - 0s 200us/sample - loss: 0.0340 - categorical_accuracy: 0.9925 - val_loss: 0.0191 - val_categorical_accuracy: 1.0000
Epoch 31/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0295 - categorical_accuracy: 0.9964
Epoch 00031: val_loss did not improve from 0.01852
1600/1600 [==============================] - 0s 215us/sample - loss: 0.0294 - categorical_accuracy: 0.9969 - val_loss: 0.0290 - val_categorical_accuracy: 0.9950
Epoch 32/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0302 - categorical_accuracy: 0.9967
Epoch 00032: val_loss did not improve from 0.01852
1600/1600 [==============================] - 0s 236us/sample - loss: 0.0313 - categorical_accuracy: 0.9962 - val_loss: 0.0224 - val_categorical_accuracy: 0.9950
Epoch 33/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0293 - categorical_accuracy: 0.9967
Epoch 00033: val_loss did not improve from 0.01852
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0291 - categorical_accuracy: 0.9969 - val_loss: 0.0437 - val_categorical_accuracy: 0.9950
Epoch 34/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0340 - categorical_accuracy: 0.9955
Epoch 00034: val_loss did not improve from 0.01852
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0337 - categorical_accuracy: 0.9956 - val_loss: 0.0202 - val_categorical_accuracy: 1.0000
0.995 0.3097758405977584


nrx: 5 - real: 2 
Train on 9153 samples, validate on 1144 samples
Epoch 1/100
9024/9153 [============================&gt;.] - ETA: 0s - loss: 1.6195 - categorical_accuracy: 0.3715
Epoch 00001: val_loss improved from inf to 0.76189, saving model to t_weights_0
9153/9153 [==============================] - 2s 272us/sample - loss: 1.6100 - categorical_accuracy: 0.3745 - val_loss: 0.7619 - val_categorical_accuracy: 0.7395
Epoch 2/100
9120/9153 [============================&gt;.] - ETA: 0s - loss: 0.7488 - categorical_accuracy: 0.6766
Epoch 00002: val_loss improved from 0.76189 to 0.51579, saving model to t_weights_0
9153/9153 [==============================] - 2s 231us/sample - loss: 0.7490 - categorical_accuracy: 0.6768 - val_loss: 0.5158 - val_categorical_accuracy: 0.7998
Epoch 3/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.5448 - categorical_accuracy: 0.7815
Epoch 00003: val_loss improved from 0.51579 to 0.37620, saving model to t_weights_0
9153/9153 [==============================] - 2s 233us/sample - loss: 0.5416 - categorical_accuracy: 0.7835 - val_loss: 0.3762 - val_categorical_accuracy: 0.8636
Epoch 4/100
9088/9153 [============================&gt;.] - ETA: 0s - loss: 0.3932 - categorical_accuracy: 0.8564
Epoch 00004: val_loss improved from 0.37620 to 0.28561, saving model to t_weights_0
9153/9153 [==============================] - 2s 231us/sample - loss: 0.3922 - categorical_accuracy: 0.8569 - val_loss: 0.2856 - val_categorical_accuracy: 0.8960
Epoch 5/100
9120/9153 [============================&gt;.] - ETA: 0s - loss: 0.3135 - categorical_accuracy: 0.8941
Epoch 00005: val_loss improved from 0.28561 to 0.21624, saving model to t_weights_0
9153/9153 [==============================] - 2s 212us/sample - loss: 0.3139 - categorical_accuracy: 0.8935 - val_loss: 0.2162 - val_categorical_accuracy: 0.9318
Epoch 6/100
9024/9153 [============================&gt;.] - ETA: 0s - loss: 0.2371 - categorical_accuracy: 0.9284
Epoch 00006: val_loss improved from 0.21624 to 0.17481, saving model to t_weights_0
9153/9153 [==============================] - 2s 219us/sample - loss: 0.2368 - categorical_accuracy: 0.9284 - val_loss: 0.1748 - val_categorical_accuracy: 0.9528
Epoch 7/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.1893 - categorical_accuracy: 0.9444
Epoch 00007: val_loss improved from 0.17481 to 0.14366, saving model to t_weights_0
9153/9153 [==============================] - 2s 229us/sample - loss: 0.1879 - categorical_accuracy: 0.9453 - val_loss: 0.1437 - val_categorical_accuracy: 0.9589
Epoch 8/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.1488 - categorical_accuracy: 0.9625
Epoch 00008: val_loss improved from 0.14366 to 0.11947, saving model to t_weights_0
9153/9153 [==============================] - 2s 229us/sample - loss: 0.1500 - categorical_accuracy: 0.9626 - val_loss: 0.1195 - val_categorical_accuracy: 0.9694
Epoch 9/100
8960/9153 [============================&gt;.] - ETA: 0s - loss: 0.1386 - categorical_accuracy: 0.9674
Epoch 00009: val_loss did not improve from 0.11947
9153/9153 [==============================] - 2s 226us/sample - loss: 0.1377 - categorical_accuracy: 0.9678 - val_loss: 0.1333 - val_categorical_accuracy: 0.9642
Epoch 10/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.1116 - categorical_accuracy: 0.9745
Epoch 00010: val_loss improved from 0.11947 to 0.10023, saving model to t_weights_0
9153/9153 [==============================] - 2s 237us/sample - loss: 0.1124 - categorical_accuracy: 0.9744 - val_loss: 0.1002 - val_categorical_accuracy: 0.9790
Epoch 11/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9765
Epoch 00011: val_loss did not improve from 0.10023
9153/9153 [==============================] - 2s 223us/sample - loss: 0.1026 - categorical_accuracy: 0.9766 - val_loss: 0.1097 - val_categorical_accuracy: 0.9738
Epoch 12/100
8960/9153 [============================&gt;.] - ETA: 0s - loss: 0.0934 - categorical_accuracy: 0.9780
Epoch 00012: val_loss did not improve from 0.10023
9153/9153 [==============================] - 2s 222us/sample - loss: 0.0935 - categorical_accuracy: 0.9779 - val_loss: 0.1050 - val_categorical_accuracy: 0.9781
Epoch 13/100
8992/9153 [============================&gt;.] - ETA: 0s - loss: 0.0862 - categorical_accuracy: 0.9810
Epoch 00013: val_loss improved from 0.10023 to 0.09513, saving model to t_weights_0
9153/9153 [==============================] - 2s 230us/sample - loss: 0.0863 - categorical_accuracy: 0.9808 - val_loss: 0.0951 - val_categorical_accuracy: 0.9781
Epoch 14/100
9088/9153 [============================&gt;.] - ETA: 0s - loss: 0.0765 - categorical_accuracy: 0.9835
Epoch 00014: val_loss improved from 0.09513 to 0.09183, saving model to t_weights_0
9153/9153 [==============================] - 2s 230us/sample - loss: 0.0762 - categorical_accuracy: 0.9836 - val_loss: 0.0918 - val_categorical_accuracy: 0.9816
Epoch 15/100
9088/9153 [============================&gt;.] - ETA: 0s - loss: 0.0728 - categorical_accuracy: 0.9827
Epoch 00015: val_loss did not improve from 0.09183
9153/9153 [==============================] - 2s 223us/sample - loss: 0.0725 - categorical_accuracy: 0.9828 - val_loss: 0.1019 - val_categorical_accuracy: 0.9816
Epoch 16/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.0683 - categorical_accuracy: 0.9857
Epoch 00016: val_loss did not improve from 0.09183
9153/9153 [==============================] - 2s 227us/sample - loss: 0.0678 - categorical_accuracy: 0.9859 - val_loss: 0.0956 - val_categorical_accuracy: 0.9843
Epoch 17/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.0623 - categorical_accuracy: 0.9884
Epoch 00017: val_loss improved from 0.09183 to 0.08120, saving model to t_weights_0
9153/9153 [==============================] - 2s 235us/sample - loss: 0.0630 - categorical_accuracy: 0.9882 - val_loss: 0.0812 - val_categorical_accuracy: 0.9895
Epoch 18/100
9120/9153 [============================&gt;.] - ETA: 0s - loss: 0.0529 - categorical_accuracy: 0.9899
Epoch 00018: val_loss did not improve from 0.08120
9153/9153 [==============================] - 2s 224us/sample - loss: 0.0528 - categorical_accuracy: 0.9899 - val_loss: 0.0847 - val_categorical_accuracy: 0.9860
Epoch 19/100
8992/9153 [============================&gt;.] - ETA: 0s - loss: 0.0608 - categorical_accuracy: 0.9872
Epoch 00019: val_loss did not improve from 0.08120
9153/9153 [==============================] - 2s 222us/sample - loss: 0.0610 - categorical_accuracy: 0.9870 - val_loss: 0.0823 - val_categorical_accuracy: 0.9878
Epoch 20/100
9056/9153 [============================&gt;.] - ETA: 0s - loss: 0.0570 - categorical_accuracy: 0.9876
Epoch 00020: val_loss did not improve from 0.08120
9153/9153 [==============================] - 2s 221us/sample - loss: 0.0568 - categorical_accuracy: 0.9878 - val_loss: 0.1242 - val_categorical_accuracy: 0.9694
Epoch 21/100
9088/9153 [============================&gt;.] - ETA: 0s - loss: 0.0539 - categorical_accuracy: 0.9903
Epoch 00021: val_loss did not improve from 0.08120
9153/9153 [==============================] - 2s 224us/sample - loss: 0.0540 - categorical_accuracy: 0.9903 - val_loss: 0.0961 - val_categorical_accuracy: 0.9878
Epoch 22/100
8928/9153 [============================&gt;.] - ETA: 0s - loss: 0.0473 - categorical_accuracy: 0.9923
Epoch 00022: val_loss did not improve from 0.08120
9153/9153 [==============================] - 2s 225us/sample - loss: 0.0479 - categorical_accuracy: 0.9922 - val_loss: 0.0976 - val_categorical_accuracy: 0.9895
0.9895105 0.5153590701535907


nrx: 10 - real: 2 
Train on 16969 samples, validate on 2121 samples
Epoch 1/100
16960/16969 [============================&gt;.] - ETA: 0s - loss: 1.4575 - categorical_accuracy: 0.4452
Epoch 00001: val_loss improved from inf to 0.85215, saving model to t_weights_0
16969/16969 [==============================] - 4s 245us/sample - loss: 1.4571 - categorical_accuracy: 0.4453 - val_loss: 0.8522 - val_categorical_accuracy: 0.6803
Epoch 2/100
16736/16969 [============================&gt;.] - ETA: 0s - loss: 0.8272 - categorical_accuracy: 0.6729
Epoch 00002: val_loss improved from 0.85215 to 0.60356, saving model to t_weights_0
16969/16969 [==============================] - 4s 226us/sample - loss: 0.8251 - categorical_accuracy: 0.6742 - val_loss: 0.6036 - val_categorical_accuracy: 0.7897
Epoch 3/100
16928/16969 [============================&gt;.] - ETA: 0s - loss: 0.6321 - categorical_accuracy: 0.7684
Epoch 00003: val_loss improved from 0.60356 to 0.48903, saving model to t_weights_0
16969/16969 [==============================] - 4s 231us/sample - loss: 0.6321 - categorical_accuracy: 0.7685 - val_loss: 0.4890 - val_categorical_accuracy: 0.8322
Epoch 4/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.4887 - categorical_accuracy: 0.8323
Epoch 00004: val_loss improved from 0.48903 to 0.39589, saving model to t_weights_0
16969/16969 [==============================] - 4s 226us/sample - loss: 0.4887 - categorical_accuracy: 0.8321 - val_loss: 0.3959 - val_categorical_accuracy: 0.8755
Epoch 5/100
16960/16969 [============================&gt;.] - ETA: 0s - loss: 0.4039 - categorical_accuracy: 0.8703
Epoch 00005: val_loss improved from 0.39589 to 0.36319, saving model to t_weights_0
16969/16969 [==============================] - 4s 231us/sample - loss: 0.4038 - categorical_accuracy: 0.8704 - val_loss: 0.3632 - val_categorical_accuracy: 0.8812
Epoch 6/100
16768/16969 [============================&gt;.] - ETA: 0s - loss: 0.3587 - categorical_accuracy: 0.8853
Epoch 00006: val_loss improved from 0.36319 to 0.35987, saving model to t_weights_0
16969/16969 [==============================] - 4s 223us/sample - loss: 0.3586 - categorical_accuracy: 0.8851 - val_loss: 0.3599 - val_categorical_accuracy: 0.8652
Epoch 7/100
16768/16969 [============================&gt;.] - ETA: 0s - loss: 0.3335 - categorical_accuracy: 0.8930
Epoch 00007: val_loss improved from 0.35987 to 0.32020, saving model to t_weights_0
16969/16969 [==============================] - 3s 197us/sample - loss: 0.3329 - categorical_accuracy: 0.8930 - val_loss: 0.3202 - val_categorical_accuracy: 0.8920
Epoch 8/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.3065 - categorical_accuracy: 0.9015
Epoch 00008: val_loss improved from 0.32020 to 0.28973, saving model to t_weights_0
16969/16969 [==============================] - 4s 231us/sample - loss: 0.3067 - categorical_accuracy: 0.9015 - val_loss: 0.2897 - val_categorical_accuracy: 0.9038
Epoch 9/100
16960/16969 [============================&gt;.] - ETA: 0s - loss: 0.2907 - categorical_accuracy: 0.9052
Epoch 00009: val_loss did not improve from 0.28973
16969/16969 [==============================] - 4s 226us/sample - loss: 0.2906 - categorical_accuracy: 0.9052 - val_loss: 0.2919 - val_categorical_accuracy: 0.9019
Epoch 10/100
16928/16969 [============================&gt;.] - ETA: 0s - loss: 0.2811 - categorical_accuracy: 0.9117
Epoch 00010: val_loss improved from 0.28973 to 0.27777, saving model to t_weights_0
16969/16969 [==============================] - 4s 225us/sample - loss: 0.2810 - categorical_accuracy: 0.9118 - val_loss: 0.2778 - val_categorical_accuracy: 0.9048
Epoch 11/100
16704/16969 [============================&gt;.] - ETA: 0s - loss: 0.2766 - categorical_accuracy: 0.9120
Epoch 00011: val_loss improved from 0.27777 to 0.27492, saving model to t_weights_0
16969/16969 [==============================] - 4s 227us/sample - loss: 0.2773 - categorical_accuracy: 0.9119 - val_loss: 0.2749 - val_categorical_accuracy: 0.9114
Epoch 12/100
16768/16969 [============================&gt;.] - ETA: 0s - loss: 0.2634 - categorical_accuracy: 0.9162
Epoch 00012: val_loss did not improve from 0.27492
16969/16969 [==============================] - 4s 230us/sample - loss: 0.2647 - categorical_accuracy: 0.9159 - val_loss: 0.3009 - val_categorical_accuracy: 0.8996
Epoch 13/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.2507 - categorical_accuracy: 0.9193
Epoch 00013: val_loss improved from 0.27492 to 0.27127, saving model to t_weights_0
16969/16969 [==============================] - 4s 228us/sample - loss: 0.2505 - categorical_accuracy: 0.9196 - val_loss: 0.2713 - val_categorical_accuracy: 0.9123
Epoch 14/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.2456 - categorical_accuracy: 0.9208
Epoch 00014: val_loss did not improve from 0.27127
16969/16969 [==============================] - 4s 229us/sample - loss: 0.2453 - categorical_accuracy: 0.9209 - val_loss: 0.2881 - val_categorical_accuracy: 0.9052
Epoch 15/100
16960/16969 [============================&gt;.] - ETA: 0s - loss: 0.2357 - categorical_accuracy: 0.9249
Epoch 00015: val_loss improved from 0.27127 to 0.26545, saving model to t_weights_0
16969/16969 [==============================] - 4s 224us/sample - loss: 0.2357 - categorical_accuracy: 0.9250 - val_loss: 0.2655 - val_categorical_accuracy: 0.9161
Epoch 16/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.2369 - categorical_accuracy: 0.9248
Epoch 00016: val_loss did not improve from 0.26545
16969/16969 [==============================] - 4s 227us/sample - loss: 0.2376 - categorical_accuracy: 0.9245 - val_loss: 0.2677 - val_categorical_accuracy: 0.9213
Epoch 17/100
16736/16969 [============================&gt;.] - ETA: 0s - loss: 0.2258 - categorical_accuracy: 0.9281
Epoch 00017: val_loss improved from 0.26545 to 0.25052, saving model to t_weights_0
16969/16969 [==============================] - 4s 227us/sample - loss: 0.2255 - categorical_accuracy: 0.9283 - val_loss: 0.2505 - val_categorical_accuracy: 0.9213
Epoch 18/100
16960/16969 [============================&gt;.] - ETA: 0s - loss: 0.2229 - categorical_accuracy: 0.9297
Epoch 00018: val_loss did not improve from 0.25052
16969/16969 [==============================] - 4s 224us/sample - loss: 0.2229 - categorical_accuracy: 0.9297 - val_loss: 0.2693 - val_categorical_accuracy: 0.9198
Epoch 19/100
16832/16969 [============================&gt;.] - ETA: 0s - loss: 0.2168 - categorical_accuracy: 0.9310
Epoch 00019: val_loss did not improve from 0.25052
16969/16969 [==============================] - 4s 227us/sample - loss: 0.2170 - categorical_accuracy: 0.9309 - val_loss: 0.2845 - val_categorical_accuracy: 0.9128
Epoch 20/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.2145 - categorical_accuracy: 0.9344
Epoch 00020: val_loss did not improve from 0.25052
16969/16969 [==============================] - 4s 222us/sample - loss: 0.2141 - categorical_accuracy: 0.9344 - val_loss: 0.2700 - val_categorical_accuracy: 0.9180
Epoch 21/100
16768/16969 [============================&gt;.] - ETA: 0s - loss: 0.2066 - categorical_accuracy: 0.9364
Epoch 00021: val_loss improved from 0.25052 to 0.24588, saving model to t_weights_0
16969/16969 [==============================] - 4s 233us/sample - loss: 0.2063 - categorical_accuracy: 0.9366 - val_loss: 0.2459 - val_categorical_accuracy: 0.9269
Epoch 22/100
16800/16969 [============================&gt;.] - ETA: 0s - loss: 0.2054 - categorical_accuracy: 0.9360
Epoch 00022: val_loss did not improve from 0.24588
16969/16969 [==============================] - 4s 217us/sample - loss: 0.2050 - categorical_accuracy: 0.9362 - val_loss: 0.2565 - val_categorical_accuracy: 0.9203
Epoch 23/100
16960/16969 [============================&gt;.] - ETA: 0s - loss: 0.1978 - categorical_accuracy: 0.9398
Epoch 00023: val_loss did not improve from 0.24588
16969/16969 [==============================] - 4s 216us/sample - loss: 0.1981 - categorical_accuracy: 0.9397 - val_loss: 0.2542 - val_categorical_accuracy: 0.9241
Epoch 24/100
16736/16969 [============================&gt;.] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9397
Epoch 00024: val_loss did not improve from 0.24588
16969/16969 [==============================] - 4s 223us/sample - loss: 0.1997 - categorical_accuracy: 0.9398 - val_loss: 0.2667 - val_categorical_accuracy: 0.9241
Epoch 25/100
16832/16969 [============================&gt;.] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9422
Epoch 00025: val_loss did not improve from 0.24588
16969/16969 [==============================] - 4s 230us/sample - loss: 0.1879 - categorical_accuracy: 0.9424 - val_loss: 0.2643 - val_categorical_accuracy: 0.9255
Epoch 26/100
16832/16969 [============================&gt;.] - ETA: 0s - loss: 0.1825 - categorical_accuracy: 0.9452
Epoch 00026: val_loss did not improve from 0.24588
16969/16969 [==============================] - 4s 224us/sample - loss: 0.1828 - categorical_accuracy: 0.9452 - val_loss: 0.2468 - val_categorical_accuracy: 0.9227
0.9354078 0.7284142797841427


nrx: 15 - real: 2 
Train on 24527 samples, validate on 3065 samples
Epoch 1/100
24288/24527 [============================&gt;.] - ETA: 0s - loss: 1.3228 - categorical_accuracy: 0.4734
Epoch 00001: val_loss improved from inf to 0.76225, saving model to t_weights_0
24527/24527 [==============================] - 6s 237us/sample - loss: 1.3183 - categorical_accuracy: 0.4747 - val_loss: 0.7623 - val_categorical_accuracy: 0.6858
Epoch 2/100
24320/24527 [============================&gt;.] - ETA: 0s - loss: 0.7422 - categorical_accuracy: 0.6950
Epoch 00002: val_loss improved from 0.76225 to 0.55635, saving model to t_weights_0
24527/24527 [==============================] - 5s 224us/sample - loss: 0.7408 - categorical_accuracy: 0.6959 - val_loss: 0.5563 - val_categorical_accuracy: 0.7853
Epoch 3/100
24448/24527 [============================&gt;.] - ETA: 0s - loss: 0.5462 - categorical_accuracy: 0.7970
Epoch 00003: val_loss improved from 0.55635 to 0.40804, saving model to t_weights_0
24527/24527 [==============================] - 5s 223us/sample - loss: 0.5457 - categorical_accuracy: 0.7972 - val_loss: 0.4080 - val_categorical_accuracy: 0.8574
Epoch 4/100
24480/24527 [============================&gt;.] - ETA: 0s - loss: 0.4217 - categorical_accuracy: 0.8552
Epoch 00004: val_loss improved from 0.40804 to 0.35661, saving model to t_weights_0
24527/24527 [==============================] - 5s 222us/sample - loss: 0.4215 - categorical_accuracy: 0.8553 - val_loss: 0.3566 - val_categorical_accuracy: 0.8741
Epoch 5/100
24416/24527 [============================&gt;.] - ETA: 0s - loss: 0.3554 - categorical_accuracy: 0.8818
Epoch 00005: val_loss improved from 0.35661 to 0.28652, saving model to t_weights_0
24527/24527 [==============================] - 5s 223us/sample - loss: 0.3548 - categorical_accuracy: 0.8820 - val_loss: 0.2865 - val_categorical_accuracy: 0.9038
Epoch 6/100
24512/24527 [============================&gt;.] - ETA: 0s - loss: 0.3072 - categorical_accuracy: 0.8994
Epoch 00006: val_loss improved from 0.28652 to 0.24605, saving model to t_weights_0
24527/24527 [==============================] - 6s 226us/sample - loss: 0.3075 - categorical_accuracy: 0.8993 - val_loss: 0.2460 - val_categorical_accuracy: 0.9165
Epoch 7/100
24320/24527 [============================&gt;.] - ETA: 0s - loss: 0.2842 - categorical_accuracy: 0.9076
Epoch 00007: val_loss did not improve from 0.24605
24527/24527 [==============================] - 5s 220us/sample - loss: 0.2841 - categorical_accuracy: 0.9077 - val_loss: 0.2694 - val_categorical_accuracy: 0.9086
Epoch 8/100
24256/24527 [============================&gt;.] - ETA: 0s - loss: 0.2607 - categorical_accuracy: 0.9150
Epoch 00008: val_loss improved from 0.24605 to 0.22868, saving model to t_weights_0
24527/24527 [==============================] - 5s 219us/sample - loss: 0.2608 - categorical_accuracy: 0.9150 - val_loss: 0.2287 - val_categorical_accuracy: 0.9230
Epoch 9/100
24448/24527 [============================&gt;.] - ETA: 0s - loss: 0.2489 - categorical_accuracy: 0.9180
Epoch 00009: val_loss improved from 0.22868 to 0.21492, saving model to t_weights_0
24527/24527 [==============================] - 5s 220us/sample - loss: 0.2490 - categorical_accuracy: 0.9180 - val_loss: 0.2149 - val_categorical_accuracy: 0.9305
Epoch 10/100
24288/24527 [============================&gt;.] - ETA: 0s - loss: 0.2309 - categorical_accuracy: 0.9254
Epoch 00010: val_loss did not improve from 0.21492
24527/24527 [==============================] - 5s 221us/sample - loss: 0.2305 - categorical_accuracy: 0.9255 - val_loss: 0.2231 - val_categorical_accuracy: 0.9282
Epoch 11/100
24288/24527 [============================&gt;.] - ETA: 0s - loss: 0.2249 - categorical_accuracy: 0.9271
Epoch 00011: val_loss improved from 0.21492 to 0.21476, saving model to t_weights_0
24527/24527 [==============================] - 5s 224us/sample - loss: 0.2245 - categorical_accuracy: 0.9272 - val_loss: 0.2148 - val_categorical_accuracy: 0.9302
Epoch 12/100
24288/24527 [============================&gt;.] - ETA: 0s - loss: 0.2133 - categorical_accuracy: 0.9321
Epoch 00012: val_loss improved from 0.21476 to 0.21074, saving model to t_weights_0
24527/24527 [==============================] - 5s 221us/sample - loss: 0.2136 - categorical_accuracy: 0.9320 - val_loss: 0.2107 - val_categorical_accuracy: 0.9318
Epoch 13/100
24416/24527 [============================&gt;.] - ETA: 0s - loss: 0.2054 - categorical_accuracy: 0.9357
Epoch 00013: val_loss improved from 0.21074 to 0.19920, saving model to t_weights_0
24527/24527 [==============================] - 6s 226us/sample - loss: 0.2054 - categorical_accuracy: 0.9356 - val_loss: 0.1992 - val_categorical_accuracy: 0.9328
Epoch 14/100
24416/24527 [============================&gt;.] - ETA: 0s - loss: 0.1964 - categorical_accuracy: 0.9368
Epoch 00014: val_loss did not improve from 0.19920
24527/24527 [==============================] - 5s 222us/sample - loss: 0.1966 - categorical_accuracy: 0.9367 - val_loss: 0.2194 - val_categorical_accuracy: 0.9308
Epoch 15/100
24480/24527 [============================&gt;.] - ETA: 0s - loss: 0.1952 - categorical_accuracy: 0.9376
Epoch 00015: val_loss improved from 0.19920 to 0.19713, saving model to t_weights_0
24527/24527 [==============================] - 6s 226us/sample - loss: 0.1953 - categorical_accuracy: 0.9376 - val_loss: 0.1971 - val_categorical_accuracy: 0.9390
Epoch 16/100
24448/24527 [============================&gt;.] - ETA: 0s - loss: 0.1851 - categorical_accuracy: 0.9412
Epoch 00016: val_loss did not improve from 0.19713
24527/24527 [==============================] - 5s 221us/sample - loss: 0.1850 - categorical_accuracy: 0.9412 - val_loss: 0.2016 - val_categorical_accuracy: 0.9367
Epoch 17/100
24416/24527 [============================&gt;.] - ETA: 0s - loss: 0.1796 - categorical_accuracy: 0.9435
Epoch 00017: val_loss improved from 0.19713 to 0.19291, saving model to t_weights_0
24527/24527 [==============================] - 6s 225us/sample - loss: 0.1797 - categorical_accuracy: 0.9434 - val_loss: 0.1929 - val_categorical_accuracy: 0.9409
Epoch 18/100
24480/24527 [============================&gt;.] - ETA: 0s - loss: 0.1787 - categorical_accuracy: 0.9444
Epoch 00018: val_loss did not improve from 0.19291
24527/24527 [==============================] - 5s 221us/sample - loss: 0.1786 - categorical_accuracy: 0.9444 - val_loss: 0.2141 - val_categorical_accuracy: 0.9321
Epoch 19/100
24320/24527 [============================&gt;.] - ETA: 0s - loss: 0.1710 - categorical_accuracy: 0.9472
Epoch 00019: val_loss did not improve from 0.19291
24527/24527 [==============================] - 5s 218us/sample - loss: 0.1714 - categorical_accuracy: 0.9471 - val_loss: 0.1933 - val_categorical_accuracy: 0.9416
Epoch 20/100
24480/24527 [============================&gt;.] - ETA: 0s - loss: 0.1692 - categorical_accuracy: 0.9467
Epoch 00020: val_loss did not improve from 0.19291
24527/24527 [==============================] - 5s 218us/sample - loss: 0.1694 - categorical_accuracy: 0.9466 - val_loss: 0.1942 - val_categorical_accuracy: 0.9419
Epoch 21/100
24480/24527 [============================&gt;.] - ETA: 0s - loss: 0.1636 - categorical_accuracy: 0.9508
Epoch 00021: val_loss did not improve from 0.19291
24527/24527 [==============================] - 5s 220us/sample - loss: 0.1635 - categorical_accuracy: 0.9509 - val_loss: 0.1995 - val_categorical_accuracy: 0.9396
Epoch 22/100
24416/24527 [============================&gt;.] - ETA: 0s - loss: 0.1585 - categorical_accuracy: 0.9523
Epoch 00022: val_loss improved from 0.19291 to 0.18126, saving model to t_weights_0
24527/24527 [==============================] - 6s 228us/sample - loss: 0.1585 - categorical_accuracy: 0.9523 - val_loss: 0.1813 - val_categorical_accuracy: 0.9475
Epoch 23/100
24352/24527 [============================&gt;.] - ETA: 0s - loss: 0.1589 - categorical_accuracy: 0.9532
Epoch 00023: val_loss did not improve from 0.18126
24527/24527 [==============================] - 5s 222us/sample - loss: 0.1588 - categorical_accuracy: 0.9533 - val_loss: 0.1939 - val_categorical_accuracy: 0.9442
Epoch 24/100
24512/24527 [============================&gt;.] - ETA: 0s - loss: 0.1542 - categorical_accuracy: 0.9545
Epoch 00024: val_loss did not improve from 0.18126
24527/24527 [==============================] - 5s 222us/sample - loss: 0.1541 - categorical_accuracy: 0.9545 - val_loss: 0.2082 - val_categorical_accuracy: 0.9436
Epoch 25/100
24480/24527 [============================&gt;.] - ETA: 0s - loss: 0.1480 - categorical_accuracy: 0.9561
Epoch 00025: val_loss did not improve from 0.18126
24527/24527 [==============================] - 5s 222us/sample - loss: 0.1480 - categorical_accuracy: 0.9561 - val_loss: 0.2014 - val_categorical_accuracy: 0.9432
Epoch 26/100
24288/24527 [============================&gt;.] - ETA: 0s - loss: 0.1504 - categorical_accuracy: 0.9549
Epoch 00026: val_loss did not improve from 0.18126
24527/24527 [==============================] - 5s 222us/sample - loss: 0.1498 - categorical_accuracy: 0.9551 - val_loss: 0.1913 - val_categorical_accuracy: 0.9511
Epoch 27/100
24416/24527 [============================&gt;.] - ETA: 0s - loss: 0.1459 - categorical_accuracy: 0.9573
Epoch 00027: val_loss did not improve from 0.18126
24527/24527 [==============================] - 5s 223us/sample - loss: 0.1460 - categorical_accuracy: 0.9572 - val_loss: 0.1942 - val_categorical_accuracy: 0.9452
0.9435563 0.7468866749688667


nrx: 20 - real: 2 
Train on 32375 samples, validate on 4046 samples
Epoch 1/100
32192/32375 [============================&gt;.] - ETA: 0s - loss: 1.1840 - categorical_accuracy: 0.5100
Epoch 00001: val_loss improved from inf to 0.70900, saving model to t_weights_0
32375/32375 [==============================] - 8s 233us/sample - loss: 1.1815 - categorical_accuracy: 0.5110 - val_loss: 0.7090 - val_categorical_accuracy: 0.7076
Epoch 2/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.6985 - categorical_accuracy: 0.7135
Epoch 00002: val_loss improved from 0.70900 to 0.52980, saving model to t_weights_0
32375/32375 [==============================] - 7s 223us/sample - loss: 0.6979 - categorical_accuracy: 0.7138 - val_loss: 0.5298 - val_categorical_accuracy: 0.8028
Epoch 3/100
32256/32375 [============================&gt;.] - ETA: 0s - loss: 0.5501 - categorical_accuracy: 0.7928
Epoch 00003: val_loss improved from 0.52980 to 0.43877, saving model to t_weights_0
32375/32375 [==============================] - 7s 218us/sample - loss: 0.5496 - categorical_accuracy: 0.7929 - val_loss: 0.4388 - val_categorical_accuracy: 0.8337
Epoch 4/100
32128/32375 [============================&gt;.] - ETA: 0s - loss: 0.4323 - categorical_accuracy: 0.8491
Epoch 00004: val_loss improved from 0.43877 to 0.31910, saving model to t_weights_0
32375/32375 [==============================] - 7s 222us/sample - loss: 0.4324 - categorical_accuracy: 0.8493 - val_loss: 0.3191 - val_categorical_accuracy: 0.8930
Epoch 5/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.3553 - categorical_accuracy: 0.8791
Epoch 00005: val_loss improved from 0.31910 to 0.26440, saving model to t_weights_0
32375/32375 [==============================] - 7s 223us/sample - loss: 0.3551 - categorical_accuracy: 0.8793 - val_loss: 0.2644 - val_categorical_accuracy: 0.9162
Epoch 6/100
32352/32375 [============================&gt;.] - ETA: 0s - loss: 0.3054 - categorical_accuracy: 0.9011
Epoch 00006: val_loss improved from 0.26440 to 0.23234, saving model to t_weights_0
32375/32375 [==============================] - 7s 213us/sample - loss: 0.3054 - categorical_accuracy: 0.9011 - val_loss: 0.2323 - val_categorical_accuracy: 0.9214
Epoch 7/100
32256/32375 [============================&gt;.] - ETA: 0s - loss: 0.2837 - categorical_accuracy: 0.9085
Epoch 00007: val_loss did not improve from 0.23234
32375/32375 [==============================] - 7s 222us/sample - loss: 0.2836 - categorical_accuracy: 0.9086 - val_loss: 0.2332 - val_categorical_accuracy: 0.9202
Epoch 8/100
32224/32375 [============================&gt;.] - ETA: 0s - loss: 0.2625 - categorical_accuracy: 0.9149
Epoch 00008: val_loss improved from 0.23234 to 0.22824, saving model to t_weights_0
32375/32375 [==============================] - 7s 207us/sample - loss: 0.2622 - categorical_accuracy: 0.9151 - val_loss: 0.2282 - val_categorical_accuracy: 0.9286
Epoch 9/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.2473 - categorical_accuracy: 0.9203
Epoch 00009: val_loss improved from 0.22824 to 0.21524, saving model to t_weights_0
32375/32375 [==============================] - 7s 221us/sample - loss: 0.2471 - categorical_accuracy: 0.9204 - val_loss: 0.2152 - val_categorical_accuracy: 0.9298
Epoch 10/100
32288/32375 [============================&gt;.] - ETA: 0s - loss: 0.2373 - categorical_accuracy: 0.9223
Epoch 00010: val_loss improved from 0.21524 to 0.21108, saving model to t_weights_0
32375/32375 [==============================] - 7s 221us/sample - loss: 0.2375 - categorical_accuracy: 0.9223 - val_loss: 0.2111 - val_categorical_accuracy: 0.9325
Epoch 11/100
32160/32375 [============================&gt;.] - ETA: 0s - loss: 0.2272 - categorical_accuracy: 0.9272
Epoch 00011: val_loss improved from 0.21108 to 0.19578, saving model to t_weights_0
32375/32375 [==============================] - 7s 215us/sample - loss: 0.2273 - categorical_accuracy: 0.9271 - val_loss: 0.1958 - val_categorical_accuracy: 0.9360
Epoch 12/100
32160/32375 [============================&gt;.] - ETA: 0s - loss: 0.2212 - categorical_accuracy: 0.9286
Epoch 00012: val_loss improved from 0.19578 to 0.19321, saving model to t_weights_0
32375/32375 [==============================] - 7s 222us/sample - loss: 0.2208 - categorical_accuracy: 0.9287 - val_loss: 0.1932 - val_categorical_accuracy: 0.9380
Epoch 13/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.2146 - categorical_accuracy: 0.9330
Epoch 00013: val_loss improved from 0.19321 to 0.19055, saving model to t_weights_0
32375/32375 [==============================] - 7s 220us/sample - loss: 0.2146 - categorical_accuracy: 0.9330 - val_loss: 0.1905 - val_categorical_accuracy: 0.9399
Epoch 14/100
32160/32375 [============================&gt;.] - ETA: 0s - loss: 0.2097 - categorical_accuracy: 0.9339
Epoch 00014: val_loss did not improve from 0.19055
32375/32375 [==============================] - 7s 220us/sample - loss: 0.2098 - categorical_accuracy: 0.9337 - val_loss: 0.1909 - val_categorical_accuracy: 0.9394
Epoch 15/100
32192/32375 [============================&gt;.] - ETA: 0s - loss: 0.2023 - categorical_accuracy: 0.9359
Epoch 00015: val_loss did not improve from 0.19055
32375/32375 [==============================] - 7s 213us/sample - loss: 0.2019 - categorical_accuracy: 0.9361 - val_loss: 0.1971 - val_categorical_accuracy: 0.9380
Epoch 16/100
32224/32375 [============================&gt;.] - ETA: 0s - loss: 0.1952 - categorical_accuracy: 0.9392
Epoch 00016: val_loss improved from 0.19055 to 0.18856, saving model to t_weights_0
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1950 - categorical_accuracy: 0.9392 - val_loss: 0.1886 - val_categorical_accuracy: 0.9432
Epoch 17/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.1920 - categorical_accuracy: 0.9399
Epoch 00017: val_loss did not improve from 0.18856
32375/32375 [==============================] - 7s 220us/sample - loss: 0.1921 - categorical_accuracy: 0.9399 - val_loss: 0.1929 - val_categorical_accuracy: 0.9449
Epoch 18/100
32192/32375 [============================&gt;.] - ETA: 0s - loss: 0.1847 - categorical_accuracy: 0.9427
Epoch 00018: val_loss did not improve from 0.18856
32375/32375 [==============================] - 7s 220us/sample - loss: 0.1852 - categorical_accuracy: 0.9425 - val_loss: 0.1978 - val_categorical_accuracy: 0.9409
Epoch 19/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.1829 - categorical_accuracy: 0.9429
Epoch 00019: val_loss improved from 0.18856 to 0.18689, saving model to t_weights_0
32375/32375 [==============================] - 7s 222us/sample - loss: 0.1829 - categorical_accuracy: 0.9430 - val_loss: 0.1869 - val_categorical_accuracy: 0.9417
Epoch 20/100
32256/32375 [============================&gt;.] - ETA: 0s - loss: 0.1769 - categorical_accuracy: 0.9459
Epoch 00020: val_loss improved from 0.18689 to 0.18318, saving model to t_weights_0
32375/32375 [==============================] - 7s 216us/sample - loss: 0.1770 - categorical_accuracy: 0.9459 - val_loss: 0.1832 - val_categorical_accuracy: 0.9454
Epoch 21/100
32352/32375 [============================&gt;.] - ETA: 0s - loss: 0.1744 - categorical_accuracy: 0.9469
Epoch 00021: val_loss did not improve from 0.18318
32375/32375 [==============================] - 7s 219us/sample - loss: 0.1743 - categorical_accuracy: 0.9469 - val_loss: 0.1844 - val_categorical_accuracy: 0.9481
Epoch 22/100
32256/32375 [============================&gt;.] - ETA: 0s - loss: 0.1710 - categorical_accuracy: 0.9477
Epoch 00022: val_loss improved from 0.18318 to 0.18200, saving model to t_weights_0
32375/32375 [==============================] - 7s 223us/sample - loss: 0.1709 - categorical_accuracy: 0.9478 - val_loss: 0.1820 - val_categorical_accuracy: 0.9478
Epoch 23/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.1689 - categorical_accuracy: 0.9482
Epoch 00023: val_loss did not improve from 0.18200
32375/32375 [==============================] - 7s 222us/sample - loss: 0.1691 - categorical_accuracy: 0.9483 - val_loss: 0.1846 - val_categorical_accuracy: 0.9461
Epoch 24/100
32224/32375 [============================&gt;.] - ETA: 0s - loss: 0.1648 - categorical_accuracy: 0.9507
Epoch 00024: val_loss improved from 0.18200 to 0.18199, saving model to t_weights_0
32375/32375 [==============================] - 7s 223us/sample - loss: 0.1652 - categorical_accuracy: 0.9505 - val_loss: 0.1820 - val_categorical_accuracy: 0.9456
Epoch 25/100
32256/32375 [============================&gt;.] - ETA: 0s - loss: 0.1632 - categorical_accuracy: 0.9507
Epoch 00025: val_loss did not improve from 0.18199
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1635 - categorical_accuracy: 0.9506 - val_loss: 0.1904 - val_categorical_accuracy: 0.9456
Epoch 26/100
32192/32375 [============================&gt;.] - ETA: 0s - loss: 0.1589 - categorical_accuracy: 0.9510
Epoch 00026: val_loss did not improve from 0.18199
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1590 - categorical_accuracy: 0.9509 - val_loss: 0.1874 - val_categorical_accuracy: 0.9486
Epoch 27/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.1563 - categorical_accuracy: 0.9530
Epoch 00027: val_loss improved from 0.18199 to 0.17872, saving model to t_weights_0
32375/32375 [==============================] - 7s 214us/sample - loss: 0.1563 - categorical_accuracy: 0.9530 - val_loss: 0.1787 - val_categorical_accuracy: 0.9483
Epoch 28/100
32256/32375 [============================&gt;.] - ETA: 0s - loss: 0.1516 - categorical_accuracy: 0.9543
Epoch 00028: val_loss did not improve from 0.17872
32375/32375 [==============================] - 7s 212us/sample - loss: 0.1517 - categorical_accuracy: 0.9543 - val_loss: 0.2067 - val_categorical_accuracy: 0.9427
Epoch 29/100
32160/32375 [============================&gt;.] - ETA: 0s - loss: 0.1495 - categorical_accuracy: 0.9553
Epoch 00029: val_loss improved from 0.17872 to 0.17521, saving model to t_weights_0
32375/32375 [==============================] - 7s 223us/sample - loss: 0.1491 - categorical_accuracy: 0.9555 - val_loss: 0.1752 - val_categorical_accuracy: 0.9516
Epoch 30/100
32352/32375 [============================&gt;.] - ETA: 0s - loss: 0.1501 - categorical_accuracy: 0.9563
Epoch 00030: val_loss did not improve from 0.17521
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1501 - categorical_accuracy: 0.9563 - val_loss: 0.2136 - val_categorical_accuracy: 0.9424
Epoch 31/100
32320/32375 [============================&gt;.] - ETA: 0s - loss: 0.1449 - categorical_accuracy: 0.9565
Epoch 00031: val_loss did not improve from 0.17521
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1451 - categorical_accuracy: 0.9564 - val_loss: 0.1854 - val_categorical_accuracy: 0.9483
Epoch 32/100
32224/32375 [============================&gt;.] - ETA: 0s - loss: 0.1422 - categorical_accuracy: 0.9590
Epoch 00032: val_loss did not improve from 0.17521
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1425 - categorical_accuracy: 0.9589 - val_loss: 0.1782 - val_categorical_accuracy: 0.9511
Epoch 33/100
32352/32375 [============================&gt;.] - ETA: 0s - loss: 0.1402 - categorical_accuracy: 0.9593
Epoch 00033: val_loss did not improve from 0.17521
32375/32375 [==============================] - 7s 221us/sample - loss: 0.1402 - categorical_accuracy: 0.9593 - val_loss: 0.1765 - val_categorical_accuracy: 0.9501
Epoch 34/100
32096/32375 [============================&gt;.] - ETA: 0s - loss: 0.1406 - categorical_accuracy: 0.9596
Epoch 00034: val_loss did not improve from 0.17521
32375/32375 [==============================] - 7s 222us/sample - loss: 0.1401 - categorical_accuracy: 0.9598 - val_loss: 0.1912 - val_categorical_accuracy: 0.9481
0.94364804 0.7787463677874636


nrx: 25 - real: 2 
Train on 40215 samples, validate on 5026 samples
Epoch 1/100
40096/40215 [============================&gt;.] - ETA: 0s - loss: 1.1341 - categorical_accuracy: 0.5369
Epoch 00001: val_loss improved from inf to 0.65772, saving model to t_weights_0
40215/40215 [==============================] - 9s 234us/sample - loss: 1.1330 - categorical_accuracy: 0.5373 - val_loss: 0.6577 - val_categorical_accuracy: 0.7527
Epoch 2/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.6030 - categorical_accuracy: 0.7779
Epoch 00002: val_loss improved from 0.65772 to 0.41607, saving model to t_weights_0
40215/40215 [==============================] - 9s 217us/sample - loss: 0.6027 - categorical_accuracy: 0.7779 - val_loss: 0.4161 - val_categorical_accuracy: 0.8597
Epoch 3/100
40128/40215 [============================&gt;.] - ETA: 0s - loss: 0.4176 - categorical_accuracy: 0.8620
Epoch 00003: val_loss improved from 0.41607 to 0.30562, saving model to t_weights_0
40215/40215 [==============================] - 9s 223us/sample - loss: 0.4173 - categorical_accuracy: 0.8621 - val_loss: 0.3056 - val_categorical_accuracy: 0.8991
Epoch 4/100
40160/40215 [============================&gt;.] - ETA: 0s - loss: 0.3228 - categorical_accuracy: 0.8962
Epoch 00004: val_loss improved from 0.30562 to 0.27329, saving model to t_weights_0
40215/40215 [==============================] - 9s 225us/sample - loss: 0.3229 - categorical_accuracy: 0.8962 - val_loss: 0.2733 - val_categorical_accuracy: 0.9107
Epoch 5/100
40128/40215 [============================&gt;.] - ETA: 0s - loss: 0.2844 - categorical_accuracy: 0.9116
Epoch 00005: val_loss improved from 0.27329 to 0.27289, saving model to t_weights_0
40215/40215 [==============================] - 9s 223us/sample - loss: 0.2844 - categorical_accuracy: 0.9116 - val_loss: 0.2729 - val_categorical_accuracy: 0.9103
Epoch 6/100
40192/40215 [============================&gt;.] - ETA: 0s - loss: 0.2616 - categorical_accuracy: 0.9200
Epoch 00006: val_loss improved from 0.27289 to 0.23978, saving model to t_weights_0
40215/40215 [==============================] - 9s 224us/sample - loss: 0.2617 - categorical_accuracy: 0.9200 - val_loss: 0.2398 - val_categorical_accuracy: 0.9230
Epoch 7/100
39968/40215 [============================&gt;.] - ETA: 0s - loss: 0.2441 - categorical_accuracy: 0.9245
Epoch 00007: val_loss improved from 0.23978 to 0.23955, saving model to t_weights_0
40215/40215 [==============================] - 9s 225us/sample - loss: 0.2442 - categorical_accuracy: 0.9244 - val_loss: 0.2395 - val_categorical_accuracy: 0.9248
Epoch 8/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.2286 - categorical_accuracy: 0.9291
Epoch 00008: val_loss did not improve from 0.23955
40215/40215 [==============================] - 9s 221us/sample - loss: 0.2287 - categorical_accuracy: 0.9291 - val_loss: 0.2812 - val_categorical_accuracy: 0.9095
Epoch 9/100
40096/40215 [============================&gt;.] - ETA: 0s - loss: 0.2183 - categorical_accuracy: 0.9332
Epoch 00009: val_loss improved from 0.23955 to 0.23936, saving model to t_weights_0
40215/40215 [==============================] - 9s 218us/sample - loss: 0.2183 - categorical_accuracy: 0.9331 - val_loss: 0.2394 - val_categorical_accuracy: 0.9284
Epoch 10/100
39968/40215 [============================&gt;.] - ETA: 0s - loss: 0.2082 - categorical_accuracy: 0.9369
Epoch 00010: val_loss improved from 0.23936 to 0.22049, saving model to t_weights_0
40215/40215 [==============================] - 9s 224us/sample - loss: 0.2078 - categorical_accuracy: 0.9370 - val_loss: 0.2205 - val_categorical_accuracy: 0.9304
Epoch 11/100
40096/40215 [============================&gt;.] - ETA: 0s - loss: 0.2023 - categorical_accuracy: 0.9371
Epoch 00011: val_loss improved from 0.22049 to 0.21948, saving model to t_weights_0
40215/40215 [==============================] - 9s 224us/sample - loss: 0.2025 - categorical_accuracy: 0.9371 - val_loss: 0.2195 - val_categorical_accuracy: 0.9322
Epoch 12/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.1953 - categorical_accuracy: 0.9418
Epoch 00012: val_loss improved from 0.21948 to 0.21899, saving model to t_weights_0
40215/40215 [==============================] - 9s 224us/sample - loss: 0.1954 - categorical_accuracy: 0.9418 - val_loss: 0.2190 - val_categorical_accuracy: 0.9337
Epoch 13/100
40000/40215 [============================&gt;.] - ETA: 0s - loss: 0.1872 - categorical_accuracy: 0.9439
Epoch 00013: val_loss improved from 0.21899 to 0.21311, saving model to t_weights_0
40215/40215 [==============================] - 9s 213us/sample - loss: 0.1872 - categorical_accuracy: 0.9439 - val_loss: 0.2131 - val_categorical_accuracy: 0.9347
Epoch 14/100
40096/40215 [============================&gt;.] - ETA: 0s - loss: 0.1821 - categorical_accuracy: 0.9439
Epoch 00014: val_loss did not improve from 0.21311
40215/40215 [==============================] - 9s 221us/sample - loss: 0.1819 - categorical_accuracy: 0.9440 - val_loss: 0.2251 - val_categorical_accuracy: 0.9333
Epoch 15/100
40000/40215 [============================&gt;.] - ETA: 0s - loss: 0.1766 - categorical_accuracy: 0.9470
Epoch 00015: val_loss did not improve from 0.21311
40215/40215 [==============================] - 9s 222us/sample - loss: 0.1770 - categorical_accuracy: 0.9469 - val_loss: 0.2203 - val_categorical_accuracy: 0.9329
Epoch 16/100
40160/40215 [============================&gt;.] - ETA: 0s - loss: 0.1725 - categorical_accuracy: 0.9471
Epoch 00016: val_loss improved from 0.21311 to 0.20760, saving model to t_weights_0
40215/40215 [==============================] - 9s 216us/sample - loss: 0.1724 - categorical_accuracy: 0.9471 - val_loss: 0.2076 - val_categorical_accuracy: 0.9409
Epoch 17/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9496
Epoch 00017: val_loss improved from 0.20760 to 0.20402, saving model to t_weights_0
40215/40215 [==============================] - 9s 224us/sample - loss: 0.1705 - categorical_accuracy: 0.9496 - val_loss: 0.2040 - val_categorical_accuracy: 0.9421
Epoch 18/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.1648 - categorical_accuracy: 0.9511
Epoch 00018: val_loss did not improve from 0.20402
40215/40215 [==============================] - 9s 223us/sample - loss: 0.1647 - categorical_accuracy: 0.9511 - val_loss: 0.2165 - val_categorical_accuracy: 0.9381
Epoch 19/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.1613 - categorical_accuracy: 0.9525
Epoch 00019: val_loss did not improve from 0.20402
40215/40215 [==============================] - 9s 219us/sample - loss: 0.1613 - categorical_accuracy: 0.9525 - val_loss: 0.2126 - val_categorical_accuracy: 0.9419
Epoch 20/100
40032/40215 [============================&gt;.] - ETA: 0s - loss: 0.1584 - categorical_accuracy: 0.9536
Epoch 00020: val_loss did not improve from 0.20402
40215/40215 [==============================] - 9s 222us/sample - loss: 0.1582 - categorical_accuracy: 0.9537 - val_loss: 0.2212 - val_categorical_accuracy: 0.9421
Epoch 21/100
40160/40215 [============================&gt;.] - ETA: 0s - loss: 0.1551 - categorical_accuracy: 0.9544
Epoch 00021: val_loss did not improve from 0.20402
40215/40215 [==============================] - 9s 221us/sample - loss: 0.1552 - categorical_accuracy: 0.9543 - val_loss: 0.2138 - val_categorical_accuracy: 0.9419
Epoch 22/100
40128/40215 [============================&gt;.] - ETA: 0s - loss: 0.1509 - categorical_accuracy: 0.9561
Epoch 00022: val_loss did not improve from 0.20402
40215/40215 [==============================] - 9s 216us/sample - loss: 0.1507 - categorical_accuracy: 0.9561 - val_loss: 0.2160 - val_categorical_accuracy: 0.9407
0.94269794 0.8270029057700291


nrx: 0 - real: 3 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: divide by zero encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1440 samples, validate on 180 samples
Epoch 1/100
1376/1440 [===========================&gt;..] - ETA: 0s - loss: 2.2088 - categorical_accuracy: 0.2493
Epoch 00001: val_loss improved from inf to 1.96212, saving model to t_weights_0
1440/1440 [==============================] - 1s 536us/sample - loss: 2.1999 - categorical_accuracy: 0.2535 - val_loss: 1.9621 - val_categorical_accuracy: 0.5333
Epoch 2/100
1376/1440 [===========================&gt;..] - ETA: 0s - loss: 1.5695 - categorical_accuracy: 0.4891
Epoch 00002: val_loss improved from 1.96212 to 0.97583, saving model to t_weights_0
1440/1440 [==============================] - 0s 272us/sample - loss: 1.5510 - categorical_accuracy: 0.4917 - val_loss: 0.9758 - val_categorical_accuracy: 0.5444
Epoch 3/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.9540 - categorical_accuracy: 0.6280
Epoch 00003: val_loss improved from 0.97583 to 0.65258, saving model to t_weights_0
1440/1440 [==============================] - 0s 272us/sample - loss: 0.9409 - categorical_accuracy: 0.6326 - val_loss: 0.6526 - val_categorical_accuracy: 0.7944
Epoch 4/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.6660 - categorical_accuracy: 0.7454
Epoch 00004: val_loss improved from 0.65258 to 0.44933, saving model to t_weights_0
1440/1440 [==============================] - 0s 265us/sample - loss: 0.6582 - categorical_accuracy: 0.7507 - val_loss: 0.4493 - val_categorical_accuracy: 0.8889
Epoch 5/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.4871 - categorical_accuracy: 0.8331
Epoch 00005: val_loss improved from 0.44933 to 0.29225, saving model to t_weights_0
1440/1440 [==============================] - 0s 250us/sample - loss: 0.4767 - categorical_accuracy: 0.8361 - val_loss: 0.2923 - val_categorical_accuracy: 0.9722
Epoch 6/100
1184/1440 [=======================&gt;......] - ETA: 0s - loss: 0.3487 - categorical_accuracy: 0.8826
Epoch 00006: val_loss improved from 0.29225 to 0.22074, saving model to t_weights_0
1440/1440 [==============================] - 0s 248us/sample - loss: 0.3383 - categorical_accuracy: 0.8889 - val_loss: 0.2207 - val_categorical_accuracy: 0.9667
Epoch 7/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.2261 - categorical_accuracy: 0.9430
Epoch 00007: val_loss improved from 0.22074 to 0.13589, saving model to t_weights_0
1440/1440 [==============================] - 0s 284us/sample - loss: 0.2235 - categorical_accuracy: 0.9431 - val_loss: 0.1359 - val_categorical_accuracy: 0.9889
Epoch 8/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.1596 - categorical_accuracy: 0.9611
Epoch 00008: val_loss improved from 0.13589 to 0.11601, saving model to t_weights_0
1440/1440 [==============================] - 0s 270us/sample - loss: 0.1624 - categorical_accuracy: 0.9611 - val_loss: 0.1160 - val_categorical_accuracy: 0.9778
Epoch 9/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.1342 - categorical_accuracy: 0.9703
Epoch 00009: val_loss improved from 0.11601 to 0.09298, saving model to t_weights_0
1440/1440 [==============================] - 0s 277us/sample - loss: 0.1310 - categorical_accuracy: 0.9708 - val_loss: 0.0930 - val_categorical_accuracy: 0.9778
Epoch 10/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.1172 - categorical_accuracy: 0.9741
Epoch 00010: val_loss improved from 0.09298 to 0.07946, saving model to t_weights_0
1440/1440 [==============================] - 0s 282us/sample - loss: 0.1156 - categorical_accuracy: 0.9743 - val_loss: 0.0795 - val_categorical_accuracy: 0.9889
Epoch 11/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.9766
Epoch 00011: val_loss improved from 0.07946 to 0.07833, saving model to t_weights_0
1440/1440 [==============================] - 0s 271us/sample - loss: 0.1023 - categorical_accuracy: 0.9778 - val_loss: 0.0783 - val_categorical_accuracy: 0.9889
Epoch 12/100
1184/1440 [=======================&gt;......] - ETA: 0s - loss: 0.0770 - categorical_accuracy: 0.9848
Epoch 00012: val_loss improved from 0.07833 to 0.05801, saving model to t_weights_0
1440/1440 [==============================] - 0s 242us/sample - loss: 0.0801 - categorical_accuracy: 0.9840 - val_loss: 0.0580 - val_categorical_accuracy: 0.9722
Epoch 13/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0758 - categorical_accuracy: 0.9848
Epoch 00013: val_loss did not improve from 0.05801
1440/1440 [==============================] - 0s 234us/sample - loss: 0.0759 - categorical_accuracy: 0.9840 - val_loss: 0.0723 - val_categorical_accuracy: 0.9889
Epoch 14/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0645 - categorical_accuracy: 0.9893
Epoch 00014: val_loss improved from 0.05801 to 0.04618, saving model to t_weights_0
1440/1440 [==============================] - 0s 281us/sample - loss: 0.0643 - categorical_accuracy: 0.9896 - val_loss: 0.0462 - val_categorical_accuracy: 0.9889
Epoch 15/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0633 - categorical_accuracy: 0.9878
Epoch 00015: val_loss did not improve from 0.04618
1440/1440 [==============================] - 0s 231us/sample - loss: 0.0639 - categorical_accuracy: 0.9875 - val_loss: 0.0535 - val_categorical_accuracy: 0.9833
Epoch 16/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0502 - categorical_accuracy: 0.9916
Epoch 00016: val_loss did not improve from 0.04618
1440/1440 [==============================] - 0s 238us/sample - loss: 0.0504 - categorical_accuracy: 0.9917 - val_loss: 0.0499 - val_categorical_accuracy: 0.9889
Epoch 17/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.0550 - categorical_accuracy: 0.9906
Epoch 00017: val_loss improved from 0.04618 to 0.03766, saving model to t_weights_0
1440/1440 [==============================] - 0s 285us/sample - loss: 0.0570 - categorical_accuracy: 0.9889 - val_loss: 0.0377 - val_categorical_accuracy: 0.9944
Epoch 18/100
1120/1440 [======================&gt;.......] - ETA: 0s - loss: 0.0516 - categorical_accuracy: 0.9893
Epoch 00018: val_loss improved from 0.03766 to 0.03581, saving model to t_weights_0
1440/1440 [==============================] - 0s 245us/sample - loss: 0.0490 - categorical_accuracy: 0.9896 - val_loss: 0.0358 - val_categorical_accuracy: 0.9944
Epoch 19/100
1152/1440 [=======================&gt;......] - ETA: 0s - loss: 0.0376 - categorical_accuracy: 0.9948
Epoch 00019: val_loss did not improve from 0.03581
1440/1440 [==============================] - 0s 210us/sample - loss: 0.0418 - categorical_accuracy: 0.9937 - val_loss: 0.0405 - val_categorical_accuracy: 0.9944
Epoch 20/100
1248/1440 [=========================&gt;....] - ETA: 0s - loss: 0.0477 - categorical_accuracy: 0.9904
Epoch 00020: val_loss improved from 0.03581 to 0.03554, saving model to t_weights_0
1440/1440 [==============================] - 0s 290us/sample - loss: 0.0464 - categorical_accuracy: 0.9917 - val_loss: 0.0355 - val_categorical_accuracy: 0.9833
Epoch 21/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.0332 - categorical_accuracy: 0.9969
Epoch 00021: val_loss improved from 0.03554 to 0.03476, saving model to t_weights_0
1440/1440 [==============================] - 0s 287us/sample - loss: 0.0353 - categorical_accuracy: 0.9958 - val_loss: 0.0348 - val_categorical_accuracy: 0.9944
Epoch 22/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0405 - categorical_accuracy: 0.9924
Epoch 00022: val_loss did not improve from 0.03476
1440/1440 [==============================] - 0s 235us/sample - loss: 0.0389 - categorical_accuracy: 0.9931 - val_loss: 0.0376 - val_categorical_accuracy: 0.9889
Epoch 23/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0349 - categorical_accuracy: 0.9931
Epoch 00023: val_loss improved from 0.03476 to 0.02923, saving model to t_weights_0
1440/1440 [==============================] - 0s 280us/sample - loss: 0.0343 - categorical_accuracy: 0.9937 - val_loss: 0.0292 - val_categorical_accuracy: 0.9944
Epoch 24/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.0358 - categorical_accuracy: 0.9914
Epoch 00024: val_loss did not improve from 0.02923
1440/1440 [==============================] - 0s 234us/sample - loss: 0.0351 - categorical_accuracy: 0.9924 - val_loss: 0.0319 - val_categorical_accuracy: 0.9944
Epoch 25/100
1120/1440 [======================&gt;.......] - ETA: 0s - loss: 0.0308 - categorical_accuracy: 0.9973
Epoch 00025: val_loss improved from 0.02923 to 0.02919, saving model to t_weights_0
1440/1440 [==============================] - 0s 241us/sample - loss: 0.0304 - categorical_accuracy: 0.9979 - val_loss: 0.0292 - val_categorical_accuracy: 0.9944
Epoch 26/100
1344/1440 [===========================&gt;..] - ETA: 0s - loss: 0.0271 - categorical_accuracy: 0.9978
Epoch 00026: val_loss did not improve from 0.02919
1440/1440 [==============================] - 0s 226us/sample - loss: 0.0268 - categorical_accuracy: 0.9979 - val_loss: 0.0365 - val_categorical_accuracy: 0.9944
Epoch 27/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0249 - categorical_accuracy: 0.9985
Epoch 00027: val_loss did not improve from 0.02919
1440/1440 [==============================] - 0s 236us/sample - loss: 0.0249 - categorical_accuracy: 0.9986 - val_loss: 0.0308 - val_categorical_accuracy: 0.9944
Epoch 28/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0252 - categorical_accuracy: 0.9985
Epoch 00028: val_loss did not improve from 0.02919
1440/1440 [==============================] - 0s 234us/sample - loss: 0.0259 - categorical_accuracy: 0.9979 - val_loss: 0.0509 - val_categorical_accuracy: 0.9944
Epoch 29/100
1280/1440 [=========================&gt;....] - ETA: 0s - loss: 0.0263 - categorical_accuracy: 0.9992
Epoch 00029: val_loss did not improve from 0.02919
1440/1440 [==============================] - 0s 238us/sample - loss: 0.0255 - categorical_accuracy: 0.9993 - val_loss: 0.0292 - val_categorical_accuracy: 0.9944
Epoch 30/100
1312/1440 [==========================&gt;...] - ETA: 0s - loss: 0.0237 - categorical_accuracy: 0.9985
Epoch 00030: val_loss did not improve from 0.02919
1440/1440 [==============================] - 0s 234us/sample - loss: 0.0255 - categorical_accuracy: 0.9972 - val_loss: 0.0350 - val_categorical_accuracy: 0.9944
0.98888886 0.28977980889073535


nrx: 5 - real: 3 
Train on 9280 samples, validate on 1160 samples
Epoch 1/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 1.5042 - categorical_accuracy: 0.4455
Epoch 00001: val_loss improved from inf to 0.70178, saving model to t_weights_0
9280/9280 [==============================] - 2s 266us/sample - loss: 1.4965 - categorical_accuracy: 0.4477 - val_loss: 0.7018 - val_categorical_accuracy: 0.7043
Epoch 2/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.7079 - categorical_accuracy: 0.7043
Epoch 00002: val_loss improved from 0.70178 to 0.48378, saving model to t_weights_0
9280/9280 [==============================] - 2s 230us/sample - loss: 0.7065 - categorical_accuracy: 0.7052 - val_loss: 0.4838 - val_categorical_accuracy: 0.8362
Epoch 3/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.4972 - categorical_accuracy: 0.8009
Epoch 00003: val_loss improved from 0.48378 to 0.33332, saving model to t_weights_0
9280/9280 [==============================] - 2s 227us/sample - loss: 0.4972 - categorical_accuracy: 0.8012 - val_loss: 0.3333 - val_categorical_accuracy: 0.8776
Epoch 4/100
9248/9280 [============================&gt;.] - ETA: 0s - loss: 0.3586 - categorical_accuracy: 0.8728
Epoch 00004: val_loss improved from 0.33332 to 0.23305, saving model to t_weights_0
9280/9280 [==============================] - 2s 218us/sample - loss: 0.3585 - categorical_accuracy: 0.8730 - val_loss: 0.2330 - val_categorical_accuracy: 0.9345
Epoch 5/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 0.2755 - categorical_accuracy: 0.9093
Epoch 00005: val_loss improved from 0.23305 to 0.20823, saving model to t_weights_0
9280/9280 [==============================] - 2s 235us/sample - loss: 0.2752 - categorical_accuracy: 0.9092 - val_loss: 0.2082 - val_categorical_accuracy: 0.9190
Epoch 6/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.2097 - categorical_accuracy: 0.9396
Epoch 00006: val_loss improved from 0.20823 to 0.12831, saving model to t_weights_0
9280/9280 [==============================] - 2s 229us/sample - loss: 0.2099 - categorical_accuracy: 0.9395 - val_loss: 0.1283 - val_categorical_accuracy: 0.9672
Epoch 7/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 0.1551 - categorical_accuracy: 0.9602
Epoch 00007: val_loss improved from 0.12831 to 0.11104, saving model to t_weights_0
9280/9280 [==============================] - 2s 231us/sample - loss: 0.1550 - categorical_accuracy: 0.9602 - val_loss: 0.1110 - val_categorical_accuracy: 0.9793
Epoch 8/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.9677
Epoch 00008: val_loss improved from 0.11104 to 0.09196, saving model to t_weights_0
9280/9280 [==============================] - 2s 230us/sample - loss: 0.1324 - categorical_accuracy: 0.9673 - val_loss: 0.0920 - val_categorical_accuracy: 0.9802
Epoch 9/100
9248/9280 [============================&gt;.] - ETA: 0s - loss: 0.1145 - categorical_accuracy: 0.9737
Epoch 00009: val_loss improved from 0.09196 to 0.07958, saving model to t_weights_0
9280/9280 [==============================] - 2s 233us/sample - loss: 0.1149 - categorical_accuracy: 0.9737 - val_loss: 0.0796 - val_categorical_accuracy: 0.9836
Epoch 10/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 0.1052 - categorical_accuracy: 0.9741
Epoch 00010: val_loss improved from 0.07958 to 0.07544, saving model to t_weights_0
9280/9280 [==============================] - 2s 232us/sample - loss: 0.1053 - categorical_accuracy: 0.9740 - val_loss: 0.0754 - val_categorical_accuracy: 0.9810
Epoch 11/100
9056/9280 [============================&gt;.] - ETA: 0s - loss: 0.0911 - categorical_accuracy: 0.9797
Epoch 00011: val_loss improved from 0.07544 to 0.07020, saving model to t_weights_0
9280/9280 [==============================] - 2s 229us/sample - loss: 0.0916 - categorical_accuracy: 0.9798 - val_loss: 0.0702 - val_categorical_accuracy: 0.9879
Epoch 12/100
9248/9280 [============================&gt;.] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9826
Epoch 00012: val_loss improved from 0.07020 to 0.06059, saving model to t_weights_0
9280/9280 [==============================] - 2s 233us/sample - loss: 0.0815 - categorical_accuracy: 0.9825 - val_loss: 0.0606 - val_categorical_accuracy: 0.9897
Epoch 13/100
9056/9280 [============================&gt;.] - ETA: 0s - loss: 0.0811 - categorical_accuracy: 0.9827
Epoch 00013: val_loss did not improve from 0.06059
9280/9280 [==============================] - 2s 227us/sample - loss: 0.0817 - categorical_accuracy: 0.9827 - val_loss: 0.0616 - val_categorical_accuracy: 0.9897
Epoch 14/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 0.0746 - categorical_accuracy: 0.9848
Epoch 00014: val_loss improved from 0.06059 to 0.05886, saving model to t_weights_0
9280/9280 [==============================] - 2s 231us/sample - loss: 0.0744 - categorical_accuracy: 0.9849 - val_loss: 0.0589 - val_categorical_accuracy: 0.9905
Epoch 15/100
9120/9280 [============================&gt;.] - ETA: 0s - loss: 0.0664 - categorical_accuracy: 0.9875
Epoch 00015: val_loss improved from 0.05886 to 0.05824, saving model to t_weights_0
9280/9280 [==============================] - 2s 229us/sample - loss: 0.0668 - categorical_accuracy: 0.9874 - val_loss: 0.0582 - val_categorical_accuracy: 0.9922
Epoch 16/100
9024/9280 [============================&gt;.] - ETA: 0s - loss: 0.0655 - categorical_accuracy: 0.9869
Epoch 00016: val_loss did not improve from 0.05824
9280/9280 [==============================] - 2s 221us/sample - loss: 0.0652 - categorical_accuracy: 0.9870 - val_loss: 0.0589 - val_categorical_accuracy: 0.9897
Epoch 17/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.0669 - categorical_accuracy: 0.9872
Epoch 00017: val_loss improved from 0.05824 to 0.04853, saving model to t_weights_0
9280/9280 [==============================] - 2s 231us/sample - loss: 0.0667 - categorical_accuracy: 0.9872 - val_loss: 0.0485 - val_categorical_accuracy: 0.9922
Epoch 18/100
9088/9280 [============================&gt;.] - ETA: 0s - loss: 0.0656 - categorical_accuracy: 0.9860
Epoch 00018: val_loss did not improve from 0.04853
9280/9280 [==============================] - 2s 223us/sample - loss: 0.0655 - categorical_accuracy: 0.9860 - val_loss: 0.0525 - val_categorical_accuracy: 0.9931
Epoch 19/100
9216/9280 [============================&gt;.] - ETA: 0s - loss: 0.0568 - categorical_accuracy: 0.9908
Epoch 00019: val_loss improved from 0.04853 to 0.04171, saving model to t_weights_0
9280/9280 [==============================] - 2s 232us/sample - loss: 0.0567 - categorical_accuracy: 0.9908 - val_loss: 0.0417 - val_categorical_accuracy: 0.9957
Epoch 20/100
9056/9280 [============================&gt;.] - ETA: 0s - loss: 0.0496 - categorical_accuracy: 0.9924
Epoch 00020: val_loss did not improve from 0.04171
9280/9280 [==============================] - 2s 227us/sample - loss: 0.0491 - categorical_accuracy: 0.9926 - val_loss: 0.0486 - val_categorical_accuracy: 0.9940
Epoch 21/100
9024/9280 [============================&gt;.] - ETA: 0s - loss: 0.0460 - categorical_accuracy: 0.9930
Epoch 00021: val_loss did not improve from 0.04171
9280/9280 [==============================] - 2s 216us/sample - loss: 0.0460 - categorical_accuracy: 0.9930 - val_loss: 0.0530 - val_categorical_accuracy: 0.9914
Epoch 22/100
9056/9280 [============================&gt;.] - ETA: 0s - loss: 0.0496 - categorical_accuracy: 0.9906
Epoch 00022: val_loss did not improve from 0.04171
9280/9280 [==============================] - 2s 205us/sample - loss: 0.0496 - categorical_accuracy: 0.9907 - val_loss: 0.0544 - val_categorical_accuracy: 0.9905
Epoch 23/100
9184/9280 [============================&gt;.] - ETA: 0s - loss: 0.0458 - categorical_accuracy: 0.9938
Epoch 00023: val_loss did not improve from 0.04171
9280/9280 [==============================] - 2s 222us/sample - loss: 0.0458 - categorical_accuracy: 0.9939 - val_loss: 0.0557 - val_categorical_accuracy: 0.9914
Epoch 24/100
9152/9280 [============================&gt;.] - ETA: 0s - loss: 0.0484 - categorical_accuracy: 0.9930
Epoch 00024: val_loss did not improve from 0.04171
9280/9280 [==============================] - 2s 223us/sample - loss: 0.0488 - categorical_accuracy: 0.9929 - val_loss: 0.0443 - val_categorical_accuracy: 0.9940
0.98706895 0.44869131699210635


nrx: 10 - real: 3 
Train on 16706 samples, validate on 2088 samples
Epoch 1/100
16576/16706 [============================&gt;.] - ETA: 0s - loss: 1.3241 - categorical_accuracy: 0.4751
Epoch 00001: val_loss improved from inf to 0.68948, saving model to t_weights_0
16706/16706 [==============================] - 4s 252us/sample - loss: 1.3189 - categorical_accuracy: 0.4773 - val_loss: 0.6895 - val_categorical_accuracy: 0.7189
Epoch 2/100
16608/16706 [============================&gt;.] - ETA: 0s - loss: 0.6761 - categorical_accuracy: 0.7264
Epoch 00002: val_loss improved from 0.68948 to 0.51835, saving model to t_weights_0
16706/16706 [==============================] - 4s 225us/sample - loss: 0.6757 - categorical_accuracy: 0.7266 - val_loss: 0.5184 - val_categorical_accuracy: 0.8132
Epoch 3/100
16608/16706 [============================&gt;.] - ETA: 0s - loss: 0.5003 - categorical_accuracy: 0.8215
Epoch 00003: val_loss improved from 0.51835 to 0.38530, saving model to t_weights_0
16706/16706 [==============================] - 4s 231us/sample - loss: 0.5003 - categorical_accuracy: 0.8216 - val_loss: 0.3853 - val_categorical_accuracy: 0.8846
Epoch 4/100
16512/16706 [============================&gt;.] - ETA: 0s - loss: 0.3633 - categorical_accuracy: 0.8861
Epoch 00004: val_loss improved from 0.38530 to 0.26650, saving model to t_weights_0
16706/16706 [==============================] - 4s 221us/sample - loss: 0.3622 - categorical_accuracy: 0.8866 - val_loss: 0.2665 - val_categorical_accuracy: 0.9282
Epoch 5/100
16608/16706 [============================&gt;.] - ETA: 0s - loss: 0.2738 - categorical_accuracy: 0.9174
Epoch 00005: val_loss improved from 0.26650 to 0.21669, saving model to t_weights_0
16706/16706 [==============================] - 4s 232us/sample - loss: 0.2735 - categorical_accuracy: 0.9176 - val_loss: 0.2167 - val_categorical_accuracy: 0.9401
Epoch 6/100
16544/16706 [============================&gt;.] - ETA: 0s - loss: 0.2241 - categorical_accuracy: 0.9356
Epoch 00006: val_loss improved from 0.21669 to 0.18251, saving model to t_weights_0
16706/16706 [==============================] - 4s 223us/sample - loss: 0.2236 - categorical_accuracy: 0.9358 - val_loss: 0.1825 - val_categorical_accuracy: 0.9473
Epoch 7/100
16544/16706 [============================&gt;.] - ETA: 0s - loss: 0.2016 - categorical_accuracy: 0.9414
Epoch 00007: val_loss improved from 0.18251 to 0.17122, saving model to t_weights_0
16706/16706 [==============================] - 4s 229us/sample - loss: 0.2017 - categorical_accuracy: 0.9413 - val_loss: 0.1712 - val_categorical_accuracy: 0.9492
Epoch 8/100
16544/16706 [============================&gt;.] - ETA: 0s - loss: 0.1777 - categorical_accuracy: 0.9510
Epoch 00008: val_loss improved from 0.17122 to 0.16504, saving model to t_weights_0
16706/16706 [==============================] - 4s 227us/sample - loss: 0.1776 - categorical_accuracy: 0.9510 - val_loss: 0.1650 - val_categorical_accuracy: 0.9511
Epoch 9/100
16544/16706 [============================&gt;.] - ETA: 0s - loss: 0.1625 - categorical_accuracy: 0.9548
Epoch 00009: val_loss improved from 0.16504 to 0.16039, saving model to t_weights_0
16706/16706 [==============================] - 4s 225us/sample - loss: 0.1629 - categorical_accuracy: 0.9547 - val_loss: 0.1604 - val_categorical_accuracy: 0.9535
Epoch 10/100
16512/16706 [============================&gt;.] - ETA: 0s - loss: 0.1551 - categorical_accuracy: 0.9571
Epoch 00010: val_loss improved from 0.16039 to 0.13706, saving model to t_weights_0
16706/16706 [==============================] - 4s 228us/sample - loss: 0.1546 - categorical_accuracy: 0.9573 - val_loss: 0.1371 - val_categorical_accuracy: 0.9598
Epoch 11/100
16640/16706 [============================&gt;.] - ETA: 0s - loss: 0.1410 - categorical_accuracy: 0.9631
Epoch 00011: val_loss improved from 0.13706 to 0.13522, saving model to t_weights_0
16706/16706 [==============================] - 4s 226us/sample - loss: 0.1412 - categorical_accuracy: 0.9630 - val_loss: 0.1352 - val_categorical_accuracy: 0.9631
Epoch 12/100
16576/16706 [============================&gt;.] - ETA: 0s - loss: 0.1325 - categorical_accuracy: 0.9657
Epoch 00012: val_loss did not improve from 0.13522
16706/16706 [==============================] - 4s 224us/sample - loss: 0.1324 - categorical_accuracy: 0.9657 - val_loss: 0.1357 - val_categorical_accuracy: 0.9617
Epoch 13/100
16576/16706 [============================&gt;.] - ETA: 0s - loss: 0.1313 - categorical_accuracy: 0.9644
Epoch 00013: val_loss did not improve from 0.13522
16706/16706 [==============================] - 4s 221us/sample - loss: 0.1307 - categorical_accuracy: 0.9647 - val_loss: 0.1874 - val_categorical_accuracy: 0.9373
Epoch 14/100
16480/16706 [============================&gt;.] - ETA: 0s - loss: 0.1262 - categorical_accuracy: 0.9667
Epoch 00014: val_loss did not improve from 0.13522
16706/16706 [==============================] - 3s 192us/sample - loss: 0.1261 - categorical_accuracy: 0.9667 - val_loss: 0.1436 - val_categorical_accuracy: 0.9588
Epoch 15/100
16608/16706 [============================&gt;.] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.9671
Epoch 00015: val_loss improved from 0.13522 to 0.13182, saving model to t_weights_0
16706/16706 [==============================] - 4s 219us/sample - loss: 0.1235 - categorical_accuracy: 0.9671 - val_loss: 0.1318 - val_categorical_accuracy: 0.9655
Epoch 16/100
16704/16706 [============================&gt;.] - ETA: 0s - loss: 0.1162 - categorical_accuracy: 0.9692
Epoch 00016: val_loss improved from 0.13182 to 0.12473, saving model to t_weights_0
16706/16706 [==============================] - 4s 229us/sample - loss: 0.1163 - categorical_accuracy: 0.9691 - val_loss: 0.1247 - val_categorical_accuracy: 0.9670
Epoch 17/100
16672/16706 [============================&gt;.] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.9677
Epoch 00017: val_loss did not improve from 0.12473
16706/16706 [==============================] - 4s 217us/sample - loss: 0.1198 - categorical_accuracy: 0.9678 - val_loss: 0.1324 - val_categorical_accuracy: 0.9636
Epoch 18/100
16704/16706 [============================&gt;.] - ETA: 0s - loss: 0.1019 - categorical_accuracy: 0.9736
Epoch 00018: val_loss did not improve from 0.12473
16706/16706 [==============================] - 4s 226us/sample - loss: 0.1018 - categorical_accuracy: 0.9736 - val_loss: 0.1395 - val_categorical_accuracy: 0.9622
Epoch 19/100
16512/16706 [============================&gt;.] - ETA: 0s - loss: 0.1022 - categorical_accuracy: 0.9743
Epoch 00019: val_loss did not improve from 0.12473
16706/16706 [==============================] - 4s 220us/sample - loss: 0.1023 - categorical_accuracy: 0.9742 - val_loss: 0.1324 - val_categorical_accuracy: 0.9670
Epoch 20/100
16576/16706 [============================&gt;.] - ETA: 0s - loss: 0.1034 - categorical_accuracy: 0.9739
Epoch 00020: val_loss did not improve from 0.12473
16706/16706 [==============================] - 4s 225us/sample - loss: 0.1030 - categorical_accuracy: 0.9740 - val_loss: 0.1352 - val_categorical_accuracy: 0.9660
Epoch 21/100
16640/16706 [============================&gt;.] - ETA: 0s - loss: 0.0962 - categorical_accuracy: 0.9758
Epoch 00021: val_loss did not improve from 0.12473
16706/16706 [==============================] - 4s 221us/sample - loss: 0.0964 - categorical_accuracy: 0.9758 - val_loss: 0.1587 - val_categorical_accuracy: 0.9593
0.9722222 0.5234732031574574


nrx: 15 - real: 3 
Train on 24682 samples, validate on 3085 samples
Epoch 1/100
24480/24682 [============================&gt;.] - ETA: 0s - loss: 1.2950 - categorical_accuracy: 0.4839
Epoch 00001: val_loss improved from inf to 0.73585, saving model to t_weights_0
24682/24682 [==============================] - 6s 242us/sample - loss: 1.2912 - categorical_accuracy: 0.4855 - val_loss: 0.7359 - val_categorical_accuracy: 0.7135
Epoch 2/100
24480/24682 [============================&gt;.] - ETA: 0s - loss: 0.7155 - categorical_accuracy: 0.7134
Epoch 00002: val_loss improved from 0.73585 to 0.46438, saving model to t_weights_0
24682/24682 [==============================] - 6s 223us/sample - loss: 0.7146 - categorical_accuracy: 0.7140 - val_loss: 0.4644 - val_categorical_accuracy: 0.8486
Epoch 3/100
24640/24682 [============================&gt;.] - ETA: 0s - loss: 0.4990 - categorical_accuracy: 0.8271
Epoch 00003: val_loss improved from 0.46438 to 0.33809, saving model to t_weights_0
24682/24682 [==============================] - 6s 224us/sample - loss: 0.4989 - categorical_accuracy: 0.8271 - val_loss: 0.3381 - val_categorical_accuracy: 0.8959
Epoch 4/100
24672/24682 [============================&gt;.] - ETA: 0s - loss: 0.3550 - categorical_accuracy: 0.8868
Epoch 00004: val_loss improved from 0.33809 to 0.24498, saving model to t_weights_0
24682/24682 [==============================] - 6s 223us/sample - loss: 0.3549 - categorical_accuracy: 0.8868 - val_loss: 0.2450 - val_categorical_accuracy: 0.9293
Epoch 5/100
24672/24682 [============================&gt;.] - ETA: 0s - loss: 0.2911 - categorical_accuracy: 0.9084
Epoch 00005: val_loss improved from 0.24498 to 0.23208, saving model to t_weights_0
24682/24682 [==============================] - 6s 225us/sample - loss: 0.2917 - categorical_accuracy: 0.9083 - val_loss: 0.2321 - val_categorical_accuracy: 0.9313
Epoch 6/100
24544/24682 [============================&gt;.] - ETA: 0s - loss: 0.2581 - categorical_accuracy: 0.9212
Epoch 00006: val_loss improved from 0.23208 to 0.21751, saving model to t_weights_0
24682/24682 [==============================] - 5s 218us/sample - loss: 0.2582 - categorical_accuracy: 0.9211 - val_loss: 0.2175 - val_categorical_accuracy: 0.9352
Epoch 7/100
24512/24682 [============================&gt;.] - ETA: 0s - loss: 0.2296 - categorical_accuracy: 0.9306
Epoch 00007: val_loss improved from 0.21751 to 0.20712, saving model to t_weights_0
24682/24682 [==============================] - 5s 219us/sample - loss: 0.2292 - categorical_accuracy: 0.9307 - val_loss: 0.2071 - val_categorical_accuracy: 0.9355
Epoch 8/100
24416/24682 [============================&gt;.] - ETA: 0s - loss: 0.2199 - categorical_accuracy: 0.9336
Epoch 00008: val_loss improved from 0.20712 to 0.18016, saving model to t_weights_0
24682/24682 [==============================] - 6s 223us/sample - loss: 0.2197 - categorical_accuracy: 0.9337 - val_loss: 0.1802 - val_categorical_accuracy: 0.9459
Epoch 9/100
24672/24682 [============================&gt;.] - ETA: 0s - loss: 0.2112 - categorical_accuracy: 0.9357
Epoch 00009: val_loss did not improve from 0.18016
24682/24682 [==============================] - 5s 221us/sample - loss: 0.2112 - categorical_accuracy: 0.9357 - val_loss: 0.1903 - val_categorical_accuracy: 0.9452
Epoch 10/100
24608/24682 [============================&gt;.] - ETA: 0s - loss: 0.1942 - categorical_accuracy: 0.9421
Epoch 00010: val_loss did not improve from 0.18016
24682/24682 [==============================] - 5s 222us/sample - loss: 0.1942 - categorical_accuracy: 0.9421 - val_loss: 0.2010 - val_categorical_accuracy: 0.9400
Epoch 11/100
24544/24682 [============================&gt;.] - ETA: 0s - loss: 0.1913 - categorical_accuracy: 0.9421
Epoch 00011: val_loss did not improve from 0.18016
24682/24682 [==============================] - 5s 222us/sample - loss: 0.1909 - categorical_accuracy: 0.9423 - val_loss: 0.1836 - val_categorical_accuracy: 0.9491
Epoch 12/100
24512/24682 [============================&gt;.] - ETA: 0s - loss: 0.1804 - categorical_accuracy: 0.9470
Epoch 00012: val_loss improved from 0.18016 to 0.17939, saving model to t_weights_0
24682/24682 [==============================] - 5s 223us/sample - loss: 0.1809 - categorical_accuracy: 0.9468 - val_loss: 0.1794 - val_categorical_accuracy: 0.9514
Epoch 13/100
24576/24682 [============================&gt;.] - ETA: 0s - loss: 0.1721 - categorical_accuracy: 0.9486
Epoch 00013: val_loss improved from 0.17939 to 0.17186, saving model to t_weights_0
24682/24682 [==============================] - 6s 227us/sample - loss: 0.1721 - categorical_accuracy: 0.9486 - val_loss: 0.1719 - val_categorical_accuracy: 0.9536
Epoch 14/100
24640/24682 [============================&gt;.] - ETA: 0s - loss: 0.1748 - categorical_accuracy: 0.9476
Epoch 00014: val_loss did not improve from 0.17186
24682/24682 [==============================] - 5s 222us/sample - loss: 0.1747 - categorical_accuracy: 0.9476 - val_loss: 0.1748 - val_categorical_accuracy: 0.9540
Epoch 15/100
24544/24682 [============================&gt;.] - ETA: 0s - loss: 0.1642 - categorical_accuracy: 0.9517
Epoch 00015: val_loss did not improve from 0.17186
24682/24682 [==============================] - 5s 221us/sample - loss: 0.1642 - categorical_accuracy: 0.9517 - val_loss: 0.1865 - val_categorical_accuracy: 0.9517
Epoch 16/100
24480/24682 [============================&gt;.] - ETA: 0s - loss: 0.1610 - categorical_accuracy: 0.9529
Epoch 00016: val_loss did not improve from 0.17186
24682/24682 [==============================] - 5s 218us/sample - loss: 0.1611 - categorical_accuracy: 0.9528 - val_loss: 0.1955 - val_categorical_accuracy: 0.9452
Epoch 17/100
24576/24682 [============================&gt;.] - ETA: 0s - loss: 0.1574 - categorical_accuracy: 0.9535
Epoch 00017: val_loss did not improve from 0.17186
24682/24682 [==============================] - 5s 217us/sample - loss: 0.1573 - categorical_accuracy: 0.9536 - val_loss: 0.1932 - val_categorical_accuracy: 0.9494
Epoch 18/100
24640/24682 [============================&gt;.] - ETA: 0s - loss: 0.1523 - categorical_accuracy: 0.9558
Epoch 00018: val_loss did not improve from 0.17186
24682/24682 [==============================] - 5s 214us/sample - loss: 0.1523 - categorical_accuracy: 0.9558 - val_loss: 0.1774 - val_categorical_accuracy: 0.9556
0.95170176 0.6456169505608641


nrx: 20 - real: 3 
Train on 32221 samples, validate on 4027 samples
Epoch 1/100
32096/32221 [============================&gt;.] - ETA: 0s - loss: 1.1568 - categorical_accuracy: 0.5272
Epoch 00001: val_loss improved from inf to 0.64784, saving model to t_weights_0
32221/32221 [==============================] - 8s 236us/sample - loss: 1.1554 - categorical_accuracy: 0.5276 - val_loss: 0.6478 - val_categorical_accuracy: 0.7358
Epoch 2/100
32128/32221 [============================&gt;.] - ETA: 0s - loss: 0.6117 - categorical_accuracy: 0.7576
Epoch 00002: val_loss improved from 0.64784 to 0.42925, saving model to t_weights_0
32221/32221 [==============================] - 7s 225us/sample - loss: 0.6115 - categorical_accuracy: 0.7578 - val_loss: 0.4293 - val_categorical_accuracy: 0.8339
Epoch 3/100
32032/32221 [============================&gt;.] - ETA: 0s - loss: 0.4457 - categorical_accuracy: 0.8438
Epoch 00003: val_loss improved from 0.42925 to 0.31584, saving model to t_weights_0
32221/32221 [==============================] - 7s 225us/sample - loss: 0.4462 - categorical_accuracy: 0.8435 - val_loss: 0.3158 - val_categorical_accuracy: 0.8994
Epoch 4/100
32128/32221 [============================&gt;.] - ETA: 0s - loss: 0.3583 - categorical_accuracy: 0.8839
Epoch 00004: val_loss improved from 0.31584 to 0.26051, saving model to t_weights_0
32221/32221 [==============================] - 7s 226us/sample - loss: 0.3581 - categorical_accuracy: 0.8840 - val_loss: 0.2605 - val_categorical_accuracy: 0.9163
Epoch 5/100
31904/32221 [============================&gt;.] - ETA: 0s - loss: 0.3057 - categorical_accuracy: 0.9052
Epoch 00005: val_loss improved from 0.26051 to 0.23046, saving model to t_weights_0
32221/32221 [==============================] - 7s 223us/sample - loss: 0.3057 - categorical_accuracy: 0.9053 - val_loss: 0.2305 - val_categorical_accuracy: 0.9280
Epoch 6/100
32032/32221 [============================&gt;.] - ETA: 0s - loss: 0.2620 - categorical_accuracy: 0.9190
Epoch 00006: val_loss improved from 0.23046 to 0.22717, saving model to t_weights_0
32221/32221 [==============================] - 7s 224us/sample - loss: 0.2623 - categorical_accuracy: 0.9190 - val_loss: 0.2272 - val_categorical_accuracy: 0.9262
Epoch 7/100
32032/32221 [============================&gt;.] - ETA: 0s - loss: 0.2381 - categorical_accuracy: 0.9274
Epoch 00007: val_loss improved from 0.22717 to 0.19020, saving model to t_weights_0
32221/32221 [==============================] - 7s 222us/sample - loss: 0.2377 - categorical_accuracy: 0.9276 - val_loss: 0.1902 - val_categorical_accuracy: 0.9419
Epoch 8/100
32192/32221 [============================&gt;.] - ETA: 0s - loss: 0.2216 - categorical_accuracy: 0.9324
Epoch 00008: val_loss did not improve from 0.19020
32221/32221 [==============================] - 7s 218us/sample - loss: 0.2216 - categorical_accuracy: 0.9324 - val_loss: 0.2022 - val_categorical_accuracy: 0.9374
Epoch 9/100
32032/32221 [============================&gt;.] - ETA: 0s - loss: 0.2068 - categorical_accuracy: 0.9380
Epoch 00009: val_loss improved from 0.19020 to 0.17961, saving model to t_weights_0
32221/32221 [==============================] - 7s 226us/sample - loss: 0.2072 - categorical_accuracy: 0.9379 - val_loss: 0.1796 - val_categorical_accuracy: 0.9444
Epoch 10/100
32032/32221 [============================&gt;.] - ETA: 0s - loss: 0.1987 - categorical_accuracy: 0.9406
Epoch 00010: val_loss improved from 0.17961 to 0.17690, saving model to t_weights_0
32221/32221 [==============================] - 7s 226us/sample - loss: 0.1986 - categorical_accuracy: 0.9406 - val_loss: 0.1769 - val_categorical_accuracy: 0.9481
Epoch 11/100
32064/32221 [============================&gt;.] - ETA: 0s - loss: 0.1877 - categorical_accuracy: 0.9448
Epoch 00011: val_loss improved from 0.17690 to 0.17660, saving model to t_weights_0
32221/32221 [==============================] - 7s 226us/sample - loss: 0.1876 - categorical_accuracy: 0.9448 - val_loss: 0.1766 - val_categorical_accuracy: 0.9488
Epoch 12/100
32000/32221 [============================&gt;.] - ETA: 0s - loss: 0.1755 - categorical_accuracy: 0.9486
Epoch 00012: val_loss did not improve from 0.17660
32221/32221 [==============================] - 7s 222us/sample - loss: 0.1755 - categorical_accuracy: 0.9486 - val_loss: 0.2139 - val_categorical_accuracy: 0.9392
Epoch 13/100
31968/32221 [============================&gt;.] - ETA: 0s - loss: 0.1711 - categorical_accuracy: 0.9510
Epoch 00013: val_loss improved from 0.17660 to 0.16706, saving model to t_weights_0
32221/32221 [==============================] - 7s 225us/sample - loss: 0.1710 - categorical_accuracy: 0.9510 - val_loss: 0.1671 - val_categorical_accuracy: 0.9536
Epoch 14/100
32192/32221 [============================&gt;.] - ETA: 0s - loss: 0.1634 - categorical_accuracy: 0.9522
Epoch 00014: val_loss did not improve from 0.16706
32221/32221 [==============================] - 7s 223us/sample - loss: 0.1633 - categorical_accuracy: 0.9522 - val_loss: 0.1924 - val_categorical_accuracy: 0.9399
Epoch 15/100
32000/32221 [============================&gt;.] - ETA: 0s - loss: 0.1621 - categorical_accuracy: 0.9538
Epoch 00015: val_loss did not improve from 0.16706
32221/32221 [==============================] - 7s 224us/sample - loss: 0.1624 - categorical_accuracy: 0.9537 - val_loss: 0.2021 - val_categorical_accuracy: 0.9392
Epoch 16/100
32096/32221 [============================&gt;.] - ETA: 0s - loss: 0.1571 - categorical_accuracy: 0.9556
Epoch 00016: val_loss improved from 0.16706 to 0.16635, saving model to t_weights_0
32221/32221 [==============================] - 7s 219us/sample - loss: 0.1568 - categorical_accuracy: 0.9557 - val_loss: 0.1663 - val_categorical_accuracy: 0.9551
Epoch 17/100
32160/32221 [============================&gt;.] - ETA: 0s - loss: 0.1507 - categorical_accuracy: 0.9567
Epoch 00017: val_loss improved from 0.16635 to 0.16086, saving model to t_weights_0
32221/32221 [==============================] - 7s 226us/sample - loss: 0.1506 - categorical_accuracy: 0.9567 - val_loss: 0.1609 - val_categorical_accuracy: 0.9546
Epoch 18/100
31968/32221 [============================&gt;.] - ETA: 0s - loss: 0.1467 - categorical_accuracy: 0.9581
Epoch 00018: val_loss improved from 0.16086 to 0.15311, saving model to t_weights_0
32221/32221 [==============================] - 7s 225us/sample - loss: 0.1468 - categorical_accuracy: 0.9581 - val_loss: 0.1531 - val_categorical_accuracy: 0.9560
Epoch 19/100
32000/32221 [============================&gt;.] - ETA: 0s - loss: 0.1458 - categorical_accuracy: 0.9587
Epoch 00019: val_loss did not improve from 0.15311
32221/32221 [==============================] - 7s 224us/sample - loss: 0.1459 - categorical_accuracy: 0.9587 - val_loss: 0.1791 - val_categorical_accuracy: 0.9508
Epoch 20/100
32128/32221 [============================&gt;.] - ETA: 0s - loss: 0.1387 - categorical_accuracy: 0.9610
Epoch 00020: val_loss did not improve from 0.15311
32221/32221 [==============================] - 7s 223us/sample - loss: 0.1387 - categorical_accuracy: 0.9610 - val_loss: 0.1593 - val_categorical_accuracy: 0.9563
Epoch 21/100
32128/32221 [============================&gt;.] - ETA: 0s - loss: 0.1355 - categorical_accuracy: 0.9625
Epoch 00021: val_loss did not improve from 0.15311
32221/32221 [==============================] - 7s 215us/sample - loss: 0.1357 - categorical_accuracy: 0.9624 - val_loss: 0.1614 - val_categorical_accuracy: 0.9578
Epoch 22/100
32064/32221 [============================&gt;.] - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.9634
Epoch 00022: val_loss did not improve from 0.15311
32221/32221 [==============================] - 7s 218us/sample - loss: 0.1328 - categorical_accuracy: 0.9633 - val_loss: 0.1784 - val_categorical_accuracy: 0.9483
Epoch 23/100
32000/32221 [============================&gt;.] - ETA: 0s - loss: 0.1304 - categorical_accuracy: 0.9646
Epoch 00023: val_loss did not improve from 0.15311
32221/32221 [==============================] - 7s 214us/sample - loss: 0.1301 - categorical_accuracy: 0.9647 - val_loss: 0.1617 - val_categorical_accuracy: 0.9578
0.9557984 0.7226838388034899


nrx: 25 - real: 3 
Train on 40221 samples, validate on 5027 samples
Epoch 1/100
40096/40221 [============================&gt;.] - ETA: 0s - loss: 1.0419 - categorical_accuracy: 0.5639
Epoch 00001: val_loss improved from inf to 0.59346, saving model to t_weights_0
40221/40221 [==============================] - 9s 230us/sample - loss: 1.0409 - categorical_accuracy: 0.5644 - val_loss: 0.5935 - val_categorical_accuracy: 0.7639
Epoch 2/100
40096/40221 [============================&gt;.] - ETA: 0s - loss: 0.5389 - categorical_accuracy: 0.7985
Epoch 00002: val_loss improved from 0.59346 to 0.35197, saving model to t_weights_0
40221/40221 [==============================] - 9s 226us/sample - loss: 0.5384 - categorical_accuracy: 0.7988 - val_loss: 0.3520 - val_categorical_accuracy: 0.8866
Epoch 3/100
40160/40221 [============================&gt;.] - ETA: 0s - loss: 0.3619 - categorical_accuracy: 0.8847
Epoch 00003: val_loss improved from 0.35197 to 0.28197, saving model to t_weights_0
40221/40221 [==============================] - 9s 226us/sample - loss: 0.3616 - categorical_accuracy: 0.8848 - val_loss: 0.2820 - val_categorical_accuracy: 0.9085
Epoch 4/100
40000/40221 [============================&gt;.] - ETA: 0s - loss: 0.2826 - categorical_accuracy: 0.9136
Epoch 00004: val_loss improved from 0.28197 to 0.21319, saving model to t_weights_0
40221/40221 [==============================] - 9s 227us/sample - loss: 0.2823 - categorical_accuracy: 0.9137 - val_loss: 0.2132 - val_categorical_accuracy: 0.9348
Epoch 5/100
40192/40221 [============================&gt;.] - ETA: 0s - loss: 0.2458 - categorical_accuracy: 0.9248
Epoch 00005: val_loss did not improve from 0.21319
40221/40221 [==============================] - 9s 225us/sample - loss: 0.2458 - categorical_accuracy: 0.9248 - val_loss: 0.2224 - val_categorical_accuracy: 0.9304
Epoch 6/100
40192/40221 [============================&gt;.] - ETA: 0s - loss: 0.2168 - categorical_accuracy: 0.9341
Epoch 00006: val_loss improved from 0.21319 to 0.20524, saving model to t_weights_0
40221/40221 [==============================] - 9s 226us/sample - loss: 0.2168 - categorical_accuracy: 0.9341 - val_loss: 0.2052 - val_categorical_accuracy: 0.9387
Epoch 7/100
40160/40221 [============================&gt;.] - ETA: 0s - loss: 0.2036 - categorical_accuracy: 0.9396
Epoch 00007: val_loss improved from 0.20524 to 0.18936, saving model to t_weights_0
40221/40221 [==============================] - 9s 219us/sample - loss: 0.2037 - categorical_accuracy: 0.9396 - val_loss: 0.1894 - val_categorical_accuracy: 0.9449
Epoch 8/100
40128/40221 [============================&gt;.] - ETA: 0s - loss: 0.1867 - categorical_accuracy: 0.9452
Epoch 00008: val_loss improved from 0.18936 to 0.18215, saving model to t_weights_0
40221/40221 [==============================] - 9s 220us/sample - loss: 0.1869 - categorical_accuracy: 0.9451 - val_loss: 0.1821 - val_categorical_accuracy: 0.9465
Epoch 9/100
39936/40221 [============================&gt;.] - ETA: 0s - loss: 0.1775 - categorical_accuracy: 0.9477
Epoch 00009: val_loss did not improve from 0.18215
40221/40221 [==============================] - 9s 224us/sample - loss: 0.1776 - categorical_accuracy: 0.9477 - val_loss: 0.1919 - val_categorical_accuracy: 0.9409
Epoch 10/100
40032/40221 [============================&gt;.] - ETA: 0s - loss: 0.1721 - categorical_accuracy: 0.9497
Epoch 00010: val_loss did not improve from 0.18215
40221/40221 [==============================] - 9s 227us/sample - loss: 0.1720 - categorical_accuracy: 0.9497 - val_loss: 0.1927 - val_categorical_accuracy: 0.9431
Epoch 11/100
39968/40221 [============================&gt;.] - ETA: 0s - loss: 0.1621 - categorical_accuracy: 0.9530
Epoch 00011: val_loss improved from 0.18215 to 0.16130, saving model to t_weights_0
40221/40221 [==============================] - 9s 226us/sample - loss: 0.1621 - categorical_accuracy: 0.9530 - val_loss: 0.1613 - val_categorical_accuracy: 0.9527
Epoch 12/100
40000/40221 [============================&gt;.] - ETA: 0s - loss: 0.1556 - categorical_accuracy: 0.9554
Epoch 00012: val_loss improved from 0.16130 to 0.15988, saving model to t_weights_0
40221/40221 [==============================] - 9s 226us/sample - loss: 0.1554 - categorical_accuracy: 0.9554 - val_loss: 0.1599 - val_categorical_accuracy: 0.9558
Epoch 13/100
39968/40221 [============================&gt;.] - ETA: 0s - loss: 0.1520 - categorical_accuracy: 0.9561
Epoch 00013: val_loss improved from 0.15988 to 0.15254, saving model to t_weights_0
40221/40221 [==============================] - 9s 227us/sample - loss: 0.1518 - categorical_accuracy: 0.9561 - val_loss: 0.1525 - val_categorical_accuracy: 0.9566
Epoch 14/100
39968/40221 [============================&gt;.] - ETA: 0s - loss: 0.1454 - categorical_accuracy: 0.9595
Epoch 00014: val_loss did not improve from 0.15254
40221/40221 [==============================] - 9s 227us/sample - loss: 0.1455 - categorical_accuracy: 0.9594 - val_loss: 0.1702 - val_categorical_accuracy: 0.9529
Epoch 15/100
39968/40221 [============================&gt;.] - ETA: 0s - loss: 0.1435 - categorical_accuracy: 0.9595
Epoch 00015: val_loss did not improve from 0.15254
40221/40221 [==============================] - 9s 217us/sample - loss: 0.1435 - categorical_accuracy: 0.9595 - val_loss: 0.1737 - val_categorical_accuracy: 0.9495
Epoch 16/100
40128/40221 [============================&gt;.] - ETA: 0s - loss: 0.1373 - categorical_accuracy: 0.9613
Epoch 00016: val_loss did not improve from 0.15254
40221/40221 [==============================] - 9s 226us/sample - loss: 0.1374 - categorical_accuracy: 0.9613 - val_loss: 0.1596 - val_categorical_accuracy: 0.9554
Epoch 17/100
40192/40221 [============================&gt;.] - ETA: 0s - loss: 0.1347 - categorical_accuracy: 0.9617
Epoch 00017: val_loss did not improve from 0.15254
40221/40221 [==============================] - 9s 228us/sample - loss: 0.1347 - categorical_accuracy: 0.9617 - val_loss: 0.1694 - val_categorical_accuracy: 0.9525
Epoch 18/100
40032/40221 [============================&gt;.] - ETA: 0s - loss: 0.1291 - categorical_accuracy: 0.9639
Epoch 00018: val_loss did not improve from 0.15254
40221/40221 [==============================] - 9s 212us/sample - loss: 0.1291 - categorical_accuracy: 0.9639 - val_loss: 0.1535 - val_categorical_accuracy: 0.9580
0.9546449 0.7449106771915247


nrx: 0 - real: 4 
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/samer/Documents/txid_framework/dataset_scripts/working/data_utilities.py:119: RuntimeWarning: invalid value encountered in true_divide
  cls_weights = np.max(stat,axis=0)/stat
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 1600 samples, validate on 200 samples
Epoch 1/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 2.2708 - categorical_accuracy: 0.1990
Epoch 00001: val_loss improved from inf to 2.13156, saving model to t_weights_0
1600/1600 [==============================] - 1s 490us/sample - loss: 2.2681 - categorical_accuracy: 0.2013 - val_loss: 2.1316 - val_categorical_accuracy: 0.2000
Epoch 2/100
1344/1600 [========================&gt;.....] - ETA: 0s - loss: 1.8939 - categorical_accuracy: 0.3490
Epoch 00002: val_loss improved from 2.13156 to 1.30188, saving model to t_weights_0
1600/1600 [==============================] - 0s 268us/sample - loss: 1.8358 - categorical_accuracy: 0.3694 - val_loss: 1.3019 - val_categorical_accuracy: 0.5300
Epoch 3/100
1440/1600 [==========================&gt;...] - ETA: 0s - loss: 1.1994 - categorical_accuracy: 0.5681
Epoch 00003: val_loss improved from 1.30188 to 0.67218, saving model to t_weights_0
1600/1600 [==============================] - 0s 276us/sample - loss: 1.1830 - categorical_accuracy: 0.5681 - val_loss: 0.6722 - val_categorical_accuracy: 0.7750
Epoch 4/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.7541 - categorical_accuracy: 0.7074
Epoch 00004: val_loss improved from 0.67218 to 0.39071, saving model to t_weights_0
1600/1600 [==============================] - 0s 241us/sample - loss: 0.7417 - categorical_accuracy: 0.7119 - val_loss: 0.3907 - val_categorical_accuracy: 0.8300
Epoch 5/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.5297 - categorical_accuracy: 0.7863
Epoch 00005: val_loss improved from 0.39071 to 0.27272, saving model to t_weights_0
1600/1600 [==============================] - 0s 253us/sample - loss: 0.5174 - categorical_accuracy: 0.7937 - val_loss: 0.2727 - val_categorical_accuracy: 0.9500
Epoch 6/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.3526 - categorical_accuracy: 0.8712
Epoch 00006: val_loss improved from 0.27272 to 0.16983, saving model to t_weights_0
1600/1600 [==============================] - 0s 267us/sample - loss: 0.3519 - categorical_accuracy: 0.8712 - val_loss: 0.1698 - val_categorical_accuracy: 0.9750
Epoch 7/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.2743 - categorical_accuracy: 0.9102
Epoch 00007: val_loss improved from 0.16983 to 0.15668, saving model to t_weights_0
1600/1600 [==============================] - 0s 233us/sample - loss: 0.2718 - categorical_accuracy: 0.9106 - val_loss: 0.1567 - val_categorical_accuracy: 0.9950
Epoch 8/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.2098 - categorical_accuracy: 0.9477
Epoch 00008: val_loss improved from 0.15668 to 0.07025, saving model to t_weights_0
1600/1600 [==============================] - 0s 288us/sample - loss: 0.2073 - categorical_accuracy: 0.9481 - val_loss: 0.0702 - val_categorical_accuracy: 1.0000
Epoch 9/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.1431 - categorical_accuracy: 0.9701
Epoch 00009: val_loss improved from 0.07025 to 0.04707, saving model to t_weights_0
1600/1600 [==============================] - 0s 282us/sample - loss: 0.1441 - categorical_accuracy: 0.9706 - val_loss: 0.0471 - val_categorical_accuracy: 1.0000
Epoch 10/100
1472/1600 [==========================&gt;...] - ETA: 0s - loss: 0.1133 - categorical_accuracy: 0.9776
Epoch 00010: val_loss improved from 0.04707 to 0.04161, saving model to t_weights_0
1600/1600 [==============================] - 0s 235us/sample - loss: 0.1181 - categorical_accuracy: 0.9731 - val_loss: 0.0416 - val_categorical_accuracy: 1.0000
Epoch 11/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0995 - categorical_accuracy: 0.9840
Epoch 00011: val_loss improved from 0.04161 to 0.02491, saving model to t_weights_0
1600/1600 [==============================] - 0s 261us/sample - loss: 0.1045 - categorical_accuracy: 0.9837 - val_loss: 0.0249 - val_categorical_accuracy: 1.0000
Epoch 12/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0858 - categorical_accuracy: 0.9827
Epoch 00012: val_loss did not improve from 0.02491
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0847 - categorical_accuracy: 0.9825 - val_loss: 0.0249 - val_categorical_accuracy: 1.0000
Epoch 13/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0757 - categorical_accuracy: 0.9860
Epoch 00013: val_loss improved from 0.02491 to 0.02052, saving model to t_weights_0
1600/1600 [==============================] - 0s 284us/sample - loss: 0.0747 - categorical_accuracy: 0.9862 - val_loss: 0.0205 - val_categorical_accuracy: 1.0000
Epoch 14/100
1536/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0648 - categorical_accuracy: 0.9902
Epoch 00014: val_loss did not improve from 0.02052
1600/1600 [==============================] - 0s 235us/sample - loss: 0.0652 - categorical_accuracy: 0.9900 - val_loss: 0.0210 - val_categorical_accuracy: 1.0000
Epoch 15/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0679 - categorical_accuracy: 0.9907
Epoch 00015: val_loss did not improve from 0.02052
1600/1600 [==============================] - 0s 239us/sample - loss: 0.0662 - categorical_accuracy: 0.9912 - val_loss: 0.0215 - val_categorical_accuracy: 1.0000
Epoch 16/100
1376/1600 [========================&gt;.....] - ETA: 0s - loss: 0.0658 - categorical_accuracy: 0.9891
Epoch 00016: val_loss improved from 0.02052 to 0.01855, saving model to t_weights_0
1600/1600 [==============================] - 0s 238us/sample - loss: 0.0617 - categorical_accuracy: 0.9900 - val_loss: 0.0185 - val_categorical_accuracy: 1.0000
Epoch 17/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0495 - categorical_accuracy: 0.9936
Epoch 00017: val_loss did not improve from 0.01855
1600/1600 [==============================] - 0s 216us/sample - loss: 0.0561 - categorical_accuracy: 0.9900 - val_loss: 0.0353 - val_categorical_accuracy: 0.9950
Epoch 18/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0533 - categorical_accuracy: 0.9887
Epoch 00018: val_loss improved from 0.01855 to 0.01642, saving model to t_weights_0
1600/1600 [==============================] - 0s 288us/sample - loss: 0.0526 - categorical_accuracy: 0.9887 - val_loss: 0.0164 - val_categorical_accuracy: 1.0000
Epoch 19/100
1568/1600 [============================&gt;.] - ETA: 0s - loss: 0.0502 - categorical_accuracy: 0.9904
Epoch 00019: val_loss did not improve from 0.01642
1600/1600 [==============================] - 0s 234us/sample - loss: 0.0508 - categorical_accuracy: 0.9900 - val_loss: 0.0275 - val_categorical_accuracy: 0.9950
Epoch 20/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0508 - categorical_accuracy: 0.9900
Epoch 00020: val_loss did not improve from 0.01642
1600/1600 [==============================] - 0s 243us/sample - loss: 0.0517 - categorical_accuracy: 0.9887 - val_loss: 0.0183 - val_categorical_accuracy: 1.0000
Epoch 21/100
1504/1600 [===========================&gt;..] - ETA: 0s - loss: 0.0423 - categorical_accuracy: 0.9960
Epoch 00021: val_loss did not improve from 0.01642
1600/1600 [==============================] - 0s 236us/sample - loss: 0.0418 - categorical_accuracy: 0.9956 - val_loss: 0.0491 - val_categorical_accuracy: 0.9850
Epoch 22/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0415 - categorical_accuracy: 0.9922
Epoch 00022: val_loss did not improve from 0.01642
1600/1600 [==============================] - 0s 217us/sample - loss: 0.0434 - categorical_accuracy: 0.9912 - val_loss: 0.0182 - val_categorical_accuracy: 1.0000
Epoch 23/100
1408/1600 [=========================&gt;....] - ETA: 0s - loss: 0.0363 - categorical_accuracy: 0.9957
Epoch 00023: val_loss did not improve from 0.01642
1600/1600 [==============================] - 0s 212us/sample - loss: 0.0348 - categorical_accuracy: 0.9962 - val_loss: 0.0193 - val_categorical_accuracy: 1.0000
0.985 0.3469387755102041


nrx: 5 - real: 4 
Train on 9416 samples, validate on 1177 samples
Epoch 1/100
9376/9416 [============================&gt;.] - ETA: 0s - loss: 1.6435 - categorical_accuracy: 0.3776
Epoch 00001: val_loss improved from inf to 0.92756, saving model to t_weights_0
9416/9416 [==============================] - 3s 281us/sample - loss: 1.6404 - categorical_accuracy: 0.3785 - val_loss: 0.9276 - val_categorical_accuracy: 0.6559
Epoch 2/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.8435 - categorical_accuracy: 0.6630
Epoch 00002: val_loss improved from 0.92756 to 0.62569, saving model to t_weights_0
9416/9416 [==============================] - 2s 231us/sample - loss: 0.8444 - categorical_accuracy: 0.6640 - val_loss: 0.6257 - val_categorical_accuracy: 0.7664
Epoch 3/100
9184/9416 [============================&gt;.] - ETA: 0s - loss: 0.6761 - categorical_accuracy: 0.7431
Epoch 00003: val_loss improved from 0.62569 to 0.51817, saving model to t_weights_0
9416/9416 [==============================] - 2s 234us/sample - loss: 0.6733 - categorical_accuracy: 0.7448 - val_loss: 0.5182 - val_categorical_accuracy: 0.7901
Epoch 4/100
9344/9416 [============================&gt;.] - ETA: 0s - loss: 0.5381 - categorical_accuracy: 0.8108
Epoch 00004: val_loss improved from 0.51817 to 0.42955, saving model to t_weights_0
9416/9416 [==============================] - 2s 234us/sample - loss: 0.5384 - categorical_accuracy: 0.8106 - val_loss: 0.4296 - val_categorical_accuracy: 0.8420
Epoch 5/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.4487 - categorical_accuracy: 0.8562
Epoch 00005: val_loss improved from 0.42955 to 0.32361, saving model to t_weights_0
9416/9416 [==============================] - 2s 234us/sample - loss: 0.4485 - categorical_accuracy: 0.8565 - val_loss: 0.3236 - val_categorical_accuracy: 0.8997
Epoch 6/100
9184/9416 [============================&gt;.] - ETA: 0s - loss: 0.3783 - categorical_accuracy: 0.8806
Epoch 00006: val_loss improved from 0.32361 to 0.27157, saving model to t_weights_0
9416/9416 [==============================] - 2s 218us/sample - loss: 0.3777 - categorical_accuracy: 0.8805 - val_loss: 0.2716 - val_categorical_accuracy: 0.9176
Epoch 7/100
9408/9416 [============================&gt;.] - ETA: 0s - loss: 0.3239 - categorical_accuracy: 0.9008
Epoch 00007: val_loss improved from 0.27157 to 0.25594, saving model to t_weights_0
9416/9416 [==============================] - 2s 217us/sample - loss: 0.3236 - categorical_accuracy: 0.9009 - val_loss: 0.2559 - val_categorical_accuracy: 0.9201
Epoch 8/100
9376/9416 [============================&gt;.] - ETA: 0s - loss: 0.2900 - categorical_accuracy: 0.9125
Epoch 00008: val_loss improved from 0.25594 to 0.22414, saving model to t_weights_0
9416/9416 [==============================] - 2s 235us/sample - loss: 0.2908 - categorical_accuracy: 0.9125 - val_loss: 0.2241 - val_categorical_accuracy: 0.9278
Epoch 9/100
9344/9416 [============================&gt;.] - ETA: 0s - loss: 0.2668 - categorical_accuracy: 0.9192
Epoch 00009: val_loss improved from 0.22414 to 0.22007, saving model to t_weights_0
9416/9416 [==============================] - 2s 234us/sample - loss: 0.2660 - categorical_accuracy: 0.9195 - val_loss: 0.2201 - val_categorical_accuracy: 0.9312
Epoch 10/100
9408/9416 [============================&gt;.] - ETA: 0s - loss: 0.2416 - categorical_accuracy: 0.9281
Epoch 00010: val_loss improved from 0.22007 to 0.21276, saving model to t_weights_0
9416/9416 [==============================] - 2s 237us/sample - loss: 0.2414 - categorical_accuracy: 0.9282 - val_loss: 0.2128 - val_categorical_accuracy: 0.9354
Epoch 11/100
9376/9416 [============================&gt;.] - ETA: 0s - loss: 0.2273 - categorical_accuracy: 0.9321
Epoch 00011: val_loss did not improve from 0.21276
9416/9416 [==============================] - 2s 226us/sample - loss: 0.2269 - categorical_accuracy: 0.9322 - val_loss: 0.2135 - val_categorical_accuracy: 0.9337
Epoch 12/100
9312/9416 [============================&gt;.] - ETA: 0s - loss: 0.2141 - categorical_accuracy: 0.9359
Epoch 00012: val_loss improved from 0.21276 to 0.20361, saving model to t_weights_0
9416/9416 [==============================] - 2s 230us/sample - loss: 0.2142 - categorical_accuracy: 0.9361 - val_loss: 0.2036 - val_categorical_accuracy: 0.9371
Epoch 13/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.1961 - categorical_accuracy: 0.9398
Epoch 00013: val_loss improved from 0.20361 to 0.19642, saving model to t_weights_0
9416/9416 [==============================] - 2s 231us/sample - loss: 0.1953 - categorical_accuracy: 0.9403 - val_loss: 0.1964 - val_categorical_accuracy: 0.9431
Epoch 14/100
9344/9416 [============================&gt;.] - ETA: 0s - loss: 0.1851 - categorical_accuracy: 0.9427
Epoch 00014: val_loss improved from 0.19642 to 0.18303, saving model to t_weights_0
9416/9416 [==============================] - 2s 236us/sample - loss: 0.1849 - categorical_accuracy: 0.9428 - val_loss: 0.1830 - val_categorical_accuracy: 0.9473
Epoch 15/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.1835 - categorical_accuracy: 0.9462
Epoch 00015: val_loss did not improve from 0.18303
9416/9416 [==============================] - 2s 226us/sample - loss: 0.1839 - categorical_accuracy: 0.9458 - val_loss: 0.1896 - val_categorical_accuracy: 0.9431
Epoch 16/100
9376/9416 [============================&gt;.] - ETA: 0s - loss: 0.1717 - categorical_accuracy: 0.9507
Epoch 00016: val_loss improved from 0.18303 to 0.18146, saving model to t_weights_0
9416/9416 [==============================] - 2s 235us/sample - loss: 0.1715 - categorical_accuracy: 0.9507 - val_loss: 0.1815 - val_categorical_accuracy: 0.9482
Epoch 17/100
9344/9416 [============================&gt;.] - ETA: 0s - loss: 0.1623 - categorical_accuracy: 0.9541
Epoch 00017: val_loss did not improve from 0.18146
9416/9416 [==============================] - 2s 226us/sample - loss: 0.1627 - categorical_accuracy: 0.9540 - val_loss: 0.1991 - val_categorical_accuracy: 0.9439
Epoch 18/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.1582 - categorical_accuracy: 0.9548
Epoch 00018: val_loss improved from 0.18146 to 0.17120, saving model to t_weights_0
9416/9416 [==============================] - 2s 234us/sample - loss: 0.1584 - categorical_accuracy: 0.9547 - val_loss: 0.1712 - val_categorical_accuracy: 0.9533
Epoch 19/100
9344/9416 [============================&gt;.] - ETA: 0s - loss: 0.1572 - categorical_accuracy: 0.9548
Epoch 00019: val_loss did not improve from 0.17120
9416/9416 [==============================] - 2s 231us/sample - loss: 0.1576 - categorical_accuracy: 0.9548 - val_loss: 0.2057 - val_categorical_accuracy: 0.9490
Epoch 20/100
9184/9416 [============================&gt;.] - ETA: 0s - loss: 0.1430 - categorical_accuracy: 0.9606
Epoch 00020: val_loss did not improve from 0.17120
9416/9416 [==============================] - 2s 222us/sample - loss: 0.1441 - categorical_accuracy: 0.9602 - val_loss: 0.1937 - val_categorical_accuracy: 0.9473
Epoch 21/100
9248/9416 [============================&gt;.] - ETA: 0s - loss: 0.1460 - categorical_accuracy: 0.9569
Epoch 00021: val_loss did not improve from 0.17120
9416/9416 [==============================] - 2s 226us/sample - loss: 0.1465 - categorical_accuracy: 0.9565 - val_loss: 0.2066 - val_categorical_accuracy: 0.9516
Epoch 22/100
9216/9416 [============================&gt;.] - ETA: 0s - loss: 0.1428 - categorical_accuracy: 0.9590
Epoch 00022: val_loss did not improve from 0.17120
9416/9416 [==============================] - 2s 226us/sample - loss: 0.1431 - categorical_accuracy: 0.9589 - val_loss: 0.2119 - val_categorical_accuracy: 0.9473
Epoch 23/100
9376/9416 [============================&gt;.] - ETA: 0s - loss: 0.1315 - categorical_accuracy: 0.9629
Epoch 00023: val_loss did not improve from 0.17120
9416/9416 [==============================] - 2s 227us/sample - loss: 0.1315 - categorical_accuracy: 0.9629 - val_loss: 0.2084 - val_categorical_accuracy: 0.9473
0.9413764 0.5313265306122449


nrx: 10 - real: 4 
Train on 17256 samples, validate on 2157 samples
Epoch 1/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 1.4896 - categorical_accuracy: 0.4210
Epoch 00001: val_loss improved from inf to 0.81871, saving model to t_weights_0
17256/17256 [==============================] - 4s 250us/sample - loss: 1.4884 - categorical_accuracy: 0.4215 - val_loss: 0.8187 - val_categorical_accuracy: 0.6931
Epoch 2/100
17152/17256 [============================&gt;.] - ETA: 0s - loss: 0.7709 - categorical_accuracy: 0.7071
Epoch 00002: val_loss improved from 0.81871 to 0.57243, saving model to t_weights_0
17256/17256 [==============================] - 4s 229us/sample - loss: 0.7704 - categorical_accuracy: 0.7075 - val_loss: 0.5724 - val_categorical_accuracy: 0.8081
Epoch 3/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.5556 - categorical_accuracy: 0.8051
Epoch 00003: val_loss improved from 0.57243 to 0.42117, saving model to t_weights_0
17256/17256 [==============================] - 4s 228us/sample - loss: 0.5549 - categorical_accuracy: 0.8054 - val_loss: 0.4212 - val_categorical_accuracy: 0.8618
Epoch 4/100
17088/17256 [============================&gt;.] - ETA: 0s - loss: 0.4390 - categorical_accuracy: 0.8578
Epoch 00004: val_loss improved from 0.42117 to 0.34273, saving model to t_weights_0
17256/17256 [==============================] - 4s 234us/sample - loss: 0.4378 - categorical_accuracy: 0.8583 - val_loss: 0.3427 - val_categorical_accuracy: 0.8911
Epoch 5/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.3690 - categorical_accuracy: 0.8806
Epoch 00005: val_loss improved from 0.34273 to 0.32714, saving model to t_weights_0
17256/17256 [==============================] - 4s 224us/sample - loss: 0.3689 - categorical_accuracy: 0.8806 - val_loss: 0.3271 - val_categorical_accuracy: 0.8846
Epoch 6/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 0.3318 - categorical_accuracy: 0.8936
Epoch 00006: val_loss improved from 0.32714 to 0.30711, saving model to t_weights_0
17256/17256 [==============================] - 4s 218us/sample - loss: 0.3317 - categorical_accuracy: 0.8936 - val_loss: 0.3071 - val_categorical_accuracy: 0.8915
Epoch 7/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.3025 - categorical_accuracy: 0.9044
Epoch 00007: val_loss improved from 0.30711 to 0.27981, saving model to t_weights_0
17256/17256 [==============================] - 4s 231us/sample - loss: 0.3022 - categorical_accuracy: 0.9045 - val_loss: 0.2798 - val_categorical_accuracy: 0.9045
Epoch 8/100
17152/17256 [============================&gt;.] - ETA: 0s - loss: 0.2790 - categorical_accuracy: 0.9113
Epoch 00008: val_loss did not improve from 0.27981
17256/17256 [==============================] - 4s 224us/sample - loss: 0.2785 - categorical_accuracy: 0.9114 - val_loss: 0.2922 - val_categorical_accuracy: 0.9059
Epoch 9/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 0.2639 - categorical_accuracy: 0.9152
Epoch 00009: val_loss did not improve from 0.27981
17256/17256 [==============================] - 4s 227us/sample - loss: 0.2640 - categorical_accuracy: 0.9151 - val_loss: 0.3096 - val_categorical_accuracy: 0.8943
Epoch 10/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.2496 - categorical_accuracy: 0.9203
Epoch 00010: val_loss improved from 0.27981 to 0.23914, saving model to t_weights_0
17256/17256 [==============================] - 4s 229us/sample - loss: 0.2493 - categorical_accuracy: 0.9204 - val_loss: 0.2391 - val_categorical_accuracy: 0.9254
Epoch 11/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.2317 - categorical_accuracy: 0.9250
Epoch 00011: val_loss did not improve from 0.23914
17256/17256 [==============================] - 4s 223us/sample - loss: 0.2314 - categorical_accuracy: 0.9251 - val_loss: 0.2403 - val_categorical_accuracy: 0.9230
Epoch 12/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.2227 - categorical_accuracy: 0.9297
Epoch 00012: val_loss improved from 0.23914 to 0.22975, saving model to t_weights_0
17256/17256 [==============================] - 4s 230us/sample - loss: 0.2229 - categorical_accuracy: 0.9296 - val_loss: 0.2298 - val_categorical_accuracy: 0.9286
Epoch 13/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.2151 - categorical_accuracy: 0.9324
Epoch 00013: val_loss improved from 0.22975 to 0.21535, saving model to t_weights_0
17256/17256 [==============================] - 4s 225us/sample - loss: 0.2149 - categorical_accuracy: 0.9324 - val_loss: 0.2154 - val_categorical_accuracy: 0.9351
Epoch 14/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.2051 - categorical_accuracy: 0.9372
Epoch 00014: val_loss improved from 0.21535 to 0.20853, saving model to t_weights_0
17256/17256 [==============================] - 4s 230us/sample - loss: 0.2049 - categorical_accuracy: 0.9372 - val_loss: 0.2085 - val_categorical_accuracy: 0.9332
Epoch 15/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 0.1966 - categorical_accuracy: 0.9382
Epoch 00015: val_loss did not improve from 0.20853
17256/17256 [==============================] - 4s 224us/sample - loss: 0.1967 - categorical_accuracy: 0.9382 - val_loss: 0.2412 - val_categorical_accuracy: 0.9263
Epoch 16/100
17056/17256 [============================&gt;.] - ETA: 0s - loss: 0.1989 - categorical_accuracy: 0.9373
Epoch 00016: val_loss did not improve from 0.20853
17256/17256 [==============================] - 4s 224us/sample - loss: 0.1990 - categorical_accuracy: 0.9374 - val_loss: 0.2517 - val_categorical_accuracy: 0.9156
Epoch 17/100
17216/17256 [============================&gt;.] - ETA: 0s - loss: 0.1891 - categorical_accuracy: 0.9398
Epoch 00017: val_loss did not improve from 0.20853
17256/17256 [==============================] - 4s 226us/sample - loss: 0.1890 - categorical_accuracy: 0.9398 - val_loss: 0.2228 - val_categorical_accuracy: 0.9337
Epoch 18/100
17184/17256 [============================&gt;.] - ETA: 0s - loss: 0.1819 - categorical_accuracy: 0.9440
Epoch 00018: val_loss did not improve from 0.20853
17256/17256 [==============================] - 4s 223us/sample - loss: 0.1820 - categorical_accuracy: 0.9441 - val_loss: 0.2248 - val_categorical_accuracy: 0.9286
Epoch 19/100
17152/17256 [============================&gt;.] - ETA: 0s - loss: 0.1878 - categorical_accuracy: 0.9415
Epoch 00019: val_loss improved from 0.20853 to 0.20765, saving model to t_weights_0
17256/17256 [==============================] - 4s 231us/sample - loss: 0.1874 - categorical_accuracy: 0.9416 - val_loss: 0.2076 - val_categorical_accuracy: 0.9383
Epoch 20/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.1740 - categorical_accuracy: 0.9474
Epoch 00020: val_loss did not improve from 0.20765
17256/17256 [==============================] - 4s 223us/sample - loss: 0.1736 - categorical_accuracy: 0.9476 - val_loss: 0.2148 - val_categorical_accuracy: 0.9388
Epoch 21/100
17088/17256 [============================&gt;.] - ETA: 0s - loss: 0.1659 - categorical_accuracy: 0.9489
Epoch 00021: val_loss did not improve from 0.20765
17256/17256 [==============================] - 4s 222us/sample - loss: 0.1655 - categorical_accuracy: 0.9490 - val_loss: 0.2120 - val_categorical_accuracy: 0.9416
Epoch 22/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.1676 - categorical_accuracy: 0.9480
Epoch 00022: val_loss did not improve from 0.20765
17256/17256 [==============================] - 4s 217us/sample - loss: 0.1669 - categorical_accuracy: 0.9483 - val_loss: 0.2133 - val_categorical_accuracy: 0.9388
Epoch 23/100
17248/17256 [============================&gt;.] - ETA: 0s - loss: 0.1589 - categorical_accuracy: 0.9522
Epoch 00023: val_loss did not improve from 0.20765
17256/17256 [==============================] - 4s 225us/sample - loss: 0.1589 - categorical_accuracy: 0.9522 - val_loss: 0.2187 - val_categorical_accuracy: 0.9379
Epoch 24/100
17120/17256 [============================&gt;.] - ETA: 0s - loss: 0.1545 - categorical_accuracy: 0.9527
Epoch 00024: val_loss did not improve from 0.20765
17256/17256 [==============================] - 4s 206us/sample - loss: 0.1543 - categorical_accuracy: 0.9527 - val_loss: 0.2213 - val_categorical_accuracy: 0.9374
0.9355586 0.6729591836734694


nrx: 15 - real: 4 
Train on 25096 samples, validate on 3137 samples
Epoch 1/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 1.2873 - categorical_accuracy: 0.4856
Epoch 00001: val_loss improved from inf to 0.73893, saving model to t_weights_0
25096/25096 [==============================] - 6s 242us/sample - loss: 1.2853 - categorical_accuracy: 0.4860 - val_loss: 0.7389 - val_categorical_accuracy: 0.7042
Epoch 2/100
25088/25096 [============================&gt;.] - ETA: 0s - loss: 0.6615 - categorical_accuracy: 0.7427
Epoch 00002: val_loss improved from 0.73893 to 0.47277, saving model to t_weights_0
25096/25096 [==============================] - 6s 226us/sample - loss: 0.6614 - categorical_accuracy: 0.7427 - val_loss: 0.4728 - val_categorical_accuracy: 0.8521
Epoch 3/100
25056/25096 [============================&gt;.] - ETA: 0s - loss: 0.4529 - categorical_accuracy: 0.8491
Epoch 00003: val_loss improved from 0.47277 to 0.34003, saving model to t_weights_0
25096/25096 [==============================] - 6s 228us/sample - loss: 0.4530 - categorical_accuracy: 0.8491 - val_loss: 0.3400 - val_categorical_accuracy: 0.8884
Epoch 4/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.3475 - categorical_accuracy: 0.8917
Epoch 00004: val_loss improved from 0.34003 to 0.28334, saving model to t_weights_0
25096/25096 [==============================] - 6s 230us/sample - loss: 0.3476 - categorical_accuracy: 0.8917 - val_loss: 0.2833 - val_categorical_accuracy: 0.9063
Epoch 5/100
25056/25096 [============================&gt;.] - ETA: 0s - loss: 0.2976 - categorical_accuracy: 0.9083
Epoch 00005: val_loss improved from 0.28334 to 0.24852, saving model to t_weights_0
25096/25096 [==============================] - 6s 224us/sample - loss: 0.2977 - categorical_accuracy: 0.9082 - val_loss: 0.2485 - val_categorical_accuracy: 0.9200
Epoch 6/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.2668 - categorical_accuracy: 0.9179
Epoch 00006: val_loss improved from 0.24852 to 0.24001, saving model to t_weights_0
25096/25096 [==============================] - 6s 229us/sample - loss: 0.2669 - categorical_accuracy: 0.9178 - val_loss: 0.2400 - val_categorical_accuracy: 0.9273
Epoch 7/100
25056/25096 [============================&gt;.] - ETA: 0s - loss: 0.2432 - categorical_accuracy: 0.9254
Epoch 00007: val_loss improved from 0.24001 to 0.20988, saving model to t_weights_0
25096/25096 [==============================] - 6s 229us/sample - loss: 0.2430 - categorical_accuracy: 0.9254 - val_loss: 0.2099 - val_categorical_accuracy: 0.9366
Epoch 8/100
24864/25096 [============================&gt;.] - ETA: 0s - loss: 0.2267 - categorical_accuracy: 0.9299
Epoch 00008: val_loss improved from 0.20988 to 0.20638, saving model to t_weights_0
25096/25096 [==============================] - 6s 224us/sample - loss: 0.2269 - categorical_accuracy: 0.9299 - val_loss: 0.2064 - val_categorical_accuracy: 0.9366
Epoch 9/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.2126 - categorical_accuracy: 0.9347
Epoch 00009: val_loss did not improve from 0.20638
25096/25096 [==============================] - 5s 218us/sample - loss: 0.2127 - categorical_accuracy: 0.9347 - val_loss: 0.2128 - val_categorical_accuracy: 0.9378
Epoch 10/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.2026 - categorical_accuracy: 0.9376
Epoch 00010: val_loss improved from 0.20638 to 0.20079, saving model to t_weights_0
25096/25096 [==============================] - 6s 230us/sample - loss: 0.2024 - categorical_accuracy: 0.9376 - val_loss: 0.2008 - val_categorical_accuracy: 0.9388
Epoch 11/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.1920 - categorical_accuracy: 0.9419
Epoch 00011: val_loss did not improve from 0.20079
25096/25096 [==============================] - 6s 224us/sample - loss: 0.1918 - categorical_accuracy: 0.9421 - val_loss: 0.2031 - val_categorical_accuracy: 0.9420
Epoch 12/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.1842 - categorical_accuracy: 0.9443
Epoch 00012: val_loss improved from 0.20079 to 0.20018, saving model to t_weights_0
25096/25096 [==============================] - 6s 228us/sample - loss: 0.1840 - categorical_accuracy: 0.9443 - val_loss: 0.2002 - val_categorical_accuracy: 0.9417
Epoch 13/100
25088/25096 [============================&gt;.] - ETA: 0s - loss: 0.1805 - categorical_accuracy: 0.9461
Epoch 00013: val_loss improved from 0.20018 to 0.18470, saving model to t_weights_0
25096/25096 [==============================] - 6s 230us/sample - loss: 0.1804 - categorical_accuracy: 0.9462 - val_loss: 0.1847 - val_categorical_accuracy: 0.9442
Epoch 14/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.1750 - categorical_accuracy: 0.9485
Epoch 00014: val_loss did not improve from 0.18470
25096/25096 [==============================] - 6s 223us/sample - loss: 0.1748 - categorical_accuracy: 0.9486 - val_loss: 0.1893 - val_categorical_accuracy: 0.9455
Epoch 15/100
25056/25096 [============================&gt;.] - ETA: 0s - loss: 0.1654 - categorical_accuracy: 0.9497
Epoch 00015: val_loss did not improve from 0.18470
25096/25096 [==============================] - 6s 228us/sample - loss: 0.1652 - categorical_accuracy: 0.9497 - val_loss: 0.1915 - val_categorical_accuracy: 0.9474
Epoch 16/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.1627 - categorical_accuracy: 0.9522
Epoch 00016: val_loss did not improve from 0.18470
25096/25096 [==============================] - 6s 224us/sample - loss: 0.1626 - categorical_accuracy: 0.9522 - val_loss: 0.1917 - val_categorical_accuracy: 0.9433
Epoch 17/100
24928/25096 [============================&gt;.] - ETA: 0s - loss: 0.1617 - categorical_accuracy: 0.9513
Epoch 00017: val_loss improved from 0.18470 to 0.17889, saving model to t_weights_0
25096/25096 [==============================] - 6s 228us/sample - loss: 0.1616 - categorical_accuracy: 0.9515 - val_loss: 0.1789 - val_categorical_accuracy: 0.9493
Epoch 18/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.1551 - categorical_accuracy: 0.9545
Epoch 00018: val_loss did not improve from 0.17889
25096/25096 [==============================] - 6s 228us/sample - loss: 0.1553 - categorical_accuracy: 0.9545 - val_loss: 0.2126 - val_categorical_accuracy: 0.9385
Epoch 19/100
24960/25096 [============================&gt;.] - ETA: 0s - loss: 0.1496 - categorical_accuracy: 0.9560
Epoch 00019: val_loss did not improve from 0.17889
25096/25096 [==============================] - 6s 224us/sample - loss: 0.1495 - categorical_accuracy: 0.9560 - val_loss: 0.1792 - val_categorical_accuracy: 0.9509
Epoch 20/100
25088/25096 [============================&gt;.] - ETA: 0s - loss: 0.1459 - categorical_accuracy: 0.9585
Epoch 00020: val_loss did not improve from 0.17889
25096/25096 [==============================] - 6s 220us/sample - loss: 0.1460 - categorical_accuracy: 0.9585 - val_loss: 0.1833 - val_categorical_accuracy: 0.9484
Epoch 21/100
25024/25096 [============================&gt;.] - ETA: 0s - loss: 0.1407 - categorical_accuracy: 0.9593
Epoch 00021: val_loss did not improve from 0.17889
25096/25096 [==============================] - 6s 222us/sample - loss: 0.1406 - categorical_accuracy: 0.9593 - val_loss: 0.2040 - val_categorical_accuracy: 0.9417
Epoch 22/100
24992/25096 [============================&gt;.] - ETA: 0s - loss: 0.1397 - categorical_accuracy: 0.9603
Epoch 00022: val_loss did not improve from 0.17889
25096/25096 [==============================] - 6s 226us/sample - loss: 0.1397 - categorical_accuracy: 0.9603 - val_loss: 0.1877 - val_categorical_accuracy: 0.9519
0.9563277 0.7221428571428572


nrx: 20 - real: 4 
Train on 32682 samples, validate on 4085 samples
Epoch 1/100
32512/32682 [============================&gt;.] - ETA: 0s - loss: 1.2064 - categorical_accuracy: 0.5050
Epoch 00001: val_loss improved from inf to 0.71626, saving model to t_weights_0
32682/32682 [==============================] - 8s 234us/sample - loss: 1.2046 - categorical_accuracy: 0.5060 - val_loss: 0.7163 - val_categorical_accuracy: 0.6891
Epoch 2/100
32640/32682 [============================&gt;.] - ETA: 0s - loss: 0.6613 - categorical_accuracy: 0.7263
Epoch 00002: val_loss improved from 0.71626 to 0.46251, saving model to t_weights_0
32682/32682 [==============================] - 7s 223us/sample - loss: 0.6612 - categorical_accuracy: 0.7265 - val_loss: 0.4625 - val_categorical_accuracy: 0.8328
Epoch 3/100
32640/32682 [============================&gt;.] - ETA: 0s - loss: 0.4561 - categorical_accuracy: 0.8340
Epoch 00003: val_loss improved from 0.46251 to 0.30893, saving model to t_weights_0
32682/32682 [==============================] - 7s 224us/sample - loss: 0.4562 - categorical_accuracy: 0.8340 - val_loss: 0.3089 - val_categorical_accuracy: 0.9072
Epoch 4/100
32448/32682 [============================&gt;.] - ETA: 0s - loss: 0.3325 - categorical_accuracy: 0.8925
Epoch 00004: val_loss improved from 0.30893 to 0.30036, saving model to t_weights_0
32682/32682 [==============================] - 7s 224us/sample - loss: 0.3323 - categorical_accuracy: 0.8926 - val_loss: 0.3004 - val_categorical_accuracy: 0.8952
Epoch 5/100
32640/32682 [============================&gt;.] - ETA: 0s - loss: 0.2767 - categorical_accuracy: 0.9137
Epoch 00005: val_loss improved from 0.30036 to 0.21714, saving model to t_weights_0
32682/32682 [==============================] - 7s 222us/sample - loss: 0.2767 - categorical_accuracy: 0.9137 - val_loss: 0.2171 - val_categorical_accuracy: 0.9366
Epoch 6/100
32672/32682 [============================&gt;.] - ETA: 0s - loss: 0.2454 - categorical_accuracy: 0.9241
Epoch 00006: val_loss improved from 0.21714 to 0.21218, saving model to t_weights_0
32682/32682 [==============================] - 7s 218us/sample - loss: 0.2454 - categorical_accuracy: 0.9241 - val_loss: 0.2122 - val_categorical_accuracy: 0.9334
Epoch 7/100
32672/32682 [============================&gt;.] - ETA: 0s - loss: 0.2243 - categorical_accuracy: 0.9320
Epoch 00007: val_loss improved from 0.21218 to 0.19208, saving model to t_weights_0
32682/32682 [==============================] - 7s 223us/sample - loss: 0.2243 - categorical_accuracy: 0.9320 - val_loss: 0.1921 - val_categorical_accuracy: 0.9432
Epoch 8/100
32576/32682 [============================&gt;.] - ETA: 0s - loss: 0.2077 - categorical_accuracy: 0.9381
Epoch 00008: val_loss did not improve from 0.19208
32682/32682 [==============================] - 7s 222us/sample - loss: 0.2078 - categorical_accuracy: 0.9381 - val_loss: 0.2011 - val_categorical_accuracy: 0.9378
Epoch 9/100
32672/32682 [============================&gt;.] - ETA: 0s - loss: 0.1998 - categorical_accuracy: 0.9388
Epoch 00009: val_loss did not improve from 0.19208
32682/32682 [==============================] - 7s 223us/sample - loss: 0.1998 - categorical_accuracy: 0.9388 - val_loss: 0.1994 - val_categorical_accuracy: 0.9415
Epoch 10/100
32640/32682 [============================&gt;.] - ETA: 0s - loss: 0.1926 - categorical_accuracy: 0.9411
Epoch 00010: val_loss did not improve from 0.19208
32682/32682 [==============================] - 7s 221us/sample - loss: 0.1926 - categorical_accuracy: 0.9411 - val_loss: 0.2008 - val_categorical_accuracy: 0.9412
Epoch 11/100
32480/32682 [============================&gt;.] - ETA: 0s - loss: 0.1795 - categorical_accuracy: 0.9464
Epoch 00011: val_loss improved from 0.19208 to 0.18063, saving model to t_weights_0
32682/32682 [==============================] - 7s 222us/sample - loss: 0.1794 - categorical_accuracy: 0.9464 - val_loss: 0.1806 - val_categorical_accuracy: 0.9491
Epoch 12/100
32480/32682 [============================&gt;.] - ETA: 0s - loss: 0.1776 - categorical_accuracy: 0.9479
Epoch 00012: val_loss improved from 0.18063 to 0.17917, saving model to t_weights_0
32682/32682 [==============================] - 7s 206us/sample - loss: 0.1774 - categorical_accuracy: 0.9479 - val_loss: 0.1792 - val_categorical_accuracy: 0.9493
Epoch 13/100
32672/32682 [============================&gt;.] - ETA: 0s - loss: 0.1638 - categorical_accuracy: 0.9529
Epoch 00013: val_loss did not improve from 0.17917
32682/32682 [==============================] - 7s 219us/sample - loss: 0.1638 - categorical_accuracy: 0.9529 - val_loss: 0.1803 - val_categorical_accuracy: 0.9498
Epoch 14/100
32576/32682 [============================&gt;.] - ETA: 0s - loss: 0.1604 - categorical_accuracy: 0.9530
Epoch 00014: val_loss did not improve from 0.17917
32682/32682 [==============================] - 7s 219us/sample - loss: 0.1603 - categorical_accuracy: 0.9529 - val_loss: 0.1834 - val_categorical_accuracy: 0.9508
Epoch 15/100
32544/32682 [============================&gt;.] - ETA: 0s - loss: 0.1577 - categorical_accuracy: 0.9538
Epoch 00015: val_loss improved from 0.17917 to 0.17137, saving model to t_weights_0
32682/32682 [==============================] - 7s 217us/sample - loss: 0.1576 - categorical_accuracy: 0.9539 - val_loss: 0.1714 - val_categorical_accuracy: 0.9520
Epoch 16/100
32576/32682 [============================&gt;.] - ETA: 0s - loss: 0.1544 - categorical_accuracy: 0.9553
Epoch 00016: val_loss did not improve from 0.17137
32682/32682 [==============================] - 7s 221us/sample - loss: 0.1544 - categorical_accuracy: 0.9553 - val_loss: 0.1770 - val_categorical_accuracy: 0.9515
Epoch 17/100
32448/32682 [============================&gt;.] - ETA: 0s - loss: 0.1472 - categorical_accuracy: 0.9581
Epoch 00017: val_loss improved from 0.17137 to 0.17089, saving model to t_weights_0
32682/32682 [==============================] - 7s 222us/sample - loss: 0.1471 - categorical_accuracy: 0.9580 - val_loss: 0.1709 - val_categorical_accuracy: 0.9535
Epoch 18/100
32576/32682 [============================&gt;.] - ETA: 0s - loss: 0.1414 - categorical_accuracy: 0.9587
Epoch 00018: val_loss improved from 0.17089 to 0.16690, saving model to t_weights_0
32682/32682 [==============================] - 7s 222us/sample - loss: 0.1416 - categorical_accuracy: 0.9587 - val_loss: 0.1669 - val_categorical_accuracy: 0.9545
Epoch 19/100
32448/32682 [============================&gt;.] - ETA: 0s - loss: 0.1374 - categorical_accuracy: 0.9612
Epoch 00019: val_loss did not improve from 0.16690
32682/32682 [==============================] - 7s 220us/sample - loss: 0.1373 - categorical_accuracy: 0.9612 - val_loss: 0.1765 - val_categorical_accuracy: 0.9537
Epoch 20/100
32576/32682 [============================&gt;.] - ETA: 0s - loss: 0.1350 - categorical_accuracy: 0.9625
Epoch 00020: val_loss improved from 0.16690 to 0.16369, saving model to t_weights_0
32682/32682 [==============================] - 7s 221us/sample - loss: 0.1347 - categorical_accuracy: 0.9625 - val_loss: 0.1637 - val_categorical_accuracy: 0.9547
Epoch 21/100
32480/32682 [============================&gt;.] - ETA: 0s - loss: 0.1327 - categorical_accuracy: 0.9629
Epoch 00021: val_loss did not improve from 0.16369
32682/32682 [==============================] - 7s 219us/sample - loss: 0.1326 - categorical_accuracy: 0.9629 - val_loss: 0.1816 - val_categorical_accuracy: 0.9530
Epoch 22/100
32640/32682 [============================&gt;.] - ETA: 0s - loss: 0.1270 - categorical_accuracy: 0.9646
Epoch 00022: val_loss did not improve from 0.16369
32682/32682 [==============================] - 7s 219us/sample - loss: 0.1270 - categorical_accuracy: 0.9646 - val_loss: 0.1725 - val_categorical_accuracy: 0.9545
Epoch 23/100
32480/32682 [============================&gt;.] - ETA: 0s - loss: 0.1243 - categorical_accuracy: 0.9658
Epoch 00023: val_loss did not improve from 0.16369
32682/32682 [==============================] - 7s 211us/sample - loss: 0.1244 - categorical_accuracy: 0.9657 - val_loss: 0.1656 - val_categorical_accuracy: 0.9535
Epoch 24/100
32576/32682 [============================&gt;.] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.9671
Epoch 00024: val_loss did not improve from 0.16369
32682/32682 [==============================] - 7s 219us/sample - loss: 0.1213 - categorical_accuracy: 0.9671 - val_loss: 0.1687 - val_categorical_accuracy: 0.9554
Epoch 25/100
32448/32682 [============================&gt;.] - ETA: 0s - loss: 0.1183 - categorical_accuracy: 0.9683
Epoch 00025: val_loss did not improve from 0.16369
32682/32682 [==============================] - 7s 220us/sample - loss: 0.1180 - categorical_accuracy: 0.9683 - val_loss: 0.1752 - val_categorical_accuracy: 0.9569
0.9554468 0.7504081632653061


nrx: 25 - real: 4 
Train on 39923 samples, validate on 4990 samples
Epoch 1/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 1.0823 - categorical_accuracy: 0.5550
Epoch 00001: val_loss improved from inf to 0.63917, saving model to t_weights_0
39923/39923 [==============================] - 9s 233us/sample - loss: 1.0816 - categorical_accuracy: 0.5552 - val_loss: 0.6392 - val_categorical_accuracy: 0.7307
Epoch 2/100
39712/39923 [============================&gt;.] - ETA: 0s - loss: 0.5854 - categorical_accuracy: 0.7728
Epoch 00002: val_loss improved from 0.63917 to 0.40254, saving model to t_weights_0
39923/39923 [==============================] - 9s 224us/sample - loss: 0.5854 - categorical_accuracy: 0.7728 - val_loss: 0.4025 - val_categorical_accuracy: 0.8577
Epoch 3/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.3954 - categorical_accuracy: 0.8683
Epoch 00003: val_loss improved from 0.40254 to 0.26759, saving model to t_weights_0
39923/39923 [==============================] - 9s 221us/sample - loss: 0.3952 - categorical_accuracy: 0.8682 - val_loss: 0.2676 - val_categorical_accuracy: 0.9160
Epoch 4/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.3085 - categorical_accuracy: 0.9046
Epoch 00004: val_loss improved from 0.26759 to 0.22845, saving model to t_weights_0
39923/39923 [==============================] - 9s 225us/sample - loss: 0.3084 - categorical_accuracy: 0.9046 - val_loss: 0.2284 - val_categorical_accuracy: 0.9267
Epoch 5/100
39712/39923 [============================&gt;.] - ETA: 0s - loss: 0.2647 - categorical_accuracy: 0.9171
Epoch 00005: val_loss improved from 0.22845 to 0.21553, saving model to t_weights_0
39923/39923 [==============================] - 9s 218us/sample - loss: 0.2648 - categorical_accuracy: 0.9171 - val_loss: 0.2155 - val_categorical_accuracy: 0.9277
Epoch 6/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.2391 - categorical_accuracy: 0.9262
Epoch 00006: val_loss improved from 0.21553 to 0.20012, saving model to t_weights_0
39923/39923 [==============================] - 9s 222us/sample - loss: 0.2391 - categorical_accuracy: 0.9262 - val_loss: 0.2001 - val_categorical_accuracy: 0.9369
Epoch 7/100
39840/39923 [============================&gt;.] - ETA: 0s - loss: 0.2205 - categorical_accuracy: 0.9319
Epoch 00007: val_loss improved from 0.20012 to 0.18722, saving model to t_weights_0
39923/39923 [==============================] - 9s 225us/sample - loss: 0.2205 - categorical_accuracy: 0.9318 - val_loss: 0.1872 - val_categorical_accuracy: 0.9405
Epoch 8/100
39744/39923 [============================&gt;.] - ETA: 0s - loss: 0.2034 - categorical_accuracy: 0.9383
Epoch 00008: val_loss improved from 0.18722 to 0.18170, saving model to t_weights_0
39923/39923 [==============================] - 9s 223us/sample - loss: 0.2032 - categorical_accuracy: 0.9385 - val_loss: 0.1817 - val_categorical_accuracy: 0.9459
Epoch 9/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.1914 - categorical_accuracy: 0.9426
Epoch 00009: val_loss improved from 0.18170 to 0.17948, saving model to t_weights_0
39923/39923 [==============================] - 9s 224us/sample - loss: 0.1915 - categorical_accuracy: 0.9426 - val_loss: 0.1795 - val_categorical_accuracy: 0.9437
Epoch 10/100
39744/39923 [============================&gt;.] - ETA: 0s - loss: 0.1866 - categorical_accuracy: 0.9440
Epoch 00010: val_loss improved from 0.17948 to 0.17759, saving model to t_weights_0
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1866 - categorical_accuracy: 0.9440 - val_loss: 0.1776 - val_categorical_accuracy: 0.9463
Epoch 11/100
39776/39923 [============================&gt;.] - ETA: 0s - loss: 0.1742 - categorical_accuracy: 0.9481
Epoch 00011: val_loss improved from 0.17759 to 0.17163, saving model to t_weights_0
39923/39923 [==============================] - 9s 223us/sample - loss: 0.1741 - categorical_accuracy: 0.9482 - val_loss: 0.1716 - val_categorical_accuracy: 0.9503
Epoch 12/100
39712/39923 [============================&gt;.] - ETA: 0s - loss: 0.1676 - categorical_accuracy: 0.9507
Epoch 00012: val_loss did not improve from 0.17163
39923/39923 [==============================] - 9s 218us/sample - loss: 0.1677 - categorical_accuracy: 0.9507 - val_loss: 0.1775 - val_categorical_accuracy: 0.9467
Epoch 13/100
39744/39923 [============================&gt;.] - ETA: 0s - loss: 0.1608 - categorical_accuracy: 0.9526
Epoch 00013: val_loss improved from 0.17163 to 0.16614, saving model to t_weights_0
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1608 - categorical_accuracy: 0.9526 - val_loss: 0.1661 - val_categorical_accuracy: 0.9523
Epoch 14/100
39680/39923 [============================&gt;.] - ETA: 0s - loss: 0.1572 - categorical_accuracy: 0.9545
Epoch 00014: val_loss did not improve from 0.16614
39923/39923 [==============================] - 9s 223us/sample - loss: 0.1571 - categorical_accuracy: 0.9545 - val_loss: 0.1749 - val_categorical_accuracy: 0.9505
Epoch 15/100
39744/39923 [============================&gt;.] - ETA: 0s - loss: 0.1512 - categorical_accuracy: 0.9560
Epoch 00015: val_loss did not improve from 0.16614
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1515 - categorical_accuracy: 0.9559 - val_loss: 0.1676 - val_categorical_accuracy: 0.9513
Epoch 16/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.1441 - categorical_accuracy: 0.9592
Epoch 00016: val_loss improved from 0.16614 to 0.16536, saving model to t_weights_0
39923/39923 [==============================] - 9s 224us/sample - loss: 0.1441 - categorical_accuracy: 0.9592 - val_loss: 0.1654 - val_categorical_accuracy: 0.9531
Epoch 17/100
39680/39923 [============================&gt;.] - ETA: 0s - loss: 0.1413 - categorical_accuracy: 0.9602
Epoch 00017: val_loss improved from 0.16536 to 0.16126, saving model to t_weights_0
39923/39923 [==============================] - 9s 223us/sample - loss: 0.1411 - categorical_accuracy: 0.9603 - val_loss: 0.1613 - val_categorical_accuracy: 0.9565
Epoch 18/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.1371 - categorical_accuracy: 0.9622
Epoch 00018: val_loss improved from 0.16126 to 0.16119, saving model to t_weights_0
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1371 - categorical_accuracy: 0.9622 - val_loss: 0.1612 - val_categorical_accuracy: 0.9539
Epoch 19/100
39712/39923 [============================&gt;.] - ETA: 0s - loss: 0.1314 - categorical_accuracy: 0.9634
Epoch 00019: val_loss improved from 0.16119 to 0.14931, saving model to t_weights_0
39923/39923 [==============================] - 9s 217us/sample - loss: 0.1315 - categorical_accuracy: 0.9633 - val_loss: 0.1493 - val_categorical_accuracy: 0.9585
Epoch 20/100
39872/39923 [============================&gt;.] - ETA: 0s - loss: 0.1275 - categorical_accuracy: 0.9650
Epoch 00020: val_loss did not improve from 0.14931
39923/39923 [==============================] - 9s 223us/sample - loss: 0.1274 - categorical_accuracy: 0.9651 - val_loss: 0.1534 - val_categorical_accuracy: 0.9561
Epoch 21/100
39904/39923 [============================&gt;.] - ETA: 0s - loss: 0.1235 - categorical_accuracy: 0.9664
Epoch 00021: val_loss did not improve from 0.14931
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1234 - categorical_accuracy: 0.9664 - val_loss: 0.1662 - val_categorical_accuracy: 0.9557
Epoch 22/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.1196 - categorical_accuracy: 0.9673
Epoch 00022: val_loss did not improve from 0.14931
39923/39923 [==============================] - 9s 221us/sample - loss: 0.1195 - categorical_accuracy: 0.9674 - val_loss: 0.1529 - val_categorical_accuracy: 0.9567
Epoch 23/100
39744/39923 [============================&gt;.] - ETA: 0s - loss: 0.1204 - categorical_accuracy: 0.9671
Epoch 00023: val_loss did not improve from 0.14931
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1204 - categorical_accuracy: 0.9671 - val_loss: 0.1636 - val_categorical_accuracy: 0.9567
Epoch 24/100
39808/39923 [============================&gt;.] - ETA: 0s - loss: 0.1149 - categorical_accuracy: 0.9692
Epoch 00024: val_loss did not improve from 0.14931
39923/39923 [==============================] - 9s 222us/sample - loss: 0.1149 - categorical_accuracy: 0.9692 - val_loss: 0.1518 - val_categorical_accuracy: 0.9585
0.9597194 0.7018367346938775
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nrx_list</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[11]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[0, 5, 10, 15, 20, 25]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nrx_list</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">smTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">smTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">capsize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nrx_list</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">capsize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Same Rx(s)&#39;</span><span class="p">,</span><span class="s1">&#39;Diff. Rx&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;N Train Rx&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Class. Accuracy&#39;</span><span class="p">)</span>
<span class="c1">#plt.xticks(range(0,len(nrx_list),2))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[0.32337888499973955, 0.5424953835515883, 0.672989333323014, 0.7467292965345177, 0.7870676739712519, 0.7908500635310862]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tx_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nrx_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">real_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smTest_results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dfTest_results</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dfTestBal_results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;1-10&#39;, &#39;11-1&#39;, &#39;14-10&#39;, &#39;14-7&#39;, &#39;17-11&#39;, &#39;20-15&#39;, &#39;20-19&#39;, &#39;7-11&#39;, &#39;7-14&#39;, &#39;8-20&#39;]
[0, 5, 10, 15, 20, 25]
[0, 1, 2, 3, 4]
[[0.93, 0.8940678, 0.93426573, 0.9349855, 0.9390813, 0.9486974], [1.0, 0.9813333, 0.98435974, 0.97603416, 0.95185554, 0.9362086], [0.995, 0.9895105, 0.9354078, 0.9435563, 0.94364804, 0.94269794], [0.98888886, 0.98706895, 0.9722222, 0.95170176, 0.9557984, 0.9546449], [0.985, 0.9413764, 0.9355586, 0.9563277, 0.9554468, 0.9597194]]
[[0.3165, 0.5837, 0.767, 0.8163, 0.8418, 0.8252], [0.3539, 0.6334, 0.6731, 0.8027, 0.8417, 0.8553], [0.3097758405977584, 0.5153590701535907, 0.7284142797841427, 0.7468866749688667, 0.7787463677874636, 0.8270029057700291], [0.28977980889073535, 0.44869131699210635, 0.5234732031574574, 0.6456169505608641, 0.7226838388034899, 0.7449106771915247], [0.3469387755102041, 0.5313265306122449, 0.6729591836734694, 0.7221428571428572, 0.7504081632653061, 0.7018367346938775]]
[[0.3165, 0.5837, 0.767, 0.8163, 0.8418, 0.8252], [0.3539, 0.6334, 0.6731, 0.8027, 0.8417, 0.8553], [0.312125, 0.514, 0.72475, 0.742125, 0.776, 0.821125], [0.28694267515923566, 0.43471337579617836, 0.5210191082802548, 0.639171974522293, 0.7125796178343949, 0.745063694267516], [0.336875, 0.534375, 0.67575, 0.725875, 0.75375, 0.708]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">rx_list_real</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[&#39;19-20&#39;, &#39;24-13&#39;, &#39;19-2&#39;, &#39;1-20&#39;, &#39;20-20&#39;, &#39;20-1&#39;, &#39;7-7&#39;, &#39;3-19&#39;, &#39;23-6&#39;, &#39;2-19&#39;, &#39;24-5&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;24-6&#39;, &#39;24-16&#39;, &#39;1-19&#39;, &#39;8-8&#39;, &#39;18-19&#39;, &#39;13-7&#39;, &#39;23-3&#39;, &#39;8-14&#39;, &#39;23-5&#39;, &#39;19-19&#39;, &#39;18-2&#39;, &#39;7-14&#39;, &#39;13-14&#39;, &#39;1-1&#39;, &#39;23-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;], [&#39;1-1&#39;, &#39;23-1&#39;, &#39;24-6&#39;, &#39;8-8&#39;, &#39;1-19&#39;, &#39;23-3&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;19-19&#39;, &#39;13-14&#39;, &#39;23-6&#39;, &#39;7-7&#39;, &#39;19-1&#39;, &#39;20-1&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;8-14&#39;, &#39;19-2&#39;, &#39;14-7&#39;, &#39;1-20&#39;, &#39;13-7&#39;, &#39;24-5&#39;, &#39;18-2&#39;, &#39;2-19&#39;, &#39;24-13&#39;, &#39;19-20&#39;, &#39;3-19&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;2-1&#39;, &#39;23-7&#39;, &#39;18-19&#39;], [&#39;24-5&#39;, &#39;23-7&#39;, &#39;18-19&#39;, &#39;23-3&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;2-1&#39;, &#39;13-7&#39;, &#39;19-19&#39;, &#39;19-2&#39;, &#39;18-2&#39;, &#39;1-20&#39;, &#39;20-1&#39;, &#39;24-16&#39;, &#39;3-19&#39;, &#39;1-19&#39;, &#39;24-13&#39;, &#39;23-6&#39;, &#39;19-1&#39;, &#39;8-7&#39;, &#39;20-19&#39;, &#39;1-1&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;7-7&#39;, &#39;2-19&#39;, &#39;23-5&#39;, &#39;8-8&#39;, &#39;19-20&#39;, &#39;13-14&#39;, &#39;7-14&#39;, &#39;23-1&#39;], [&#39;1-20&#39;, &#39;1-19&#39;, &#39;20-19&#39;, &#39;23-7&#39;, &#39;2-1&#39;, &#39;20-1&#39;, &#39;19-19&#39;, &#39;14-7&#39;, &#39;23-1&#39;, &#39;3-19&#39;, &#39;8-8&#39;, &#39;7-7&#39;, &#39;13-7&#39;, &#39;20-20&#39;, &#39;24-16&#39;, &#39;18-2&#39;, &#39;8-7&#39;, &#39;23-5&#39;, &#39;7-14&#39;, &#39;18-19&#39;, &#39;24-6&#39;, &#39;19-1&#39;, &#39;13-14&#39;, &#39;2-19&#39;, &#39;19-20&#39;, &#39;24-5&#39;, &#39;23-3&#39;, &#39;19-2&#39;, &#39;8-14&#39;, &#39;23-6&#39;, &#39;24-13&#39;, &#39;1-1&#39;], [&#39;18-19&#39;, &#39;20-1&#39;, &#39;13-14&#39;, &#39;18-2&#39;, &#39;14-7&#39;, &#39;20-20&#39;, &#39;13-7&#39;, &#39;19-20&#39;, &#39;2-19&#39;, &#39;19-19&#39;, &#39;19-1&#39;, &#39;1-20&#39;, &#39;24-5&#39;, &#39;20-19&#39;, &#39;8-7&#39;, &#39;23-1&#39;, &#39;7-7&#39;, &#39;8-8&#39;, &#39;2-1&#39;, &#39;1-19&#39;, &#39;3-19&#39;, &#39;23-3&#39;, &#39;23-6&#39;, &#39;23-5&#39;, &#39;24-6&#39;, &#39;8-14&#39;, &#39;24-16&#39;, &#39;7-14&#39;, &#39;1-1&#39;, &#39;19-2&#39;, &#39;24-13&#39;, &#39;23-7&#39;]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
